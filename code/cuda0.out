nohup: ignoring input
=============================================
Start Training: GPU=0, LR=1e-5, gamma=0.99, tau=0.1
Task Number: 500, Process Number: 16
Model Directory: ../models/_20250328_1118_lr_1e-5_gamma_0.99_tau_0.1_bmm_0_16_500
=============================================
*** Loading map ***
Map size: 21x35 with 352 endpoints and 0 home stations.
Done! (0 s)
*** PreProcessing map ***
*** Loading map ***
Map size: 21x35 with 352 endpoints and 0 home stations.
Done! (0 s)
*** PreProcessing map ***
*** Loading map ***
Map size: 21x35 with 352 endpoints and 0 home stations.
Done! (0 s)
*** PreProcessing map ***
*** Loading map ***
Map size: 21x35 with 352 endpoints and 0 home stations.
Done! (0 s)
*** PreProcessing map ***
Done! (0 s)
*** Loading map ***
Map size: 21x35 with 352 endpoints and 0 home stations.
Done! (0 s)
*** PreProcessing map ***
Done! (0 s)
*** Loading map ***
Done! (0 s)
Map size: 21x35 with 352 endpoints and 0 home stations.
Done! (0 s)
*** PreProcessing map ***
Done! (0 s)
*** Loading map ***
Map size: 21x35 with 352 endpoints and 0 home stations.
Done! (0 s)
*** PreProcessing map ***
*** Loading map ***
Map size: 21x35 with 352 endpoints and 0 home stations.
Done! (0 s)
*** PreProcessing map ***
*** Loading map ***
Map size: 21x35 with 352 endpoints and 0 home stations.
Done! (0 s)
*** PreProcessing map ***
*** Loading map ***
Map size: 21x35 with 352 endpoints and 0 home stations.
Done! (0 s)
*** PreProcessing map ***
Done! (0 s)
*** Loading map ***
Map size: 21x35 with 352 endpoints and 0 home stations.
Done! (0 s)
*** PreProcessing map ***
*** Loading map ***
*** Loading map ***
Map size: 21x35 with 352 endpoints and 0 home stations.
Done! (0 s)
*** PreProcessing map ***
Map size: 21x35 with 352 endpoints and 0 home stations.
Done! (0 s)
*** PreProcessing map ***
Done! (0 s)
*** Loading map ***
Map size: 21x35 with 352 endpoints and 0 home stations.
Done! (0 s)
*** PreProcessing map ***
Done! (0 s)
Done! (0 s)
*** Loading map ***
Map size: 21x35 with 352 endpoints and 0 home stations.
Done! (0 s)
*** PreProcessing map ***
Done! (0 s)
Done! (0 s)
Done! (0 s)
Done! (0 s)
Done! (0 s)
*** Loading map ***
Map size: 21x35 with 352 endpoints and 0 home stations.
Done! (0 s)
*** PreProcessing map ***
Done! (0 s)
Done! (0 s)
Done! (0 s)
/localhome/yya305/miniconda3/envs/MAPD_RL/lib/python3.11/site-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(f"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}")
id: 52 reward: -0.023351648351648352 service_time: 17 s_time: 17 penalty: 0 agent_num: 13 done: False
______________________
id: 51 reward: -0.03333333333333333 service_time: 28 s_time: 28 penalty: 0 agent_num: 15 done: False
______________________
id: 43 reward: -0.012276785714285714 service_time: 11 s_time: 11 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: -0.02976190476190476 service_time: 25 s_time: 25 penalty: 0 agent_num: 15 done: False
______________________
id: 42 reward: -0.021577380952380952 service_time: 29 s_time: 29 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: -0.007554945054945055 service_time: 11 s_time: 11 penalty: 0 agent_num: 26 done: False
______________________
id: 47 reward: -0.03273809523809524 service_time: 44 s_time: 44 penalty: 0 agent_num: 24 done: False
______________________
id: 53 reward: -0.017080745341614908 service_time: 22 s_time: 22 penalty: 0 agent_num: 23 done: False
______________________
id: 50 reward: -0.0467687074829932 service_time: 55 s_time: 55 penalty: 0 agent_num: 21 done: False
______________________
id: 49 reward: -0.014668367346938776 service_time: 23 s_time: 23 penalty: 0 agent_num: 28 done: False
______________________
id: 41 reward: -0.015756302521008403 service_time: 30 s_time: 30 penalty: 0 agent_num: 34 done: False
______________________
id: 46 reward: -0.00916988416988417 service_time: 19 s_time: 19 penalty: 0 agent_num: 37 done: False
______________________
id: 48 reward: -0.010714285714285714 service_time: 18 s_time: 18 penalty: 0 agent_num: 30 done: False
______________________
id: 55 reward: -0.008928571428571428 service_time: 16 s_time: 16 penalty: 0 agent_num: 32 done: False
______________________
id: 54 reward: -0.007988721804511278 service_time: 17 s_time: 17 penalty: 0 agent_num: 38 done: False
______________________
id: 44 reward: -0.01830357142857143 service_time: 41 s_time: 41 penalty: 0 agent_num: 40 done: False
______________________
Using cuda device
Step:  0
Pretraining Loss:  tensor(0.0243, device='cuda:0', grad_fn=<MeanBackward0>)
id: 51 reward: -0.03571428571428571 service_time: 58 s_time: 30 penalty: 0 agent_num: 15 done: False
______________________
id: 43 reward: -0.041294642857142856 service_time: 48 s_time: 37 penalty: 0 agent_num: 16 done: False
______________________
id: 52 reward: -0.020604395604395604 service_time: 32 s_time: 15 penalty: 0 agent_num: 13 done: False
______________________
id: 40 reward: -0.03333333333333333 service_time: 53 s_time: 28 penalty: 0 agent_num: 15 done: False
______________________
id: 42 reward: -0.026785714285714284 service_time: 65 s_time: 36 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: -0.011675824175824176 service_time: 28 s_time: 17 penalty: 0 agent_num: 26 done: False
______________________
id: 48 reward: -0.013095238095238096 service_time: 40 s_time: 22 penalty: 0 agent_num: 30 done: False
______________________
id: 47 reward: -0.023809523809523808 service_time: 76 s_time: 32 penalty: 0 agent_num: 24 done: False
______________________
id: 53 reward: -0.031055900621118012 service_time: 62 s_time: 40 penalty: 0 agent_num: 23 done: False
______________________
id: 49 reward: -0.017857142857142856 service_time: 51 s_time: 28 penalty: 0 agent_num: 28 done: False
______________________
id: 46 reward: -0.0019305019305019305 service_time: 23 s_time: 4 penalty: 0 agent_num: 37 done: False
______________________
id: 55 reward: -0.00390625 service_time: 23 s_time: 7 penalty: 0 agent_num: 32 done: False
______________________
id: 41 reward: -0.007352941176470588 service_time: 44 s_time: 14 penalty: 0 agent_num: 34 done: False
______________________
id: 44 reward: -0.022767857142857142 service_time: 92 s_time: 51 penalty: 0 agent_num: 40 done: False
______________________
id: 54 reward: -0.011278195488721804 service_time: 41 s_time: 24 penalty: 0 agent_num: 38 done: False
______________________
id: 50 reward: -0.02806122448979592 service_time: 88 s_time: 33 penalty: 0 agent_num: 21 done: False
______________________
Step:  16
Pretraining Loss:  tensor(0.0315, device='cuda:0', grad_fn=<MeanBackward0>)
id: 51 reward: -0.013095238095238096 service_time: 69 s_time: 11 penalty: 0 agent_num: 15 done: False
______________________
id: 43 reward: -0.05022321428571429 service_time: 93 s_time: 45 penalty: 0 agent_num: 16 done: False
______________________
id: 52 reward: -0.0260989010989011 service_time: 51 s_time: 19 penalty: 0 agent_num: 13 done: False
______________________
id: 40 reward: -0.02023809523809524 service_time: 70 s_time: 17 penalty: 0 agent_num: 15 done: False
______________________
id: 42 reward: -0.022321428571428572 service_time: 95 s_time: 30 penalty: 0 agent_num: 24 done: False
______________________
id: 48 reward: -0.019642857142857142 service_time: 73 s_time: 33 penalty: 0 agent_num: 30 done: False
______________________
id: 53 reward: -0.017857142857142856 service_time: 85 s_time: 23 penalty: 0 agent_num: 23 done: False
______________________
id: 45 reward: -0.020604395604395604 service_time: 58 s_time: 30 penalty: 0 agent_num: 26 done: False
______________________
id: 47 reward: -0.011904761904761904 service_time: 92 s_time: 16 penalty: 0 agent_num: 24 done: False
______________________
id: 46 reward: 0.0 service_time: 23 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 49 reward: -0.01020408163265306 service_time: 67 s_time: 16 penalty: 0 agent_num: 28 done: False
______________________
id: 54 reward: -0.011748120300751879 service_time: 66 s_time: 25 penalty: 0 agent_num: 38 done: False
______________________
id: 55 reward: -0.020089285714285716 service_time: 59 s_time: 36 penalty: 0 agent_num: 32 done: False
______________________
id: 50 reward: -0.025510204081632654 service_time: 118 s_time: 30 penalty: 0 agent_num: 21 done: False
______________________
id: 41 reward: -0.017857142857142856 service_time: 78 s_time: 34 penalty: 0 agent_num: 34 done: False
______________________
id: 44 reward: -0.016964285714285713 service_time: 130 s_time: 38 penalty: 0 agent_num: 40 done: False
______________________
Step:  32
Pretraining Loss:  tensor(0.0355, device='cuda:0', grad_fn=<MeanBackward0>)
id: 40 reward: -0.02023809523809524 service_time: 87 s_time: 17 penalty: 0 agent_num: 15 done: False
______________________
id: 43 reward: -0.006696428571428571 service_time: 99 s_time: 6 penalty: 0 agent_num: 16 done: False
______________________
id: 51 reward: -0.01904761904761905 service_time: 85 s_time: 16 penalty: 0 agent_num: 15 done: False
______________________
id: 52 reward: -0.03708791208791209 service_time: 78 s_time: 27 penalty: 0 agent_num: 13 done: False
______________________
id: 42 reward: 0.0 service_time: 95 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: 0.0 service_time: 58 s_time: 0 penalty: 0 agent_num: 26 done: False
______________________
id: 47 reward: -0.011904761904761904 service_time: 108 s_time: 16 penalty: 0 agent_num: 24 done: False
______________________
id: 53 reward: -0.024844720496894408 service_time: 117 s_time: 32 penalty: 0 agent_num: 23 done: False
______________________
id: 55 reward: -0.017857142857142856 service_time: 91 s_time: 32 penalty: 0 agent_num: 32 done: False
______________________
id: 46 reward: -0.018822393822393823 service_time: 62 s_time: 39 penalty: 0 agent_num: 37 done: False
______________________
id: 49 reward: -0.005739795918367347 service_time: 76 s_time: 9 penalty: 0 agent_num: 28 done: False
______________________
id: 54 reward: -0.011278195488721804 service_time: 90 s_time: 24 penalty: 0 agent_num: 38 done: False
______________________
id: 50 reward: -0.012755102040816327 service_time: 133 s_time: 15 penalty: 0 agent_num: 21 done: False
______________________
id: 48 reward: -0.02142857142857143 service_time: 109 s_time: 36 penalty: 0 agent_num: 30 done: False
______________________
id: 41 reward: -0.01365546218487395 service_time: 104 s_time: 26 penalty: 0 agent_num: 34 done: False
______________________
id: 44 reward: -0.017857142857142856 service_time: 170 s_time: 40 penalty: 0 agent_num: 40 done: False
______________________
Step:  48
Pretraining Loss:  tensor(0.0383, device='cuda:0', grad_fn=<MeanBackward0>)
id: 40 reward: -0.03214285714285714 service_time: 114 s_time: 27 penalty: 0 agent_num: 15 done: False
______________________
id: 51 reward: -0.036904761904761905 service_time: 116 s_time: 31 penalty: 0 agent_num: 15 done: False
______________________
id: 43 reward: -0.0390625 service_time: 134 s_time: 35 penalty: 0 agent_num: 16 done: False
______________________
id: 42 reward: -0.03125 service_time: 137 s_time: 42 penalty: 0 agent_num: 24 done: False
______________________
id: 47 reward: -0.027529761904761904 service_time: 145 s_time: 37 penalty: 0 agent_num: 24 done: False
______________________
id: 52 reward: -0.03571428571428571 service_time: 104 s_time: 26 penalty: 0 agent_num: 13 done: False
______________________
id: 45 reward: -0.028846153846153848 service_time: 100 s_time: 42 penalty: 0 agent_num: 26 done: False
______________________
id: 53 reward: -0.004658385093167702 service_time: 123 s_time: 6 penalty: 0 agent_num: 23 done: False
______________________
id: 49 reward: -0.01211734693877551 service_time: 95 s_time: 19 penalty: 0 agent_num: 28 done: False
______________________
id: 46 reward: -0.006274131274131274 service_time: 75 s_time: 13 penalty: 0 agent_num: 37 done: False
______________________
id: 48 reward: -0.004761904761904762 service_time: 117 s_time: 8 penalty: 0 agent_num: 30 done: False
______________________
id: 41 reward: -0.009978991596638655 service_time: 123 s_time: 19 penalty: 0 agent_num: 34 done: False
______________________
id: 55 reward: -0.010602678571428572 service_time: 110 s_time: 19 penalty: 0 agent_num: 32 done: False
______________________
id: 54 reward: -0.018796992481203006 service_time: 130 s_time: 40 penalty: 0 agent_num: 38 done: False
______________________
id: 50 reward: -0.027210884353741496 service_time: 165 s_time: 32 penalty: 0 agent_num: 21 done: False
______________________
id: 44 reward: -0.020089285714285716 service_time: 215 s_time: 45 penalty: 0 agent_num: 40 done: False
______________________
Step:  64
Pretraining Loss:  tensor(0.0384, device='cuda:0', grad_fn=<MeanBackward0>)
id: 51 reward: -0.05119047619047619 service_time: 159 s_time: 43 penalty: 0 agent_num: 15 done: False
______________________
id: 40 reward: -0.04285714285714286 service_time: 150 s_time: 36 penalty: 0 agent_num: 15 done: False
______________________
id: 52 reward: -0.034340659340659344 service_time: 129 s_time: 25 penalty: 0 agent_num: 13 done: False
______________________
id: 43 reward: -0.027901785714285716 service_time: 159 s_time: 25 penalty: 0 agent_num: 16 done: False
______________________
id: 42 reward: -0.012648809523809524 service_time: 154 s_time: 17 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: -0.018543956043956044 service_time: 127 s_time: 27 penalty: 0 agent_num: 26 done: False
______________________
id: 47 reward: -0.01488095238095238 service_time: 165 s_time: 20 penalty: 0 agent_num: 24 done: False
______________________
id: 53 reward: -0.024844720496894408 service_time: 155 s_time: 32 penalty: 0 agent_num: 23 done: False
______________________
id: 49 reward: -0.008928571428571428 service_time: 109 s_time: 14 penalty: 0 agent_num: 28 done: False
______________________
id: 46 reward: -0.016891891891891893 service_time: 110 s_time: 35 penalty: 0 agent_num: 37 done: False
______________________
id: 50 reward: 0.0 service_time: 165 s_time: 0 penalty: 0 agent_num: 21 done: False
______________________
id: 55 reward: -0.016741071428571428 service_time: 140 s_time: 30 penalty: 0 agent_num: 32 done: False
______________________
id: 41 reward: -0.015756302521008403 service_time: 153 s_time: 30 penalty: 0 agent_num: 34 done: False
______________________
id: 54 reward: -0.0018796992481203006 service_time: 134 s_time: 4 penalty: 0 agent_num: 38 done: False
______________________
id: 48 reward: -0.01011904761904762 service_time: 134 s_time: 17 penalty: 0 agent_num: 30 done: False
______________________
id: 44 reward: -0.00625 service_time: 229 s_time: 14 penalty: 0 agent_num: 40 done: False
______________________
Step:  80
Pretraining Loss:  tensor(0.0392, device='cuda:0', grad_fn=<MeanBackward0>)
id: 52 reward: -0.016483516483516484 service_time: 141 s_time: 12 penalty: 0 agent_num: 13 done: False
______________________
id: 40 reward: -0.02142857142857143 service_time: 168 s_time: 18 penalty: 0 agent_num: 15 done: False
______________________
id: 51 reward: -0.039285714285714285 service_time: 192 s_time: 33 penalty: 0 agent_num: 15 done: False
______________________
id: 43 reward: -0.0234375 service_time: 180 s_time: 21 penalty: 0 agent_num: 16 done: False
______________________
id: 47 reward: -0.019345238095238096 service_time: 191 s_time: 26 penalty: 0 agent_num: 24 done: False
______________________
id: 42 reward: -0.027529761904761904 service_time: 191 s_time: 37 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: -0.012362637362637362 service_time: 145 s_time: 18 penalty: 0 agent_num: 26 done: False
______________________
id: 49 reward: -0.015306122448979591 service_time: 133 s_time: 24 penalty: 0 agent_num: 28 done: False
______________________
id: 41 reward: -0.008403361344537815 service_time: 169 s_time: 16 penalty: 0 agent_num: 34 done: False
______________________
id: 53 reward: -0.013975155279503106 service_time: 173 s_time: 18 penalty: 0 agent_num: 23 done: False
______________________
id: 46 reward: -0.005791505791505791 service_time: 122 s_time: 12 penalty: 0 agent_num: 37 done: False
______________________
id: 54 reward: -0.010338345864661654 service_time: 156 s_time: 22 penalty: 0 agent_num: 38 done: False
______________________
id: 55 reward: -0.011160714285714286 service_time: 160 s_time: 20 penalty: 0 agent_num: 32 done: False
______________________
id: 48 reward: -0.024404761904761905 service_time: 175 s_time: 41 penalty: 0 agent_num: 30 done: False
______________________
id: 44 reward: -0.008035714285714285 service_time: 247 s_time: 18 penalty: 0 agent_num: 40 done: False
______________________
id: 50 reward: -0.10204081632653061 service_time: 285 s_time: 120 penalty: 0 agent_num: 21 done: False
______________________
Step:  96
Pretraining Loss:  tensor(0.0420, device='cuda:0', grad_fn=<MeanBackward0>)
id: 40 reward: 0.0 service_time: 168 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 43 reward: -0.025669642857142856 service_time: 203 s_time: 23 penalty: 0 agent_num: 16 done: False
______________________
id: 51 reward: -0.04404761904761905 service_time: 229 s_time: 37 penalty: 0 agent_num: 15 done: False
______________________
id: 52 reward: -0.05357142857142857 service_time: 180 s_time: 39 penalty: 0 agent_num: 13 done: False
______________________
id: 45 reward: -0.020604395604395604 service_time: 175 s_time: 30 penalty: 0 agent_num: 26 done: False
______________________
id: 42 reward: 0.0 service_time: 191 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 47 reward: -0.023809523809523808 service_time: 223 s_time: 32 penalty: 0 agent_num: 24 done: False
______________________
id: 46 reward: -0.02364864864864865 service_time: 171 s_time: 49 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: -0.013975155279503106 service_time: 191 s_time: 18 penalty: 0 agent_num: 23 done: False
______________________
id: 41 reward: -0.017331932773109245 service_time: 202 s_time: 33 penalty: 0 agent_num: 34 done: False
______________________
id: 49 reward: -0.007653061224489796 service_time: 145 s_time: 12 penalty: 0 agent_num: 28 done: False
______________________
id: 48 reward: -0.025595238095238095 service_time: 218 s_time: 43 penalty: 0 agent_num: 30 done: False
______________________
id: 55 reward: -0.012276785714285714 service_time: 182 s_time: 22 penalty: 0 agent_num: 32 done: False
______________________
id: 54 reward: 0.0 service_time: 156 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 44 reward: -0.009375 service_time: 268 s_time: 21 penalty: 0 agent_num: 40 done: False
______________________
id: 50 reward: -0.0467687074829932 service_time: 340 s_time: 55 penalty: 0 agent_num: 21 done: False
______________________
Step:  112
Pretraining Loss:  tensor(0.0406, device='cuda:0', grad_fn=<MeanBackward0>)
id: 52 reward: -0.03708791208791209 service_time: 207 s_time: 27 penalty: 0 agent_num: 13 done: False
______________________
id: 51 reward: -0.039285714285714285 service_time: 262 s_time: 33 penalty: 0 agent_num: 15 done: False
______________________
id: 40 reward: -0.07857142857142857 service_time: 234 s_time: 66 penalty: 0 agent_num: 15 done: False
______________________
id: 53 reward: -0.007763975155279503 service_time: 201 s_time: 10 penalty: 0 agent_num: 23 done: False
______________________
id: 47 reward: -0.011160714285714286 service_time: 238 s_time: 15 penalty: 0 agent_num: 24 done: False
______________________
id: 49 reward: -0.014668367346938776 service_time: 168 s_time: 23 penalty: 0 agent_num: 28 done: False
______________________
id: 41 reward: -0.011554621848739496 service_time: 224 s_time: 22 penalty: 0 agent_num: 34 done: False
______________________
id: 42 reward: -0.03571428571428571 service_time: 239 s_time: 48 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: -0.006181318681318681 service_time: 184 s_time: 9 penalty: 0 agent_num: 26 done: False
______________________
id: 48 reward: -0.013095238095238096 service_time: 240 s_time: 22 penalty: 0 agent_num: 30 done: False
______________________
id: 43 reward: -0.03459821428571429 service_time: 234 s_time: 31 penalty: 0 agent_num: 16 done: False
______________________
id: 54 reward: -0.01644736842105263 service_time: 191 s_time: 35 penalty: 0 agent_num: 38 done: False
______________________
id: 55 reward: -0.0005580357142857143 service_time: 183 s_time: 1 penalty: 0 agent_num: 32 done: False
______________________
id: 44 reward: -0.002232142857142857 service_time: 273 s_time: 5 penalty: 0 agent_num: 40 done: False
______________________
id: 46 reward: -0.014961389961389961 service_time: 202 s_time: 31 penalty: 0 agent_num: 37 done: False
______________________
id: 50 reward: -0.02040816326530612 service_time: 364 s_time: 24 penalty: 0 agent_num: 21 done: False
______________________
Step:  128
Pretraining Loss:  tensor(0.0433, device='cuda:0', grad_fn=<MeanBackward0>)
id: 51 reward: -0.02976190476190476 service_time: 287 s_time: 25 penalty: 0 agent_num: 15 done: False
______________________
id: 43 reward: -0.017857142857142856 service_time: 250 s_time: 16 penalty: 0 agent_num: 16 done: False
______________________
id: 52 reward: -0.061813186813186816 service_time: 252 s_time: 45 penalty: 0 agent_num: 13 done: False
______________________
id: 53 reward: 0.0 service_time: 201 s_time: 0 penalty: 0 agent_num: 23 done: False
______________________
id: 40 reward: -0.030952380952380953 service_time: 260 s_time: 26 penalty: 0 agent_num: 15 done: False
______________________
id: 42 reward: -0.01711309523809524 service_time: 262 s_time: 23 penalty: 0 agent_num: 24 done: False
______________________
id: 47 reward: -0.009672619047619048 service_time: 251 s_time: 13 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: 0.0 service_time: 184 s_time: 0 penalty: 0 agent_num: 26 done: False
______________________
id: 48 reward: -0.007142857142857143 service_time: 252 s_time: 12 penalty: 0 agent_num: 30 done: False
______________________
id: 49 reward: -0.011479591836734694 service_time: 186 s_time: 18 penalty: 0 agent_num: 28 done: False
______________________
id: 55 reward: -0.04352678571428571 service_time: 261 s_time: 78 penalty: 0 agent_num: 32 done: False
______________________
id: 46 reward: -0.0033783783783783786 service_time: 209 s_time: 7 penalty: 0 agent_num: 37 done: False
______________________
id: 41 reward: -0.014705882352941176 service_time: 252 s_time: 28 penalty: 0 agent_num: 34 done: False
______________________
id: 50 reward: -0.030612244897959183 service_time: 400 s_time: 36 penalty: 0 agent_num: 21 done: False
______________________
id: 54 reward: -0.017857142857142856 service_time: 229 s_time: 38 penalty: 0 agent_num: 38 done: False
______________________
id: 44 reward: -0.013839285714285714 service_time: 304 s_time: 31 penalty: 0 agent_num: 40 done: False
______________________
Step:  144
Pretraining Loss:  tensor(0.0506, device='cuda:0', grad_fn=<MeanBackward0>)
id: 52 reward: -0.059065934065934064 service_time: 295 s_time: 43 penalty: 0 agent_num: 13 done: False
______________________
id: 43 reward: -0.036830357142857144 service_time: 283 s_time: 33 penalty: 0 agent_num: 16 done: False
______________________
id: 51 reward: -0.025 service_time: 308 s_time: 21 penalty: 0 agent_num: 15 done: False
______________________
id: 47 reward: -0.021577380952380952 service_time: 280 s_time: 29 penalty: 0 agent_num: 24 done: False
______________________
id: 40 reward: -0.02261904761904762 service_time: 279 s_time: 19 penalty: 0 agent_num: 15 done: False
______________________
id: 45 reward: -0.032280219780219783 service_time: 231 s_time: 47 penalty: 0 agent_num: 26 done: False
______________________
id: 42 reward: -0.03050595238095238 service_time: 303 s_time: 41 penalty: 0 agent_num: 24 done: False
______________________
id: 53 reward: -0.06133540372670807 service_time: 280 s_time: 79 penalty: 0 agent_num: 23 done: False
______________________
id: 41 reward: -0.016281512605042018 service_time: 283 s_time: 31 penalty: 0 agent_num: 34 done: False
______________________
id: 49 reward: -0.03125 service_time: 235 s_time: 49 penalty: 0 agent_num: 28 done: False
______________________
id: 44 reward: -0.006696428571428571 service_time: 319 s_time: 15 penalty: 0 agent_num: 40 done: False
______________________
id: 48 reward: -0.017261904761904763 service_time: 281 s_time: 29 penalty: 0 agent_num: 30 done: False
______________________
id: 55 reward: 0.0011160714285714285 service_time: 259 s_time: -2 penalty: 0 agent_num: 32 done: False
______________________
id: 46 reward: 0.0 service_time: 209 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 54 reward: -0.01456766917293233 service_time: 260 s_time: 31 penalty: 0 agent_num: 38 done: False
______________________
id: 50 reward: -0.039965986394557826 service_time: 447 s_time: 47 penalty: 0 agent_num: 21 done: False
______________________
Step:  160
Pretraining Loss:  tensor(0.0522, device='cuda:0', grad_fn=<MeanBackward0>)
id: 52 reward: -0.034340659340659344 service_time: 320 s_time: 25 penalty: 0 agent_num: 13 done: False
______________________
id: 43 reward: -0.030133928571428572 service_time: 310 s_time: 27 penalty: 0 agent_num: 16 done: False
______________________
id: 53 reward: -0.026397515527950312 service_time: 314 s_time: 34 penalty: 0 agent_num: 23 done: False
______________________
id: 45 reward: -0.022664835164835164 service_time: 264 s_time: 33 penalty: 0 agent_num: 26 done: False
______________________
id: 40 reward: -0.02738095238095238 service_time: 302 s_time: 23 penalty: 0 agent_num: 15 done: False
______________________
id: 51 reward: -0.04404761904761905 service_time: 345 s_time: 37 penalty: 0 agent_num: 15 done: False
______________________
id: 42 reward: -0.024553571428571428 service_time: 336 s_time: 33 penalty: 0 agent_num: 24 done: False
______________________
id: 49 reward: 0.0 service_time: 235 s_time: 0 penalty: 0 agent_num: 28 done: False
______________________
id: 47 reward: -0.017857142857142856 service_time: 304 s_time: 24 penalty: 0 agent_num: 24 done: False
______________________
id: 48 reward: -0.017857142857142856 service_time: 311 s_time: 30 penalty: 0 agent_num: 30 done: False
______________________
id: 55 reward: -0.027901785714285716 service_time: 309 s_time: 50 penalty: 0 agent_num: 32 done: False
______________________
id: 41 reward: 0.0 service_time: 283 s_time: 0 penalty: 0 agent_num: 34 done: False
______________________
id: 46 reward: -0.02944015444015444 service_time: 270 s_time: 61 penalty: 0 agent_num: 37 done: False
______________________
id: 54 reward: -0.008928571428571428 service_time: 279 s_time: 19 penalty: 0 agent_num: 38 done: False
______________________
id: 50 reward: -0.026360544217687076 service_time: 478 s_time: 31 penalty: 0 agent_num: 21 done: False
______________________
id: 44 reward: -0.015178571428571428 service_time: 353 s_time: 34 penalty: 0 agent_num: 40 done: False
______________________
Step:  176
Pretraining Loss:  tensor(0.0516, device='cuda:0', grad_fn=<MeanBackward0>)
id: 52 reward: 0.0 service_time: 320 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 43 reward: -0.0390625 service_time: 345 s_time: 35 penalty: 0 agent_num: 16 done: False
______________________
id: 47 reward: -0.011904761904761904 service_time: 320 s_time: 16 penalty: 0 agent_num: 24 done: False
______________________
id: 41 reward: -0.026785714285714284 service_time: 334 s_time: 51 penalty: 0 agent_num: 34 done: False
______________________
id: 45 reward: -0.006868131868131868 service_time: 274 s_time: 10 penalty: 0 agent_num: 26 done: False
______________________
id: 53 reward: 0.0 service_time: 314 s_time: 0 penalty: 0 agent_num: 23 done: False
______________________
id: 55 reward: -0.021763392857142856 service_time: 348 s_time: 39 penalty: 0 agent_num: 32 done: False
______________________
id: 51 reward: -0.06190476190476191 service_time: 397 s_time: 52 penalty: 0 agent_num: 15 done: False
______________________
id: 42 reward: -0.022321428571428572 service_time: 366 s_time: 30 penalty: 0 agent_num: 24 done: False
______________________
id: 49 reward: -0.06441326530612244 service_time: 336 s_time: 101 penalty: 0 agent_num: 28 done: False
______________________
id: 48 reward: -0.007738095238095238 service_time: 324 s_time: 13 penalty: 0 agent_num: 30 done: False
______________________
id: 40 reward: -0.05714285714285714 service_time: 350 s_time: 48 penalty: 0 agent_num: 15 done: False
______________________
id: 44 reward: -0.01607142857142857 service_time: 389 s_time: 36 penalty: 0 agent_num: 40 done: False
______________________
id: 46 reward: -0.015926640926640926 service_time: 303 s_time: 33 penalty: 0 agent_num: 37 done: False
______________________
id: 54 reward: -0.009868421052631578 service_time: 300 s_time: 21 penalty: 0 agent_num: 38 done: False
______________________
id: 50 reward: -0.026360544217687076 service_time: 509 s_time: 31 penalty: 0 agent_num: 21 done: False
______________________
Step:  192
Pretraining Loss:  tensor(0.0573, device='cuda:0', grad_fn=<MeanBackward0>)
id: 52 reward: -0.0521978021978022 service_time: 358 s_time: 38 penalty: 0 agent_num: 13 done: False
______________________
id: 43 reward: 0.0011160714285714285 service_time: 344 s_time: -1 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: -0.02738095238095238 service_time: 373 s_time: 23 penalty: 0 agent_num: 15 done: False
______________________
id: 45 reward: -0.021291208791208792 service_time: 305 s_time: 31 penalty: 0 agent_num: 26 done: False
______________________
id: 51 reward: 0.0 service_time: 397 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 53 reward: -0.04891304347826087 service_time: 377 s_time: 63 penalty: 0 agent_num: 23 done: False
______________________
id: 42 reward: -0.023809523809523808 service_time: 398 s_time: 32 penalty: 0 agent_num: 24 done: False
______________________
id: 48 reward: 0.0 service_time: 324 s_time: 0 penalty: 0 agent_num: 30 done: False
______________________
id: 47 reward: -0.020833333333333332 service_time: 348 s_time: 28 penalty: 0 agent_num: 24 done: False
______________________
id: 49 reward: -0.016581632653061226 service_time: 362 s_time: 26 penalty: 0 agent_num: 28 done: False
______________________
id: 41 reward: -0.01207983193277311 service_time: 357 s_time: 23 penalty: 0 agent_num: 34 done: False
______________________
id: 46 reward: -0.004826254826254826 service_time: 313 s_time: 10 penalty: 0 agent_num: 37 done: False
______________________
id: 44 reward: -0.008035714285714285 service_time: 407 s_time: 18 penalty: 0 agent_num: 40 done: False
______________________
id: 55 reward: -0.020089285714285716 service_time: 384 s_time: 36 penalty: 0 agent_num: 32 done: False
______________________
id: 54 reward: -0.01456766917293233 service_time: 331 s_time: 31 penalty: 0 agent_num: 38 done: False
______________________
id: 50 reward: -0.036564625850340135 service_time: 552 s_time: 43 penalty: 0 agent_num: 21 done: False
______________________
Step:  208
Pretraining Loss:  tensor(0.0569, device='cuda:0', grad_fn=<MeanBackward0>)
id: 40 reward: -0.013095238095238096 service_time: 384 s_time: 11 penalty: 0 agent_num: 15 done: False
______________________
id: 45 reward: -0.025412087912087912 service_time: 342 s_time: 37 penalty: 0 agent_num: 26 done: False
______________________
id: 43 reward: -0.0546875 service_time: 393 s_time: 49 penalty: 0 agent_num: 16 done: False
______________________
id: 42 reward: -0.023065476190476192 service_time: 429 s_time: 31 penalty: 0 agent_num: 24 done: False
______________________
id: 52 reward: 0.03021978021978022 service_time: 336 s_time: -22 penalty: 0 agent_num: 13 done: False
______________________
id: 47 reward: -0.029017857142857144 service_time: 387 s_time: 39 penalty: 0 agent_num: 24 done: False
______________________
id: 48 reward: -0.02976190476190476 service_time: 374 s_time: 50 penalty: 0 agent_num: 30 done: False
______________________
id: 51 reward: -0.07738095238095238 service_time: 462 s_time: 65 penalty: 0 agent_num: 15 done: False
______________________
id: 41 reward: -0.011554621848739496 service_time: 379 s_time: 22 penalty: 0 agent_num: 34 done: False
______________________
id: 44 reward: -0.008035714285714285 service_time: 425 s_time: 18 penalty: 0 agent_num: 40 done: False
______________________
id: 53 reward: -0.014751552795031056 service_time: 396 s_time: 19 penalty: 0 agent_num: 23 done: False
______________________
id: 55 reward: -0.009486607142857142 service_time: 401 s_time: 17 penalty: 0 agent_num: 32 done: False
______________________
id: 46 reward: -0.024613899613899613 service_time: 364 s_time: 51 penalty: 0 agent_num: 37 done: False
______________________
id: 49 reward: -0.014668367346938776 service_time: 385 s_time: 23 penalty: 0 agent_num: 28 done: False
______________________
id: 54 reward: -0.011278195488721804 service_time: 355 s_time: 24 penalty: 0 agent_num: 38 done: False
______________________
id: 50 reward: -0.013605442176870748 service_time: 568 s_time: 16 penalty: 0 agent_num: 21 done: False
______________________
Step:  224
Pretraining Loss:  tensor(0.0609, device='cuda:0', grad_fn=<MeanBackward0>)
id: 43 reward: -0.029017857142857144 service_time: 419 s_time: 26 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: -0.05 service_time: 426 s_time: 42 penalty: 0 agent_num: 15 done: False
______________________
id: 52 reward: 0.013736263736263736 service_time: 326 s_time: -10 penalty: 0 agent_num: 13 done: False
______________________
id: 45 reward: -0.02815934065934066 service_time: 383 s_time: 41 penalty: 0 agent_num: 26 done: False
______________________
id: 53 reward: -0.02406832298136646 service_time: 427 s_time: 31 penalty: 0 agent_num: 23 done: False
______________________
id: 48 reward: -0.01607142857142857 service_time: 401 s_time: 27 penalty: 0 agent_num: 30 done: False
______________________
id: 49 reward: 0.0 service_time: 385 s_time: 0 penalty: 0 agent_num: 28 done: False
______________________
id: 42 reward: -0.029017857142857144 service_time: 468 s_time: 39 penalty: 0 agent_num: 24 done: False
______________________
id: 47 reward: -0.013392857142857142 service_time: 405 s_time: 18 penalty: 0 agent_num: 24 done: False
______________________
id: 55 reward: -0.013392857142857142 service_time: 425 s_time: 24 penalty: 0 agent_num: 32 done: False
______________________
id: 51 reward: -0.02976190476190476 service_time: 487 s_time: 25 penalty: 0 agent_num: 15 done: False
______________________
id: 46 reward: -0.008687258687258687 service_time: 382 s_time: 18 penalty: 0 agent_num: 37 done: False
______________________
id: 41 reward: 0.0 service_time: 379 s_time: 0 penalty: 0 agent_num: 34 done: False
______________________
id: 54 reward: -0.007518796992481203 service_time: 371 s_time: 16 penalty: 0 agent_num: 38 done: False
______________________
id: 44 reward: -0.011607142857142858 service_time: 451 s_time: 26 penalty: 0 agent_num: 40 done: False
______________________
id: 50 reward: -0.03231292517006803 service_time: 606 s_time: 38 penalty: 0 agent_num: 21 done: False
______________________
Step:  240
Pretraining Loss:  tensor(0.0654, device='cuda:0', grad_fn=<MeanBackward0>)
id: 40 reward: 0.011904761904761904 service_time: 416 s_time: -10 penalty: 0 agent_num: 15 done: False
______________________
id: 43 reward: 0.0 service_time: 419 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 47 reward: 0.0 service_time: 405 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: -0.021291208791208792 service_time: 414 s_time: 31 penalty: 0 agent_num: 26 done: False
______________________
id: 52 reward: -0.0260989010989011 service_time: 345 s_time: 19 penalty: 0 agent_num: 13 done: False
______________________
id: 51 reward: 0.02619047619047619 service_time: 465 s_time: -22 penalty: 0 agent_num: 15 done: False
______________________
id: 42 reward: -0.01711309523809524 service_time: 491 s_time: 23 penalty: 0 agent_num: 24 done: False
______________________
id: 53 reward: -0.02406832298136646 service_time: 458 s_time: 31 penalty: 0 agent_num: 23 done: False
______________________
id: 55 reward: -0.0033482142857142855 service_time: 431 s_time: 6 penalty: 0 agent_num: 32 done: False
______________________
id: 48 reward: -0.0125 service_time: 422 s_time: 21 penalty: 0 agent_num: 30 done: False
______________________
id: 41 reward: -0.023634453781512604 service_time: 424 s_time: 45 penalty: 0 agent_num: 34 done: False
______________________
id: 44 reward: 0.002232142857142857 service_time: 446 s_time: -5 penalty: 0 agent_num: 40 done: False
______________________
id: 46 reward: -0.0019305019305019305 service_time: 386 s_time: 4 penalty: 0 agent_num: 37 done: False
______________________
id: 54 reward: -0.0042293233082706765 service_time: 380 s_time: 9 penalty: 0 agent_num: 38 done: False
______________________
id: 49 reward: -0.046556122448979595 service_time: 458 s_time: 73 penalty: 0 agent_num: 28 done: False
______________________
id: 50 reward: -0.05357142857142857 service_time: 669 s_time: 63 penalty: 0 agent_num: 21 done: False
______________________
Step:  256
Pretraining Loss:  tensor(0.0669, device='cuda:0', grad_fn=<MeanBackward0>)
id: 43 reward: -0.026785714285714284 service_time: 443 s_time: 24 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: 0.0 service_time: 416 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 51 reward: 0.009523809523809525 service_time: 457 s_time: -8 penalty: 0 agent_num: 15 done: False
______________________
id: 45 reward: -0.019230769230769232 service_time: 442 s_time: 28 penalty: 0 agent_num: 26 done: False
______________________
id: 47 reward: -0.028273809523809524 service_time: 443 s_time: 38 penalty: 0 agent_num: 24 done: False
______________________
id: 42 reward: -0.01488095238095238 service_time: 511 s_time: 20 penalty: 0 agent_num: 24 done: False
______________________
id: 53 reward: -0.023291925465838508 service_time: 488 s_time: 30 penalty: 0 agent_num: 23 done: False
______________________
id: 46 reward: -0.019787644787644786 service_time: 427 s_time: 41 penalty: 0 agent_num: 37 done: False
______________________
id: 52 reward: -0.06593406593406594 service_time: 393 s_time: 48 penalty: 0 agent_num: 13 done: False
______________________
id: 48 reward: -0.023809523809523808 service_time: 462 s_time: 40 penalty: 0 agent_num: 30 done: False
______________________
id: 55 reward: 0.0 service_time: 431 s_time: 0 penalty: 0 agent_num: 32 done: False
______________________
id: 41 reward: 0.0005252100840336134 service_time: 423 s_time: -1 penalty: 0 agent_num: 34 done: False
______________________
id: 49 reward: 0.0 service_time: 458 s_time: 0 penalty: 0 agent_num: 28 done: False
______________________
id: 54 reward: -0.01268796992481203 service_time: 407 s_time: 27 penalty: 0 agent_num: 38 done: False
______________________
id: 44 reward: -0.023660714285714285 service_time: 499 s_time: 53 penalty: 0 agent_num: 40 done: False
______________________
id: 50 reward: -0.045068027210884355 service_time: 722 s_time: 53 penalty: 0 agent_num: 21 done: False
______________________
Step:  272
Pretraining Loss:  tensor(0.0649, device='cuda:0', grad_fn=<MeanBackward0>)
id: 43 reward: -0.027901785714285716 service_time: 468 s_time: 25 penalty: 0 agent_num: 16 done: False
______________________
id: 52 reward: -0.03021978021978022 service_time: 415 s_time: 22 penalty: 0 agent_num: 13 done: False
______________________
id: 40 reward: 0.034523809523809526 service_time: 387 s_time: -29 penalty: 0 agent_num: 15 done: False
______________________
id: 51 reward: 0.009523809523809525 service_time: 449 s_time: -8 penalty: 0 agent_num: 15 done: False
______________________
id: 45 reward: -0.007554945054945055 service_time: 453 s_time: 11 penalty: 0 agent_num: 26 done: False
______________________
id: 47 reward: -0.023065476190476192 service_time: 474 s_time: 31 penalty: 0 agent_num: 24 done: False
______________________
id: 41 reward: -0.01050420168067227 service_time: 443 s_time: 20 penalty: 0 agent_num: 34 done: False
______________________
id: 42 reward: -0.024553571428571428 service_time: 544 s_time: 33 penalty: 0 agent_num: 24 done: False
______________________
id: 55 reward: -0.04296875 service_time: 508 s_time: 77 penalty: 0 agent_num: 32 done: False
______________________
id: 53 reward: -0.021739130434782608 service_time: 516 s_time: 28 penalty: 0 agent_num: 23 done: False
______________________
id: 48 reward: -0.011904761904761904 service_time: 482 s_time: 20 penalty: 0 agent_num: 30 done: False
______________________
id: 44 reward: -0.011607142857142858 service_time: 525 s_time: 26 penalty: 0 agent_num: 40 done: False
______________________
id: 50 reward: 0.004251700680272109 service_time: 717 s_time: -5 penalty: 0 agent_num: 21 done: False
______________________
id: 46 reward: 0.0 service_time: 427 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 54 reward: -0.011278195488721804 service_time: 431 s_time: 24 penalty: 0 agent_num: 38 done: False
______________________
id: 49 reward: -0.03316326530612245 service_time: 510 s_time: 52 penalty: 0 agent_num: 28 done: False
______________________
Step:  288
Pretraining Loss:  tensor(0.0652, device='cuda:0', grad_fn=<MeanBackward0>)
id: 40 reward: 0.011904761904761904 service_time: 377 s_time: -10 penalty: 0 agent_num: 15 done: False
______________________
id: 51 reward: 0.03333333333333333 service_time: 421 s_time: -28 penalty: 0 agent_num: 15 done: False
______________________
id: 43 reward: 0.0 service_time: 468 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 52 reward: 0.03159340659340659 service_time: 392 s_time: -23 penalty: 0 agent_num: 13 done: False
______________________
id: 45 reward: -0.02197802197802198 service_time: 485 s_time: 32 penalty: 0 agent_num: 26 done: False
______________________
id: 42 reward: -0.021577380952380952 service_time: 573 s_time: 29 penalty: 0 agent_num: 24 done: False
______________________
id: 55 reward: -0.007254464285714286 service_time: 521 s_time: 13 penalty: 0 agent_num: 32 done: False
______________________
id: 53 reward: -0.02251552795031056 service_time: 545 s_time: 29 penalty: 0 agent_num: 23 done: False
______________________
id: 47 reward: -0.022321428571428572 service_time: 504 s_time: 30 penalty: 0 agent_num: 24 done: False
______________________
id: 48 reward: -0.01369047619047619 service_time: 505 s_time: 23 penalty: 0 agent_num: 30 done: False
______________________
id: 41 reward: -0.027836134453781514 service_time: 496 s_time: 53 penalty: 0 agent_num: 34 done: False
______________________
id: 54 reward: -0.006578947368421052 service_time: 445 s_time: 14 penalty: 0 agent_num: 38 done: False
______________________
id: 46 reward: -0.019305019305019305 service_time: 467 s_time: 40 penalty: 0 agent_num: 37 done: False
______________________
id: 44 reward: -0.011160714285714286 service_time: 550 s_time: 25 penalty: 0 agent_num: 40 done: False
______________________
id: 49 reward: -0.01594387755102041 service_time: 535 s_time: 25 penalty: 0 agent_num: 28 done: False
______________________
id: 50 reward: 0.0008503401360544217 service_time: 716 s_time: -1 penalty: 0 agent_num: 21 done: False
______________________
Step:  304
Pretraining Loss:  tensor(0.0645, device='cuda:0', grad_fn=<MeanBackward0>)
id: 40 reward: 0.0 service_time: 377 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 51 reward: 0.0 service_time: 421 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 52 reward: 0.006868131868131868 service_time: 387 s_time: -5 penalty: 0 agent_num: 13 done: False
______________________
id: 43 reward: 0.0 service_time: 468 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 45 reward: -0.018543956043956044 service_time: 512 s_time: 27 penalty: 0 agent_num: 26 done: False
______________________
id: 47 reward: -0.033482142857142856 service_time: 549 s_time: 45 penalty: 0 agent_num: 24 done: False
______________________
id: 42 reward: 0.0 service_time: 573 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 48 reward: -0.01369047619047619 service_time: 528 s_time: 23 penalty: 0 agent_num: 30 done: False
______________________
id: 53 reward: 0.0 service_time: 545 s_time: 0 penalty: 0 agent_num: 23 done: False
______________________
id: 41 reward: 0.0 service_time: 496 s_time: 0 penalty: 0 agent_num: 34 done: False
______________________
id: 54 reward: -0.014097744360902255 service_time: 475 s_time: 30 penalty: 0 agent_num: 38 done: False
______________________
id: 44 reward: -0.012946428571428572 service_time: 579 s_time: 29 penalty: 0 agent_num: 40 done: False
______________________
id: 49 reward: -0.012755102040816327 service_time: 555 s_time: 20 penalty: 0 agent_num: 28 done: False
______________________
id: 46 reward: -0.015444015444015444 service_time: 499 s_time: 32 penalty: 0 agent_num: 37 done: False
______________________
id: 55 reward: 0.0 service_time: 521 s_time: 0 penalty: 0 agent_num: 32 done: False
______________________
id: 50 reward: -0.04336734693877551 service_time: 767 s_time: 51 penalty: 0 agent_num: 21 done: False
______________________
Step:  320
Pretraining Loss:  tensor(0.0681, device='cuda:0', grad_fn=<MeanBackward0>)
id: 51 reward: 0.02857142857142857 service_time: 397 s_time: -24 penalty: 0 agent_num: 15 done: False
______________________
id: 40 reward: 0.0 service_time: 377 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 43 reward: 0.018973214285714284 service_time: 451 s_time: -17 penalty: 0 agent_num: 16 done: False
______________________
id: 52 reward: -0.034340659340659344 service_time: 412 s_time: 25 penalty: 0 agent_num: 13 done: False
______________________
id: 45 reward: -0.0260989010989011 service_time: 550 s_time: 38 penalty: 0 agent_num: 26 done: False
______________________
id: 47 reward: -0.026041666666666668 service_time: 584 s_time: 35 penalty: 0 agent_num: 24 done: False
______________________
id: 42 reward: -0.02976190476190476 service_time: 613 s_time: 40 penalty: 0 agent_num: 24 done: False
______________________
id: 53 reward: -0.023291925465838508 service_time: 575 s_time: 30 penalty: 0 agent_num: 23 done: False
______________________
id: 46 reward: -0.012065637065637066 service_time: 524 s_time: 25 penalty: 0 agent_num: 37 done: False
______________________
id: 55 reward: -0.03962053571428571 service_time: 592 s_time: 71 penalty: 0 agent_num: 32 done: False
______________________
id: 41 reward: -0.029936974789915968 service_time: 553 s_time: 57 penalty: 0 agent_num: 34 done: False
______________________
id: 48 reward: -0.024404761904761905 service_time: 569 s_time: 41 penalty: 0 agent_num: 30 done: False
______________________
id: 54 reward: 0.0 service_time: 475 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 49 reward: -0.011479591836734694 service_time: 573 s_time: 18 penalty: 0 agent_num: 28 done: False
______________________
id: 44 reward: 0.0 service_time: 579 s_time: 0 penalty: 0 agent_num: 40 done: False
______________________
id: 50 reward: -0.03571428571428571 service_time: 809 s_time: 42 penalty: 0 agent_num: 21 done: False
______________________
Step:  336
Pretraining Loss:  tensor(0.0729, device='cuda:0', grad_fn=<MeanBackward0>)
id: 43 reward: 0.008928571428571428 service_time: 443 s_time: -8 penalty: 0 agent_num: 16 done: False
______________________
id: 51 reward: 0.004761904761904762 service_time: 393 s_time: -4 penalty: 0 agent_num: 15 done: False
______________________
id: 40 reward: 0.0 service_time: 377 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 52 reward: 0.0 service_time: 412 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 45 reward: -0.008241758241758242 service_time: 562 s_time: 12 penalty: 0 agent_num: 26 done: False
______________________
id: 47 reward: -0.023065476190476192 service_time: 615 s_time: 31 penalty: 0 agent_num: 24 done: False
______________________
id: 53 reward: -0.043478260869565216 service_time: 631 s_time: 56 penalty: 0 agent_num: 23 done: False
______________________
id: 42 reward: -0.026041666666666668 service_time: 648 s_time: 35 penalty: 0 agent_num: 24 done: False
______________________
id: 48 reward: -0.017261904761904763 service_time: 598 s_time: 29 penalty: 0 agent_num: 30 done: False
______________________
id: 55 reward: 0.0005580357142857143 service_time: 591 s_time: -1 penalty: 0 agent_num: 32 done: False
______________________
id: 54 reward: -0.007048872180451127 service_time: 490 s_time: 15 penalty: 0 agent_num: 38 done: False
______________________
id: 41 reward: -0.009978991596638655 service_time: 572 s_time: 19 penalty: 0 agent_num: 34 done: False
______________________
id: 46 reward: -0.006274131274131274 service_time: 537 s_time: 13 penalty: 0 agent_num: 37 done: False
______________________
id: 49 reward: -0.018494897959183673 service_time: 602 s_time: 29 penalty: 0 agent_num: 28 done: False
______________________
id: 44 reward: -0.02544642857142857 service_time: 636 s_time: 57 penalty: 0 agent_num: 40 done: False
______________________
id: 50 reward: 0.04421768707482993 service_time: 757 s_time: -52 penalty: 0 agent_num: 21 done: False
______________________
Step:  352
Pretraining Loss:  tensor(0.0721, device='cuda:0', grad_fn=<MeanBackward0>)
id: 51 reward: 0.005952380952380952 service_time: 388 s_time: -5 penalty: 0 agent_num: 15 done: False
______________________
id: 43 reward: 0.0 service_time: 443 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: 0.0 service_time: 377 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 52 reward: 0.0 service_time: 412 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 53 reward: -0.016304347826086956 service_time: 652 s_time: 21 penalty: 0 agent_num: 23 done: False
______________________
id: 45 reward: -0.017857142857142856 service_time: 588 s_time: 26 penalty: 0 agent_num: 26 done: False
______________________
id: 42 reward: -0.02976190476190476 service_time: 688 s_time: 40 penalty: 0 agent_num: 24 done: False
______________________
id: 47 reward: -0.010416666666666666 service_time: 629 s_time: 14 penalty: 0 agent_num: 24 done: False
______________________
id: 54 reward: -0.020206766917293232 service_time: 533 s_time: 43 penalty: 0 agent_num: 38 done: False
______________________
id: 41 reward: 0.0 service_time: 572 s_time: 0 penalty: 0 agent_num: 34 done: False
______________________
id: 46 reward: -0.014961389961389961 service_time: 568 s_time: 31 penalty: 0 agent_num: 37 done: False
______________________
id: 48 reward: -0.025 service_time: 640 s_time: 42 penalty: 0 agent_num: 30 done: False
______________________
id: 49 reward: -0.022321428571428572 service_time: 637 s_time: 35 penalty: 0 agent_num: 28 done: False
______________________
id: 55 reward: -0.021205357142857144 service_time: 629 s_time: 38 penalty: 0 agent_num: 32 done: False
______________________
id: 44 reward: -0.019196428571428573 service_time: 679 s_time: 43 penalty: 0 agent_num: 40 done: False
______________________
id: 50 reward: 0.04931972789115646 service_time: 699 s_time: -58 penalty: 0 agent_num: 21 done: False
______________________
Step:  368
Pretraining Loss:  tensor(0.0738, device='cuda:0', grad_fn=<MeanBackward0>)
id: 40 reward: 0.0 service_time: 377 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 51 reward: 0.010714285714285714 service_time: 379 s_time: -9 penalty: 0 agent_num: 15 done: False
______________________
id: 43 reward: 0.0 service_time: 443 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 52 reward: 0.0 service_time: 412 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 45 reward: 0.0 service_time: 588 s_time: 0 penalty: 0 agent_num: 26 done: False
______________________
id: 41 reward: -0.028361344537815126 service_time: 626 s_time: 54 penalty: 0 agent_num: 34 done: False
______________________
id: 42 reward: -0.03050595238095238 service_time: 729 s_time: 41 penalty: 0 agent_num: 24 done: False
______________________
id: 55 reward: -0.018415178571428572 service_time: 662 s_time: 33 penalty: 0 agent_num: 32 done: False
______________________
id: 53 reward: 0.0038819875776397515 service_time: 647 s_time: -5 penalty: 0 agent_num: 23 done: False
______________________
id: 47 reward: -0.03273809523809524 service_time: 673 s_time: 44 penalty: 0 agent_num: 24 done: False
______________________
id: 46 reward: -0.00723938223938224 service_time: 583 s_time: 15 penalty: 0 agent_num: 37 done: False
______________________
id: 49 reward: -0.006377551020408163 service_time: 647 s_time: 10 penalty: 0 agent_num: 28 done: False
______________________
id: 54 reward: -0.016917293233082706 service_time: 569 s_time: 36 penalty: 0 agent_num: 38 done: False
______________________
id: 50 reward: 0.025510204081632654 service_time: 669 s_time: -30 penalty: 0 agent_num: 21 done: False
______________________
id: 48 reward: -0.01607142857142857 service_time: 667 s_time: 27 penalty: 0 agent_num: 30 done: False
______________________
id: 44 reward: -0.020089285714285716 service_time: 724 s_time: 45 penalty: 0 agent_num: 40 done: False
______________________
Step:  384
Pretraining Loss:  tensor(0.0791, device='cuda:0', grad_fn=<MeanBackward0>)
id: 40 reward: -0.04285714285714286 service_time: 413 s_time: 36 penalty: 0 agent_num: 15 done: False
______________________
id: 51 reward: 0.0 service_time: 379 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 43 reward: 0.0 service_time: 443 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 52 reward: 0.0 service_time: 412 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 50 reward: 0.023809523809523808 service_time: 641 s_time: -28 penalty: 0 agent_num: 21 done: False
______________________
id: 45 reward: -0.04120879120879121 service_time: 648 s_time: 60 penalty: 0 agent_num: 26 done: False
______________________
id: 47 reward: -0.011904761904761904 service_time: 689 s_time: 16 penalty: 0 agent_num: 24 done: False
______________________
id: 48 reward: 0.0011904761904761906 service_time: 665 s_time: -2 penalty: 0 agent_num: 30 done: False
______________________
id: 53 reward: -0.039596273291925464 service_time: 698 s_time: 51 penalty: 0 agent_num: 23 done: False
______________________
id: 54 reward: 0.0 service_time: 569 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 41 reward: -0.01995798319327731 service_time: 664 s_time: 38 penalty: 0 agent_num: 34 done: False
______________________
id: 42 reward: -0.01711309523809524 service_time: 752 s_time: 23 penalty: 0 agent_num: 24 done: False
______________________
id: 49 reward: -0.01721938775510204 service_time: 674 s_time: 27 penalty: 0 agent_num: 28 done: False
______________________
id: 46 reward: -0.004343629343629344 service_time: 592 s_time: 9 penalty: 0 agent_num: 37 done: False
______________________
id: 44 reward: 0.0017857142857142857 service_time: 720 s_time: -4 penalty: 0 agent_num: 40 done: False
______________________
id: 55 reward: 0.0 service_time: 662 s_time: 0 penalty: 0 agent_num: 32 done: False
______________________
Step:  400
Pretraining Loss:  tensor(0.0749, device='cuda:0', grad_fn=<MeanBackward0>)
id: 51 reward: 0.004761904761904762 service_time: 375 s_time: -4 penalty: 0 agent_num: 15 done: False
______________________
id: 40 reward: 0.0 service_time: 413 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 52 reward: 0.0 service_time: 412 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 43 reward: 0.0 service_time: 443 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 53 reward: -0.02096273291925466 service_time: 725 s_time: 27 penalty: 0 agent_num: 23 done: False
______________________
id: 45 reward: -0.01510989010989011 service_time: 670 s_time: 22 penalty: 0 agent_num: 26 done: False
______________________
id: 47 reward: -0.029017857142857144 service_time: 728 s_time: 39 penalty: 0 agent_num: 24 done: False
______________________
id: 41 reward: -0.012605042016806723 service_time: 688 s_time: 24 penalty: 0 agent_num: 34 done: False
______________________
id: 50 reward: 0.0 service_time: 641 s_time: 0 penalty: 0 agent_num: 21 done: False
______________________
id: 46 reward: -0.004826254826254826 service_time: 602 s_time: 10 penalty: 0 agent_num: 37 done: False
______________________
id: 48 reward: -0.047619047619047616 service_time: 745 s_time: 80 penalty: 0 agent_num: 30 done: False
______________________
id: 49 reward: 0.0012755102040816326 service_time: 672 s_time: -2 penalty: 0 agent_num: 28 done: False
______________________
id: 54 reward: -0.028665413533834585 service_time: 630 s_time: 61 penalty: 0 agent_num: 38 done: False
______________________
id: 55 reward: -0.03125 service_time: 718 s_time: 56 penalty: 0 agent_num: 32 done: False
______________________
id: 42 reward: 0.011160714285714286 service_time: 737 s_time: -15 penalty: 0 agent_num: 24 done: False
______________________
id: 44 reward: -0.017857142857142856 service_time: 760 s_time: 40 penalty: 0 agent_num: 40 done: False
______________________
Step:  416
Pretraining Loss:  tensor(0.0845, device='cuda:0', grad_fn=<MeanBackward0>)
id: 52 reward: 0.016483516483516484 service_time: 400 s_time: -12 penalty: 0 agent_num: 13 done: False
______________________
id: 40 reward: -0.04523809523809524 service_time: 451 s_time: 38 penalty: 0 agent_num: 15 done: False
______________________
id: 51 reward: 0.0 service_time: 375 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 43 reward: -0.03571428571428571 service_time: 475 s_time: 32 penalty: 0 agent_num: 16 done: False
______________________
id: 50 reward: 0.031462585034013606 service_time: 604 s_time: -37 penalty: 0 agent_num: 21 done: False
______________________
id: 45 reward: -0.019917582417582416 service_time: 699 s_time: 29 penalty: 0 agent_num: 26 done: False
______________________
id: 46 reward: -0.008204633204633204 service_time: 619 s_time: 17 penalty: 0 agent_num: 37 done: False
______________________
id: 47 reward: -0.018601190476190476 service_time: 753 s_time: 25 penalty: 0 agent_num: 24 done: False
______________________
id: 41 reward: -0.017331932773109245 service_time: 721 s_time: 33 penalty: 0 agent_num: 34 done: False
______________________
id: 42 reward: 0.01636904761904762 service_time: 715 s_time: -22 penalty: 0 agent_num: 24 done: False
______________________
id: 44 reward: 0.0008928571428571428 service_time: 758 s_time: -2 penalty: 0 agent_num: 40 done: False
______________________
id: 48 reward: 0.0 service_time: 745 s_time: 0 penalty: 0 agent_num: 30 done: False
______________________
id: 49 reward: -0.061224489795918366 service_time: 768 s_time: 96 penalty: 0 agent_num: 28 done: False
______________________
id: 55 reward: -0.023995535714285716 service_time: 761 s_time: 43 penalty: 0 agent_num: 32 done: False
______________________
id: 53 reward: -0.036490683229813664 service_time: 772 s_time: 47 penalty: 0 agent_num: 23 done: False
______________________
id: 54 reward: -0.019736842105263157 service_time: 672 s_time: 42 penalty: 0 agent_num: 38 done: False
______________________
Step:  432
Pretraining Loss:  tensor(0.0928, device='cuda:0', grad_fn=<MeanBackward0>)
id: 40 reward: 0.041666666666666664 service_time: 416 s_time: -35 penalty: 0 agent_num: 15 done: False
______________________
id: 52 reward: 0.0 service_time: 400 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 51 reward: -0.030952380952380953 service_time: 401 s_time: 26 penalty: 0 agent_num: 15 done: False
______________________
id: 43 reward: -0.006696428571428571 service_time: 481 s_time: 6 penalty: 0 agent_num: 16 done: False
______________________
id: 50 reward: -0.04251700680272109 service_time: 654 s_time: 50 penalty: 0 agent_num: 21 done: False
______________________
id: 53 reward: 0.011645962732919254 service_time: 757 s_time: -15 penalty: 0 agent_num: 23 done: False
______________________
id: 45 reward: -0.010302197802197802 service_time: 714 s_time: 15 penalty: 0 agent_num: 26 done: False
______________________
id: 46 reward: -0.012548262548262547 service_time: 645 s_time: 26 penalty: 0 agent_num: 37 done: False
______________________
id: 42 reward: -0.043154761904761904 service_time: 773 s_time: 58 penalty: 0 agent_num: 24 done: False
______________________
id: 47 reward: -0.009672619047619048 service_time: 766 s_time: 13 penalty: 0 agent_num: 24 done: False
______________________
id: 48 reward: -0.02619047619047619 service_time: 789 s_time: 44 penalty: 0 agent_num: 30 done: False
______________________
id: 49 reward: -0.03571428571428571 service_time: 824 s_time: 56 penalty: 0 agent_num: 28 done: False
______________________
id: 41 reward: -0.017331932773109245 service_time: 754 s_time: 33 penalty: 0 agent_num: 34 done: False
______________________
id: 55 reward: -0.014508928571428572 service_time: 787 s_time: 26 penalty: 0 agent_num: 32 done: False
______________________
id: 44 reward: -0.028125 service_time: 821 s_time: 63 penalty: 0 agent_num: 40 done: False
______________________
id: 54 reward: -0.011748120300751879 service_time: 697 s_time: 25 penalty: 0 agent_num: 38 done: False
______________________
Step:  448
Pretraining Loss:  tensor(0.0942, device='cuda:0', grad_fn=<MeanBackward0>)
id: 52 reward: 0.0 service_time: 400 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 40 reward: -0.10833333333333334 service_time: 507 s_time: 91 penalty: 0 agent_num: 15 done: False
______________________
id: 43 reward: -0.029017857142857144 service_time: 507 s_time: 26 penalty: 0 agent_num: 16 done: False
______________________
id: 51 reward: -0.015476190476190477 service_time: 414 s_time: 13 penalty: 0 agent_num: 15 done: False
______________________
id: 42 reward: -0.004464285714285714 service_time: 779 s_time: 6 penalty: 0 agent_num: 24 done: False
______________________
id: 53 reward: -0.009316770186335404 service_time: 769 s_time: 12 penalty: 0 agent_num: 23 done: False
______________________
id: 41 reward: 0.0 service_time: 754 s_time: 0 penalty: 0 agent_num: 34 done: False
______________________
id: 46 reward: -0.023166023166023165 service_time: 693 s_time: 48 penalty: 0 agent_num: 37 done: False
______________________
id: 47 reward: -0.033482142857142856 service_time: 811 s_time: 45 penalty: 0 agent_num: 24 done: False
______________________
id: 50 reward: -0.030612244897959183 service_time: 690 s_time: 36 penalty: 0 agent_num: 21 done: False
______________________
id: 48 reward: -0.01369047619047619 service_time: 812 s_time: 23 penalty: 0 agent_num: 30 done: False
______________________
id: 45 reward: -0.020604395604395604 service_time: 744 s_time: 30 penalty: 0 agent_num: 26 done: False
______________________
id: 44 reward: -0.0026785714285714286 service_time: 827 s_time: 6 penalty: 0 agent_num: 40 done: False
______________________
id: 55 reward: -0.014508928571428572 service_time: 813 s_time: 26 penalty: 0 agent_num: 32 done: False
______________________
id: 54 reward: -0.014097744360902255 service_time: 727 s_time: 30 penalty: 0 agent_num: 38 done: False
______________________
id: 49 reward: 0.01721938775510204 service_time: 797 s_time: -27 penalty: 0 agent_num: 28 done: False
______________________
Step:  464
Pretraining Loss:  tensor(0.0940, device='cuda:0', grad_fn=<MeanBackward0>)
id: 52 reward: -0.10164835164835165 service_time: 474 s_time: 74 penalty: 0 agent_num: 13 done: False
______________________
id: 40 reward: 0.009523809523809525 service_time: 499 s_time: -8 penalty: 0 agent_num: 15 done: False
______________________
id: 51 reward: -0.025 service_time: 435 s_time: 21 penalty: 0 agent_num: 15 done: False
______________________
id: 50 reward: 0.0 service_time: 690 s_time: 0 penalty: 0 agent_num: 21 done: False
______________________
id: 42 reward: 0.000744047619047619 service_time: 778 s_time: -1 penalty: 0 agent_num: 24 done: False
______________________
id: 43 reward: -0.09821428571428571 service_time: 595 s_time: 88 penalty: 0 agent_num: 16 done: False
______________________
id: 45 reward: -0.034340659340659344 service_time: 794 s_time: 50 penalty: 0 agent_num: 26 done: False
______________________
id: 48 reward: -0.008928571428571428 service_time: 827 s_time: 15 penalty: 0 agent_num: 30 done: False
______________________
id: 53 reward: 0.0015527950310559005 service_time: 767 s_time: -2 penalty: 0 agent_num: 23 done: False
______________________
id: 46 reward: -0.016891891891891893 service_time: 728 s_time: 35 penalty: 0 agent_num: 37 done: False
______________________
id: 49 reward: -0.035076530612244895 service_time: 852 s_time: 55 penalty: 0 agent_num: 28 done: False
______________________
id: 41 reward: -0.027836134453781514 service_time: 807 s_time: 53 penalty: 0 agent_num: 34 done: False
______________________
id: 44 reward: 0.0017857142857142857 service_time: 823 s_time: -4 penalty: 0 agent_num: 40 done: False
______________________
id: 55 reward: 0.002232142857142857 service_time: 809 s_time: -4 penalty: 0 agent_num: 32 done: False
______________________
id: 47 reward: -0.01488095238095238 service_time: 831 s_time: 20 penalty: 0 agent_num: 24 done: False
______________________
id: 54 reward: -0.008458646616541353 service_time: 745 s_time: 18 penalty: 0 agent_num: 38 done: False
______________________
Step:  480
Pretraining Loss:  tensor(0.0829, device='cuda:0', grad_fn=<MeanBackward0>)
id: 52 reward: 0.0027472527472527475 service_time: 472 s_time: -2 penalty: 0 agent_num: 13 done: False
______________________
id: 40 reward: -0.02738095238095238 service_time: 522 s_time: 23 penalty: 0 agent_num: 15 done: False
______________________
id: 51 reward: -0.08571428571428572 service_time: 507 s_time: 72 penalty: 0 agent_num: 15 done: False
______________________
id: 43 reward: 0.0078125 service_time: 588 s_time: -7 penalty: 0 agent_num: 16 done: False
______________________
id: 42 reward: -0.008928571428571428 service_time: 790 s_time: 12 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: -0.03777472527472527 service_time: 849 s_time: 55 penalty: 0 agent_num: 26 done: False
______________________
id: 53 reward: 0.010093167701863354 service_time: 754 s_time: -13 penalty: 0 agent_num: 23 done: False
______________________
id: 46 reward: -0.011583011583011582 service_time: 752 s_time: 24 penalty: 0 agent_num: 37 done: False
______________________
id: 47 reward: -0.022321428571428572 service_time: 861 s_time: 30 penalty: 0 agent_num: 24 done: False
______________________
id: 41 reward: -0.017331932773109245 service_time: 840 s_time: 33 penalty: 0 agent_num: 34 done: False
______________________
id: 49 reward: -0.02295918367346939 service_time: 888 s_time: 36 penalty: 0 agent_num: 28 done: False
______________________
id: 48 reward: -0.009523809523809525 service_time: 843 s_time: 16 penalty: 0 agent_num: 30 done: False
______________________
id: 50 reward: -0.013605442176870748 service_time: 706 s_time: 16 penalty: 0 agent_num: 21 done: False
______________________
id: 44 reward: -0.028125 service_time: 886 s_time: 63 penalty: 0 agent_num: 40 done: False
______________________
id: 54 reward: -0.01362781954887218 service_time: 774 s_time: 29 penalty: 0 agent_num: 38 done: False
______________________
id: 55 reward: -0.03794642857142857 service_time: 877 s_time: 68 penalty: 0 agent_num: 32 done: False
______________________
Step:  496
Pretraining Loss:  tensor(0.0868, device='cuda:0', grad_fn=<MeanBackward0>)
id: 52 reward: 0.0 service_time: 472 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 43 reward: 0.016741071428571428 service_time: 573 s_time: -15 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: -0.05 service_time: 564 s_time: 42 penalty: 0 agent_num: 15 done: False
______________________
id: 51 reward: 0.007142857142857143 service_time: 501 s_time: -6 penalty: 0 agent_num: 15 done: False
______________________
id: 42 reward: 0.002232142857142857 service_time: 787 s_time: -3 penalty: 0 agent_num: 24 done: False
______________________
id: 53 reward: 0.0015527950310559005 service_time: 752 s_time: -2 penalty: 0 agent_num: 23 done: False
______________________
id: 41 reward: -0.01680672268907563 service_time: 872 s_time: 32 penalty: 0 agent_num: 34 done: False
______________________
id: 50 reward: -0.08503401360544217 service_time: 806 s_time: 100 penalty: 0 agent_num: 21 done: False
______________________
id: 46 reward: -0.010135135135135136 service_time: 773 s_time: 21 penalty: 0 agent_num: 37 done: False
______________________
id: 45 reward: -0.012362637362637362 service_time: 867 s_time: 18 penalty: 0 agent_num: 26 done: False
______________________
id: 48 reward: -0.006547619047619048 service_time: 854 s_time: 11 penalty: 0 agent_num: 30 done: False
______________________
id: 49 reward: -0.008928571428571428 service_time: 902 s_time: 14 penalty: 0 agent_num: 28 done: False
______________________
id: 47 reward: 0.000744047619047619 service_time: 860 s_time: -1 penalty: 0 agent_num: 24 done: False
______________________
id: 44 reward: -0.013839285714285714 service_time: 917 s_time: 31 penalty: 0 agent_num: 40 done: False
______________________
id: 55 reward: -0.015625 service_time: 905 s_time: 28 penalty: 0 agent_num: 32 done: False
______________________
id: 54 reward: -0.0037593984962406013 service_time: 782 s_time: 8 penalty: 0 agent_num: 38 done: False
______________________
Step:  512
Pretraining Loss:  tensor(0.0900, device='cuda:0', grad_fn=<MeanBackward0>)
id: 52 reward: 0.01510989010989011 service_time: 461 s_time: -11 penalty: 0 agent_num: 13 done: False
______________________
id: 43 reward: 0.0 service_time: 573 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 51 reward: -0.1392857142857143 service_time: 618 s_time: 117 penalty: 0 agent_num: 15 done: False
______________________
id: 40 reward: -0.08095238095238096 service_time: 632 s_time: 68 penalty: 0 agent_num: 15 done: False
______________________
id: 45 reward: -0.02815934065934066 service_time: 908 s_time: 41 penalty: 0 agent_num: 26 done: False
______________________
id: 53 reward: -0.07608695652173914 service_time: 850 s_time: 98 penalty: 0 agent_num: 23 done: False
______________________
id: 41 reward: -0.008403361344537815 service_time: 888 s_time: 16 penalty: 0 agent_num: 34 done: False
______________________
id: 46 reward: -0.017374517374517374 service_time: 809 s_time: 36 penalty: 0 agent_num: 37 done: False
______________________
id: 42 reward: -0.03125 service_time: 829 s_time: 42 penalty: 0 agent_num: 24 done: False
______________________
id: 50 reward: 0.0 service_time: 806 s_time: 0 penalty: 0 agent_num: 21 done: False
______________________
id: 47 reward: -0.028273809523809524 service_time: 898 s_time: 38 penalty: 0 agent_num: 24 done: False
______________________
id: 48 reward: -0.02023809523809524 service_time: 888 s_time: 34 penalty: 0 agent_num: 30 done: False
______________________
id: 54 reward: -0.006578947368421052 service_time: 796 s_time: 14 penalty: 0 agent_num: 38 done: False
______________________
id: 44 reward: -0.015178571428571428 service_time: 951 s_time: 34 penalty: 0 agent_num: 40 done: False
______________________
id: 55 reward: -0.01171875 service_time: 926 s_time: 21 penalty: 0 agent_num: 32 done: False
______________________
id: 49 reward: 0.002551020408163265 service_time: 898 s_time: -4 penalty: 0 agent_num: 28 done: False
______________________
Step:  528
Pretraining Loss:  tensor(0.0869, device='cuda:0', grad_fn=<MeanBackward0>)
id: 43 reward: 0.0 service_time: 573 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: 0.013095238095238096 service_time: 621 s_time: -11 penalty: 0 agent_num: 15 done: False
______________________
id: 52 reward: -0.042582417582417584 service_time: 492 s_time: 31 penalty: 0 agent_num: 13 done: False
______________________
id: 51 reward: 0.011904761904761904 service_time: 608 s_time: -10 penalty: 0 agent_num: 15 done: False
______________________
id: 50 reward: -0.027210884353741496 service_time: 838 s_time: 32 penalty: 0 agent_num: 21 done: False
______________________
id: 46 reward: -0.01447876447876448 service_time: 839 s_time: 30 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: 0.004658385093167702 service_time: 844 s_time: -6 penalty: 0 agent_num: 23 done: False
______________________
id: 49 reward: -0.046556122448979595 service_time: 971 s_time: 73 penalty: 0 agent_num: 28 done: False
______________________
id: 41 reward: 0.0 service_time: 888 s_time: 0 penalty: 0 agent_num: 34 done: False
______________________
id: 47 reward: 0.010416666666666666 service_time: 884 s_time: -14 penalty: 0 agent_num: 24 done: False
______________________
id: 42 reward: -0.09970238095238096 service_time: 963 s_time: 134 penalty: 0 agent_num: 24 done: False
______________________
id: 48 reward: -0.01011904761904762 service_time: 905 s_time: 17 penalty: 0 agent_num: 30 done: False
______________________
id: 54 reward: -0.01268796992481203 service_time: 823 s_time: 27 penalty: 0 agent_num: 38 done: False
______________________
id: 55 reward: -0.008928571428571428 service_time: 942 s_time: 16 penalty: 0 agent_num: 32 done: False
______________________
id: 45 reward: -0.021291208791208792 service_time: 939 s_time: 31 penalty: 0 agent_num: 26 done: False
______________________
id: 44 reward: 0.0 service_time: 951 s_time: 0 penalty: 0 agent_num: 40 done: False
______________________
Step:  544
Pretraining Loss:  tensor(0.0924, device='cuda:0', grad_fn=<MeanBackward0>)
id: 43 reward: 0.0 service_time: 573 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: -0.060714285714285714 service_time: 672 s_time: 51 penalty: 0 agent_num: 15 done: False
______________________
id: 52 reward: -0.0673076923076923 service_time: 541 s_time: 49 penalty: 0 agent_num: 13 done: False
______________________
id: 51 reward: 0.0 service_time: 608 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 45 reward: 0.0013736263736263737 service_time: 937 s_time: -2 penalty: 0 agent_num: 26 done: False
______________________
id: 42 reward: 0.001488095238095238 service_time: 961 s_time: -2 penalty: 0 agent_num: 24 done: False
______________________
id: 46 reward: 0.0 service_time: 839 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 55 reward: -0.011160714285714286 service_time: 962 s_time: 20 penalty: 0 agent_num: 32 done: False
______________________
id: 48 reward: -0.025 service_time: 947 s_time: 42 penalty: 0 agent_num: 30 done: False
______________________
id: 47 reward: -0.04241071428571429 service_time: 941 s_time: 57 penalty: 0 agent_num: 24 done: False
______________________
id: 53 reward: -0.02251552795031056 service_time: 873 s_time: 29 penalty: 0 agent_num: 23 done: False
______________________
id: 50 reward: 0.0 service_time: 838 s_time: 0 penalty: 0 agent_num: 21 done: False
______________________
id: 49 reward: 0.006377551020408163 service_time: 961 s_time: -10 penalty: 0 agent_num: 28 done: False
______________________
id: 41 reward: -0.04044117647058824 service_time: 965 s_time: 77 penalty: 0 agent_num: 34 done: False
______________________
id: 44 reward: -0.024553571428571428 service_time: 1006 s_time: 55 penalty: 0 agent_num: 40 done: False
______________________
id: 54 reward: -0.009398496240601503 service_time: 843 s_time: 20 penalty: 0 agent_num: 38 done: False
______________________
Step:  560
Pretraining Loss:  tensor(0.0958, device='cuda:0', grad_fn=<MeanBackward0>)
id: 43 reward: 0.0 service_time: 573 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 52 reward: -0.03296703296703297 service_time: 565 s_time: 24 penalty: 0 agent_num: 13 done: False
______________________
id: 40 reward: 0.004761904761904762 service_time: 668 s_time: -4 penalty: 0 agent_num: 15 done: False
______________________
id: 51 reward: 0.0 service_time: 608 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 50 reward: 0.0 service_time: 838 s_time: 0 penalty: 0 agent_num: 21 done: False
______________________
id: 42 reward: 0.021577380952380952 service_time: 932 s_time: -29 penalty: 0 agent_num: 24 done: False
______________________
id: 46 reward: -0.01447876447876448 service_time: 869 s_time: 30 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: -0.03571428571428571 service_time: 919 s_time: 46 penalty: 0 agent_num: 23 done: False
______________________
id: 49 reward: -0.029974489795918366 service_time: 1008 s_time: 47 penalty: 0 agent_num: 28 done: False
______________________
id: 41 reward: -0.014705882352941176 service_time: 993 s_time: 28 penalty: 0 agent_num: 34 done: False
______________________
id: 47 reward: -0.03422619047619048 service_time: 987 s_time: 46 penalty: 0 agent_num: 24 done: False
______________________
id: 55 reward: -0.012834821428571428 service_time: 985 s_time: 23 penalty: 0 agent_num: 32 done: False
______________________
id: 48 reward: -0.026785714285714284 service_time: 992 s_time: 45 penalty: 0 agent_num: 30 done: False
______________________
id: 45 reward: -0.044642857142857144 service_time: 1002 s_time: 65 penalty: 0 agent_num: 26 done: False
______________________
id: 54 reward: -0.01268796992481203 service_time: 870 s_time: 27 penalty: 0 agent_num: 38 done: False
______________________
id: 44 reward: -0.013839285714285714 service_time: 1037 s_time: 31 penalty: 0 agent_num: 40 done: False
______________________
Step:  576
Pretraining Loss:  tensor(0.0970, device='cuda:0', grad_fn=<MeanBackward0>)
id: 43 reward: 0.0 service_time: 573 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 51 reward: 0.0 service_time: 608 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 52 reward: 0.0 service_time: 565 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 40 reward: -0.017857142857142856 service_time: 683 s_time: 15 penalty: 0 agent_num: 15 done: False
______________________
id: 42 reward: 0.004464285714285714 service_time: 926 s_time: -6 penalty: 0 agent_num: 24 done: False
______________________
id: 53 reward: 0.010093167701863354 service_time: 906 s_time: -13 penalty: 0 agent_num: 23 done: False
______________________
id: 45 reward: -0.007554945054945055 service_time: 1013 s_time: 11 penalty: 0 agent_num: 26 done: False
______________________
id: 50 reward: -0.030612244897959183 service_time: 874 s_time: 36 penalty: 0 agent_num: 21 done: False
______________________
id: 55 reward: -0.021205357142857144 service_time: 1023 s_time: 38 penalty: 0 agent_num: 32 done: False
______________________
id: 47 reward: 0.003720238095238095 service_time: 982 s_time: -5 penalty: 0 agent_num: 24 done: False
______________________
id: 46 reward: 0.0 service_time: 869 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 41 reward: -0.006827731092436975 service_time: 1006 s_time: 13 penalty: 0 agent_num: 34 done: False
______________________
id: 44 reward: -0.0004464285714285714 service_time: 1038 s_time: 1 penalty: 0 agent_num: 40 done: False
______________________
id: 48 reward: 0.0005952380952380953 service_time: 991 s_time: -1 penalty: 0 agent_num: 30 done: False
______________________
id: 49 reward: -0.04145408163265306 service_time: 1073 s_time: 65 penalty: 0 agent_num: 28 done: False
______________________
id: 54 reward: -0.020206766917293232 service_time: 913 s_time: 43 penalty: 0 agent_num: 38 done: False
______________________
Step:  592
Pretraining Loss:  tensor(0.0922, device='cuda:0', grad_fn=<MeanBackward0>)
id: 51 reward: 0.0 service_time: 608 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 43 reward: -0.06138392857142857 service_time: 628 s_time: 55 penalty: 0 agent_num: 16 done: False
______________________
id: 52 reward: -0.024725274725274724 service_time: 583 s_time: 18 penalty: 0 agent_num: 13 done: False
______________________
id: 40 reward: -0.03333333333333333 service_time: 711 s_time: 28 penalty: 0 agent_num: 15 done: False
______________________
id: 53 reward: 0.010093167701863354 service_time: 893 s_time: -13 penalty: 0 agent_num: 23 done: False
______________________
id: 42 reward: 0.0 service_time: 926 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 50 reward: -0.04251700680272109 service_time: 924 s_time: 50 penalty: 0 agent_num: 21 done: False
______________________
id: 45 reward: 0.0020604395604395605 service_time: 1010 s_time: -3 penalty: 0 agent_num: 26 done: False
______________________
id: 46 reward: -0.02944015444015444 service_time: 930 s_time: 61 penalty: 0 agent_num: 37 done: False
______________________
id: 47 reward: 0.0 service_time: 982 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 55 reward: 0.0 service_time: 1023 s_time: 0 penalty: 0 agent_num: 32 done: False
______________________
id: 41 reward: -0.01207983193277311 service_time: 1029 s_time: 23 penalty: 0 agent_num: 34 done: False
______________________
id: 44 reward: -0.004910714285714286 service_time: 1049 s_time: 11 penalty: 0 agent_num: 40 done: False
______________________
id: 49 reward: -0.026785714285714284 service_time: 1115 s_time: 42 penalty: 0 agent_num: 28 done: False
______________________
id: 54 reward: -0.01362781954887218 service_time: 942 s_time: 29 penalty: 0 agent_num: 38 done: False
______________________
id: 48 reward: -0.02619047619047619 service_time: 1035 s_time: 44 penalty: 0 agent_num: 30 done: False
______________________
Step:  608
Pretraining Loss:  tensor(0.1041, device='cuda:0', grad_fn=<MeanBackward0>)
id: 52 reward: 0.0 service_time: 583 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 51 reward: -0.047619047619047616 service_time: 648 s_time: 40 penalty: 0 agent_num: 15 done: False
______________________
id: 43 reward: -0.018973214285714284 service_time: 645 s_time: 17 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: -0.02023809523809524 service_time: 728 s_time: 17 penalty: 0 agent_num: 15 done: False
______________________
id: 42 reward: -0.012648809523809524 service_time: 943 s_time: 17 penalty: 0 agent_num: 24 done: False
______________________
id: 53 reward: 0.0 service_time: 893 s_time: 0 penalty: 0 agent_num: 23 done: False
______________________
id: 50 reward: 0.0 service_time: 924 s_time: 0 penalty: 0 agent_num: 21 done: False
______________________
id: 55 reward: -0.025669642857142856 service_time: 1069 s_time: 46 penalty: 0 agent_num: 32 done: False
______________________
id: 47 reward: -0.04836309523809524 service_time: 1047 s_time: 65 penalty: 0 agent_num: 24 done: False
______________________
id: 41 reward: -0.007878151260504201 service_time: 1044 s_time: 15 penalty: 0 agent_num: 34 done: False
______________________
id: 45 reward: -0.036401098901098904 service_time: 1063 s_time: 53 penalty: 0 agent_num: 26 done: False
______________________
id: 44 reward: -0.010267857142857143 service_time: 1072 s_time: 23 penalty: 0 agent_num: 40 done: False
______________________
id: 46 reward: 0.0 service_time: 930 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 48 reward: -0.027976190476190477 service_time: 1082 s_time: 47 penalty: 0 agent_num: 30 done: False
______________________
id: 49 reward: -0.02040816326530612 service_time: 1147 s_time: 32 penalty: 0 agent_num: 28 done: False
______________________
id: 54 reward: -0.01644736842105263 service_time: 977 s_time: 35 penalty: 0 agent_num: 38 done: False
______________________
Step:  624
Pretraining Loss:  tensor(0.1140, device='cuda:0', grad_fn=<MeanBackward0>)
id: 52 reward: -0.061813186813186816 service_time: 628 s_time: 45 penalty: 0 agent_num: 13 done: False
______________________
id: 51 reward: 0.0 service_time: 648 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 40 reward: 0.02976190476190476 service_time: 703 s_time: -25 penalty: 0 agent_num: 15 done: False
______________________
id: 43 reward: -0.10714285714285714 service_time: 741 s_time: 96 penalty: 0 agent_num: 16 done: False
______________________
id: 53 reward: -0.021739130434782608 service_time: 921 s_time: 28 penalty: 0 agent_num: 23 done: False
______________________
id: 42 reward: -0.019345238095238096 service_time: 969 s_time: 26 penalty: 0 agent_num: 24 done: False
______________________
id: 55 reward: 0.0 service_time: 1069 s_time: 0 penalty: 0 agent_num: 32 done: False
______________________
id: 46 reward: -0.011583011583011582 service_time: 954 s_time: 24 penalty: 0 agent_num: 37 done: False
______________________
id: 45 reward: 0.016483516483516484 service_time: 1039 s_time: -24 penalty: 0 agent_num: 26 done: False
______________________
id: 41 reward: -0.014705882352941176 service_time: 1072 s_time: 28 penalty: 0 agent_num: 34 done: False
______________________
id: 47 reward: -0.027529761904761904 service_time: 1084 s_time: 37 penalty: 0 agent_num: 24 done: False
______________________
id: 44 reward: -0.002232142857142857 service_time: 1077 s_time: 5 penalty: 0 agent_num: 40 done: False
______________________
id: 50 reward: -0.00935374149659864 service_time: 935 s_time: 11 penalty: 0 agent_num: 21 done: False
______________________
id: 49 reward: -0.01721938775510204 service_time: 1174 s_time: 27 penalty: 0 agent_num: 28 done: False
______________________
id: 54 reward: -0.015037593984962405 service_time: 1009 s_time: 32 penalty: 0 agent_num: 38 done: False
______________________
id: 48 reward: -0.022023809523809525 service_time: 1119 s_time: 37 penalty: 0 agent_num: 30 done: False
______________________
Step:  640
Pretraining Loss:  tensor(0.0951, device='cuda:0', grad_fn=<MeanBackward0>)
id: 52 reward: 0.04120879120879121 service_time: 598 s_time: -30 penalty: 0 agent_num: 13 done: False
______________________
id: 51 reward: -0.017857142857142856 service_time: 663 s_time: 15 penalty: 0 agent_num: 15 done: False
______________________
id: 40 reward: 0.0 service_time: 703 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 43 reward: -0.030133928571428572 service_time: 768 s_time: 27 penalty: 0 agent_num: 16 done: False
______________________
id: 50 reward: 0.01445578231292517 service_time: 918 s_time: -17 penalty: 0 agent_num: 21 done: False
______________________
id: 42 reward: -0.01711309523809524 service_time: 992 s_time: 23 penalty: 0 agent_num: 24 done: False
______________________
id: 55 reward: -0.018973214285714284 service_time: 1103 s_time: 34 penalty: 0 agent_num: 32 done: False
______________________
id: 45 reward: 0.010302197802197802 service_time: 1024 s_time: -15 penalty: 0 agent_num: 26 done: False
______________________
id: 48 reward: -0.024404761904761905 service_time: 1160 s_time: 41 penalty: 0 agent_num: 30 done: False
______________________
id: 53 reward: -0.06366459627329192 service_time: 1003 s_time: 82 penalty: 0 agent_num: 23 done: False
______________________
id: 44 reward: -0.010714285714285714 service_time: 1101 s_time: 24 penalty: 0 agent_num: 40 done: False
______________________
id: 47 reward: -0.018601190476190476 service_time: 1109 s_time: 25 penalty: 0 agent_num: 24 done: False
______________________
id: 46 reward: -0.026061776061776062 service_time: 1008 s_time: 54 penalty: 0 agent_num: 37 done: False
______________________
id: 41 reward: -0.022058823529411766 service_time: 1114 s_time: 42 penalty: 0 agent_num: 34 done: False
______________________
id: 49 reward: -0.004464285714285714 service_time: 1181 s_time: 7 penalty: 0 agent_num: 28 done: False
______________________
id: 54 reward: -0.013157894736842105 service_time: 1037 s_time: 28 penalty: 0 agent_num: 38 done: False
______________________
Step:  656
Pretraining Loss:  tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)
id: 51 reward: -0.058333333333333334 service_time: 712 s_time: 49 penalty: 0 agent_num: 15 done: False
______________________
id: 52 reward: 0.0 service_time: 598 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 40 reward: -0.0761904761904762 service_time: 767 s_time: 64 penalty: 0 agent_num: 15 done: False
______________________
id: 43 reward: -0.03459821428571429 service_time: 799 s_time: 31 penalty: 0 agent_num: 16 done: False
______________________
id: 50 reward: -0.06462585034013606 service_time: 994 s_time: 76 penalty: 0 agent_num: 21 done: False
______________________
id: 45 reward: 0.0 service_time: 1024 s_time: 0 penalty: 0 agent_num: 26 done: False
______________________
id: 46 reward: -0.014961389961389961 service_time: 1039 s_time: 31 penalty: 0 agent_num: 37 done: False
______________________
id: 47 reward: 0.017857142857142856 service_time: 1085 s_time: -24 penalty: 0 agent_num: 24 done: False
______________________
id: 55 reward: -0.014508928571428572 service_time: 1129 s_time: 26 penalty: 0 agent_num: 32 done: False
______________________
id: 49 reward: -0.024872448979591837 service_time: 1220 s_time: 39 penalty: 0 agent_num: 28 done: False
______________________
id: 44 reward: -0.013839285714285714 service_time: 1132 s_time: 31 penalty: 0 agent_num: 40 done: False
______________________
id: 42 reward: -0.046875 service_time: 1055 s_time: 63 penalty: 0 agent_num: 24 done: False
______________________
id: 53 reward: 0.002329192546583851 service_time: 1000 s_time: -3 penalty: 0 agent_num: 23 done: False
______________________
id: 41 reward: 0.0 service_time: 1114 s_time: 0 penalty: 0 agent_num: 34 done: False
______________________
id: 54 reward: -0.007988721804511278 service_time: 1054 s_time: 17 penalty: 0 agent_num: 38 done: False
______________________
id: 48 reward: -0.016666666666666666 service_time: 1188 s_time: 28 penalty: 0 agent_num: 30 done: False
______________________
Step:  672
Pretraining Loss:  tensor(0.0925, device='cuda:0', grad_fn=<MeanBackward0>)
id: 52 reward: -0.050824175824175824 service_time: 635 s_time: 37 penalty: 0 agent_num: 13 done: False
______________________
id: 51 reward: -0.11547619047619048 service_time: 809 s_time: 97 penalty: 0 agent_num: 15 done: False
______________________
id: 40 reward: -0.08928571428571429 service_time: 842 s_time: 75 penalty: 0 agent_num: 15 done: False
______________________
id: 43 reward: -0.027901785714285716 service_time: 824 s_time: 25 penalty: 0 agent_num: 16 done: False
______________________
id: 50 reward: 0.011054421768707483 service_time: 981 s_time: -13 penalty: 0 agent_num: 21 done: False
______________________
id: 47 reward: -0.025297619047619048 service_time: 1119 s_time: 34 penalty: 0 agent_num: 24 done: False
______________________
id: 41 reward: -0.009453781512605041 service_time: 1132 s_time: 18 penalty: 0 agent_num: 34 done: False
______________________
id: 54 reward: -0.020206766917293232 service_time: 1097 s_time: 43 penalty: 0 agent_num: 38 done: False
______________________
id: 45 reward: 0.011675824175824176 service_time: 1007 s_time: -17 penalty: 0 agent_num: 26 done: False
______________________
id: 55 reward: -0.022879464285714284 service_time: 1170 s_time: 41 penalty: 0 agent_num: 32 done: False
______________________
id: 46 reward: 0.0 service_time: 1039 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 48 reward: -0.023809523809523808 service_time: 1228 s_time: 40 penalty: 0 agent_num: 30 done: False
______________________
id: 49 reward: -0.0006377551020408163 service_time: 1221 s_time: 1 penalty: 0 agent_num: 28 done: False
______________________
id: 53 reward: -0.04813664596273292 service_time: 1062 s_time: 62 penalty: 0 agent_num: 23 done: False
______________________
id: 44 reward: -0.014732142857142857 service_time: 1165 s_time: 33 penalty: 0 agent_num: 40 done: False
______________________
id: 42 reward: -0.031994047619047616 service_time: 1098 s_time: 43 penalty: 0 agent_num: 24 done: False
______________________
Step:  688
Pretraining Loss:  tensor(0.0894, device='cuda:0', grad_fn=<MeanBackward0>)
id: 52 reward: -0.054945054945054944 service_time: 675 s_time: 40 penalty: 0 agent_num: 13 done: False
______________________
id: 51 reward: 0.036904761904761905 service_time: 778 s_time: -31 penalty: 0 agent_num: 15 done: False
______________________
id: 40 reward: -0.03333333333333333 service_time: 870 s_time: 28 penalty: 0 agent_num: 15 done: False
______________________
id: 43 reward: -0.04017857142857143 service_time: 860 s_time: 36 penalty: 0 agent_num: 16 done: False
______________________
id: 50 reward: 0.012755102040816327 service_time: 966 s_time: -15 penalty: 0 agent_num: 21 done: False
______________________
id: 53 reward: 0.018633540372670808 service_time: 1038 s_time: -24 penalty: 0 agent_num: 23 done: False
______________________
id: 47 reward: -0.05505952380952381 service_time: 1193 s_time: 74 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: -0.08722527472527472 service_time: 1134 s_time: 127 penalty: 0 agent_num: 26 done: False
______________________
id: 42 reward: -0.10863095238095238 service_time: 1244 s_time: 146 penalty: 0 agent_num: 24 done: False
______________________
id: 55 reward: -0.016741071428571428 service_time: 1200 s_time: 30 penalty: 0 agent_num: 32 done: False
______________________
id: 41 reward: -0.02888655462184874 service_time: 1187 s_time: 55 penalty: 0 agent_num: 34 done: False
______________________
id: 44 reward: 0.0 service_time: 1165 s_time: 0 penalty: 0 agent_num: 40 done: False
______________________
id: 46 reward: -0.024613899613899613 service_time: 1090 s_time: 51 penalty: 0 agent_num: 37 done: False
______________________
id: 49 reward: -0.019770408163265307 service_time: 1252 s_time: 31 penalty: 0 agent_num: 28 done: False
______________________
id: 54 reward: -0.006109022556390977 service_time: 1110 s_time: 13 penalty: 0 agent_num: 38 done: False
______________________
id: 48 reward: -0.015476190476190477 service_time: 1254 s_time: 26 penalty: 0 agent_num: 30 done: False
______________________
Step:  704
Pretraining Loss:  tensor(0.0815, device='cuda:0', grad_fn=<MeanBackward0>)
id: 52 reward: 0.0027472527472527475 service_time: 673 s_time: -2 penalty: 0 agent_num: 13 done: False
______________________
id: 51 reward: -0.05 service_time: 820 s_time: 42 penalty: 0 agent_num: 15 done: False
______________________
id: 40 reward: 0.04880952380952381 service_time: 829 s_time: -41 penalty: 0 agent_num: 15 done: False
______________________
id: 43 reward: -0.036830357142857144 service_time: 893 s_time: 33 penalty: 0 agent_num: 16 done: False
______________________
id: 53 reward: -0.03260869565217391 service_time: 1080 s_time: 42 penalty: 0 agent_num: 23 done: False
______________________
id: 50 reward: -0.034013605442176874 service_time: 1006 s_time: 40 penalty: 0 agent_num: 21 done: False
______________________
id: 47 reward: 0.013392857142857142 service_time: 1175 s_time: -18 penalty: 0 agent_num: 24 done: False
______________________
id: 49 reward: -0.0012755102040816326 service_time: 1254 s_time: 2 penalty: 0 agent_num: 28 done: False
______________________
id: 55 reward: -0.03515625 service_time: 1263 s_time: 63 penalty: 0 agent_num: 32 done: False
______________________
id: 54 reward: -0.010338345864661654 service_time: 1132 s_time: 22 penalty: 0 agent_num: 38 done: False
______________________
id: 46 reward: -0.0222007722007722 service_time: 1136 s_time: 46 penalty: 0 agent_num: 37 done: False
______________________
id: 44 reward: -0.034375 service_time: 1242 s_time: 77 penalty: 0 agent_num: 40 done: False
______________________
id: 48 reward: -0.023214285714285715 service_time: 1293 s_time: 39 penalty: 0 agent_num: 30 done: False
______________________
id: 41 reward: -0.019432773109243698 service_time: 1224 s_time: 37 penalty: 0 agent_num: 34 done: False
______________________
id: 45 reward: -0.05563186813186813 service_time: 1215 s_time: 81 penalty: 0 agent_num: 26 done: False
______________________
id: 42 reward: 0.006696428571428571 service_time: 1235 s_time: -9 penalty: 0 agent_num: 24 done: False
______________________
Step:  720
Pretraining Loss:  tensor(0.0833, device='cuda:0', grad_fn=<MeanBackward0>)
id: 52 reward: 0.0 service_time: 673 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 51 reward: -0.05952380952380952 service_time: 870 s_time: 50 penalty: 0 agent_num: 15 done: False
______________________
id: 43 reward: -0.06808035714285714 service_time: 954 s_time: 61 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: 0.02023809523809524 service_time: 812 s_time: -17 penalty: 0 agent_num: 15 done: False
______________________
id: 42 reward: 0.0 service_time: 1235 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 47 reward: 0.0 service_time: 1175 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 46 reward: -0.003861003861003861 service_time: 1144 s_time: 8 penalty: 0 agent_num: 37 done: False
______________________
id: 50 reward: 0.0 service_time: 1006 s_time: 0 penalty: 0 agent_num: 21 done: False
______________________
id: 49 reward: -0.03188775510204082 service_time: 1304 s_time: 50 penalty: 0 agent_num: 28 done: False
______________________
id: 53 reward: -0.019409937888198756 service_time: 1105 s_time: 25 penalty: 0 agent_num: 23 done: False
______________________
id: 48 reward: -0.005952380952380952 service_time: 1303 s_time: 10 penalty: 0 agent_num: 30 done: False
______________________
id: 45 reward: 0.019230769230769232 service_time: 1187 s_time: -28 penalty: 0 agent_num: 26 done: False
______________________
id: 44 reward: -0.01830357142857143 service_time: 1283 s_time: 41 penalty: 0 agent_num: 40 done: False
______________________
id: 54 reward: -0.01456766917293233 service_time: 1163 s_time: 31 penalty: 0 agent_num: 38 done: False
______________________
id: 55 reward: -0.030691964285714284 service_time: 1318 s_time: 55 penalty: 0 agent_num: 32 done: False
______________________
id: 41 reward: -0.02888655462184874 service_time: 1279 s_time: 55 penalty: 0 agent_num: 34 done: False
______________________
Step:  736
Pretraining Loss:  tensor(0.0769, device='cuda:0', grad_fn=<MeanBackward0>)
id: 52 reward: -0.03296703296703297 service_time: 697 s_time: 24 penalty: 0 agent_num: 13 done: False
______________________
id: 40 reward: 0.0 service_time: 812 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 51 reward: 0.02261904761904762 service_time: 851 s_time: -19 penalty: 0 agent_num: 15 done: False
______________________
id: 43 reward: -0.029017857142857144 service_time: 980 s_time: 26 penalty: 0 agent_num: 16 done: False
______________________
id: 49 reward: -0.021045918367346938 service_time: 1337 s_time: 33 penalty: 0 agent_num: 28 done: False
______________________
id: 45 reward: 0.015796703296703296 service_time: 1164 s_time: -23 penalty: 0 agent_num: 26 done: False
______________________
id: 50 reward: -0.027210884353741496 service_time: 1038 s_time: 32 penalty: 0 agent_num: 21 done: False
______________________
id: 47 reward: 0.00818452380952381 service_time: 1164 s_time: -11 penalty: 0 agent_num: 24 done: False
______________________
id: 53 reward: -0.09239130434782608 service_time: 1224 s_time: 119 penalty: 0 agent_num: 23 done: False
______________________
id: 55 reward: -0.018415178571428572 service_time: 1351 s_time: 33 penalty: 0 agent_num: 32 done: False
______________________
id: 48 reward: -0.030357142857142857 service_time: 1354 s_time: 51 penalty: 0 agent_num: 30 done: False
______________________
id: 46 reward: -0.018822393822393823 service_time: 1183 s_time: 39 penalty: 0 agent_num: 37 done: False
______________________
id: 41 reward: -0.008403361344537815 service_time: 1295 s_time: 16 penalty: 0 agent_num: 34 done: False
______________________
id: 44 reward: -0.004910714285714286 service_time: 1294 s_time: 11 penalty: 0 agent_num: 40 done: False
______________________
id: 54 reward: -0.009398496240601503 service_time: 1183 s_time: 20 penalty: 0 agent_num: 38 done: False
______________________
id: 42 reward: -0.058779761904761904 service_time: 1314 s_time: 79 penalty: 0 agent_num: 24 done: False
______________________
Step:  752
Pretraining Loss:  tensor(0.0814, device='cuda:0', grad_fn=<MeanBackward0>)
id: 40 reward: -0.04523809523809524 service_time: 850 s_time: 38 penalty: 0 agent_num: 15 done: False
______________________
id: 51 reward: -0.075 service_time: 914 s_time: 63 penalty: 0 agent_num: 15 done: False
______________________
id: 52 reward: -0.09203296703296704 service_time: 764 s_time: 67 penalty: 0 agent_num: 13 done: False
______________________
id: 43 reward: -0.09821428571428571 service_time: 1068 s_time: 88 penalty: 0 agent_num: 16 done: False
______________________
id: 45 reward: -0.09409340659340659 service_time: 1301 s_time: 137 penalty: 0 agent_num: 26 done: False
______________________
id: 50 reward: 0.02295918367346939 service_time: 1011 s_time: -27 penalty: 0 agent_num: 21 done: False
______________________
id: 47 reward: 0.0 service_time: 1164 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 48 reward: 0.0005952380952380953 service_time: 1353 s_time: -1 penalty: 0 agent_num: 30 done: False
______________________
id: 42 reward: -0.005208333333333333 service_time: 1321 s_time: 7 penalty: 0 agent_num: 24 done: False
______________________
id: 46 reward: -0.007722007722007722 service_time: 1199 s_time: 16 penalty: 0 agent_num: 37 done: False
______________________
id: 54 reward: -0.007048872180451127 service_time: 1198 s_time: 15 penalty: 0 agent_num: 38 done: False
______________________
id: 44 reward: -0.015178571428571428 service_time: 1328 s_time: 34 penalty: 0 agent_num: 40 done: False
______________________
id: 49 reward: -0.010841836734693877 service_time: 1354 s_time: 17 penalty: 0 agent_num: 28 done: False
______________________
id: 53 reward: -0.08074534161490683 service_time: 1328 s_time: 104 penalty: 0 agent_num: 23 done: False
______________________
id: 55 reward: -0.005580357142857143 service_time: 1361 s_time: 10 penalty: 0 agent_num: 32 done: False
______________________
id: 41 reward: -0.02415966386554622 service_time: 1341 s_time: 46 penalty: 0 agent_num: 34 done: False
______________________
Step:  768
Pretraining Loss:  tensor(0.0815, device='cuda:0', grad_fn=<MeanBackward0>)
id: 52 reward: 0.02197802197802198 service_time: 748 s_time: -16 penalty: 0 agent_num: 13 done: False
______________________
id: 40 reward: 0.0 service_time: 850 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 51 reward: -0.04880952380952381 service_time: 955 s_time: 41 penalty: 0 agent_num: 15 done: False
______________________
id: 43 reward: 0.0 service_time: 1068 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 47 reward: -0.017857142857142856 service_time: 1188 s_time: 24 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: 0.019917582417582416 service_time: 1272 s_time: -29 penalty: 0 agent_num: 26 done: False
______________________
id: 50 reward: 0.0008503401360544217 service_time: 1010 s_time: -1 penalty: 0 agent_num: 21 done: False
______________________
id: 53 reward: 0.019409937888198756 service_time: 1303 s_time: -25 penalty: 0 agent_num: 23 done: False
______________________
id: 49 reward: 0.01721938775510204 service_time: 1327 s_time: -27 penalty: 0 agent_num: 28 done: False
______________________
id: 55 reward: 0.0 service_time: 1361 s_time: 0 penalty: 0 agent_num: 32 done: False
______________________
id: 46 reward: -0.013996138996138996 service_time: 1228 s_time: 29 penalty: 0 agent_num: 37 done: False
______________________
id: 48 reward: -0.006547619047619048 service_time: 1364 s_time: 11 penalty: 0 agent_num: 30 done: False
______________________
id: 54 reward: -0.016917293233082706 service_time: 1234 s_time: 36 penalty: 0 agent_num: 38 done: False
______________________
id: 41 reward: -0.012605042016806723 service_time: 1365 s_time: 24 penalty: 0 agent_num: 34 done: False
______________________
id: 44 reward: 0.0 service_time: 1328 s_time: 0 penalty: 0 agent_num: 40 done: False
______________________
id: 42 reward: 0.0 service_time: 1321 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
Step:  784
Pretraining Loss:  tensor(0.0787, device='cuda:0', grad_fn=<MeanBackward0>)
id: 52 reward: 0.0 service_time: 748 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 40 reward: 0.0 service_time: 850 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 43 reward: 0.002232142857142857 service_time: 1066 s_time: -2 penalty: 0 agent_num: 16 done: False
______________________
id: 51 reward: -0.04642857142857143 service_time: 994 s_time: 39 penalty: 0 agent_num: 15 done: False
______________________
id: 50 reward: -0.02806122448979592 service_time: 1043 s_time: 33 penalty: 0 agent_num: 21 done: False
______________________
id: 47 reward: 0.001488095238095238 service_time: 1186 s_time: -2 penalty: 0 agent_num: 24 done: False
______________________
id: 53 reward: 0.0 service_time: 1303 s_time: 0 penalty: 0 agent_num: 23 done: False
______________________
id: 48 reward: 0.0 service_time: 1364 s_time: 0 penalty: 0 agent_num: 30 done: False
______________________
id: 45 reward: -0.038461538461538464 service_time: 1328 s_time: 56 penalty: 0 agent_num: 26 done: False
______________________
id: 54 reward: -0.00046992481203007516 service_time: 1235 s_time: 1 penalty: 0 agent_num: 38 done: False
______________________
id: 46 reward: 0.0 service_time: 1228 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 49 reward: 0.0012755102040816326 service_time: 1325 s_time: -2 penalty: 0 agent_num: 28 done: False
______________________
id: 42 reward: -0.043154761904761904 service_time: 1379 s_time: 58 penalty: 0 agent_num: 24 done: False
______________________
id: 44 reward: -0.0013392857142857143 service_time: 1331 s_time: 3 penalty: 0 agent_num: 40 done: False
______________________
id: 41 reward: 0.0 service_time: 1365 s_time: 0 penalty: 0 agent_num: 34 done: False
______________________
id: 55 reward: -0.022321428571428572 service_time: 1401 s_time: 40 penalty: 0 agent_num: 32 done: False
______________________
Step:  800
Pretraining Loss:  tensor(0.0760, device='cuda:0', grad_fn=<MeanBackward0>)
id: 51 reward: -0.034523809523809526 service_time: 1023 s_time: 29 penalty: 0 agent_num: 15 done: False
______________________
id: 52 reward: -0.10302197802197802 service_time: 823 s_time: 75 penalty: 0 agent_num: 13 done: False
______________________
id: 40 reward: -0.02857142857142857 service_time: 874 s_time: 24 penalty: 0 agent_num: 15 done: False
______________________
id: 43 reward: -0.04575892857142857 service_time: 1107 s_time: 41 penalty: 0 agent_num: 16 done: False
______________________
id: 47 reward: -0.047619047619047616 service_time: 1250 s_time: 64 penalty: 0 agent_num: 24 done: False
______________________
id: 50 reward: -0.08333333333333333 service_time: 1141 s_time: 98 penalty: 0 agent_num: 21 done: False
______________________
id: 48 reward: 0.0 service_time: 1364 s_time: 0 penalty: 0 agent_num: 30 done: False
______________________
id: 46 reward: 0.005308880308880309 service_time: 1217 s_time: -11 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: -0.10170807453416149 service_time: 1434 s_time: 131 penalty: 0 agent_num: 23 done: False
______________________
id: 55 reward: 0.0011160714285714285 service_time: 1399 s_time: -2 penalty: 0 agent_num: 32 done: False
______________________
id: 44 reward: 0.0004464285714285714 service_time: 1330 s_time: -1 penalty: 0 agent_num: 40 done: False
______________________
id: 49 reward: -0.0389030612244898 service_time: 1386 s_time: 61 penalty: 0 agent_num: 28 done: False
______________________
id: 54 reward: 0.0 service_time: 1235 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 42 reward: -0.04389880952380952 service_time: 1438 s_time: 59 penalty: 0 agent_num: 24 done: False
______________________
id: 41 reward: 0.0015756302521008404 service_time: 1362 s_time: -3 penalty: 0 agent_num: 34 done: False
______________________
id: 45 reward: -0.029532967032967032 service_time: 1371 s_time: 43 penalty: 0 agent_num: 26 done: False
______________________
Step:  816
Pretraining Loss:  tensor(0.0863, device='cuda:0', grad_fn=<MeanBackward0>)
id: 40 reward: -0.04880952380952381 service_time: 915 s_time: 41 penalty: 0 agent_num: 15 done: False
______________________
id: 43 reward: -0.07589285714285714 service_time: 1175 s_time: 68 penalty: 0 agent_num: 16 done: False
______________________
id: 51 reward: -0.06428571428571428 service_time: 1077 s_time: 54 penalty: 0 agent_num: 15 done: False
______________________
id: 52 reward: -0.09752747252747253 service_time: 894 s_time: 71 penalty: 0 agent_num: 13 done: False
______________________
id: 50 reward: -0.03826530612244898 service_time: 1186 s_time: 45 penalty: 0 agent_num: 21 done: False
______________________
id: 47 reward: -0.11011904761904762 service_time: 1398 s_time: 148 penalty: 0 agent_num: 24 done: False
______________________
id: 48 reward: 0.0 service_time: 1364 s_time: 0 penalty: 0 agent_num: 30 done: False
______________________
id: 53 reward: -0.05124223602484472 service_time: 1500 s_time: 66 penalty: 0 agent_num: 23 done: False
______________________
id: 54 reward: 0.0 service_time: 1235 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 41 reward: 0.0 service_time: 1362 s_time: 0 penalty: 0 agent_num: 34 done: False
______________________
id: 49 reward: 0.002551020408163265 service_time: 1382 s_time: -4 penalty: 0 agent_num: 28 done: False
______________________
id: 46 reward: 0.0 service_time: 1217 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 44 reward: 0.0 service_time: 1330 s_time: 0 penalty: 0 agent_num: 40 done: False
______________________
id: 42 reward: -0.04241071428571429 service_time: 1495 s_time: 57 penalty: 0 agent_num: 24 done: False
______________________
id: 55 reward: 0.005580357142857143 service_time: 1389 s_time: -10 penalty: 0 agent_num: 32 done: False
______________________
id: 45 reward: 0.0006868131868131869 service_time: 1370 s_time: -1 penalty: 0 agent_num: 26 done: False
______________________
Step:  832
Pretraining Loss:  tensor(0.0739, device='cuda:0', grad_fn=<MeanBackward0>)
id: 52 reward: -0.0782967032967033 service_time: 951 s_time: 57 penalty: 0 agent_num: 13 done: False
______________________
id: 40 reward: -0.11428571428571428 service_time: 1011 s_time: 96 penalty: 0 agent_num: 15 done: False
______________________
id: 43 reward: -0.05022321428571429 service_time: 1220 s_time: 45 penalty: 0 agent_num: 16 done: False
______________________
id: 50 reward: -0.11904761904761904 service_time: 1326 s_time: 140 penalty: 0 agent_num: 21 done: False
______________________
id: 41 reward: 0.004726890756302521 service_time: 1353 s_time: -9 penalty: 0 agent_num: 34 done: False
______________________
id: 55 reward: 0.0005580357142857143 service_time: 1388 s_time: -1 penalty: 0 agent_num: 32 done: False
______________________
id: 46 reward: 0.0 service_time: 1217 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 49 reward: 0.0 service_time: 1382 s_time: 0 penalty: 0 agent_num: 28 done: False
______________________
id: 51 reward: -0.10952380952380952 service_time: 1169 s_time: 92 penalty: 0 agent_num: 15 done: False
______________________
id: 44 reward: 0.0008928571428571428 service_time: 1328 s_time: -2 penalty: 0 agent_num: 40 done: False
______________________
id: 47 reward: 0.010416666666666666 service_time: 1384 s_time: -14 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: 0.0013736263736263737 service_time: 1368 s_time: -2 penalty: 0 agent_num: 26 done: False
______________________
id: 53 reward: 0.012422360248447204 service_time: 1484 s_time: -16 penalty: 0 agent_num: 23 done: False
______________________
id: 42 reward: 0.001488095238095238 service_time: 1493 s_time: -2 penalty: 0 agent_num: 24 done: False
______________________
id: 54 reward: 20.008928571428573 service_time: 1216 s_time: -19 penalty: 0 agent_num: 38 done: True
______________________
id: 48 reward: 20.001190476190477 service_time: 1362 s_time: -2 penalty: 0 agent_num: 30 done: True
______________________
Step:  848
Pretraining Loss:  tensor(0.0732, device='cuda:0', grad_fn=<MeanBackward0>)
id: 54 reward: -0.01917989417989418 service_time: 29 s_time: 29 penalty: 0 agent_num: 27 done: False
______________________
id: 52 reward: -0.06868131868131869 service_time: 1001 s_time: 50 penalty: 0 agent_num: 13 done: False
______________________
id: 43 reward: -0.08370535714285714 service_time: 1295 s_time: 75 penalty: 0 agent_num: 16 done: False
______________________
id: 53 reward: 0.003105590062111801 service_time: 1480 s_time: -4 penalty: 0 agent_num: 23 done: False
______________________
id: 50 reward: -0.05442176870748299 service_time: 1390 s_time: 64 penalty: 0 agent_num: 21 done: False
______________________
id: 51 reward: -0.07976190476190476 service_time: 1236 s_time: 67 penalty: 0 agent_num: 15 done: False
______________________
id: 47 reward: 0.0 service_time: 1384 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 40 reward: -0.09642857142857143 service_time: 1092 s_time: 81 penalty: 0 agent_num: 15 done: False
______________________
id: 41 reward: 0.0 service_time: 1353 s_time: 0 penalty: 0 agent_num: 34 done: False
______________________
id: 48 reward: -0.011054421768707483 service_time: 26 s_time: 26 penalty: 0 agent_num: 42 done: False
______________________
id: 46 reward: 0.0 service_time: 1217 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 55 reward: 0.006138392857142857 service_time: 1377 s_time: -11 penalty: 0 agent_num: 32 done: False
______________________
id: 49 reward: 0.0 service_time: 1382 s_time: 0 penalty: 0 agent_num: 28 done: False
______________________
id: 45 reward: 0.0 service_time: 1368 s_time: 0 penalty: 0 agent_num: 26 done: False
______________________
id: 42 reward: 0.000744047619047619 service_time: 1492 s_time: -1 penalty: 0 agent_num: 24 done: False
______________________
id: 44 reward: 20.00267857142857 service_time: 1322 s_time: -6 penalty: 0 agent_num: 40 done: True
______________________
Step:  864
Pretraining Loss:  tensor(0.0394, device='cuda:0', grad_fn=<MeanBackward0>)
id: 44 reward: -0.019642857142857142 service_time: 11 s_time: 11 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: -0.0869047619047619 service_time: 1309 s_time: 73 penalty: 0 agent_num: 15 done: False
______________________
id: 54 reward: 0.0 service_time: 29 s_time: 0 penalty: 0 agent_num: 27 done: False
______________________
id: 52 reward: -0.06593406593406594 service_time: 1049 s_time: 48 penalty: 0 agent_num: 13 done: False
______________________
id: 43 reward: -0.06808035714285714 service_time: 1356 s_time: 61 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: -0.16904761904761906 service_time: 1234 s_time: 142 penalty: 0 agent_num: 15 done: False
______________________
id: 55 reward: 0.0 service_time: 1377 s_time: 0 penalty: 0 agent_num: 32 done: False
______________________
id: 53 reward: 0.0 service_time: 1480 s_time: 0 penalty: 0 agent_num: 23 done: False
______________________
id: 41 reward: 0.0 service_time: 1353 s_time: 0 penalty: 0 agent_num: 34 done: False
______________________
id: 50 reward: -0.06037414965986394 service_time: 1461 s_time: 71 penalty: 0 agent_num: 21 done: False
______________________
id: 49 reward: 0.0 service_time: 1382 s_time: 0 penalty: 0 agent_num: 28 done: False
______________________
id: 48 reward: -0.013180272108843538 service_time: 57 s_time: 31 penalty: 0 agent_num: 42 done: False
______________________
id: 47 reward: 0.0 service_time: 1384 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 46 reward: 0.0 service_time: 1217 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 42 reward: 0.002232142857142857 service_time: 1489 s_time: -3 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: 20.0 service_time: 1368 s_time: 0 penalty: 0 agent_num: 26 done: True
______________________
Step:  880
Pretraining Loss:  tensor(0.0466, device='cuda:0', grad_fn=<MeanBackward0>)
id: 44 reward: -0.08928571428571429 service_time: 61 s_time: 50 penalty: 0 agent_num: 10 done: False
______________________
id: 52 reward: -0.12912087912087913 service_time: 1143 s_time: 94 penalty: 0 agent_num: 13 done: False
______________________
id: 51 reward: -0.07738095238095238 service_time: 1374 s_time: 65 penalty: 0 agent_num: 15 done: False
______________________
id: 54 reward: -0.023809523809523808 service_time: 65 s_time: 36 penalty: 0 agent_num: 27 done: False
______________________
id: 45 reward: -0.019387755102040816 service_time: 38 s_time: 38 penalty: 0 agent_num: 35 done: False
______________________
id: 43 reward: -0.07700892857142858 service_time: 1425 s_time: 69 penalty: 0 agent_num: 16 done: False
______________________
id: 53 reward: 0.0 service_time: 1480 s_time: 0 penalty: 0 agent_num: 23 done: False
______________________
id: 47 reward: 0.001488095238095238 service_time: 1382 s_time: -2 penalty: 0 agent_num: 24 done: False
______________________
id: 40 reward: -0.08452380952380953 service_time: 1305 s_time: 71 penalty: 0 agent_num: 15 done: False
______________________
id: 49 reward: 0.0 service_time: 1382 s_time: 0 penalty: 0 agent_num: 28 done: False
______________________
id: 42 reward: 0.0 service_time: 1489 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 48 reward: -0.013180272108843538 service_time: 88 s_time: 31 penalty: 0 agent_num: 42 done: False
______________________
id: 55 reward: 0.0 service_time: 1377 s_time: 0 penalty: 0 agent_num: 32 done: False
______________________
id: 50 reward: -0.15816326530612246 service_time: 1647 s_time: 186 penalty: 0 agent_num: 21 done: False
______________________
id: 41 reward: 20.002100840336134 service_time: 1349 s_time: -4 penalty: 0 agent_num: 34 done: True
______________________
id: 46 reward: 20.00096525096525 service_time: 1215 s_time: -2 penalty: 0 agent_num: 37 done: True
______________________
Step:  896
Pretraining Loss:  tensor(0.0448, device='cuda:0', grad_fn=<MeanBackward0>)
id: 52 reward: -0.0673076923076923 service_time: 1192 s_time: 49 penalty: 0 agent_num: 13 done: False
______________________
id: 41 reward: -0.04626623376623377 service_time: 57 s_time: 57 penalty: 0 agent_num: 22 done: False
______________________
id: 54 reward: -0.017857142857142856 service_time: 92 s_time: 27 penalty: 0 agent_num: 27 done: False
______________________
id: 51 reward: -0.058333333333333334 service_time: 1423 s_time: 49 penalty: 0 agent_num: 15 done: False
______________________
id: 40 reward: -0.14285714285714285 service_time: 1425 s_time: 120 penalty: 0 agent_num: 15 done: False
______________________
id: 43 reward: -0.06919642857142858 service_time: 1487 s_time: 62 penalty: 0 agent_num: 16 done: False
______________________
id: 45 reward: -0.01020408163265306 service_time: 58 s_time: 20 penalty: 0 agent_num: 35 done: False
______________________
id: 44 reward: -0.05714285714285714 service_time: 93 s_time: 32 penalty: 0 agent_num: 10 done: False
______________________
id: 48 reward: -0.008078231292517007 service_time: 107 s_time: 19 penalty: 0 agent_num: 42 done: False
______________________
id: 47 reward: 0.0 service_time: 1382 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 46 reward: -0.014751552795031056 service_time: 38 s_time: 38 penalty: 0 agent_num: 46 done: False
______________________
id: 42 reward: 0.0 service_time: 1489 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 49 reward: 0.0 service_time: 1382 s_time: 0 penalty: 0 agent_num: 28 done: False
______________________
id: 55 reward: 0.0 service_time: 1377 s_time: 0 penalty: 0 agent_num: 32 done: False
______________________
id: 50 reward: -0.06377551020408163 service_time: 1722 s_time: 75 penalty: 0 agent_num: 21 done: False
______________________
id: 53 reward: 20.001552795031056 service_time: 1478 s_time: -2 penalty: 0 agent_num: 23 done: True
______________________
Step:  912
Pretraining Loss:  tensor(0.0393, device='cuda:0', grad_fn=<MeanBackward0>)
id: 53 reward: -0.044642857142857144 service_time: 40 s_time: 40 penalty: 0 agent_num: 16 done: False
______________________
id: 52 reward: -0.06868131868131869 service_time: 1242 s_time: 50 penalty: 0 agent_num: 13 done: False
______________________
id: 51 reward: -0.0869047619047619 service_time: 1496 s_time: 73 penalty: 0 agent_num: 15 done: False
______________________
id: 41 reward: -0.005681818181818182 service_time: 64 s_time: 7 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: 0.0 service_time: 1382 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 54 reward: -0.015873015873015872 service_time: 116 s_time: 24 penalty: 0 agent_num: 27 done: False
______________________
id: 40 reward: -0.11071428571428571 service_time: 1518 s_time: 93 penalty: 0 agent_num: 15 done: False
______________________
id: 45 reward: 0.0 service_time: 58 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 44 reward: -0.048214285714285716 service_time: 120 s_time: 27 penalty: 0 agent_num: 10 done: False
______________________
id: 46 reward: -0.009704968944099378 service_time: 63 s_time: 25 penalty: 0 agent_num: 46 done: False
______________________
id: 55 reward: 0.0 service_time: 1377 s_time: 0 penalty: 0 agent_num: 32 done: False
______________________
id: 48 reward: -0.01488095238095238 service_time: 142 s_time: 35 penalty: 0 agent_num: 42 done: False
______________________
id: 43 reward: -0.18080357142857142 service_time: 1649 s_time: 162 penalty: 0 agent_num: 16 done: False
______________________
id: 50 reward: -0.141156462585034 service_time: 1888 s_time: 166 penalty: 0 agent_num: 21 done: False
______________________
id: 42 reward: 20.00297619047619 service_time: 1485 s_time: -4 penalty: 0 agent_num: 24 done: True
______________________
id: 49 reward: 20.00063775510204 service_time: 1381 s_time: -1 penalty: 0 agent_num: 28 done: True
______________________
Step:  928
Pretraining Loss:  tensor(0.0375, device='cuda:0', grad_fn=<MeanBackward0>)
id: 53 reward: -0.03459821428571429 service_time: 71 s_time: 31 penalty: 0 agent_num: 16 done: False
______________________
id: 41 reward: -0.03977272727272727 service_time: 113 s_time: 49 penalty: 0 agent_num: 22 done: False
______________________
id: 52 reward: -0.17994505494505494 service_time: 1373 s_time: 131 penalty: 0 agent_num: 13 done: False
______________________
id: 42 reward: -0.016534391534391533 service_time: 25 s_time: 25 penalty: 0 agent_num: 27 done: False
______________________
id: 54 reward: -0.01984126984126984 service_time: 146 s_time: 30 penalty: 0 agent_num: 27 done: False
______________________
id: 49 reward: -0.015306122448979591 service_time: 30 s_time: 30 penalty: 0 agent_num: 35 done: False
______________________
id: 40 reward: -0.09642857142857143 service_time: 1599 s_time: 81 penalty: 0 agent_num: 15 done: False
______________________
id: 51 reward: -0.07976190476190476 service_time: 1563 s_time: 67 penalty: 0 agent_num: 15 done: False
______________________
id: 44 reward: -0.07321428571428572 service_time: 161 s_time: 41 penalty: 0 agent_num: 10 done: False
______________________
id: 45 reward: -0.03520408163265306 service_time: 127 s_time: 69 penalty: 0 agent_num: 35 done: False
______________________
id: 46 reward: -0.009316770186335404 service_time: 87 s_time: 24 penalty: 0 agent_num: 46 done: False
______________________
id: 48 reward: -0.0017006802721088435 service_time: 146 s_time: 4 penalty: 0 agent_num: 42 done: False
______________________
id: 50 reward: 0.005952380952380952 service_time: 1881 s_time: -7 penalty: 0 agent_num: 21 done: False
______________________
id: 43 reward: -0.19977678571428573 service_time: 1828 s_time: 179 penalty: 0 agent_num: 16 done: False
______________________
id: 47 reward: 20.001488095238095 service_time: 1380 s_time: -2 penalty: 0 agent_num: 24 done: True
______________________
id: 55 reward: 20.000558035714285 service_time: 1376 s_time: -1 penalty: 0 agent_num: 32 done: True
______________________
Step:  944
Pretraining Loss:  tensor(0.0383, device='cuda:0', grad_fn=<MeanBackward0>)
id: 53 reward: -0.029017857142857144 service_time: 97 s_time: 26 penalty: 0 agent_num: 16 done: False
______________________
id: 47 reward: -0.013392857142857142 service_time: 12 s_time: 12 penalty: 0 agent_num: 16 done: False
______________________
id: 55 reward: -0.011363636363636364 service_time: 14 s_time: 14 penalty: 0 agent_num: 22 done: False
______________________
id: 42 reward: -0.004629629629629629 service_time: 32 s_time: 7 penalty: 0 agent_num: 27 done: False
______________________
id: 54 reward: -0.01917989417989418 service_time: 175 s_time: 29 penalty: 0 agent_num: 27 done: False
______________________
id: 43 reward: 0.002232142857142857 service_time: 1826 s_time: -2 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: -0.07738095238095238 service_time: 1664 s_time: 65 penalty: 0 agent_num: 15 done: False
______________________
id: 49 reward: -0.01479591836734694 service_time: 59 s_time: 29 penalty: 0 agent_num: 35 done: False
______________________
id: 51 reward: -0.27976190476190477 service_time: 1798 s_time: 235 penalty: 0 agent_num: 15 done: False
______________________
id: 44 reward: -0.023214285714285715 service_time: 174 s_time: 13 penalty: 0 agent_num: 10 done: False
______________________
id: 45 reward: -0.014285714285714285 service_time: 155 s_time: 28 penalty: 0 agent_num: 35 done: False
______________________
id: 52 reward: -0.08791208791208792 service_time: 1437 s_time: 64 penalty: 0 agent_num: 13 done: False
______________________
id: 41 reward: -0.028409090909090908 service_time: 148 s_time: 35 penalty: 0 agent_num: 22 done: False
______________________
id: 48 reward: -0.01445578231292517 service_time: 180 s_time: 34 penalty: 0 agent_num: 42 done: False
______________________
id: 46 reward: -0.01358695652173913 service_time: 122 s_time: 35 penalty: 0 agent_num: 46 done: False
______________________
id: 50 reward: 0.002551020408163265 service_time: 1878 s_time: -3 penalty: 0 agent_num: 21 done: False
______________________
Step:  960
Pretraining Loss:  tensor(0.0356, device='cuda:0', grad_fn=<MeanBackward0>)
id: 53 reward: -0.033482142857142856 service_time: 127 s_time: 30 penalty: 0 agent_num: 16 done: False
______________________
id: 47 reward: -0.03794642857142857 service_time: 46 s_time: 34 penalty: 0 agent_num: 16 done: False
______________________
id: 42 reward: -0.006613756613756613 service_time: 42 s_time: 10 penalty: 0 agent_num: 27 done: False
______________________
id: 55 reward: -0.024350649350649352 service_time: 44 s_time: 30 penalty: 0 agent_num: 22 done: False
______________________
id: 52 reward: -0.09340659340659341 service_time: 1505 s_time: 68 penalty: 0 agent_num: 13 done: False
______________________
id: 43 reward: 0.0 service_time: 1826 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 51 reward: -0.10476190476190476 service_time: 1886 s_time: 88 penalty: 0 agent_num: 15 done: False
______________________
id: 54 reward: -0.008597883597883597 service_time: 188 s_time: 13 penalty: 0 agent_num: 27 done: False
______________________
id: 44 reward: -0.0125 service_time: 181 s_time: 7 penalty: 0 agent_num: 10 done: False
______________________
id: 49 reward: -0.0066326530612244895 service_time: 72 s_time: 13 penalty: 0 agent_num: 35 done: False
______________________
id: 50 reward: 0.0017006802721088435 service_time: 1876 s_time: -2 penalty: 0 agent_num: 21 done: False
______________________
id: 45 reward: 0.0 service_time: 155 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.008078231292517007 service_time: 199 s_time: 19 penalty: 0 agent_num: 42 done: False
______________________
id: 46 reward: -0.007763975155279503 service_time: 142 s_time: 20 penalty: 0 agent_num: 46 done: False
______________________
id: 41 reward: -0.025162337662337664 service_time: 179 s_time: 31 penalty: 0 agent_num: 22 done: False
______________________
id: 40 reward: 20.007142857142856 service_time: 1658 s_time: -6 penalty: 0 agent_num: 15 done: True
______________________
Step:  976
Pretraining Loss:  tensor(0.0468, device='cuda:0', grad_fn=<MeanBackward0>)
id: 40 reward: -0.015037593984962405 service_time: 16 s_time: 16 penalty: 0 agent_num: 19 done: False
______________________
id: 47 reward: -0.030133928571428572 service_time: 73 s_time: 27 penalty: 0 agent_num: 16 done: False
______________________
id: 53 reward: -0.04352678571428571 service_time: 166 s_time: 39 penalty: 0 agent_num: 16 done: False
______________________
id: 54 reward: -0.007936507936507936 service_time: 200 s_time: 12 penalty: 0 agent_num: 27 done: False
______________________
id: 55 reward: -0.025162337662337664 service_time: 75 s_time: 31 penalty: 0 agent_num: 22 done: False
______________________
id: 43 reward: 0.012276785714285714 service_time: 1815 s_time: -11 penalty: 0 agent_num: 16 done: False
______________________
id: 42 reward: -0.013888888888888888 service_time: 63 s_time: 21 penalty: 0 agent_num: 27 done: False
______________________
id: 52 reward: -0.14148351648351648 service_time: 1608 s_time: 103 penalty: 0 agent_num: 13 done: False
______________________
id: 44 reward: -0.030357142857142857 service_time: 198 s_time: 17 penalty: 0 agent_num: 10 done: False
______________________
id: 49 reward: -0.010714285714285714 service_time: 93 s_time: 21 penalty: 0 agent_num: 35 done: False
______________________
id: 51 reward: 0.0011904761904761906 service_time: 1885 s_time: -1 penalty: 0 agent_num: 15 done: False
______________________
id: 45 reward: -0.02193877551020408 service_time: 198 s_time: 43 penalty: 0 agent_num: 35 done: False
______________________
id: 41 reward: -0.0349025974025974 service_time: 222 s_time: 43 penalty: 0 agent_num: 22 done: False
______________________
id: 48 reward: -0.012755102040816327 service_time: 229 s_time: 30 penalty: 0 agent_num: 42 done: False
______________________
id: 46 reward: 0.0 service_time: 142 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 50 reward: 0.0 service_time: 1876 s_time: 0 penalty: 0 agent_num: 21 done: False
______________________
Step:  992
Pretraining Loss:  tensor(0.0379, device='cuda:0', grad_fn=<MeanBackward0>)
id: 44 reward: -0.05357142857142857 service_time: 228 s_time: 30 penalty: 0 agent_num: 10 done: False
______________________
id: 40 reward: -0.017857142857142856 service_time: 35 s_time: 19 penalty: 0 agent_num: 19 done: False
______________________
id: 53 reward: -0.011160714285714286 service_time: 176 s_time: 10 penalty: 0 agent_num: 16 done: False
______________________
id: 47 reward: 0.0 service_time: 73 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 51 reward: 0.0 service_time: 1885 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 42 reward: -0.010582010582010581 service_time: 79 s_time: 16 penalty: 0 agent_num: 27 done: False
______________________
id: 55 reward: -0.028409090909090908 service_time: 110 s_time: 35 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: -0.01173469387755102 service_time: 116 s_time: 23 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: -0.013227513227513227 service_time: 220 s_time: 20 penalty: 0 agent_num: 27 done: False
______________________
id: 50 reward: 0.006802721088435374 service_time: 1868 s_time: -8 penalty: 0 agent_num: 21 done: False
______________________
id: 52 reward: -0.16346153846153846 service_time: 1727 s_time: 119 penalty: 0 agent_num: 13 done: False
______________________
id: 45 reward: -0.007653061224489796 service_time: 213 s_time: 15 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: 0.0 service_time: 229 s_time: 0 penalty: 0 agent_num: 42 done: False
______________________
id: 41 reward: -0.017045454545454544 service_time: 243 s_time: 21 penalty: 0 agent_num: 22 done: False
______________________
id: 46 reward: -0.007375776397515528 service_time: 161 s_time: 19 penalty: 0 agent_num: 46 done: False
______________________
id: 43 reward: 20.002232142857142 service_time: 1813 s_time: -2 penalty: 0 agent_num: 16 done: True
______________________
Step:  1008
Pretraining Loss:  tensor(0.0382, device='cuda:0', grad_fn=<MeanBackward0>)
id: 44 reward: -0.10892857142857143 service_time: 289 s_time: 61 penalty: 0 agent_num: 10 done: False
______________________
id: 47 reward: -0.046875 service_time: 115 s_time: 42 penalty: 0 agent_num: 16 done: False
______________________
id: 53 reward: -0.04799107142857143 service_time: 219 s_time: 43 penalty: 0 agent_num: 16 done: False
______________________
id: 42 reward: -0.02513227513227513 service_time: 117 s_time: 38 penalty: 0 agent_num: 27 done: False
______________________
id: 40 reward: -0.022556390977443608 service_time: 59 s_time: 24 penalty: 0 agent_num: 19 done: False
______________________
id: 51 reward: 0.0 service_time: 1885 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 49 reward: -0.005612244897959183 service_time: 127 s_time: 11 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: -0.018518518518518517 service_time: 248 s_time: 28 penalty: 0 agent_num: 27 done: False
______________________
id: 52 reward: -0.17445054945054944 service_time: 1854 s_time: 127 penalty: 0 agent_num: 13 done: False
______________________
id: 55 reward: 0.0 service_time: 110 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 45 reward: -0.009693877551020408 service_time: 232 s_time: 19 penalty: 0 agent_num: 35 done: False
______________________
id: 43 reward: -0.036224489795918365 service_time: 71 s_time: 71 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.008078231292517007 service_time: 248 s_time: 19 penalty: 0 agent_num: 42 done: False
______________________
id: 41 reward: -0.027597402597402596 service_time: 277 s_time: 34 penalty: 0 agent_num: 22 done: False
______________________
id: 46 reward: -0.01746894409937888 service_time: 206 s_time: 45 penalty: 0 agent_num: 46 done: False
______________________
id: 50 reward: 0.0 service_time: 1868 s_time: 0 penalty: 0 agent_num: 21 done: False
______________________
Step:  1024
Pretraining Loss:  tensor(0.0421, device='cuda:0', grad_fn=<MeanBackward0>)
id: 44 reward: 0.0 service_time: 289 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 47 reward: -0.03236607142857143 service_time: 144 s_time: 29 penalty: 0 agent_num: 16 done: False
______________________
id: 53 reward: -0.03571428571428571 service_time: 251 s_time: 32 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: -0.012218045112781954 service_time: 72 s_time: 13 penalty: 0 agent_num: 19 done: False
______________________
id: 42 reward: 0.0 service_time: 117 s_time: 0 penalty: 0 agent_num: 27 done: False
______________________
id: 51 reward: 0.0 service_time: 1885 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 54 reward: -0.01917989417989418 service_time: 277 s_time: 29 penalty: 0 agent_num: 27 done: False
______________________
id: 50 reward: 0.0008503401360544217 service_time: 1867 s_time: -1 penalty: 0 agent_num: 21 done: False
______________________
id: 49 reward: -0.009693877551020408 service_time: 146 s_time: 19 penalty: 0 agent_num: 35 done: False
______________________
id: 45 reward: 0.0 service_time: 232 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 43 reward: -0.01173469387755102 service_time: 94 s_time: 23 penalty: 0 agent_num: 35 done: False
______________________
id: 46 reward: 0.0011645962732919255 service_time: 203 s_time: -3 penalty: 0 agent_num: 46 done: False
______________________
id: 48 reward: -0.029336734693877552 service_time: 317 s_time: 69 penalty: 0 agent_num: 42 done: False
______________________
id: 52 reward: -0.1401098901098901 service_time: 1956 s_time: 102 penalty: 0 agent_num: 13 done: False
______________________
id: 41 reward: -0.033279220779220776 service_time: 318 s_time: 41 penalty: 0 agent_num: 22 done: False
______________________
id: 55 reward: -0.05844155844155844 service_time: 182 s_time: 72 penalty: 0 agent_num: 22 done: False
______________________
Step:  1040
Pretraining Loss:  tensor(0.0420, device='cuda:0', grad_fn=<MeanBackward0>)
id: 47 reward: 0.0 service_time: 144 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 44 reward: 0.0 service_time: 289 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 53 reward: -0.03236607142857143 service_time: 280 s_time: 29 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: -0.020676691729323307 service_time: 94 s_time: 22 penalty: 0 agent_num: 19 done: False
______________________
id: 42 reward: -0.026455026455026454 service_time: 157 s_time: 40 penalty: 0 agent_num: 27 done: False
______________________
id: 52 reward: -0.0013736263736263737 service_time: 1957 s_time: 1 penalty: 0 agent_num: 13 done: False
______________________
id: 49 reward: -0.013775510204081633 service_time: 173 s_time: 27 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: 0.0 service_time: 277 s_time: 0 penalty: 0 agent_num: 27 done: False
______________________
id: 55 reward: 0.018668831168831168 service_time: 159 s_time: -23 penalty: 0 agent_num: 22 done: False
______________________
id: 43 reward: -0.009183673469387756 service_time: 112 s_time: 18 penalty: 0 agent_num: 35 done: False
______________________
id: 45 reward: -0.029081632653061223 service_time: 289 s_time: 57 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.01403061224489796 service_time: 350 s_time: 33 penalty: 0 agent_num: 42 done: False
______________________
id: 46 reward: -0.01436335403726708 service_time: 240 s_time: 37 penalty: 0 agent_num: 46 done: False
______________________
id: 41 reward: -0.027597402597402596 service_time: 352 s_time: 34 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: 20.0 service_time: 1885 s_time: 0 penalty: 0 agent_num: 15 done: True
______________________
id: 50 reward: 20.0 service_time: 1867 s_time: 0 penalty: 0 agent_num: 21 done: True
______________________
Step:  1056
Pretraining Loss:  tensor(0.0480, device='cuda:0', grad_fn=<MeanBackward0>)
id: 51 reward: -0.0633116883116883 service_time: 39 s_time: 39 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: 0.04285714285714286 service_time: 265 s_time: -24 penalty: 0 agent_num: 10 done: False
______________________
id: 47 reward: -0.03125 service_time: 172 s_time: 28 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: -0.043233082706766915 service_time: 140 s_time: 46 penalty: 0 agent_num: 19 done: False
______________________
id: 53 reward: -0.052455357142857144 service_time: 327 s_time: 47 penalty: 0 agent_num: 16 done: False
______________________
id: 42 reward: -0.011243386243386243 service_time: 174 s_time: 17 penalty: 0 agent_num: 27 done: False
______________________
id: 50 reward: -0.011083743842364532 service_time: 18 s_time: 18 penalty: 0 agent_num: 29 done: False
______________________
id: 55 reward: -0.008928571428571428 service_time: 170 s_time: 11 penalty: 0 agent_num: 22 done: False
______________________
id: 45 reward: -0.015306122448979591 service_time: 319 s_time: 30 penalty: 0 agent_num: 35 done: False
______________________
id: 49 reward: -0.009693877551020408 service_time: 192 s_time: 19 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: -0.047619047619047616 service_time: 349 s_time: 72 penalty: 0 agent_num: 27 done: False
______________________
id: 46 reward: 0.0 service_time: 240 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 43 reward: 0.0 service_time: 112 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 52 reward: 0.005494505494505495 service_time: 1953 s_time: -4 penalty: 0 agent_num: 13 done: False
______________________
id: 48 reward: 0.0 service_time: 350 s_time: 0 penalty: 0 agent_num: 42 done: False
______________________
id: 41 reward: -0.020292207792207792 service_time: 377 s_time: 25 penalty: 0 agent_num: 22 done: False
______________________
Step:  1072
Pretraining Loss:  tensor(0.0400, device='cuda:0', grad_fn=<MeanBackward0>)
id: 51 reward: -0.04383116883116883 service_time: 66 s_time: 27 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: -0.07857142857142857 service_time: 309 s_time: 44 penalty: 0 agent_num: 10 done: False
______________________
id: 53 reward: -0.016741071428571428 service_time: 342 s_time: 15 penalty: 0 agent_num: 16 done: False
______________________
id: 47 reward: -0.018973214285714284 service_time: 189 s_time: 17 penalty: 0 agent_num: 16 done: False
______________________
id: 50 reward: -0.017241379310344827 service_time: 46 s_time: 28 penalty: 0 agent_num: 29 done: False
______________________
id: 55 reward: -0.021103896103896104 service_time: 196 s_time: 26 penalty: 0 agent_num: 22 done: False
______________________
id: 40 reward: -0.05263157894736842 service_time: 196 s_time: 56 penalty: 0 agent_num: 19 done: False
______________________
id: 54 reward: -0.017195767195767195 service_time: 375 s_time: 26 penalty: 0 agent_num: 27 done: False
______________________
id: 42 reward: -0.018518518518518517 service_time: 202 s_time: 28 penalty: 0 agent_num: 27 done: False
______________________
id: 49 reward: -0.013265306122448979 service_time: 218 s_time: 26 penalty: 0 agent_num: 35 done: False
______________________
id: 45 reward: -0.009693877551020408 service_time: 338 s_time: 19 penalty: 0 agent_num: 35 done: False
______________________
id: 46 reward: -0.0034937888198757765 service_time: 249 s_time: 9 penalty: 0 agent_num: 46 done: False
______________________
id: 48 reward: -0.017431972789115645 service_time: 391 s_time: 41 penalty: 0 agent_num: 42 done: False
______________________
id: 43 reward: -0.01683673469387755 service_time: 145 s_time: 33 penalty: 0 agent_num: 35 done: False
______________________
id: 41 reward: -0.00974025974025974 service_time: 389 s_time: 12 penalty: 0 agent_num: 22 done: False
______________________
id: 52 reward: 0.0027472527472527475 service_time: 1951 s_time: -2 penalty: 0 agent_num: 13 done: False
______________________
Step:  1088
Pretraining Loss:  tensor(0.0464, device='cuda:0', grad_fn=<MeanBackward0>)
id: 51 reward: -0.022727272727272728 service_time: 80 s_time: 14 penalty: 0 agent_num: 11 done: False
______________________
id: 53 reward: 0.005580357142857143 service_time: 337 s_time: -5 penalty: 0 agent_num: 16 done: False
______________________
id: 47 reward: -0.013392857142857142 service_time: 201 s_time: 12 penalty: 0 agent_num: 16 done: False
______________________
id: 44 reward: 0.0 service_time: 309 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 40 reward: 0.0 service_time: 196 s_time: 0 penalty: 0 agent_num: 19 done: False
______________________
id: 50 reward: 0.0 service_time: 46 s_time: 0 penalty: 0 agent_num: 29 done: False
______________________
id: 42 reward: -0.012566137566137565 service_time: 221 s_time: 19 penalty: 0 agent_num: 27 done: False
______________________
id: 49 reward: 0.0 service_time: 218 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 55 reward: -0.025162337662337664 service_time: 227 s_time: 31 penalty: 0 agent_num: 22 done: False
______________________
id: 45 reward: -0.00816326530612245 service_time: 354 s_time: 16 penalty: 0 agent_num: 35 done: False
______________________
id: 52 reward: 0.0 service_time: 1951 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 54 reward: 0.0 service_time: 375 s_time: 0 penalty: 0 agent_num: 27 done: False
______________________
id: 46 reward: -0.012422360248447204 service_time: 281 s_time: 32 penalty: 0 agent_num: 46 done: False
______________________
id: 43 reward: 0.0 service_time: 145 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.008928571428571428 service_time: 412 s_time: 21 penalty: 0 agent_num: 42 done: False
______________________
id: 41 reward: -0.02353896103896104 service_time: 418 s_time: 29 penalty: 0 agent_num: 22 done: False
______________________
Step:  1104
Pretraining Loss:  tensor(0.0414, device='cuda:0', grad_fn=<MeanBackward0>)
id: 51 reward: -0.021103896103896104 service_time: 93 s_time: 13 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: 0.0035714285714285713 service_time: 307 s_time: -2 penalty: 0 agent_num: 10 done: False
______________________
id: 53 reward: -0.10825892857142858 service_time: 434 s_time: 97 penalty: 0 agent_num: 16 done: False
______________________
id: 47 reward: 0.0 service_time: 201 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 42 reward: -0.01917989417989418 service_time: 250 s_time: 29 penalty: 0 agent_num: 27 done: False
______________________
id: 55 reward: -0.012987012987012988 service_time: 243 s_time: 16 penalty: 0 agent_num: 22 done: False
______________________
id: 41 reward: 0.0 service_time: 418 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: -0.026530612244897958 service_time: 270 s_time: 52 penalty: 0 agent_num: 35 done: False
______________________
id: 50 reward: -0.0332512315270936 service_time: 100 s_time: 54 penalty: 0 agent_num: 29 done: False
______________________
id: 54 reward: -0.02513227513227513 service_time: 413 s_time: 38 penalty: 0 agent_num: 27 done: False
______________________
id: 40 reward: -0.03477443609022556 service_time: 233 s_time: 37 penalty: 0 agent_num: 19 done: False
______________________
id: 45 reward: 0.0 service_time: 354 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 46 reward: -0.006211180124223602 service_time: 297 s_time: 16 penalty: 0 agent_num: 46 done: False
______________________
id: 43 reward: -0.027551020408163266 service_time: 199 s_time: 54 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: 0.00042517006802721087 service_time: 411 s_time: -1 penalty: 0 agent_num: 42 done: False
______________________
id: 52 reward: 0.0 service_time: 1951 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
Step:  1120
Pretraining Loss:  tensor(0.0476, device='cuda:0', grad_fn=<MeanBackward0>)
id: 51 reward: 0.0 service_time: 93 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: -0.03236607142857143 service_time: 230 s_time: 29 penalty: 0 agent_num: 16 done: False
______________________
id: 44 reward: -0.0375 service_time: 328 s_time: 21 penalty: 0 agent_num: 10 done: False
______________________
id: 53 reward: -0.05803571428571429 service_time: 486 s_time: 52 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: 0.0 service_time: 233 s_time: 0 penalty: 0 agent_num: 19 done: False
______________________
id: 55 reward: -0.025162337662337664 service_time: 274 s_time: 31 penalty: 0 agent_num: 22 done: False
______________________
id: 42 reward: 0.0 service_time: 250 s_time: 0 penalty: 0 agent_num: 27 done: False
______________________
id: 50 reward: -0.009236453201970444 service_time: 115 s_time: 15 penalty: 0 agent_num: 29 done: False
______________________
id: 49 reward: -0.014285714285714285 service_time: 298 s_time: 28 penalty: 0 agent_num: 35 done: False
______________________
id: 41 reward: -0.04626623376623377 service_time: 475 s_time: 57 penalty: 0 agent_num: 22 done: False
______________________
id: 45 reward: -0.0326530612244898 service_time: 418 s_time: 64 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: -0.005291005291005291 service_time: 421 s_time: 8 penalty: 0 agent_num: 27 done: False
______________________
id: 46 reward: -0.006987577639751553 service_time: 315 s_time: 18 penalty: 0 agent_num: 46 done: False
______________________
id: 43 reward: -0.020918367346938777 service_time: 240 s_time: 41 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.021683673469387755 service_time: 462 s_time: 51 penalty: 0 agent_num: 42 done: False
______________________
id: 52 reward: 20.0 service_time: 1951 s_time: 0 penalty: 0 agent_num: 13 done: True
______________________
Step:  1136
Pretraining Loss:  tensor(0.0491, device='cuda:0', grad_fn=<MeanBackward0>)
id: 51 reward: -0.05032467532467533 service_time: 124 s_time: 31 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: 0.055357142857142855 service_time: 297 s_time: -31 penalty: 0 agent_num: 10 done: False
______________________
id: 47 reward: -0.029017857142857144 service_time: 256 s_time: 26 penalty: 0 agent_num: 16 done: False
______________________
id: 52 reward: -0.01521164021164021 service_time: 23 s_time: 23 penalty: 0 agent_num: 27 done: False
______________________
id: 53 reward: 0.0 service_time: 486 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 41 reward: -0.021103896103896104 service_time: 501 s_time: 26 penalty: 0 agent_num: 22 done: False
______________________
id: 42 reward: -0.03835978835978836 service_time: 308 s_time: 58 penalty: 0 agent_num: 27 done: False
______________________
id: 54 reward: -0.022486772486772486 service_time: 455 s_time: 34 penalty: 0 agent_num: 27 done: False
______________________
id: 50 reward: -0.034482758620689655 service_time: 171 s_time: 56 penalty: 0 agent_num: 29 done: False
______________________
id: 55 reward: -0.021103896103896104 service_time: 300 s_time: 26 penalty: 0 agent_num: 22 done: False
______________________
id: 43 reward: -0.01020408163265306 service_time: 260 s_time: 20 penalty: 0 agent_num: 35 done: False
______________________
id: 49 reward: -0.02295918367346939 service_time: 343 s_time: 45 penalty: 0 agent_num: 35 done: False
______________________
id: 46 reward: -0.01048136645962733 service_time: 342 s_time: 27 penalty: 0 agent_num: 46 done: False
______________________
id: 40 reward: -0.046052631578947366 service_time: 282 s_time: 49 penalty: 0 agent_num: 19 done: False
______________________
id: 45 reward: -0.02040816326530612 service_time: 458 s_time: 40 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.011904761904761904 service_time: 490 s_time: 28 penalty: 0 agent_num: 42 done: False
______________________
Step:  1152
Pretraining Loss:  tensor(0.0443, device='cuda:0', grad_fn=<MeanBackward0>)
id: 51 reward: -0.03571428571428571 service_time: 146 s_time: 22 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: 0.005357142857142857 service_time: 294 s_time: -3 penalty: 0 agent_num: 10 done: False
______________________
id: 47 reward: 0.0 service_time: 256 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 52 reward: -0.017857142857142856 service_time: 50 s_time: 27 penalty: 0 agent_num: 27 done: False
______________________
id: 40 reward: -0.046052631578947366 service_time: 331 s_time: 49 penalty: 0 agent_num: 19 done: False
______________________
id: 54 reward: 0.0033068783068783067 service_time: 450 s_time: -5 penalty: 0 agent_num: 27 done: False
______________________
id: 55 reward: -0.013798701298701298 service_time: 317 s_time: 17 penalty: 0 agent_num: 22 done: False
______________________
id: 42 reward: -0.010582010582010581 service_time: 324 s_time: 16 penalty: 0 agent_num: 27 done: False
______________________
id: 49 reward: 0.0 service_time: 343 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 53 reward: -0.10491071428571429 service_time: 580 s_time: 94 penalty: 0 agent_num: 16 done: False
______________________
id: 50 reward: -0.01293103448275862 service_time: 192 s_time: 21 penalty: 0 agent_num: 29 done: False
______________________
id: 45 reward: -0.013775510204081633 service_time: 485 s_time: 27 penalty: 0 agent_num: 35 done: False
______________________
id: 41 reward: -0.00974025974025974 service_time: 513 s_time: 12 penalty: 0 agent_num: 22 done: False
______________________
id: 43 reward: -0.017857142857142856 service_time: 295 s_time: 35 penalty: 0 agent_num: 35 done: False
______________________
id: 46 reward: -0.01125776397515528 service_time: 371 s_time: 29 penalty: 0 agent_num: 46 done: False
______________________
id: 48 reward: -0.01488095238095238 service_time: 525 s_time: 35 penalty: 0 agent_num: 42 done: False
______________________
Step:  1168
Pretraining Loss:  tensor(0.0464, device='cuda:0', grad_fn=<MeanBackward0>)
id: 51 reward: 0.0 service_time: 146 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: 0.0 service_time: 256 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 44 reward: 0.0017857142857142857 service_time: 293 s_time: -1 penalty: 0 agent_num: 10 done: False
______________________
id: 52 reward: -0.03042328042328042 service_time: 96 s_time: 46 penalty: 0 agent_num: 27 done: False
______________________
id: 55 reward: -0.021103896103896104 service_time: 343 s_time: 26 penalty: 0 agent_num: 22 done: False
______________________
id: 42 reward: -0.03505291005291005 service_time: 377 s_time: 53 penalty: 0 agent_num: 27 done: False
______________________
id: 50 reward: -0.012315270935960592 service_time: 212 s_time: 20 penalty: 0 agent_num: 29 done: False
______________________
id: 41 reward: -0.015422077922077922 service_time: 532 s_time: 19 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: -0.030612244897959183 service_time: 403 s_time: 60 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: -0.04431216931216931 service_time: 517 s_time: 67 penalty: 0 agent_num: 27 done: False
______________________
id: 43 reward: -0.01683673469387755 service_time: 328 s_time: 33 penalty: 0 agent_num: 35 done: False
______________________
id: 45 reward: 0.0 service_time: 485 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 46 reward: -0.010093167701863354 service_time: 397 s_time: 26 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: -0.05133928571428571 service_time: 626 s_time: 46 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: -0.03665413533834586 service_time: 370 s_time: 39 penalty: 0 agent_num: 19 done: False
______________________
id: 48 reward: -0.01445578231292517 service_time: 559 s_time: 34 penalty: 0 agent_num: 42 done: False
______________________
Step:  1184
Pretraining Loss:  tensor(0.0527, device='cuda:0', grad_fn=<MeanBackward0>)
id: 51 reward: -0.07142857142857142 service_time: 190 s_time: 44 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: 0.0 service_time: 293 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 47 reward: -0.049107142857142856 service_time: 300 s_time: 44 penalty: 0 agent_num: 16 done: False
______________________
id: 53 reward: 0.03571428571428571 service_time: 594 s_time: -32 penalty: 0 agent_num: 16 done: False
______________________
id: 55 reward: -0.03409090909090909 service_time: 385 s_time: 42 penalty: 0 agent_num: 22 done: False
______________________
id: 50 reward: -0.010467980295566502 service_time: 229 s_time: 17 penalty: 0 agent_num: 29 done: False
______________________
id: 40 reward: -0.014097744360902255 service_time: 385 s_time: 15 penalty: 0 agent_num: 19 done: False
______________________
id: 54 reward: -0.015873015873015872 service_time: 541 s_time: 24 penalty: 0 agent_num: 27 done: False
______________________
id: 45 reward: -0.022448979591836733 service_time: 529 s_time: 44 penalty: 0 agent_num: 35 done: False
______________________
id: 52 reward: -0.011243386243386243 service_time: 113 s_time: 17 penalty: 0 agent_num: 27 done: False
______________________
id: 49 reward: -0.009183673469387756 service_time: 421 s_time: 18 penalty: 0 agent_num: 35 done: False
______________________
id: 43 reward: 0.0 service_time: 328 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 42 reward: -0.008597883597883597 service_time: 390 s_time: 13 penalty: 0 agent_num: 27 done: False
______________________
id: 41 reward: -0.032467532467532464 service_time: 572 s_time: 40 penalty: 0 agent_num: 22 done: False
______________________
id: 48 reward: -0.007653061224489796 service_time: 577 s_time: 18 penalty: 0 agent_num: 42 done: False
______________________
id: 46 reward: 0.0 service_time: 397 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
Step:  1200
Pretraining Loss:  tensor(0.0464, device='cuda:0', grad_fn=<MeanBackward0>)
id: 44 reward: -0.06428571428571428 service_time: 329 s_time: 36 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: -0.024350649350649352 service_time: 205 s_time: 15 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: 0.0 service_time: 300 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 50 reward: -0.019088669950738917 service_time: 260 s_time: 31 penalty: 0 agent_num: 29 done: False
______________________
id: 53 reward: 0.04017857142857143 service_time: 558 s_time: -36 penalty: 0 agent_num: 16 done: False
______________________
id: 55 reward: -0.03409090909090909 service_time: 427 s_time: 42 penalty: 0 agent_num: 22 done: False
______________________
id: 41 reward: -0.016233766233766232 service_time: 592 s_time: 20 penalty: 0 agent_num: 22 done: False
______________________
id: 54 reward: -0.017857142857142856 service_time: 568 s_time: 27 penalty: 0 agent_num: 27 done: False
______________________
id: 52 reward: 0.0 service_time: 113 s_time: 0 penalty: 0 agent_num: 27 done: False
______________________
id: 42 reward: -0.01984126984126984 service_time: 420 s_time: 30 penalty: 0 agent_num: 27 done: False
______________________
id: 49 reward: -0.015816326530612244 service_time: 452 s_time: 31 penalty: 0 agent_num: 35 done: False
______________________
id: 45 reward: -0.01479591836734694 service_time: 558 s_time: 29 penalty: 0 agent_num: 35 done: False
______________________
id: 46 reward: -0.016304347826086956 service_time: 439 s_time: 42 penalty: 0 agent_num: 46 done: False
______________________
id: 48 reward: 0.0 service_time: 577 s_time: 0 penalty: 0 agent_num: 42 done: False
______________________
id: 43 reward: -0.034183673469387756 service_time: 395 s_time: 67 penalty: 0 agent_num: 35 done: False
______________________
id: 40 reward: -0.05639097744360902 service_time: 445 s_time: 60 penalty: 0 agent_num: 19 done: False
______________________
Step:  1216
Pretraining Loss:  tensor(0.0505, device='cuda:0', grad_fn=<MeanBackward0>)
id: 44 reward: 0.0 service_time: 329 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 47 reward: -0.03571428571428571 service_time: 332 s_time: 32 penalty: 0 agent_num: 16 done: False
______________________
id: 53 reward: 0.029017857142857144 service_time: 532 s_time: -26 penalty: 0 agent_num: 16 done: False
______________________
id: 50 reward: -0.017241379310344827 service_time: 288 s_time: 28 penalty: 0 agent_num: 29 done: False
______________________
id: 54 reward: -0.021164021164021163 service_time: 600 s_time: 32 penalty: 0 agent_num: 27 done: False
______________________
id: 55 reward: -0.02922077922077922 service_time: 463 s_time: 36 penalty: 0 agent_num: 22 done: False
______________________
id: 40 reward: -0.02443609022556391 service_time: 471 s_time: 26 penalty: 0 agent_num: 19 done: False
______________________
id: 45 reward: 0.0020408163265306124 service_time: 554 s_time: -4 penalty: 0 agent_num: 35 done: False
______________________
id: 43 reward: 0.0 service_time: 395 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 52 reward: -0.02513227513227513 service_time: 151 s_time: 38 penalty: 0 agent_num: 27 done: False
______________________
id: 48 reward: -0.0233843537414966 service_time: 632 s_time: 55 penalty: 0 agent_num: 42 done: False
______________________
id: 46 reward: -0.008928571428571428 service_time: 462 s_time: 23 penalty: 0 agent_num: 46 done: False
______________________
id: 49 reward: -0.005612244897959183 service_time: 463 s_time: 11 penalty: 0 agent_num: 35 done: False
______________________
id: 42 reward: -0.027777777777777776 service_time: 462 s_time: 42 penalty: 0 agent_num: 27 done: False
______________________
id: 41 reward: -0.03977272727272727 service_time: 641 s_time: 49 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: -0.12824675324675325 service_time: 284 s_time: 79 penalty: 0 agent_num: 11 done: False
______________________
Step:  1232
Pretraining Loss:  tensor(0.0537, device='cuda:0', grad_fn=<MeanBackward0>)
id: 44 reward: 0.0 service_time: 329 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 53 reward: 0.03571428571428571 service_time: 500 s_time: -32 penalty: 0 agent_num: 16 done: False
______________________
id: 50 reward: -0.027093596059113302 service_time: 332 s_time: 44 penalty: 0 agent_num: 29 done: False
______________________
id: 47 reward: -0.0033482142857142855 service_time: 335 s_time: 3 penalty: 0 agent_num: 16 done: False
______________________
id: 42 reward: 0.0026455026455026454 service_time: 458 s_time: -4 penalty: 0 agent_num: 27 done: False
______________________
id: 54 reward: -0.009259259259259259 service_time: 614 s_time: 14 penalty: 0 agent_num: 27 done: False
______________________
id: 51 reward: 0.06818181818181818 service_time: 242 s_time: -42 penalty: 0 agent_num: 11 done: False
______________________
id: 55 reward: -0.02353896103896104 service_time: 492 s_time: 29 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: -0.01173469387755102 service_time: 486 s_time: 23 penalty: 0 agent_num: 35 done: False
______________________
id: 46 reward: 0.00038819875776397513 service_time: 461 s_time: -1 penalty: 0 agent_num: 46 done: False
______________________
id: 52 reward: -0.037037037037037035 service_time: 207 s_time: 56 penalty: 0 agent_num: 27 done: False
______________________
id: 41 reward: -0.05113636363636364 service_time: 704 s_time: 63 penalty: 0 agent_num: 22 done: False
______________________
id: 45 reward: -0.02295918367346939 service_time: 599 s_time: 45 penalty: 0 agent_num: 35 done: False
______________________
id: 43 reward: -0.0326530612244898 service_time: 459 s_time: 64 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.017006802721088437 service_time: 672 s_time: 40 penalty: 0 agent_num: 42 done: False
______________________
id: 40 reward: -0.015977443609022556 service_time: 488 s_time: 17 penalty: 0 agent_num: 19 done: False
______________________
Step:  1248
Pretraining Loss:  tensor(0.0634, device='cuda:0', grad_fn=<MeanBackward0>)
id: 44 reward: -0.14464285714285716 service_time: 410 s_time: 81 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: -0.0633116883116883 service_time: 281 s_time: 39 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: -0.027901785714285716 service_time: 360 s_time: 25 penalty: 0 agent_num: 16 done: False
______________________
id: 53 reward: 0.002232142857142857 service_time: 498 s_time: -2 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: -0.03665413533834586 service_time: 527 s_time: 39 penalty: 0 agent_num: 19 done: False
______________________
id: 50 reward: -0.012315270935960592 service_time: 352 s_time: 20 penalty: 0 agent_num: 29 done: False
______________________
id: 54 reward: 0.0 service_time: 614 s_time: 0 penalty: 0 agent_num: 27 done: False
______________________
id: 52 reward: -0.0205026455026455 service_time: 238 s_time: 31 penalty: 0 agent_num: 27 done: False
______________________
id: 45 reward: -0.013775510204081633 service_time: 626 s_time: 27 penalty: 0 agent_num: 35 done: False
______________________
id: 55 reward: -0.033279220779220776 service_time: 533 s_time: 41 penalty: 0 agent_num: 22 done: False
______________________
id: 41 reward: 0.0016233766233766235 service_time: 702 s_time: -2 penalty: 0 agent_num: 22 done: False
______________________
id: 46 reward: -0.022903726708074536 service_time: 520 s_time: 59 penalty: 0 agent_num: 46 done: False
______________________
id: 42 reward: -0.028439153439153438 service_time: 501 s_time: 43 penalty: 0 agent_num: 27 done: False
______________________
id: 43 reward: -0.015816326530612244 service_time: 490 s_time: 31 penalty: 0 agent_num: 35 done: False
______________________
id: 49 reward: 0.0 service_time: 486 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.015306122448979591 service_time: 708 s_time: 36 penalty: 0 agent_num: 42 done: False
______________________
Step:  1264
Pretraining Loss:  tensor(0.0592, device='cuda:0', grad_fn=<MeanBackward0>)
id: 51 reward: 0.027597402597402596 service_time: 264 s_time: -17 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: 0.05357142857142857 service_time: 380 s_time: -30 penalty: 0 agent_num: 10 done: False
______________________
id: 53 reward: 0.030133928571428572 service_time: 471 s_time: -27 penalty: 0 agent_num: 16 done: False
______________________
id: 47 reward: -0.016741071428571428 service_time: 375 s_time: 15 penalty: 0 agent_num: 16 done: False
______________________
id: 50 reward: -0.008004926108374385 service_time: 365 s_time: 13 penalty: 0 agent_num: 29 done: False
______________________
id: 55 reward: -0.030844155844155844 service_time: 571 s_time: 38 penalty: 0 agent_num: 22 done: False
______________________
id: 52 reward: -0.013888888888888888 service_time: 259 s_time: 21 penalty: 0 agent_num: 27 done: False
______________________
id: 45 reward: -0.02295918367346939 service_time: 671 s_time: 45 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: -0.046957671957671955 service_time: 685 s_time: 71 penalty: 0 agent_num: 27 done: False
______________________
id: 46 reward: -0.01048136645962733 service_time: 547 s_time: 27 penalty: 0 agent_num: 46 done: False
______________________
id: 49 reward: -0.03520408163265306 service_time: 555 s_time: 69 penalty: 0 agent_num: 35 done: False
______________________
id: 43 reward: -0.011224489795918367 service_time: 512 s_time: 22 penalty: 0 agent_num: 35 done: False
______________________
id: 42 reward: -0.041005291005291 service_time: 563 s_time: 62 penalty: 0 agent_num: 27 done: False
______________________
id: 41 reward: -0.04707792207792208 service_time: 760 s_time: 58 penalty: 0 agent_num: 22 done: False
______________________
id: 48 reward: 0.0008503401360544217 service_time: 706 s_time: -2 penalty: 0 agent_num: 42 done: False
______________________
id: 40 reward: -0.03195488721804511 service_time: 561 s_time: 34 penalty: 0 agent_num: 19 done: False
______________________
Step:  1280
Pretraining Loss:  tensor(0.0583, device='cuda:0', grad_fn=<MeanBackward0>)
id: 44 reward: 0.0 service_time: 380 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 47 reward: -0.030133928571428572 service_time: 402 s_time: 27 penalty: 0 agent_num: 16 done: False
______________________
id: 53 reward: 0.0011160714285714285 service_time: 470 s_time: -1 penalty: 0 agent_num: 16 done: False
______________________
id: 50 reward: -0.01600985221674877 service_time: 391 s_time: 26 penalty: 0 agent_num: 29 done: False
______________________
id: 40 reward: -0.018796992481203006 service_time: 581 s_time: 20 penalty: 0 agent_num: 19 done: False
______________________
id: 52 reward: 0.0 service_time: 259 s_time: 0 penalty: 0 agent_num: 27 done: False
______________________
id: 51 reward: -0.0698051948051948 service_time: 307 s_time: 43 penalty: 0 agent_num: 11 done: False
______________________
id: 54 reward: -0.0291005291005291 service_time: 729 s_time: 44 penalty: 0 agent_num: 27 done: False
______________________
id: 55 reward: -0.021915584415584416 service_time: 598 s_time: 27 penalty: 0 agent_num: 22 done: False
______________________
id: 42 reward: -0.017195767195767195 service_time: 589 s_time: 26 penalty: 0 agent_num: 27 done: False
______________________
id: 46 reward: -0.0019409937888198758 service_time: 552 s_time: 5 penalty: 0 agent_num: 46 done: False
______________________
id: 45 reward: -0.015816326530612244 service_time: 702 s_time: 31 penalty: 0 agent_num: 35 done: False
______________________
id: 41 reward: 0.00974025974025974 service_time: 748 s_time: -12 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: -0.02295918367346939 service_time: 600 s_time: 45 penalty: 0 agent_num: 35 done: False
______________________
id: 43 reward: -0.01683673469387755 service_time: 545 s_time: 33 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.03358843537414966 service_time: 785 s_time: 79 penalty: 0 agent_num: 42 done: False
______________________
Step:  1296
Pretraining Loss:  tensor(0.0634, device='cuda:0', grad_fn=<MeanBackward0>)
id: 51 reward: 0.008116883116883116 service_time: 302 s_time: -5 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: 0.017857142857142856 service_time: 370 s_time: -10 penalty: 0 agent_num: 10 done: False
______________________
id: 53 reward: -0.05357142857142857 service_time: 518 s_time: 48 penalty: 0 agent_num: 16 done: False
______________________
id: 47 reward: 0.0 service_time: 402 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 55 reward: -0.01948051948051948 service_time: 622 s_time: 24 penalty: 0 agent_num: 22 done: False
______________________
id: 50 reward: -0.020935960591133004 service_time: 425 s_time: 34 penalty: 0 agent_num: 29 done: False
______________________
id: 45 reward: -0.0163265306122449 service_time: 734 s_time: 32 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: -0.013227513227513227 service_time: 749 s_time: 20 penalty: 0 agent_num: 27 done: False
______________________
id: 46 reward: -0.023291925465838508 service_time: 612 s_time: 60 penalty: 0 agent_num: 46 done: False
______________________
id: 49 reward: -0.012755102040816327 service_time: 625 s_time: 25 penalty: 0 agent_num: 35 done: False
______________________
id: 41 reward: 0.024350649350649352 service_time: 718 s_time: -30 penalty: 0 agent_num: 22 done: False
______________________
id: 42 reward: -0.023148148148148147 service_time: 624 s_time: 35 penalty: 0 agent_num: 27 done: False
______________________
id: 52 reward: -0.041666666666666664 service_time: 322 s_time: 63 penalty: 0 agent_num: 27 done: False
______________________
id: 43 reward: -0.009693877551020408 service_time: 564 s_time: 19 penalty: 0 agent_num: 35 done: False
______________________
id: 40 reward: -0.023496240601503758 service_time: 606 s_time: 25 penalty: 0 agent_num: 19 done: False
______________________
id: 48 reward: -0.011479591836734694 service_time: 812 s_time: 27 penalty: 0 agent_num: 42 done: False
______________________
Step:  1312
Pretraining Loss:  tensor(0.0613, device='cuda:0', grad_fn=<MeanBackward0>)
id: 44 reward: 0.0 service_time: 370 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: -0.07142857142857142 service_time: 346 s_time: 44 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: -0.017857142857142856 service_time: 418 s_time: 16 penalty: 0 agent_num: 16 done: False
______________________
id: 53 reward: 0.0 service_time: 518 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 55 reward: -0.021915584415584416 service_time: 649 s_time: 27 penalty: 0 agent_num: 22 done: False
______________________
id: 41 reward: 0.020292207792207792 service_time: 693 s_time: -25 penalty: 0 agent_num: 22 done: False
______________________
id: 52 reward: -0.013227513227513227 service_time: 342 s_time: 20 penalty: 0 agent_num: 27 done: False
______________________
id: 50 reward: -0.019704433497536946 service_time: 457 s_time: 32 penalty: 0 agent_num: 29 done: False
______________________
id: 54 reward: -0.0006613756613756613 service_time: 750 s_time: 1 penalty: 0 agent_num: 27 done: False
______________________
id: 40 reward: 0.03571428571428571 service_time: 568 s_time: -38 penalty: 0 agent_num: 19 done: False
______________________
id: 45 reward: -0.008673469387755102 service_time: 751 s_time: 17 penalty: 0 agent_num: 35 done: False
______________________
id: 46 reward: 0.0 service_time: 612 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 49 reward: -0.01020408163265306 service_time: 645 s_time: 20 penalty: 0 agent_num: 35 done: False
______________________
id: 43 reward: -0.01020408163265306 service_time: 584 s_time: 20 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.00510204081632653 service_time: 824 s_time: 12 penalty: 0 agent_num: 42 done: False
______________________
id: 42 reward: -0.031746031746031744 service_time: 672 s_time: 48 penalty: 0 agent_num: 27 done: False
______________________
Step:  1328
Pretraining Loss:  tensor(0.0558, device='cuda:0', grad_fn=<MeanBackward0>)
id: 51 reward: 0.006493506493506494 service_time: 342 s_time: -4 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: 0.0 service_time: 370 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 47 reward: -0.036830357142857144 service_time: 451 s_time: 33 penalty: 0 agent_num: 16 done: False
______________________
id: 53 reward: 0.0 service_time: 518 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: 0.0 service_time: 568 s_time: 0 penalty: 0 agent_num: 19 done: False
______________________
id: 55 reward: -0.030032467532467532 service_time: 686 s_time: 37 penalty: 0 agent_num: 22 done: False
______________________
id: 50 reward: 0.0 service_time: 457 s_time: 0 penalty: 0 agent_num: 29 done: False
______________________
id: 54 reward: -0.007275132275132275 service_time: 761 s_time: 11 penalty: 0 agent_num: 27 done: False
______________________
id: 49 reward: 0.0020408163265306124 service_time: 641 s_time: -4 penalty: 0 agent_num: 35 done: False
______________________
id: 46 reward: -0.022903726708074536 service_time: 671 s_time: 59 penalty: 0 agent_num: 46 done: False
______________________
id: 45 reward: -0.02346938775510204 service_time: 797 s_time: 46 penalty: 0 agent_num: 35 done: False
______________________
id: 43 reward: -0.00510204081632653 service_time: 594 s_time: 10 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.005952380952380952 service_time: 838 s_time: 14 penalty: 0 agent_num: 42 done: False
______________________
id: 42 reward: 0.004629629629629629 service_time: 665 s_time: -7 penalty: 0 agent_num: 27 done: False
______________________
id: 52 reward: 0.0006613756613756613 service_time: 341 s_time: -1 penalty: 0 agent_num: 27 done: False
______________________
id: 41 reward: -0.04220779220779221 service_time: 745 s_time: 52 penalty: 0 agent_num: 22 done: False
______________________
Step:  1344
Pretraining Loss:  tensor(0.0571, device='cuda:0', grad_fn=<MeanBackward0>)
id: 44 reward: -0.05 service_time: 398 s_time: 28 penalty: 0 agent_num: 10 done: False
______________________
id: 47 reward: 0.0 service_time: 451 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 53 reward: 0.0 service_time: 518 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 51 reward: 0.024350649350649352 service_time: 327 s_time: -15 penalty: 0 agent_num: 11 done: False
______________________
id: 50 reward: -0.03017241379310345 service_time: 506 s_time: 49 penalty: 0 agent_num: 29 done: False
______________________
id: 55 reward: 0.0 service_time: 686 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 54 reward: -0.008597883597883597 service_time: 774 s_time: 13 penalty: 0 agent_num: 27 done: False
______________________
id: 52 reward: -0.046296296296296294 service_time: 411 s_time: 70 penalty: 0 agent_num: 27 done: False
______________________
id: 40 reward: 0.02725563909774436 service_time: 539 s_time: -29 penalty: 0 agent_num: 19 done: False
______________________
id: 41 reward: 0.02922077922077922 service_time: 709 s_time: -36 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: -0.04030612244897959 service_time: 720 s_time: 79 penalty: 0 agent_num: 35 done: False
______________________
id: 46 reward: 0.0007763975155279503 service_time: 669 s_time: -2 penalty: 0 agent_num: 46 done: False
______________________
id: 43 reward: -0.013775510204081633 service_time: 621 s_time: 27 penalty: 0 agent_num: 35 done: False
______________________
id: 42 reward: 0.0013227513227513227 service_time: 663 s_time: -2 penalty: 0 agent_num: 27 done: False
______________________
id: 48 reward: -0.007227891156462585 service_time: 855 s_time: 17 penalty: 0 agent_num: 42 done: False
______________________
id: 45 reward: -0.015816326530612244 service_time: 828 s_time: 31 penalty: 0 agent_num: 35 done: False
______________________
Step:  1360
Pretraining Loss:  tensor(0.0569, device='cuda:0', grad_fn=<MeanBackward0>)
id: 44 reward: 0.0 service_time: 398 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 47 reward: -0.049107142857142856 service_time: 495 s_time: 44 penalty: 0 agent_num: 16 done: False
______________________
id: 53 reward: 0.0234375 service_time: 497 s_time: -21 penalty: 0 agent_num: 16 done: False
______________________
id: 51 reward: -0.05519480519480519 service_time: 361 s_time: 34 penalty: 0 agent_num: 11 done: False
______________________
id: 40 reward: 0.016917293233082706 service_time: 521 s_time: -18 penalty: 0 agent_num: 19 done: False
______________________
id: 50 reward: -0.025246305418719212 service_time: 547 s_time: 41 penalty: 0 agent_num: 29 done: False
______________________
id: 55 reward: -0.040584415584415584 service_time: 736 s_time: 50 penalty: 0 agent_num: 22 done: False
______________________
id: 41 reward: -0.037337662337662336 service_time: 755 s_time: 46 penalty: 0 agent_num: 22 done: False
______________________
id: 54 reward: -0.02513227513227513 service_time: 812 s_time: 38 penalty: 0 agent_num: 27 done: False
______________________
id: 49 reward: -0.01683673469387755 service_time: 753 s_time: 33 penalty: 0 agent_num: 35 done: False
______________________
id: 45 reward: -0.015816326530612244 service_time: 859 s_time: 31 penalty: 0 agent_num: 35 done: False
______________________
id: 43 reward: 0.0010204081632653062 service_time: 619 s_time: -2 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.00977891156462585 service_time: 878 s_time: 23 penalty: 0 agent_num: 42 done: False
______________________
id: 52 reward: 0.0 service_time: 411 s_time: 0 penalty: 0 agent_num: 27 done: False
______________________
id: 46 reward: -0.027562111801242236 service_time: 740 s_time: 71 penalty: 0 agent_num: 46 done: False
______________________
id: 42 reward: -0.02447089947089947 service_time: 700 s_time: 37 penalty: 0 agent_num: 27 done: False
______________________
Step:  1376
Pretraining Loss:  tensor(0.0574, device='cuda:0', grad_fn=<MeanBackward0>)
id: 51 reward: 0.021103896103896104 service_time: 348 s_time: -13 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: 0.02142857142857143 service_time: 386 s_time: -12 penalty: 0 agent_num: 10 done: False
______________________
id: 47 reward: -0.017857142857142856 service_time: 511 s_time: 16 penalty: 0 agent_num: 16 done: False
______________________
id: 53 reward: 0.0 service_time: 497 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 55 reward: -0.030844155844155844 service_time: 774 s_time: 38 penalty: 0 agent_num: 22 done: False
______________________
id: 41 reward: 0.0 service_time: 755 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 52 reward: -0.018518518518518517 service_time: 439 s_time: 28 penalty: 0 agent_num: 27 done: False
______________________
id: 40 reward: 0.03571428571428571 service_time: 483 s_time: -38 penalty: 0 agent_num: 19 done: False
______________________
id: 50 reward: -0.011083743842364532 service_time: 565 s_time: 18 penalty: 0 agent_num: 29 done: False
______________________
id: 54 reward: -0.015873015873015872 service_time: 836 s_time: 24 penalty: 0 agent_num: 27 done: False
______________________
id: 49 reward: -0.01479591836734694 service_time: 782 s_time: 29 penalty: 0 agent_num: 35 done: False
______________________
id: 43 reward: -0.02040816326530612 service_time: 659 s_time: 40 penalty: 0 agent_num: 35 done: False
______________________
id: 46 reward: 0.0 service_time: 740 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 48 reward: 0.0 service_time: 878 s_time: 0 penalty: 0 agent_num: 42 done: False
______________________
id: 42 reward: -0.01984126984126984 service_time: 730 s_time: 30 penalty: 0 agent_num: 27 done: False
______________________
id: 45 reward: -0.005612244897959183 service_time: 870 s_time: 11 penalty: 0 agent_num: 35 done: False
______________________
Step:  1392
Pretraining Loss:  tensor(0.0576, device='cuda:0', grad_fn=<MeanBackward0>)
id: 44 reward: 0.0035714285714285713 service_time: 384 s_time: -2 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: 0.0 service_time: 348 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 53 reward: 0.0 service_time: 497 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 47 reward: 0.0 service_time: 511 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: -0.07048872180451128 service_time: 558 s_time: 75 penalty: 0 agent_num: 19 done: False
______________________
id: 50 reward: -0.022783251231527094 service_time: 602 s_time: 37 penalty: 0 agent_num: 29 done: False
______________________
id: 55 reward: 0.032467532467532464 service_time: 734 s_time: -40 penalty: 0 agent_num: 22 done: False
______________________
id: 41 reward: 0.017045454545454544 service_time: 734 s_time: -21 penalty: 0 agent_num: 22 done: False
______________________
id: 54 reward: 0.0 service_time: 836 s_time: 0 penalty: 0 agent_num: 27 done: False
______________________
id: 45 reward: 0.00816326530612245 service_time: 854 s_time: -16 penalty: 0 agent_num: 35 done: False
______________________
id: 43 reward: -0.015816326530612244 service_time: 690 s_time: 31 penalty: 0 agent_num: 35 done: False
______________________
id: 49 reward: -0.01479591836734694 service_time: 811 s_time: 29 penalty: 0 agent_num: 35 done: False
______________________
id: 52 reward: -0.031746031746031744 service_time: 487 s_time: 48 penalty: 0 agent_num: 27 done: False
______________________
id: 48 reward: -0.03018707482993197 service_time: 949 s_time: 71 penalty: 0 agent_num: 42 done: False
______________________
id: 46 reward: -0.029503105590062112 service_time: 816 s_time: 76 penalty: 0 agent_num: 46 done: False
______________________
id: 42 reward: -0.06613756613756613 service_time: 830 s_time: 100 penalty: 0 agent_num: 27 done: False
______________________
Step:  1408
Pretraining Loss:  tensor(0.0628, device='cuda:0', grad_fn=<MeanBackward0>)
id: 51 reward: 0.0 service_time: 348 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: -0.12678571428571428 service_time: 455 s_time: 71 penalty: 0 agent_num: 10 done: False
______________________
id: 53 reward: 0.0 service_time: 497 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 47 reward: 0.0 service_time: 511 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 41 reward: 0.0 service_time: 734 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 40 reward: 0.0 service_time: 558 s_time: 0 penalty: 0 agent_num: 19 done: False
______________________
id: 55 reward: -0.010551948051948052 service_time: 747 s_time: 13 penalty: 0 agent_num: 22 done: False
______________________
id: 52 reward: -0.027777777777777776 service_time: 529 s_time: 42 penalty: 0 agent_num: 27 done: False
______________________
id: 54 reward: -0.03373015873015873 service_time: 887 s_time: 51 penalty: 0 agent_num: 27 done: False
______________________
id: 50 reward: -0.01600985221674877 service_time: 628 s_time: 26 penalty: 0 agent_num: 29 done: False
______________________
id: 45 reward: -0.02193877551020408 service_time: 897 s_time: 43 penalty: 0 agent_num: 35 done: False
______________________
id: 49 reward: -0.010714285714285714 service_time: 832 s_time: 21 penalty: 0 agent_num: 35 done: False
______________________
id: 43 reward: -0.008673469387755102 service_time: 707 s_time: 17 penalty: 0 agent_num: 35 done: False
______________________
id: 46 reward: -0.012422360248447204 service_time: 848 s_time: 32 penalty: 0 agent_num: 46 done: False
______________________
id: 48 reward: -0.0055272108843537416 service_time: 962 s_time: 13 penalty: 0 agent_num: 42 done: False
______________________
id: 42 reward: -0.02513227513227513 service_time: 868 s_time: 38 penalty: 0 agent_num: 27 done: False
______________________
Step:  1424
Pretraining Loss:  tensor(0.0616, device='cuda:0', grad_fn=<MeanBackward0>)
id: 44 reward: 0.0 service_time: 455 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 47 reward: -0.027901785714285716 service_time: 536 s_time: 25 penalty: 0 agent_num: 16 done: False
______________________
id: 51 reward: 0.011363636363636364 service_time: 341 s_time: -7 penalty: 0 agent_num: 11 done: False
______________________
id: 53 reward: -0.09263392857142858 service_time: 580 s_time: 83 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: -0.07048872180451128 service_time: 633 s_time: 75 penalty: 0 agent_num: 19 done: False
______________________
id: 55 reward: -0.03814935064935065 service_time: 794 s_time: 47 penalty: 0 agent_num: 22 done: False
______________________
id: 41 reward: 0.0016233766233766235 service_time: 732 s_time: -2 penalty: 0 agent_num: 22 done: False
______________________
id: 54 reward: -0.01984126984126984 service_time: 917 s_time: 30 penalty: 0 agent_num: 27 done: False
______________________
id: 50 reward: -0.01539408866995074 service_time: 653 s_time: 25 penalty: 0 agent_num: 29 done: False
______________________
id: 45 reward: -0.008673469387755102 service_time: 914 s_time: 17 penalty: 0 agent_num: 35 done: False
______________________
id: 49 reward: -0.014285714285714285 service_time: 860 s_time: 28 penalty: 0 agent_num: 35 done: False
______________________
id: 52 reward: -0.013227513227513227 service_time: 549 s_time: 20 penalty: 0 agent_num: 27 done: False
______________________
id: 46 reward: -0.013975155279503106 service_time: 884 s_time: 36 penalty: 0 agent_num: 46 done: False
______________________
id: 43 reward: -0.007142857142857143 service_time: 721 s_time: 14 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.016156462585034014 service_time: 1000 s_time: 38 penalty: 0 agent_num: 42 done: False
______________________
id: 42 reward: -0.0006613756613756613 service_time: 869 s_time: 1 penalty: 0 agent_num: 27 done: False
______________________
Step:  1440
Pretraining Loss:  tensor(0.0615, device='cuda:0', grad_fn=<MeanBackward0>)
id: 51 reward: -0.024350649350649352 service_time: 356 s_time: 15 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: 0.0 service_time: 455 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 47 reward: 0.0 service_time: 536 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: -0.10902255639097744 service_time: 749 s_time: 116 penalty: 0 agent_num: 19 done: False
______________________
id: 41 reward: -0.020292207792207792 service_time: 757 s_time: 25 penalty: 0 agent_num: 22 done: False
______________________
id: 52 reward: 0.0 service_time: 549 s_time: 0 penalty: 0 agent_num: 27 done: False
______________________
id: 54 reward: -0.011904761904761904 service_time: 935 s_time: 18 penalty: 0 agent_num: 27 done: False
______________________
id: 53 reward: -0.08705357142857142 service_time: 658 s_time: 78 penalty: 0 agent_num: 16 done: False
______________________
id: 50 reward: 0.0018472906403940886 service_time: 650 s_time: -3 penalty: 0 agent_num: 29 done: False
______________________
id: 55 reward: 0.010551948051948052 service_time: 781 s_time: -13 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: -0.007653061224489796 service_time: 875 s_time: 15 penalty: 0 agent_num: 35 done: False
______________________
id: 43 reward: -0.001530612244897959 service_time: 724 s_time: 3 penalty: 0 agent_num: 35 done: False
______________________
id: 45 reward: -0.0066326530612244895 service_time: 927 s_time: 13 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: 0.00042517006802721087 service_time: 999 s_time: -1 penalty: 0 agent_num: 42 done: False
______________________
id: 42 reward: -0.023148148148148147 service_time: 904 s_time: 35 penalty: 0 agent_num: 27 done: False
______________________
id: 46 reward: -0.003105590062111801 service_time: 892 s_time: 8 penalty: 0 agent_num: 46 done: False
______________________
Step:  1456
Pretraining Loss:  tensor(0.0605, device='cuda:0', grad_fn=<MeanBackward0>)
id: 44 reward: 0.039285714285714285 service_time: 433 s_time: -22 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: -0.040584415584415584 service_time: 381 s_time: 25 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: -0.021205357142857144 service_time: 555 s_time: 19 penalty: 0 agent_num: 16 done: False
______________________
id: 53 reward: 0.0 service_time: 658 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 54 reward: -0.009259259259259259 service_time: 949 s_time: 14 penalty: 0 agent_num: 27 done: False
______________________
id: 55 reward: 0.015422077922077922 service_time: 762 s_time: -19 penalty: 0 agent_num: 22 done: False
______________________
id: 40 reward: -0.02631578947368421 service_time: 777 s_time: 28 penalty: 0 agent_num: 19 done: False
______________________
id: 41 reward: -0.05844155844155844 service_time: 829 s_time: 72 penalty: 0 agent_num: 22 done: False
______________________
id: 45 reward: -0.020918367346938777 service_time: 968 s_time: 41 penalty: 0 agent_num: 35 done: False
______________________
id: 50 reward: -0.0067733990147783255 service_time: 661 s_time: 11 penalty: 0 agent_num: 29 done: False
______________________
id: 49 reward: -0.014285714285714285 service_time: 903 s_time: 28 penalty: 0 agent_num: 35 done: False
______________________
id: 42 reward: -0.00992063492063492 service_time: 919 s_time: 15 penalty: 0 agent_num: 27 done: False
______________________
id: 43 reward: -0.00510204081632653 service_time: 734 s_time: 10 penalty: 0 agent_num: 35 done: False
______________________
id: 52 reward: -0.023809523809523808 service_time: 585 s_time: 36 penalty: 0 agent_num: 27 done: False
______________________
id: 46 reward: -0.005046583850931677 service_time: 905 s_time: 13 penalty: 0 agent_num: 46 done: False
______________________
id: 48 reward: -0.0195578231292517 service_time: 1045 s_time: 46 penalty: 0 agent_num: 42 done: False
______________________
Step:  1472
Pretraining Loss:  tensor(0.0750, device='cuda:0', grad_fn=<MeanBackward0>)
id: 44 reward: 0.0 service_time: 433 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: 0.0 service_time: 381 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 41 reward: 0.013798701298701298 service_time: 812 s_time: -17 penalty: 0 agent_num: 22 done: False
______________________
id: 40 reward: -0.0009398496240601503 service_time: 778 s_time: 1 penalty: 0 agent_num: 19 done: False
______________________
id: 53 reward: -0.0390625 service_time: 693 s_time: 35 penalty: 0 agent_num: 16 done: False
______________________
id: 47 reward: -0.030133928571428572 service_time: 582 s_time: 27 penalty: 0 agent_num: 16 done: False
______________________
id: 55 reward: -0.026785714285714284 service_time: 795 s_time: 33 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: -0.00510204081632653 service_time: 913 s_time: 10 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: -0.005291005291005291 service_time: 957 s_time: 8 penalty: 0 agent_num: 27 done: False
______________________
id: 50 reward: -0.02894088669950739 service_time: 708 s_time: 47 penalty: 0 agent_num: 29 done: False
______________________
id: 52 reward: -0.022486772486772486 service_time: 619 s_time: 34 penalty: 0 agent_num: 27 done: False
______________________
id: 42 reward: -0.01984126984126984 service_time: 949 s_time: 30 penalty: 0 agent_num: 27 done: False
______________________
id: 43 reward: -0.013265306122448979 service_time: 760 s_time: 26 penalty: 0 agent_num: 35 done: False
______________________
id: 45 reward: -0.01020408163265306 service_time: 988 s_time: 20 penalty: 0 agent_num: 35 done: False
______________________
id: 46 reward: -0.007763975155279503 service_time: 925 s_time: 20 penalty: 0 agent_num: 46 done: False
______________________
id: 48 reward: -0.01488095238095238 service_time: 1080 s_time: 35 penalty: 0 agent_num: 42 done: False
______________________
Step:  1488
Pretraining Loss:  tensor(0.0665, device='cuda:0', grad_fn=<MeanBackward0>)
id: 44 reward: -0.03571428571428571 service_time: 453 s_time: 20 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: -0.048701298701298704 service_time: 411 s_time: 30 penalty: 0 agent_num: 11 done: False
______________________
id: 53 reward: 0.0 service_time: 693 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 47 reward: 0.0 service_time: 582 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 41 reward: -0.021103896103896104 service_time: 838 s_time: 26 penalty: 0 agent_num: 22 done: False
______________________
id: 54 reward: -0.021164021164021163 service_time: 989 s_time: 32 penalty: 0 agent_num: 27 done: False
______________________
id: 40 reward: 0.010338345864661654 service_time: 767 s_time: -11 penalty: 0 agent_num: 19 done: False
______________________
id: 55 reward: -0.10876623376623376 service_time: 929 s_time: 134 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: -0.00816326530612245 service_time: 929 s_time: 16 penalty: 0 agent_num: 35 done: False
______________________
id: 50 reward: -0.004310344827586207 service_time: 715 s_time: 7 penalty: 0 agent_num: 29 done: False
______________________
id: 52 reward: -0.022486772486772486 service_time: 653 s_time: 34 penalty: 0 agent_num: 27 done: False
______________________
id: 43 reward: -0.019387755102040816 service_time: 798 s_time: 38 penalty: 0 agent_num: 35 done: False
______________________
id: 42 reward: -0.023148148148148147 service_time: 984 s_time: 35 penalty: 0 agent_num: 27 done: False
______________________
id: 45 reward: -0.022448979591836733 service_time: 1032 s_time: 44 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.01020408163265306 service_time: 1104 s_time: 24 penalty: 0 agent_num: 42 done: False
______________________
id: 46 reward: -0.008540372670807454 service_time: 947 s_time: 22 penalty: 0 agent_num: 46 done: False
______________________
Step:  1504
Pretraining Loss:  tensor(0.0659, device='cuda:0', grad_fn=<MeanBackward0>)
id: 44 reward: 0.0 service_time: 453 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: -0.03571428571428571 service_time: 433 s_time: 22 penalty: 0 agent_num: 11 done: False
______________________
id: 53 reward: -0.078125 service_time: 763 s_time: 70 penalty: 0 agent_num: 16 done: False
______________________
id: 47 reward: -0.044642857142857144 service_time: 622 s_time: 40 penalty: 0 agent_num: 16 done: False
______________________
id: 41 reward: 0.0 service_time: 838 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 40 reward: 0.0 service_time: 767 s_time: 0 penalty: 0 agent_num: 19 done: False
______________________
id: 55 reward: 0.060064935064935064 service_time: 855 s_time: -74 penalty: 0 agent_num: 22 done: False
______________________
id: 54 reward: -0.01984126984126984 service_time: 1019 s_time: 30 penalty: 0 agent_num: 27 done: False
______________________
id: 52 reward: -0.01984126984126984 service_time: 683 s_time: 30 penalty: 0 agent_num: 27 done: False
______________________
id: 50 reward: -0.034482758620689655 service_time: 771 s_time: 56 penalty: 0 agent_num: 29 done: False
______________________
id: 49 reward: -0.015816326530612244 service_time: 960 s_time: 31 penalty: 0 agent_num: 35 done: False
______________________
id: 43 reward: -0.01683673469387755 service_time: 831 s_time: 33 penalty: 0 agent_num: 35 done: False
______________________
id: 46 reward: 0.0 service_time: 947 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 42 reward: -0.023809523809523808 service_time: 1020 s_time: 36 penalty: 0 agent_num: 27 done: False
______________________
id: 48 reward: -0.003826530612244898 service_time: 1113 s_time: 9 penalty: 0 agent_num: 42 done: False
______________________
id: 45 reward: -0.0163265306122449 service_time: 1064 s_time: 32 penalty: 0 agent_num: 35 done: False
______________________
Step:  1520
Pretraining Loss:  tensor(0.0613, device='cuda:0', grad_fn=<MeanBackward0>)
id: 51 reward: 0.0 service_time: 433 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: 0.0 service_time: 453 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 47 reward: 0.0 service_time: 622 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 53 reward: 0.0 service_time: 763 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 41 reward: -0.03896103896103896 service_time: 886 s_time: 48 penalty: 0 agent_num: 22 done: False
______________________
id: 40 reward: -0.014097744360902255 service_time: 782 s_time: 15 penalty: 0 agent_num: 19 done: False
______________________
id: 55 reward: -0.04707792207792208 service_time: 913 s_time: 58 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: -0.011224489795918367 service_time: 982 s_time: 22 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: -0.005952380952380952 service_time: 1028 s_time: 9 penalty: 0 agent_num: 27 done: False
______________________
id: 42 reward: -0.013227513227513227 service_time: 1040 s_time: 20 penalty: 0 agent_num: 27 done: False
______________________
id: 48 reward: -0.00977891156462585 service_time: 1136 s_time: 23 penalty: 0 agent_num: 42 done: False
______________________
id: 43 reward: -0.013265306122448979 service_time: 857 s_time: 26 penalty: 0 agent_num: 35 done: False
______________________
id: 52 reward: -0.03373015873015873 service_time: 734 s_time: 51 penalty: 0 agent_num: 27 done: False
______________________
id: 45 reward: -0.017346938775510204 service_time: 1098 s_time: 34 penalty: 0 agent_num: 35 done: False
______________________
id: 46 reward: -0.02562111801242236 service_time: 1013 s_time: 66 penalty: 0 agent_num: 46 done: False
______________________
id: 50 reward: -0.005541871921182266 service_time: 780 s_time: 9 penalty: 0 agent_num: 29 done: False
______________________
Step:  1536
Pretraining Loss:  tensor(0.0597, device='cuda:0', grad_fn=<MeanBackward0>)
id: 44 reward: -0.06428571428571428 service_time: 489 s_time: 36 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: 0.0 service_time: 433 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: -0.04575892857142857 service_time: 663 s_time: 41 penalty: 0 agent_num: 16 done: False
______________________
id: 53 reward: -0.03125 service_time: 791 s_time: 28 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: 0.0009398496240601503 service_time: 781 s_time: -1 penalty: 0 agent_num: 19 done: False
______________________
id: 52 reward: -0.010582010582010581 service_time: 750 s_time: 16 penalty: 0 agent_num: 27 done: False
______________________
id: 55 reward: 0.0 service_time: 913 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: -0.01020408163265306 service_time: 1002 s_time: 20 penalty: 0 agent_num: 35 done: False
______________________
id: 50 reward: -0.022167487684729065 service_time: 816 s_time: 36 penalty: 0 agent_num: 29 done: False
______________________
id: 41 reward: -0.0698051948051948 service_time: 972 s_time: 86 penalty: 0 agent_num: 22 done: False
______________________
id: 43 reward: -0.02346938775510204 service_time: 903 s_time: 46 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: 0.0017006802721088435 service_time: 1132 s_time: -4 penalty: 0 agent_num: 42 done: False
______________________
id: 46 reward: -0.01358695652173913 service_time: 1048 s_time: 35 penalty: 0 agent_num: 46 done: False
______________________
id: 42 reward: 0.0006613756613756613 service_time: 1039 s_time: -1 penalty: 0 agent_num: 27 done: False
______________________
id: 54 reward: -0.026455026455026454 service_time: 1068 s_time: 40 penalty: 0 agent_num: 27 done: False
______________________
id: 45 reward: 0.0 service_time: 1098 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
Step:  1552
Pretraining Loss:  tensor(0.0559, device='cuda:0', grad_fn=<MeanBackward0>)
id: 44 reward: 0.0 service_time: 489 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: 0.0 service_time: 433 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 53 reward: -0.013392857142857142 service_time: 803 s_time: 12 penalty: 0 agent_num: 16 done: False
______________________
id: 47 reward: 0.002232142857142857 service_time: 661 s_time: -2 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: 0.0 service_time: 781 s_time: 0 penalty: 0 agent_num: 19 done: False
______________________
id: 55 reward: -0.030032467532467532 service_time: 950 s_time: 37 penalty: 0 agent_num: 22 done: False
______________________
id: 54 reward: -0.021164021164021163 service_time: 1100 s_time: 32 penalty: 0 agent_num: 27 done: False
______________________
id: 49 reward: -0.0035714285714285713 service_time: 1009 s_time: 7 penalty: 0 agent_num: 35 done: False
______________________
id: 46 reward: -0.010093167701863354 service_time: 1074 s_time: 26 penalty: 0 agent_num: 46 done: False
______________________
id: 45 reward: -0.03214285714285714 service_time: 1161 s_time: 63 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.016156462585034014 service_time: 1170 s_time: 38 penalty: 0 agent_num: 42 done: False
______________________
id: 41 reward: -0.07954545454545454 service_time: 1070 s_time: 98 penalty: 0 agent_num: 22 done: False
______________________
id: 52 reward: -0.015873015873015872 service_time: 774 s_time: 24 penalty: 0 agent_num: 27 done: False
______________________
id: 42 reward: -0.05026455026455026 service_time: 1115 s_time: 76 penalty: 0 agent_num: 27 done: False
______________________
id: 43 reward: -0.025 service_time: 952 s_time: 49 penalty: 0 agent_num: 35 done: False
______________________
id: 50 reward: -0.027093596059113302 service_time: 860 s_time: 44 penalty: 0 agent_num: 29 done: False
______________________
Step:  1568
Pretraining Loss:  tensor(0.0642, device='cuda:0', grad_fn=<MeanBackward0>)
id: 44 reward: -0.14642857142857144 service_time: 571 s_time: 82 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: -0.03409090909090909 service_time: 454 s_time: 21 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: -0.027901785714285716 service_time: 686 s_time: 25 penalty: 0 agent_num: 16 done: False
______________________
id: 53 reward: 0.0 service_time: 803 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: -0.03571428571428571 service_time: 819 s_time: 38 penalty: 0 agent_num: 19 done: False
______________________
id: 41 reward: 0.030032467532467532 service_time: 1033 s_time: -37 penalty: 0 agent_num: 22 done: False
______________________
id: 55 reward: 0.022727272727272728 service_time: 922 s_time: -28 penalty: 0 agent_num: 22 done: False
______________________
id: 52 reward: -0.02447089947089947 service_time: 811 s_time: 37 penalty: 0 agent_num: 27 done: False
______________________
id: 49 reward: -0.018367346938775512 service_time: 1045 s_time: 36 penalty: 0 agent_num: 35 done: False
______________________
id: 43 reward: 0.002551020408163265 service_time: 947 s_time: -5 penalty: 0 agent_num: 35 done: False
______________________
id: 42 reward: -0.025793650793650792 service_time: 1154 s_time: 39 penalty: 0 agent_num: 27 done: False
______________________
id: 50 reward: 0.0 service_time: 860 s_time: 0 penalty: 0 agent_num: 29 done: False
______________________
id: 54 reward: -0.016534391534391533 service_time: 1125 s_time: 25 penalty: 0 agent_num: 27 done: False
______________________
id: 46 reward: -0.013975155279503106 service_time: 1110 s_time: 36 penalty: 0 agent_num: 46 done: False
______________________
id: 48 reward: -0.017431972789115645 service_time: 1211 s_time: 41 penalty: 0 agent_num: 42 done: False
______________________
id: 45 reward: 0.0 service_time: 1161 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
------------------------------------
| time/                 |          |
|    fps                | 8        |
|    iterations         | 100      |
|    time_elapsed       | 189      |
|    total_timesteps    | 1600     |
| train/                |          |
|    entropy_loss       | 0.0579   |
|    explained_variance | -242     |
|    learning_rate      | 1e-05    |
|    n_updates          | 99       |
|    policy_loss        | 0.0642   |
|    value_loss         | 0.103    |
------------------------------------
Step:  1584
Pretraining Loss:  tensor(0.0669, device='cuda:0', grad_fn=<MeanBackward0>)
id: 44 reward: 0.0 service_time: 571 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: 0.0 service_time: 454 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: -0.029017857142857144 service_time: 712 s_time: 26 penalty: 0 agent_num: 16 done: False
______________________
id: 53 reward: -0.04575892857142857 service_time: 844 s_time: 41 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: 0.008458646616541353 service_time: 810 s_time: -9 penalty: 0 agent_num: 19 done: False
______________________
id: 55 reward: -0.060064935064935064 service_time: 996 s_time: 74 penalty: 0 agent_num: 22 done: False
______________________
id: 52 reward: -0.015873015873015872 service_time: 835 s_time: 24 penalty: 0 agent_num: 27 done: False
______________________
id: 41 reward: -0.045454545454545456 service_time: 1089 s_time: 56 penalty: 0 agent_num: 22 done: False
______________________
id: 42 reward: -0.015873015873015872 service_time: 1178 s_time: 24 penalty: 0 agent_num: 27 done: False
______________________
id: 46 reward: 0.0 service_time: 1110 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 49 reward: -0.024489795918367346 service_time: 1093 s_time: 48 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: -0.02513227513227513 service_time: 1163 s_time: 38 penalty: 0 agent_num: 27 done: False
______________________
id: 48 reward: -0.011904761904761904 service_time: 1239 s_time: 28 penalty: 0 agent_num: 42 done: False
______________________
id: 43 reward: -0.0326530612244898 service_time: 1011 s_time: 64 penalty: 0 agent_num: 35 done: False
______________________
id: 45 reward: -0.02857142857142857 service_time: 1217 s_time: 56 penalty: 0 agent_num: 35 done: False
______________________
id: 50 reward: -0.029556650246305417 service_time: 908 s_time: 48 penalty: 0 agent_num: 29 done: False
______________________
Step:  1600
Pretraining Loss:  tensor(0.0613, device='cuda:0', grad_fn=<MeanBackward0>)
id: 44 reward: 0.0375 service_time: 550 s_time: -21 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: 0.0 service_time: 454 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: 0.0 service_time: 712 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: 0.0009398496240601503 service_time: 809 s_time: -1 penalty: 0 agent_num: 19 done: False
______________________
id: 53 reward: -0.013392857142857142 service_time: 856 s_time: 12 penalty: 0 agent_num: 16 done: False
______________________
id: 55 reward: 0.0 service_time: 996 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 43 reward: 0.0010204081632653062 service_time: 1009 s_time: -2 penalty: 0 agent_num: 35 done: False
______________________
id: 41 reward: 0.012987012987012988 service_time: 1073 s_time: -16 penalty: 0 agent_num: 22 done: False
______________________
id: 52 reward: 0.0013227513227513227 service_time: 833 s_time: -2 penalty: 0 agent_num: 27 done: False
______________________
id: 48 reward: -0.011904761904761904 service_time: 1267 s_time: 28 penalty: 0 agent_num: 42 done: False
______________________
id: 49 reward: -0.012755102040816327 service_time: 1118 s_time: 25 penalty: 0 agent_num: 35 done: False
______________________
id: 46 reward: -0.010093167701863354 service_time: 1136 s_time: 26 penalty: 0 agent_num: 46 done: False
______________________
id: 54 reward: -0.01917989417989418 service_time: 1192 s_time: 29 penalty: 0 agent_num: 27 done: False
______________________
id: 50 reward: -0.024630541871921183 service_time: 948 s_time: 40 penalty: 0 agent_num: 29 done: False
______________________
id: 42 reward: -0.021825396825396824 service_time: 1211 s_time: 33 penalty: 0 agent_num: 27 done: False
______________________
id: 45 reward: -0.026020408163265306 service_time: 1268 s_time: 51 penalty: 0 agent_num: 35 done: False
______________________
Step:  1616
Pretraining Loss:  tensor(0.0588, device='cuda:0', grad_fn=<MeanBackward0>)
id: 44 reward: -0.07142857142857142 service_time: 590 s_time: 40 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: 0.0 service_time: 454 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: -0.015625 service_time: 726 s_time: 14 penalty: 0 agent_num: 16 done: False
______________________
id: 53 reward: 0.002232142857142857 service_time: 854 s_time: -2 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: -0.03383458646616541 service_time: 845 s_time: 36 penalty: 0 agent_num: 19 done: False
______________________
id: 52 reward: -0.04365079365079365 service_time: 899 s_time: 66 penalty: 0 agent_num: 27 done: False
______________________
id: 41 reward: 0.0 service_time: 1073 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 42 reward: -0.023809523809523808 service_time: 1247 s_time: 36 penalty: 0 agent_num: 27 done: False
______________________
id: 43 reward: 0.0010204081632653062 service_time: 1007 s_time: -2 penalty: 0 agent_num: 35 done: False
______________________
id: 45 reward: -0.011224489795918367 service_time: 1290 s_time: 22 penalty: 0 agent_num: 35 done: False
______________________
id: 55 reward: -0.07873376623376624 service_time: 1093 s_time: 97 penalty: 0 agent_num: 22 done: False
______________________
id: 46 reward: -0.01281055900621118 service_time: 1169 s_time: 33 penalty: 0 agent_num: 46 done: False
______________________
id: 49 reward: -0.01020408163265306 service_time: 1138 s_time: 20 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.022534013605442178 service_time: 1320 s_time: 53 penalty: 0 agent_num: 42 done: False
______________________
id: 50 reward: 0.0012315270935960591 service_time: 946 s_time: -2 penalty: 0 agent_num: 29 done: False
______________________
id: 54 reward: -0.017195767195767195 service_time: 1218 s_time: 26 penalty: 0 agent_num: 27 done: False
______________________
Step:  1632
Pretraining Loss:  tensor(0.0571, device='cuda:0', grad_fn=<MeanBackward0>)
id: 44 reward: -0.10357142857142858 service_time: 648 s_time: 58 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: 0.0 service_time: 454 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 53 reward: -0.029017857142857144 service_time: 880 s_time: 26 penalty: 0 agent_num: 16 done: False
______________________
id: 47 reward: 0.0 service_time: 726 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 55 reward: 0.04220779220779221 service_time: 1041 s_time: -52 penalty: 0 agent_num: 22 done: False
______________________
id: 40 reward: 0.0 service_time: 845 s_time: 0 penalty: 0 agent_num: 19 done: False
______________________
id: 41 reward: 0.0 service_time: 1073 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 43 reward: -0.03469387755102041 service_time: 1075 s_time: 68 penalty: 0 agent_num: 35 done: False
______________________
id: 45 reward: 0.001530612244897959 service_time: 1287 s_time: -3 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: -0.015873015873015872 service_time: 1242 s_time: 24 penalty: 0 agent_num: 27 done: False
______________________
id: 48 reward: 0.0008503401360544217 service_time: 1318 s_time: -2 penalty: 0 agent_num: 42 done: False
______________________
id: 52 reward: -0.010582010582010581 service_time: 915 s_time: 16 penalty: 0 agent_num: 27 done: False
______________________
id: 50 reward: -0.06465517241379311 service_time: 1051 s_time: 105 penalty: 0 agent_num: 29 done: False
______________________
id: 46 reward: 0.0 service_time: 1169 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 49 reward: -0.01173469387755102 service_time: 1161 s_time: 23 penalty: 0 agent_num: 35 done: False
______________________
id: 42 reward: -0.026455026455026454 service_time: 1287 s_time: 40 penalty: 0 agent_num: 27 done: False
______________________
Step:  1648
Pretraining Loss:  tensor(0.0689, device='cuda:0', grad_fn=<MeanBackward0>)
id: 44 reward: 0.0 service_time: 648 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: 0.0 service_time: 454 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: -0.027901785714285716 service_time: 751 s_time: 25 penalty: 0 agent_num: 16 done: False
______________________
id: 53 reward: 0.0 service_time: 880 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 55 reward: -0.032467532467532464 service_time: 1081 s_time: 40 penalty: 0 agent_num: 22 done: False
______________________
id: 40 reward: -0.021616541353383457 service_time: 868 s_time: 23 penalty: 0 agent_num: 19 done: False
______________________
id: 42 reward: -0.012566137566137565 service_time: 1306 s_time: 19 penalty: 0 agent_num: 27 done: False
______________________
id: 52 reward: -0.023148148148148147 service_time: 950 s_time: 35 penalty: 0 agent_num: 27 done: False
______________________
id: 45 reward: -0.025 service_time: 1336 s_time: 49 penalty: 0 agent_num: 35 done: False
______________________
id: 41 reward: 0.03571428571428571 service_time: 1029 s_time: -44 penalty: 0 agent_num: 22 done: False
______________________
id: 43 reward: -0.009183673469387756 service_time: 1093 s_time: 18 penalty: 0 agent_num: 35 done: False
______________________
id: 50 reward: -0.020320197044334975 service_time: 1084 s_time: 33 penalty: 0 agent_num: 29 done: False
______________________
id: 46 reward: -0.016692546583850932 service_time: 1212 s_time: 43 penalty: 0 agent_num: 46 done: False
______________________
id: 48 reward: -0.02040816326530612 service_time: 1366 s_time: 48 penalty: 0 agent_num: 42 done: False
______________________
id: 54 reward: -0.01521164021164021 service_time: 1265 s_time: 23 penalty: 0 agent_num: 27 done: False
______________________
id: 49 reward: -0.013775510204081633 service_time: 1188 s_time: 27 penalty: 0 agent_num: 35 done: False
______________________
Step:  1664
Pretraining Loss:  tensor(0.0840, device='cuda:0', grad_fn=<MeanBackward0>)
id: 51 reward: -0.04383116883116883 service_time: 481 s_time: 27 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: 0.0 service_time: 648 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 53 reward: -0.12946428571428573 service_time: 996 s_time: 116 penalty: 0 agent_num: 16 done: False
______________________
id: 47 reward: -0.03236607142857143 service_time: 780 s_time: 29 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: -0.02537593984962406 service_time: 895 s_time: 27 penalty: 0 agent_num: 19 done: False
______________________
id: 41 reward: -0.08116883116883117 service_time: 1129 s_time: 100 penalty: 0 agent_num: 22 done: False
______________________
id: 52 reward: -0.012566137566137565 service_time: 969 s_time: 19 penalty: 0 agent_num: 27 done: False
______________________
id: 45 reward: -0.0005102040816326531 service_time: 1337 s_time: 1 penalty: 0 agent_num: 35 done: False
______________________
id: 43 reward: -0.01173469387755102 service_time: 1116 s_time: 23 penalty: 0 agent_num: 35 done: False
______________________
id: 49 reward: -0.007653061224489796 service_time: 1203 s_time: 15 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: -0.01455026455026455 service_time: 1287 s_time: 22 penalty: 0 agent_num: 27 done: False
______________________
id: 48 reward: -0.003826530612244898 service_time: 1375 s_time: 9 penalty: 0 agent_num: 42 done: False
______________________
id: 50 reward: -0.003078817733990148 service_time: 1089 s_time: 5 penalty: 0 agent_num: 29 done: False
______________________
id: 46 reward: 0.00038819875776397513 service_time: 1211 s_time: -1 penalty: 0 agent_num: 46 done: False
______________________
id: 55 reward: -0.056006493506493504 service_time: 1150 s_time: 69 penalty: 0 agent_num: 22 done: False
______________________
id: 42 reward: -0.013888888888888888 service_time: 1327 s_time: 21 penalty: 0 agent_num: 27 done: False
______________________
Step:  1680
Pretraining Loss:  tensor(0.0643, device='cuda:0', grad_fn=<MeanBackward0>)
id: 44 reward: -0.0625 service_time: 683 s_time: 35 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: -0.07142857142857142 service_time: 525 s_time: 44 penalty: 0 agent_num: 11 done: False
______________________
id: 53 reward: 0.03459821428571429 service_time: 965 s_time: -31 penalty: 0 agent_num: 16 done: False
______________________
id: 47 reward: 0.0 service_time: 780 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: 0.0 service_time: 895 s_time: 0 penalty: 0 agent_num: 19 done: False
______________________
id: 41 reward: -0.07792207792207792 service_time: 1225 s_time: 96 penalty: 0 agent_num: 22 done: False
______________________
id: 52 reward: -0.02447089947089947 service_time: 1006 s_time: 37 penalty: 0 agent_num: 27 done: False
______________________
id: 42 reward: -0.0205026455026455 service_time: 1358 s_time: 31 penalty: 0 agent_num: 27 done: False
______________________
id: 55 reward: 0.012987012987012988 service_time: 1134 s_time: -16 penalty: 0 agent_num: 22 done: False
______________________
id: 43 reward: 0.0 service_time: 1116 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 49 reward: -0.014285714285714285 service_time: 1231 s_time: 28 penalty: 0 agent_num: 35 done: False
______________________
id: 50 reward: -0.02586206896551724 service_time: 1131 s_time: 42 penalty: 0 agent_num: 29 done: False
______________________
id: 46 reward: -0.022127329192546584 service_time: 1268 s_time: 57 penalty: 0 agent_num: 46 done: False
______________________
id: 45 reward: -0.013775510204081633 service_time: 1364 s_time: 27 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: 0.0013227513227513227 service_time: 1285 s_time: -2 penalty: 0 agent_num: 27 done: False
______________________
id: 48 reward: -0.00935374149659864 service_time: 1397 s_time: 22 penalty: 0 agent_num: 42 done: False
______________________
Step:  1696
Pretraining Loss:  tensor(0.0661, device='cuda:0', grad_fn=<MeanBackward0>)
id: 44 reward: 0.0 service_time: 683 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: 0.0 service_time: 525 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: -0.04799107142857143 service_time: 823 s_time: 43 penalty: 0 agent_num: 16 done: False
______________________
id: 53 reward: 0.041294642857142856 service_time: 928 s_time: -37 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: 0.007518796992481203 service_time: 887 s_time: -8 penalty: 0 agent_num: 19 done: False
______________________
id: 52 reward: -0.011243386243386243 service_time: 1023 s_time: 17 penalty: 0 agent_num: 27 done: False
______________________
id: 55 reward: -0.016233766233766232 service_time: 1154 s_time: 20 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: -0.01020408163265306 service_time: 1251 s_time: 20 penalty: 0 agent_num: 35 done: False
______________________
id: 43 reward: -0.015816326530612244 service_time: 1147 s_time: 31 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: -0.02976190476190476 service_time: 1330 s_time: 45 penalty: 0 agent_num: 27 done: False
______________________
id: 45 reward: -0.011224489795918367 service_time: 1386 s_time: 22 penalty: 0 agent_num: 35 done: False
______________________
id: 41 reward: -0.03977272727272727 service_time: 1274 s_time: 49 penalty: 0 agent_num: 22 done: False
______________________
id: 50 reward: -0.01416256157635468 service_time: 1154 s_time: 23 penalty: 0 agent_num: 29 done: False
______________________
id: 46 reward: -0.015139751552795032 service_time: 1307 s_time: 39 penalty: 0 agent_num: 46 done: False
______________________
id: 48 reward: -0.012755102040816327 service_time: 1427 s_time: 30 penalty: 0 agent_num: 42 done: False
______________________
id: 42 reward: 0.005291005291005291 service_time: 1350 s_time: -8 penalty: 0 agent_num: 27 done: False
______________________
Step:  1712
Pretraining Loss:  tensor(0.0687, device='cuda:0', grad_fn=<MeanBackward0>)
id: 51 reward: 0.01461038961038961 service_time: 516 s_time: -9 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: -0.05714285714285714 service_time: 715 s_time: 32 penalty: 0 agent_num: 10 done: False
______________________
id: 47 reward: 0.0 service_time: 823 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 53 reward: -0.046875 service_time: 970 s_time: 42 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: -0.02443609022556391 service_time: 913 s_time: 26 penalty: 0 agent_num: 19 done: False
______________________
id: 55 reward: 0.015422077922077922 service_time: 1135 s_time: -19 penalty: 0 agent_num: 22 done: False
______________________
id: 52 reward: -0.017857142857142856 service_time: 1050 s_time: 27 penalty: 0 agent_num: 27 done: False
______________________
id: 42 reward: 0.016534391534391533 service_time: 1325 s_time: -25 penalty: 0 agent_num: 27 done: False
______________________
id: 50 reward: 0.011083743842364532 service_time: 1136 s_time: -18 penalty: 0 agent_num: 29 done: False
______________________
id: 43 reward: -0.031122448979591835 service_time: 1208 s_time: 61 penalty: 0 agent_num: 35 done: False
______________________
id: 45 reward: -0.017346938775510204 service_time: 1420 s_time: 34 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: -0.04298941798941799 service_time: 1395 s_time: 65 penalty: 0 agent_num: 27 done: False
______________________
id: 49 reward: -0.017346938775510204 service_time: 1285 s_time: 34 penalty: 0 agent_num: 35 done: False
______________________
id: 46 reward: -0.014751552795031056 service_time: 1345 s_time: 38 penalty: 0 agent_num: 46 done: False
______________________
id: 41 reward: -0.056818181818181816 service_time: 1344 s_time: 70 penalty: 0 agent_num: 22 done: False
______________________
id: 48 reward: -0.012329931972789115 service_time: 1456 s_time: 29 penalty: 0 agent_num: 42 done: False
______________________
Step:  1728
Pretraining Loss:  tensor(0.0754, device='cuda:0', grad_fn=<MeanBackward0>)
id: 51 reward: 0.0 service_time: 516 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: 0.03571428571428571 service_time: 695 s_time: -20 penalty: 0 agent_num: 10 done: False
______________________
id: 53 reward: 0.0 service_time: 970 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 47 reward: -0.041294642857142856 service_time: 860 s_time: 37 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: -0.02725563909774436 service_time: 942 s_time: 29 penalty: 0 agent_num: 19 done: False
______________________
id: 42 reward: 0.0 service_time: 1325 s_time: 0 penalty: 0 agent_num: 27 done: False
______________________
id: 41 reward: -0.022727272727272728 service_time: 1372 s_time: 28 penalty: 0 agent_num: 22 done: False
______________________
id: 55 reward: -0.036525974025974024 service_time: 1180 s_time: 45 penalty: 0 agent_num: 22 done: False
______________________
id: 52 reward: 0.0 service_time: 1050 s_time: 0 penalty: 0 agent_num: 27 done: False
______________________
id: 54 reward: -0.011904761904761904 service_time: 1413 s_time: 18 penalty: 0 agent_num: 27 done: False
______________________
id: 45 reward: -0.011224489795918367 service_time: 1442 s_time: 22 penalty: 0 agent_num: 35 done: False
______________________
id: 50 reward: -0.03694581280788178 service_time: 1196 s_time: 60 penalty: 0 agent_num: 29 done: False
______________________
id: 43 reward: -0.00510204081632653 service_time: 1218 s_time: 10 penalty: 0 agent_num: 35 done: False
______________________
id: 49 reward: -0.009693877551020408 service_time: 1304 s_time: 19 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: 0.0 service_time: 1456 s_time: 0 penalty: 0 agent_num: 42 done: False
______________________
id: 46 reward: -0.01358695652173913 service_time: 1380 s_time: 35 penalty: 0 agent_num: 46 done: False
______________________
Step:  1744
Pretraining Loss:  tensor(0.0684, device='cuda:0', grad_fn=<MeanBackward0>)
id: 44 reward: -0.02142857142857143 service_time: 707 s_time: 12 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: -0.060064935064935064 service_time: 553 s_time: 37 penalty: 0 agent_num: 11 done: False
______________________
id: 53 reward: 0.0 service_time: 970 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 47 reward: 0.0 service_time: 860 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: -0.06860902255639098 service_time: 1015 s_time: 73 penalty: 0 agent_num: 19 done: False
______________________
id: 52 reward: -0.047619047619047616 service_time: 1122 s_time: 72 penalty: 0 agent_num: 27 done: False
______________________
id: 42 reward: -0.02976190476190476 service_time: 1370 s_time: 45 penalty: 0 agent_num: 27 done: False
______________________
id: 54 reward: -0.007936507936507936 service_time: 1425 s_time: 12 penalty: 0 agent_num: 27 done: False
______________________
id: 55 reward: -0.030032467532467532 service_time: 1217 s_time: 37 penalty: 0 agent_num: 22 done: False
______________________
id: 50 reward: -0.0166256157635468 service_time: 1223 s_time: 27 penalty: 0 agent_num: 29 done: False
______________________
id: 43 reward: -0.014285714285714285 service_time: 1246 s_time: 28 penalty: 0 agent_num: 35 done: False
______________________
id: 41 reward: -0.016233766233766232 service_time: 1392 s_time: 20 penalty: 0 agent_num: 22 done: False
______________________
id: 45 reward: 0.0 service_time: 1442 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 49 reward: -0.018367346938775512 service_time: 1340 s_time: 36 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.008078231292517007 service_time: 1475 s_time: 19 penalty: 0 agent_num: 42 done: False
______________________
id: 46 reward: -0.009316770186335404 service_time: 1404 s_time: 24 penalty: 0 agent_num: 46 done: False
______________________
Step:  1760
Pretraining Loss:  tensor(0.0665, device='cuda:0', grad_fn=<MeanBackward0>)
id: 44 reward: 0.0 service_time: 707 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: 0.0 service_time: 553 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 53 reward: 0.0 service_time: 970 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 47 reward: 0.0 service_time: 860 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: -0.0037593984962406013 service_time: 1019 s_time: 4 penalty: 0 agent_num: 19 done: False
______________________
id: 54 reward: 0.0 service_time: 1425 s_time: 0 penalty: 0 agent_num: 27 done: False
______________________
id: 52 reward: 0.0 service_time: 1122 s_time: 0 penalty: 0 agent_num: 27 done: False
______________________
id: 41 reward: 0.015422077922077922 service_time: 1373 s_time: -19 penalty: 0 agent_num: 22 done: False
______________________
id: 45 reward: -0.03520408163265306 service_time: 1511 s_time: 69 penalty: 0 agent_num: 35 done: False
______________________
id: 55 reward: 0.018668831168831168 service_time: 1194 s_time: -23 penalty: 0 agent_num: 22 done: False
______________________
id: 42 reward: 0.0 service_time: 1370 s_time: 0 penalty: 0 agent_num: 27 done: False
______________________
id: 50 reward: -0.03263546798029557 service_time: 1276 s_time: 53 penalty: 0 agent_num: 29 done: False
______________________
id: 49 reward: -0.018877551020408164 service_time: 1377 s_time: 37 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.004251700680272109 service_time: 1485 s_time: 10 penalty: 0 agent_num: 42 done: False
______________________
id: 46 reward: -0.01436335403726708 service_time: 1441 s_time: 37 penalty: 0 agent_num: 46 done: False
______________________
id: 43 reward: -0.020918367346938777 service_time: 1287 s_time: 41 penalty: 0 agent_num: 35 done: False
______________________
Step:  1776
Pretraining Loss:  tensor(0.0721, device='cuda:0', grad_fn=<MeanBackward0>)
id: 51 reward: -0.06818181818181818 service_time: 595 s_time: 42 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: 0.0 service_time: 707 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 53 reward: -0.08035714285714286 service_time: 1042 s_time: 72 penalty: 0 agent_num: 16 done: False
______________________
id: 47 reward: -0.03459821428571429 service_time: 891 s_time: 31 penalty: 0 agent_num: 16 done: False
______________________
id: 54 reward: -0.042328042328042326 service_time: 1489 s_time: 64 penalty: 0 agent_num: 27 done: False
______________________
id: 55 reward: 0.0 service_time: 1194 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 42 reward: -0.01521164021164021 service_time: 1393 s_time: 23 penalty: 0 agent_num: 27 done: False
______________________
id: 41 reward: -0.00487012987012987 service_time: 1379 s_time: 6 penalty: 0 agent_num: 22 done: False
______________________
id: 40 reward: -0.03853383458646616 service_time: 1060 s_time: 41 penalty: 0 agent_num: 19 done: False
______________________
id: 52 reward: -0.0205026455026455 service_time: 1153 s_time: 31 penalty: 0 agent_num: 27 done: False
______________________
id: 50 reward: -0.020320197044334975 service_time: 1309 s_time: 33 penalty: 0 agent_num: 29 done: False
______________________
id: 43 reward: -0.0163265306122449 service_time: 1319 s_time: 32 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.008928571428571428 service_time: 1506 s_time: 21 penalty: 0 agent_num: 42 done: False
______________________
id: 45 reward: -0.018877551020408164 service_time: 1548 s_time: 37 penalty: 0 agent_num: 35 done: False
______________________
id: 49 reward: -0.017857142857142856 service_time: 1412 s_time: 35 penalty: 0 agent_num: 35 done: False
______________________
id: 46 reward: 0.0007763975155279503 service_time: 1439 s_time: -2 penalty: 0 agent_num: 46 done: False
______________________
Step:  1792
Pretraining Loss:  tensor(0.0700, device='cuda:0', grad_fn=<MeanBackward0>)
id: 44 reward: 0.0 service_time: 707 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: 0.0 service_time: 595 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 53 reward: -0.024553571428571428 service_time: 1064 s_time: 22 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: 0.004699248120300752 service_time: 1055 s_time: -5 penalty: 0 agent_num: 19 done: False
______________________
id: 47 reward: -0.04352678571428571 service_time: 930 s_time: 39 penalty: 0 agent_num: 16 done: False
______________________
id: 55 reward: -0.002435064935064935 service_time: 1197 s_time: 3 penalty: 0 agent_num: 22 done: False
______________________
id: 41 reward: -0.11038961038961038 service_time: 1515 s_time: 136 penalty: 0 agent_num: 22 done: False
______________________
id: 54 reward: -0.017857142857142856 service_time: 1516 s_time: 27 penalty: 0 agent_num: 27 done: False
______________________
id: 42 reward: -0.025793650793650792 service_time: 1432 s_time: 39 penalty: 0 agent_num: 27 done: False
______________________
id: 45 reward: -0.010714285714285714 service_time: 1569 s_time: 21 penalty: 0 agent_num: 35 done: False
______________________
id: 50 reward: 0.0012315270935960591 service_time: 1307 s_time: -2 penalty: 0 agent_num: 29 done: False
______________________
id: 48 reward: -0.00935374149659864 service_time: 1528 s_time: 22 penalty: 0 agent_num: 42 done: False
______________________
id: 49 reward: -0.00510204081632653 service_time: 1422 s_time: 10 penalty: 0 agent_num: 35 done: False
______________________
id: 52 reward: -0.018518518518518517 service_time: 1181 s_time: 28 penalty: 0 agent_num: 27 done: False
______________________
id: 43 reward: -0.0163265306122449 service_time: 1351 s_time: 32 penalty: 0 agent_num: 35 done: False
______________________
id: 46 reward: -0.016692546583850932 service_time: 1482 s_time: 43 penalty: 0 agent_num: 46 done: False
______________________
Step:  1808
Pretraining Loss:  tensor(0.0668, device='cuda:0', grad_fn=<MeanBackward0>)
id: 44 reward: -0.15357142857142858 service_time: 793 s_time: 86 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: 0.0 service_time: 595 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: -0.03794642857142857 service_time: 964 s_time: 34 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: 0.018796992481203006 service_time: 1035 s_time: -20 penalty: 0 agent_num: 19 done: False
______________________
id: 55 reward: 0.0008116883116883117 service_time: 1196 s_time: -1 penalty: 0 agent_num: 22 done: False
______________________
id: 53 reward: 0.0 service_time: 1064 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 41 reward: -0.012175324675324676 service_time: 1530 s_time: 15 penalty: 0 agent_num: 22 done: False
______________________
id: 42 reward: -0.04497354497354497 service_time: 1500 s_time: 68 penalty: 0 agent_num: 27 done: False
______________________
id: 54 reward: -0.009259259259259259 service_time: 1530 s_time: 14 penalty: 0 agent_num: 27 done: False
______________________
id: 49 reward: -0.01479591836734694 service_time: 1451 s_time: 29 penalty: 0 agent_num: 35 done: False
______________________
id: 52 reward: 0.0 service_time: 1181 s_time: 0 penalty: 0 agent_num: 27 done: False
______________________
id: 45 reward: -0.0066326530612244895 service_time: 1582 s_time: 13 penalty: 0 agent_num: 35 done: False
______________________
id: 50 reward: -0.04864532019704434 service_time: 1386 s_time: 79 penalty: 0 agent_num: 29 done: False
______________________
id: 48 reward: -0.011904761904761904 service_time: 1556 s_time: 28 penalty: 0 agent_num: 42 done: False
______________________
id: 46 reward: -0.018633540372670808 service_time: 1530 s_time: 48 penalty: 0 agent_num: 46 done: False
______________________
id: 43 reward: -0.020918367346938777 service_time: 1392 s_time: 41 penalty: 0 agent_num: 35 done: False
______________________
Step:  1824
Pretraining Loss:  tensor(0.0714, device='cuda:0', grad_fn=<MeanBackward0>)
id: 51 reward: -0.01948051948051948 service_time: 607 s_time: 12 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: 0.0 service_time: 793 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 53 reward: 0.0 service_time: 1064 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 47 reward: 0.0 service_time: 964 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: -0.044172932330827065 service_time: 1082 s_time: 47 penalty: 0 agent_num: 19 done: False
______________________
id: 55 reward: -0.05438311688311688 service_time: 1263 s_time: 67 penalty: 0 agent_num: 22 done: False
______________________
id: 45 reward: -0.017346938775510204 service_time: 1616 s_time: 34 penalty: 0 agent_num: 35 done: False
______________________
id: 41 reward: -0.028409090909090908 service_time: 1565 s_time: 35 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: -0.02295918367346939 service_time: 1496 s_time: 45 penalty: 0 agent_num: 35 done: False
______________________
id: 50 reward: 0.003694581280788177 service_time: 1380 s_time: -6 penalty: 0 agent_num: 29 done: False
______________________
id: 48 reward: -0.011054421768707483 service_time: 1582 s_time: 26 penalty: 0 agent_num: 42 done: False
______________________
id: 52 reward: 0.0 service_time: 1181 s_time: 0 penalty: 0 agent_num: 27 done: False
______________________
id: 54 reward: -0.03042328042328042 service_time: 1576 s_time: 46 penalty: 0 agent_num: 27 done: False
______________________
id: 46 reward: -0.004658385093167702 service_time: 1542 s_time: 12 penalty: 0 agent_num: 46 done: False
______________________
id: 43 reward: -0.0035714285714285713 service_time: 1399 s_time: 7 penalty: 0 agent_num: 35 done: False
______________________
id: 42 reward: -0.03571428571428571 service_time: 1554 s_time: 54 penalty: 0 agent_num: 27 done: False
______________________
Step:  1840
Pretraining Loss:  tensor(0.0811, device='cuda:0', grad_fn=<MeanBackward0>)
id: 44 reward: 0.0 service_time: 793 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 53 reward: -0.05803571428571429 service_time: 1116 s_time: 52 penalty: 0 agent_num: 16 done: False
______________________
id: 51 reward: 0.0 service_time: 607 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: -0.036830357142857144 service_time: 997 s_time: 33 penalty: 0 agent_num: 16 done: False
______________________
id: 55 reward: -0.04626623376623377 service_time: 1320 s_time: 57 penalty: 0 agent_num: 22 done: False
______________________
id: 40 reward: -0.06390977443609022 service_time: 1150 s_time: 68 penalty: 0 agent_num: 19 done: False
______________________
id: 41 reward: 0.0 service_time: 1565 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 52 reward: 0.009259259259259259 service_time: 1167 s_time: -14 penalty: 0 agent_num: 27 done: False
______________________
id: 54 reward: -0.028439153439153438 service_time: 1619 s_time: 43 penalty: 0 agent_num: 27 done: False
______________________
id: 42 reward: 0.01455026455026455 service_time: 1532 s_time: -22 penalty: 0 agent_num: 27 done: False
______________________
id: 49 reward: -0.008673469387755102 service_time: 1513 s_time: 17 penalty: 0 agent_num: 35 done: False
______________________
id: 45 reward: -0.01683673469387755 service_time: 1649 s_time: 33 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: 0.0 service_time: 1582 s_time: 0 penalty: 0 agent_num: 42 done: False
______________________
id: 43 reward: -0.010714285714285714 service_time: 1420 s_time: 21 penalty: 0 agent_num: 35 done: False
______________________
id: 50 reward: -0.02647783251231527 service_time: 1423 s_time: 43 penalty: 0 agent_num: 29 done: False
______________________
id: 46 reward: -0.016692546583850932 service_time: 1585 s_time: 43 penalty: 0 agent_num: 46 done: False
______________________
Step:  1856
Pretraining Loss:  tensor(0.0756, device='cuda:0', grad_fn=<MeanBackward0>)
id: 44 reward: 0.04107142857142857 service_time: 770 s_time: -23 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: -0.18019480519480519 service_time: 718 s_time: 111 penalty: 0 agent_num: 11 done: False
______________________
id: 53 reward: -0.03125 service_time: 1144 s_time: 28 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: 0.007518796992481203 service_time: 1142 s_time: -8 penalty: 0 agent_num: 19 done: False
______________________
id: 47 reward: -0.03571428571428571 service_time: 1029 s_time: 32 penalty: 0 agent_num: 16 done: False
______________________
id: 41 reward: -0.030032467532467532 service_time: 1602 s_time: 37 penalty: 0 agent_num: 22 done: False
______________________
id: 55 reward: -0.032467532467532464 service_time: 1360 s_time: 40 penalty: 0 agent_num: 22 done: False
______________________
id: 45 reward: -0.01020408163265306 service_time: 1669 s_time: 20 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: 0.009259259259259259 service_time: 1605 s_time: -14 penalty: 0 agent_num: 27 done: False
______________________
id: 52 reward: -0.0291005291005291 service_time: 1211 s_time: 44 penalty: 0 agent_num: 27 done: False
______________________
id: 49 reward: 0.0035714285714285713 service_time: 1506 s_time: -7 penalty: 0 agent_num: 35 done: False
______________________
id: 43 reward: 0.0 service_time: 1420 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.025085034013605442 service_time: 1641 s_time: 59 penalty: 0 agent_num: 42 done: False
______________________
id: 42 reward: 0.0 service_time: 1532 s_time: 0 penalty: 0 agent_num: 27 done: False
______________________
id: 50 reward: 0.0 service_time: 1423 s_time: 0 penalty: 0 agent_num: 29 done: False
______________________
id: 46 reward: -0.008928571428571428 service_time: 1608 s_time: 23 penalty: 0 agent_num: 46 done: False
______________________
Step:  1872
Pretraining Loss:  tensor(0.0700, device='cuda:0', grad_fn=<MeanBackward0>)
id: 44 reward: -0.07321428571428572 service_time: 811 s_time: 41 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: -0.0633116883116883 service_time: 757 s_time: 39 penalty: 0 agent_num: 11 done: False
______________________
id: 53 reward: 0.008928571428571428 service_time: 1136 s_time: -8 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: -0.022556390977443608 service_time: 1166 s_time: 24 penalty: 0 agent_num: 19 done: False
______________________
id: 41 reward: -0.021915584415584416 service_time: 1629 s_time: 27 penalty: 0 agent_num: 22 done: False
______________________
id: 42 reward: 0.008597883597883597 service_time: 1519 s_time: -13 penalty: 0 agent_num: 27 done: False
______________________
id: 47 reward: -0.044642857142857144 service_time: 1069 s_time: 40 penalty: 0 agent_num: 16 done: False
______________________
id: 55 reward: -0.030032467532467532 service_time: 1397 s_time: 37 penalty: 0 agent_num: 22 done: False
______________________
id: 52 reward: -0.005952380952380952 service_time: 1220 s_time: 9 penalty: 0 agent_num: 27 done: False
______________________
id: 54 reward: -0.037698412698412696 service_time: 1662 s_time: 57 penalty: 0 agent_num: 27 done: False
______________________
id: 43 reward: -0.02040816326530612 service_time: 1460 s_time: 40 penalty: 0 agent_num: 35 done: False
______________________
id: 45 reward: 0.0010204081632653062 service_time: 1667 s_time: -2 penalty: 0 agent_num: 35 done: False
______________________
id: 49 reward: -0.02806122448979592 service_time: 1561 s_time: 55 penalty: 0 agent_num: 35 done: False
______________________
id: 46 reward: -0.0007763975155279503 service_time: 1610 s_time: 2 penalty: 0 agent_num: 46 done: False
______________________
id: 48 reward: -0.003401360544217687 service_time: 1649 s_time: 8 penalty: 0 agent_num: 42 done: False
______________________
id: 50 reward: -0.029556650246305417 service_time: 1471 s_time: 48 penalty: 0 agent_num: 29 done: False
______________________
Step:  1888
Pretraining Loss:  tensor(0.0750, device='cuda:0', grad_fn=<MeanBackward0>)
id: 51 reward: -0.016233766233766232 service_time: 767 s_time: 10 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: -0.05 service_time: 839 s_time: 28 penalty: 0 agent_num: 10 done: False
______________________
id: 53 reward: -0.027901785714285716 service_time: 1161 s_time: 25 penalty: 0 agent_num: 16 done: False
______________________
id: 47 reward: 0.0 service_time: 1069 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: -0.09398496240601503 service_time: 1266 s_time: 100 penalty: 0 agent_num: 19 done: False
______________________
id: 41 reward: 0.0016233766233766235 service_time: 1627 s_time: -2 penalty: 0 agent_num: 22 done: False
______________________
id: 52 reward: -0.07341269841269842 service_time: 1331 s_time: 111 penalty: 0 agent_num: 27 done: False
______________________
id: 45 reward: -0.02857142857142857 service_time: 1723 s_time: 56 penalty: 0 agent_num: 35 done: False
______________________
id: 55 reward: -0.049512987012987016 service_time: 1458 s_time: 61 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: -0.023979591836734693 service_time: 1608 s_time: 47 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.00977891156462585 service_time: 1672 s_time: 23 penalty: 0 agent_num: 42 done: False
______________________
id: 43 reward: -0.02959183673469388 service_time: 1518 s_time: 58 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: -0.02976190476190476 service_time: 1707 s_time: 45 penalty: 0 agent_num: 27 done: False
______________________
id: 46 reward: -0.009316770186335404 service_time: 1634 s_time: 24 penalty: 0 agent_num: 46 done: False
______________________
id: 42 reward: -0.026455026455026454 service_time: 1559 s_time: 40 penalty: 0 agent_num: 27 done: False
______________________
id: 50 reward: -0.0024630541871921183 service_time: 1475 s_time: 4 penalty: 0 agent_num: 29 done: False
______________________
Step:  1904
Pretraining Loss:  tensor(0.0819, device='cuda:0', grad_fn=<MeanBackward0>)
id: 51 reward: 0.0 service_time: 767 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: -0.08035714285714286 service_time: 884 s_time: 45 penalty: 0 agent_num: 10 done: False
______________________
id: 47 reward: 0.0 service_time: 1069 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: 0.03571428571428571 service_time: 1228 s_time: -38 penalty: 0 agent_num: 19 done: False
______________________
id: 53 reward: -0.17075892857142858 service_time: 1314 s_time: 153 penalty: 0 agent_num: 16 done: False
______________________
id: 41 reward: -0.048701298701298704 service_time: 1687 s_time: 60 penalty: 0 agent_num: 22 done: False
______________________
id: 42 reward: 0.01917989417989418 service_time: 1530 s_time: -29 penalty: 0 agent_num: 27 done: False
______________________
id: 55 reward: -0.017045454545454544 service_time: 1479 s_time: 21 penalty: 0 agent_num: 22 done: False
______________________
id: 43 reward: -0.009183673469387756 service_time: 1536 s_time: 18 penalty: 0 agent_num: 35 done: False
______________________
id: 49 reward: 0.001530612244897959 service_time: 1605 s_time: -3 penalty: 0 agent_num: 35 done: False
______________________
id: 52 reward: -0.02447089947089947 service_time: 1368 s_time: 37 penalty: 0 agent_num: 27 done: False
______________________
id: 45 reward: -0.002551020408163265 service_time: 1728 s_time: 5 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: 0.0 service_time: 1672 s_time: 0 penalty: 0 agent_num: 42 done: False
______________________
id: 46 reward: -0.0007763975155279503 service_time: 1636 s_time: 2 penalty: 0 agent_num: 46 done: False
______________________
id: 50 reward: -0.020320197044334975 service_time: 1508 s_time: 33 penalty: 0 agent_num: 29 done: False
______________________
id: 54 reward: 0.006613756613756613 service_time: 1697 s_time: -10 penalty: 0 agent_num: 27 done: False
______________________
Step:  1920
Pretraining Loss:  tensor(0.0808, device='cuda:0', grad_fn=<MeanBackward0>)
id: 44 reward: 0.0 service_time: 884 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: 0.0 service_time: 767 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: -0.04575892857142857 service_time: 1110 s_time: 41 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: -0.06766917293233082 service_time: 1300 s_time: 72 penalty: 0 agent_num: 19 done: False
______________________
id: 41 reward: -0.030844155844155844 service_time: 1725 s_time: 38 penalty: 0 agent_num: 22 done: False
______________________
id: 55 reward: -0.016233766233766232 service_time: 1499 s_time: 20 penalty: 0 agent_num: 22 done: False
______________________
id: 53 reward: 0.027901785714285716 service_time: 1289 s_time: -25 penalty: 0 agent_num: 16 done: False
______________________
id: 45 reward: -0.00816326530612245 service_time: 1744 s_time: 16 penalty: 0 agent_num: 35 done: False
______________________
id: 42 reward: -0.012566137566137565 service_time: 1549 s_time: 19 penalty: 0 agent_num: 27 done: False
______________________
id: 54 reward: -0.013888888888888888 service_time: 1718 s_time: 21 penalty: 0 agent_num: 27 done: False
______________________
id: 49 reward: -0.027551020408163266 service_time: 1659 s_time: 54 penalty: 0 agent_num: 35 done: False
______________________
id: 43 reward: -0.02142857142857143 service_time: 1578 s_time: 42 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.022534013605442178 service_time: 1725 s_time: 53 penalty: 0 agent_num: 42 done: False
______________________
id: 46 reward: -0.013975155279503106 service_time: 1672 s_time: 36 penalty: 0 agent_num: 46 done: False
______________________
id: 50 reward: -0.04433497536945813 service_time: 1580 s_time: 72 penalty: 0 agent_num: 29 done: False
______________________
id: 52 reward: -0.07539682539682539 service_time: 1482 s_time: 114 penalty: 0 agent_num: 27 done: False
______________________
Step:  1936
Pretraining Loss:  tensor(0.0852, device='cuda:0', grad_fn=<MeanBackward0>)
id: 51 reward: 0.0 service_time: 767 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: 0.0 service_time: 884 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 53 reward: 0.0 service_time: 1289 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 47 reward: 0.0 service_time: 1110 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 41 reward: 0.006493506493506494 service_time: 1717 s_time: -8 penalty: 0 agent_num: 22 done: False
______________________
id: 40 reward: -0.03289473684210526 service_time: 1335 s_time: 35 penalty: 0 agent_num: 19 done: False
______________________
id: 55 reward: 0.0 service_time: 1499 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 45 reward: -0.017857142857142856 service_time: 1779 s_time: 35 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: -0.016534391534391533 service_time: 1743 s_time: 25 penalty: 0 agent_num: 27 done: False
______________________
id: 49 reward: -0.008673469387755102 service_time: 1676 s_time: 17 penalty: 0 agent_num: 35 done: False
______________________
id: 43 reward: 0.004591836734693878 service_time: 1569 s_time: -9 penalty: 0 agent_num: 35 done: False
______________________
id: 42 reward: -0.023809523809523808 service_time: 1585 s_time: 36 penalty: 0 agent_num: 27 done: False
______________________
id: 46 reward: -0.011645962732919254 service_time: 1702 s_time: 30 penalty: 0 agent_num: 46 done: False
______________________
id: 52 reward: 0.046296296296296294 service_time: 1412 s_time: -70 penalty: 0 agent_num: 27 done: False
______________________
id: 48 reward: -0.00467687074829932 service_time: 1736 s_time: 11 penalty: 0 agent_num: 42 done: False
______________________
id: 50 reward: -0.06096059113300493 service_time: 1679 s_time: 99 penalty: 0 agent_num: 29 done: False
______________________
Step:  1952
Pretraining Loss:  tensor(0.0856, device='cuda:0', grad_fn=<MeanBackward0>)
id: 51 reward: 0.0 service_time: 767 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: -0.04285714285714286 service_time: 908 s_time: 24 penalty: 0 agent_num: 10 done: False
______________________
id: 47 reward: 0.0 service_time: 1110 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: -0.042293233082706765 service_time: 1380 s_time: 45 penalty: 0 agent_num: 19 done: False
______________________
id: 53 reward: -0.04352678571428571 service_time: 1328 s_time: 39 penalty: 0 agent_num: 16 done: False
______________________
id: 41 reward: 0.0 service_time: 1717 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 55 reward: -0.00487012987012987 service_time: 1505 s_time: 6 penalty: 0 agent_num: 22 done: False
______________________
id: 54 reward: 0.0 service_time: 1743 s_time: 0 penalty: 0 agent_num: 27 done: False
______________________
id: 49 reward: -0.009183673469387756 service_time: 1694 s_time: 18 penalty: 0 agent_num: 35 done: False
______________________
id: 42 reward: -0.01917989417989418 service_time: 1614 s_time: 29 penalty: 0 agent_num: 27 done: False
______________________
id: 45 reward: -0.022448979591836733 service_time: 1823 s_time: 44 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.011904761904761904 service_time: 1764 s_time: 28 penalty: 0 agent_num: 42 done: False
______________________
id: 46 reward: 0.0 service_time: 1702 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 52 reward: -0.03042328042328042 service_time: 1458 s_time: 46 penalty: 0 agent_num: 27 done: False
______________________
id: 43 reward: -0.0336734693877551 service_time: 1635 s_time: 66 penalty: 0 agent_num: 35 done: False
______________________
id: 50 reward: 0.008004926108374385 service_time: 1666 s_time: -13 penalty: 0 agent_num: 29 done: False
______________________
Step:  1968
Pretraining Loss:  tensor(0.0776, device='cuda:0', grad_fn=<MeanBackward0>)
id: 44 reward: 0.0 service_time: 908 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: -0.04220779220779221 service_time: 793 s_time: 26 penalty: 0 agent_num: 11 done: False
______________________
id: 40 reward: -0.042293233082706765 service_time: 1425 s_time: 45 penalty: 0 agent_num: 19 done: False
______________________
id: 47 reward: -0.041294642857142856 service_time: 1147 s_time: 37 penalty: 0 agent_num: 16 done: False
______________________
id: 41 reward: 0.025162337662337664 service_time: 1686 s_time: -31 penalty: 0 agent_num: 22 done: False
______________________
id: 53 reward: -0.05580357142857143 service_time: 1378 s_time: 50 penalty: 0 agent_num: 16 done: False
______________________
id: 55 reward: -0.0349025974025974 service_time: 1548 s_time: 43 penalty: 0 agent_num: 22 done: False
______________________
id: 42 reward: -0.006613756613756613 service_time: 1624 s_time: 10 penalty: 0 agent_num: 27 done: False
______________________
id: 49 reward: 0.0010204081632653062 service_time: 1692 s_time: -2 penalty: 0 agent_num: 35 done: False
______________________
id: 45 reward: -0.0010204081632653062 service_time: 1825 s_time: 2 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.012755102040816327 service_time: 1794 s_time: 30 penalty: 0 agent_num: 42 done: False
______________________
id: 50 reward: 0.019088669950738917 service_time: 1635 s_time: -31 penalty: 0 agent_num: 29 done: False
______________________
id: 46 reward: -0.01048136645962733 service_time: 1729 s_time: 27 penalty: 0 agent_num: 46 done: False
______________________
id: 52 reward: -0.01455026455026455 service_time: 1480 s_time: 22 penalty: 0 agent_num: 27 done: False
______________________
id: 54 reward: -0.042328042328042326 service_time: 1807 s_time: 64 penalty: 0 agent_num: 27 done: False
______________________
id: 43 reward: 0.0020408163265306124 service_time: 1631 s_time: -4 penalty: 0 agent_num: 35 done: False
______________________
Step:  1984
Pretraining Loss:  tensor(0.0815, device='cuda:0', grad_fn=<MeanBackward0>)
id: 51 reward: 0.0 service_time: 793 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: -0.06785714285714285 service_time: 946 s_time: 38 penalty: 0 agent_num: 10 done: False
______________________
id: 40 reward: -0.03665413533834586 service_time: 1464 s_time: 39 penalty: 0 agent_num: 19 done: False
______________________
id: 41 reward: 0.0 service_time: 1686 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 53 reward: 0.06138392857142857 service_time: 1323 s_time: -55 penalty: 0 agent_num: 16 done: False
______________________
id: 55 reward: -0.11201298701298701 service_time: 1686 s_time: 138 penalty: 0 agent_num: 22 done: False
______________________
id: 54 reward: 0.0013227513227513227 service_time: 1805 s_time: -2 penalty: 0 agent_num: 27 done: False
______________________
id: 49 reward: -0.027551020408163266 service_time: 1746 s_time: 54 penalty: 0 agent_num: 35 done: False
______________________
id: 45 reward: -0.01989795918367347 service_time: 1864 s_time: 39 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.008078231292517007 service_time: 1813 s_time: 19 penalty: 0 agent_num: 42 done: False
______________________
id: 47 reward: -0.060267857142857144 service_time: 1201 s_time: 54 penalty: 0 agent_num: 16 done: False
______________________
id: 42 reward: -0.03042328042328042 service_time: 1670 s_time: 46 penalty: 0 agent_num: 27 done: False
______________________
id: 46 reward: -0.01125776397515528 service_time: 1758 s_time: 29 penalty: 0 agent_num: 46 done: False
______________________
id: 43 reward: -0.017346938775510204 service_time: 1665 s_time: 34 penalty: 0 agent_num: 35 done: False
______________________
id: 50 reward: -0.054187192118226604 service_time: 1723 s_time: 88 penalty: 0 agent_num: 29 done: False
______________________
id: 52 reward: -0.031084656084656083 service_time: 1527 s_time: 47 penalty: 0 agent_num: 27 done: False
______________________
Step:  2000
Pretraining Loss:  tensor(0.0919, device='cuda:0', grad_fn=<MeanBackward0>)
id: 51 reward: 0.0 service_time: 793 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: -0.03571428571428571 service_time: 966 s_time: 20 penalty: 0 agent_num: 10 done: False
______________________
id: 47 reward: 0.0 service_time: 1201 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 53 reward: -0.024553571428571428 service_time: 1345 s_time: 22 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: 0.02725563909774436 service_time: 1435 s_time: -29 penalty: 0 agent_num: 19 done: False
______________________
id: 55 reward: 0.00487012987012987 service_time: 1680 s_time: -6 penalty: 0 agent_num: 22 done: False
______________________
id: 41 reward: 0.0 service_time: 1686 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: -0.00816326530612245 service_time: 1762 s_time: 16 penalty: 0 agent_num: 35 done: False
______________________
id: 42 reward: -0.022486772486772486 service_time: 1704 s_time: 34 penalty: 0 agent_num: 27 done: False
______________________
id: 45 reward: -0.01173469387755102 service_time: 1887 s_time: 23 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: -0.05423280423280423 service_time: 1887 s_time: 82 penalty: 0 agent_num: 27 done: False
______________________
id: 46 reward: 0.002717391304347826 service_time: 1751 s_time: -7 penalty: 0 agent_num: 46 done: False
______________________
id: 48 reward: -0.01403061224489796 service_time: 1846 s_time: 33 penalty: 0 agent_num: 42 done: False
______________________
id: 43 reward: -0.03163265306122449 service_time: 1727 s_time: 62 penalty: 0 agent_num: 35 done: False
______________________
id: 52 reward: -0.013227513227513227 service_time: 1547 s_time: 20 penalty: 0 agent_num: 27 done: False
______________________
id: 50 reward: -0.03694581280788178 service_time: 1783 s_time: 60 penalty: 0 agent_num: 29 done: False
______________________
Step:  2016
Pretraining Loss:  tensor(0.0713, device='cuda:0', grad_fn=<MeanBackward0>)
id: 44 reward: -0.048214285714285716 service_time: 993 s_time: 27 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: -0.0698051948051948 service_time: 836 s_time: 43 penalty: 0 agent_num: 11 done: False
______________________
id: 53 reward: 0.0 service_time: 1345 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 47 reward: -0.030133928571428572 service_time: 1228 s_time: 27 penalty: 0 agent_num: 16 done: False
______________________
id: 55 reward: -0.018668831168831168 service_time: 1703 s_time: 23 penalty: 0 agent_num: 22 done: False
______________________
id: 41 reward: 0.0016233766233766235 service_time: 1684 s_time: -2 penalty: 0 agent_num: 22 done: False
______________________
id: 54 reward: -0.027777777777777776 service_time: 1929 s_time: 42 penalty: 0 agent_num: 27 done: False
______________________
id: 49 reward: -0.015816326530612244 service_time: 1793 s_time: 31 penalty: 0 agent_num: 35 done: False
______________________
id: 45 reward: 0.0163265306122449 service_time: 1855 s_time: -32 penalty: 0 agent_num: 35 done: False
______________________
id: 40 reward: -0.10056390977443609 service_time: 1542 s_time: 107 penalty: 0 agent_num: 19 done: False
______________________
id: 46 reward: -0.02251552795031056 service_time: 1809 s_time: 58 penalty: 0 agent_num: 46 done: False
______________________
id: 48 reward: -0.01870748299319728 service_time: 1890 s_time: 44 penalty: 0 agent_num: 42 done: False
______________________
id: 43 reward: -0.0005102040816326531 service_time: 1728 s_time: 1 penalty: 0 agent_num: 35 done: False
______________________
id: 50 reward: -0.0024630541871921183 service_time: 1787 s_time: 4 penalty: 0 agent_num: 29 done: False
______________________
id: 42 reward: -0.08068783068783068 service_time: 1826 s_time: 122 penalty: 0 agent_num: 27 done: False
______________________
id: 52 reward: -0.03571428571428571 service_time: 1601 s_time: 54 penalty: 0 agent_num: 27 done: False
______________________
Step:  2032
Pretraining Loss:  tensor(0.0631, device='cuda:0', grad_fn=<MeanBackward0>)
id: 53 reward: 0.0 service_time: 1345 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 44 reward: -0.12857142857142856 service_time: 1065 s_time: 72 penalty: 0 agent_num: 10 done: False
______________________
id: 47 reward: 0.0 service_time: 1228 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 51 reward: 0.0 service_time: 836 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 55 reward: -0.03571428571428571 service_time: 1747 s_time: 44 penalty: 0 agent_num: 22 done: False
______________________
id: 40 reward: -0.008458646616541353 service_time: 1551 s_time: 9 penalty: 0 agent_num: 19 done: False
______________________
id: 41 reward: -0.030844155844155844 service_time: 1722 s_time: 38 penalty: 0 agent_num: 22 done: False
______________________
id: 45 reward: -0.03010204081632653 service_time: 1914 s_time: 59 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.00467687074829932 service_time: 1901 s_time: 11 penalty: 0 agent_num: 42 done: False
______________________
id: 49 reward: 0.0010204081632653062 service_time: 1791 s_time: -2 penalty: 0 agent_num: 35 done: False
______________________
id: 50 reward: -0.013546798029556651 service_time: 1809 s_time: 22 penalty: 0 agent_num: 29 done: False
______________________
id: 54 reward: -0.007275132275132275 service_time: 1940 s_time: 11 penalty: 0 agent_num: 27 done: False
______________________
id: 43 reward: -0.02142857142857143 service_time: 1770 s_time: 42 penalty: 0 agent_num: 35 done: False
______________________
id: 46 reward: -0.010093167701863354 service_time: 1835 s_time: 26 penalty: 0 agent_num: 46 done: False
______________________
id: 52 reward: -0.003968253968253968 service_time: 1607 s_time: 6 penalty: 0 agent_num: 27 done: False
______________________
id: 42 reward: -0.04497354497354497 service_time: 1894 s_time: 68 penalty: 0 agent_num: 27 done: False
______________________
Step:  2048
Pretraining Loss:  tensor(0.0618, device='cuda:0', grad_fn=<MeanBackward0>)
id: 44 reward: 0.0035714285714285713 service_time: 1063 s_time: -2 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: 0.0 service_time: 836 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 53 reward: 0.0 service_time: 1345 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 47 reward: -0.036830357142857144 service_time: 1261 s_time: 33 penalty: 0 agent_num: 16 done: False
______________________
id: 41 reward: -0.04220779220779221 service_time: 1774 s_time: 52 penalty: 0 agent_num: 22 done: False
______________________
id: 40 reward: 0.0 service_time: 1551 s_time: 0 penalty: 0 agent_num: 19 done: False
______________________
id: 55 reward: 0.0016233766233766235 service_time: 1745 s_time: -2 penalty: 0 agent_num: 22 done: False
______________________
id: 45 reward: 0.0 service_time: 1914 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 52 reward: 0.006613756613756613 service_time: 1597 s_time: -10 penalty: 0 agent_num: 27 done: False
______________________
id: 46 reward: -0.013198757763975156 service_time: 1869 s_time: 34 penalty: 0 agent_num: 46 done: False
______________________
id: 49 reward: -0.023979591836734693 service_time: 1838 s_time: 47 penalty: 0 agent_num: 35 done: False
______________________
id: 43 reward: -0.012244897959183673 service_time: 1794 s_time: 24 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.002976190476190476 service_time: 1908 s_time: 7 penalty: 0 agent_num: 42 done: False
______________________
id: 50 reward: -0.04926108374384237 service_time: 1889 s_time: 80 penalty: 0 agent_num: 29 done: False
______________________
id: 54 reward: -0.021825396825396824 service_time: 1973 s_time: 33 penalty: 0 agent_num: 27 done: False
______________________
id: 42 reward: -0.027777777777777776 service_time: 1936 s_time: 42 penalty: 0 agent_num: 27 done: False
______________________
Step:  2064
Pretraining Loss:  tensor(0.0560, device='cuda:0', grad_fn=<MeanBackward0>)
id: 44 reward: 0.0035714285714285713 service_time: 1061 s_time: -2 penalty: 0 agent_num: 10 done: False
______________________
id: 40 reward: -0.03289473684210526 service_time: 1586 s_time: 35 penalty: 0 agent_num: 19 done: False
______________________
id: 55 reward: 0.0 service_time: 1745 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: 0.0 service_time: 836 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: 0.0 service_time: 1261 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 41 reward: -0.03165584415584415 service_time: 1813 s_time: 39 penalty: 0 agent_num: 22 done: False
______________________
id: 53 reward: 0.014508928571428572 service_time: 1332 s_time: -13 penalty: 0 agent_num: 16 done: False
______________________
id: 49 reward: 0.0020408163265306124 service_time: 1834 s_time: -4 penalty: 0 agent_num: 35 done: False
______________________
id: 43 reward: -0.015306122448979591 service_time: 1824 s_time: 30 penalty: 0 agent_num: 35 done: False
______________________
id: 50 reward: -0.019088669950738917 service_time: 1920 s_time: 31 penalty: 0 agent_num: 29 done: False
______________________
id: 42 reward: -0.04563492063492063 service_time: 2005 s_time: 69 penalty: 0 agent_num: 27 done: False
______________________
id: 54 reward: -0.001984126984126984 service_time: 1976 s_time: 3 penalty: 0 agent_num: 27 done: False
______________________
id: 46 reward: -0.007375776397515528 service_time: 1888 s_time: 19 penalty: 0 agent_num: 46 done: False
______________________
id: 45 reward: -0.0163265306122449 service_time: 1946 s_time: 32 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.0021258503401360546 service_time: 1913 s_time: 5 penalty: 0 agent_num: 42 done: False
______________________
id: 52 reward: -0.09391534391534391 service_time: 1739 s_time: 142 penalty: 0 agent_num: 27 done: False
______________________
Step:  2080
Pretraining Loss:  tensor(0.0522, device='cuda:0', grad_fn=<MeanBackward0>)
id: 44 reward: -0.039285714285714285 service_time: 1083 s_time: 22 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: 0.0 service_time: 836 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: -0.018973214285714284 service_time: 1278 s_time: 17 penalty: 0 agent_num: 16 done: False
______________________
id: 53 reward: -0.03794642857142857 service_time: 1366 s_time: 34 penalty: 0 agent_num: 16 done: False
______________________
id: 55 reward: 0.0 service_time: 1745 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 41 reward: 0.0 service_time: 1813 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 40 reward: 0.010338345864661654 service_time: 1575 s_time: -11 penalty: 0 agent_num: 19 done: False
______________________
id: 43 reward: -0.015306122448979591 service_time: 1854 s_time: 30 penalty: 0 agent_num: 35 done: False
______________________
id: 46 reward: -0.008540372670807454 service_time: 1910 s_time: 22 penalty: 0 agent_num: 46 done: False
______________________
id: 45 reward: -0.018367346938775512 service_time: 1982 s_time: 36 penalty: 0 agent_num: 35 done: False
______________________
id: 49 reward: -0.017346938775510204 service_time: 1868 s_time: 34 penalty: 0 agent_num: 35 done: False
______________________
id: 50 reward: -0.008004926108374385 service_time: 1933 s_time: 13 penalty: 0 agent_num: 29 done: False
______________________
id: 42 reward: 0.009259259259259259 service_time: 1991 s_time: -14 penalty: 0 agent_num: 27 done: False
______________________
id: 52 reward: 0.009259259259259259 service_time: 1725 s_time: -14 penalty: 0 agent_num: 27 done: False
______________________
id: 48 reward: -0.008928571428571428 service_time: 1934 s_time: 21 penalty: 0 agent_num: 42 done: False
______________________
id: 54 reward: 0.008597883597883597 service_time: 1963 s_time: -13 penalty: 0 agent_num: 27 done: False
______________________
Step:  2096
Pretraining Loss:  tensor(0.0554, device='cuda:0', grad_fn=<MeanBackward0>)
id: 53 reward: 0.0033482142857142855 service_time: 1363 s_time: -3 penalty: 0 agent_num: 16 done: False
______________________
id: 44 reward: 0.0 service_time: 1083 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 47 reward: -0.04352678571428571 service_time: 1317 s_time: 39 penalty: 0 agent_num: 16 done: False
______________________
id: 55 reward: -0.03165584415584415 service_time: 1784 s_time: 39 penalty: 0 agent_num: 22 done: False
______________________
id: 41 reward: 0.0008116883116883117 service_time: 1812 s_time: -1 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: -0.032467532467532464 service_time: 856 s_time: 20 penalty: 0 agent_num: 11 done: False
______________________
id: 40 reward: 0.02913533834586466 service_time: 1544 s_time: -31 penalty: 0 agent_num: 19 done: False
______________________
id: 49 reward: 0.0010204081632653062 service_time: 1866 s_time: -2 penalty: 0 agent_num: 35 done: False
______________________
id: 43 reward: -0.006122448979591836 service_time: 1866 s_time: 12 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: 0.0 service_time: 1934 s_time: 0 penalty: 0 agent_num: 42 done: False
______________________
id: 54 reward: -0.046957671957671955 service_time: 2034 s_time: 71 penalty: 0 agent_num: 27 done: False
______________________
id: 45 reward: 0.0 service_time: 1982 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 42 reward: -0.04828042328042328 service_time: 2064 s_time: 73 penalty: 0 agent_num: 27 done: False
______________________
id: 46 reward: 0.0 service_time: 1910 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 52 reward: 0.0033068783068783067 service_time: 1720 s_time: -5 penalty: 0 agent_num: 27 done: False
______________________
id: 50 reward: -0.0332512315270936 service_time: 1987 s_time: 54 penalty: 0 agent_num: 29 done: False
______________________
Step:  2112
Pretraining Loss:  tensor(0.0597, device='cuda:0', grad_fn=<MeanBackward0>)
id: 51 reward: -0.05032467532467533 service_time: 887 s_time: 31 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: 0.0 service_time: 1083 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 53 reward: 0.0 service_time: 1363 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 47 reward: -0.0390625 service_time: 1352 s_time: 35 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: -0.04887218045112782 service_time: 1596 s_time: 52 penalty: 0 agent_num: 19 done: False
______________________
id: 55 reward: -0.05762987012987013 service_time: 1855 s_time: 71 penalty: 0 agent_num: 22 done: False
______________________
id: 41 reward: -0.011363636363636364 service_time: 1826 s_time: 14 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: -0.04030612244897959 service_time: 1945 s_time: 79 penalty: 0 agent_num: 35 done: False
______________________
id: 43 reward: -0.017857142857142856 service_time: 1901 s_time: 35 penalty: 0 agent_num: 35 done: False
______________________
id: 46 reward: -0.015139751552795032 service_time: 1949 s_time: 39 penalty: 0 agent_num: 46 done: False
______________________
id: 52 reward: 0.0033068783068783067 service_time: 1715 s_time: -5 penalty: 0 agent_num: 27 done: False
______________________
id: 45 reward: -0.02857142857142857 service_time: 2038 s_time: 56 penalty: 0 agent_num: 35 done: False
______________________
id: 50 reward: -0.022167487684729065 service_time: 2023 s_time: 36 penalty: 0 agent_num: 29 done: False
______________________
id: 42 reward: 0.004629629629629629 service_time: 2057 s_time: -7 penalty: 0 agent_num: 27 done: False
______________________
id: 54 reward: -0.031746031746031744 service_time: 2082 s_time: 48 penalty: 0 agent_num: 27 done: False
______________________
id: 48 reward: -0.01870748299319728 service_time: 1978 s_time: 44 penalty: 0 agent_num: 42 done: False
______________________
Step:  2128
Pretraining Loss:  tensor(0.0641, device='cuda:0', grad_fn=<MeanBackward0>)
id: 51 reward: 0.0 service_time: 887 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: 0.0 service_time: 1083 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 53 reward: -0.04799107142857143 service_time: 1406 s_time: 43 penalty: 0 agent_num: 16 done: False
______________________
id: 47 reward: -0.06808035714285714 service_time: 1413 s_time: 61 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: -0.07800751879699248 service_time: 1679 s_time: 83 penalty: 0 agent_num: 19 done: False
______________________
id: 41 reward: -0.05032467532467533 service_time: 1888 s_time: 62 penalty: 0 agent_num: 22 done: False
______________________
id: 55 reward: -0.06493506493506493 service_time: 1935 s_time: 80 penalty: 0 agent_num: 22 done: False
______________________
id: 43 reward: -0.002551020408163265 service_time: 1906 s_time: 5 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: 0.0026455026455026454 service_time: 2078 s_time: -4 penalty: 0 agent_num: 27 done: False
______________________
id: 48 reward: -0.005952380952380952 service_time: 1992 s_time: 14 penalty: 0 agent_num: 42 done: False
______________________
id: 49 reward: -0.017857142857142856 service_time: 1980 s_time: 35 penalty: 0 agent_num: 35 done: False
______________________
id: 45 reward: -0.0163265306122449 service_time: 2070 s_time: 32 penalty: 0 agent_num: 35 done: False
______________________
id: 46 reward: -0.017080745341614908 service_time: 1993 s_time: 44 penalty: 0 agent_num: 46 done: False
______________________
id: 42 reward: 0.001984126984126984 service_time: 2054 s_time: -3 penalty: 0 agent_num: 27 done: False
______________________
id: 52 reward: -0.06415343915343916 service_time: 1812 s_time: 97 penalty: 0 agent_num: 27 done: False
______________________
id: 50 reward: 0.0012315270935960591 service_time: 2021 s_time: -2 penalty: 0 agent_num: 29 done: False
______________________
Step:  2144
Pretraining Loss:  tensor(0.0580, device='cuda:0', grad_fn=<MeanBackward0>)
id: 51 reward: -0.0698051948051948 service_time: 930 s_time: 43 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: 0.0 service_time: 1083 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 53 reward: -0.18191964285714285 service_time: 1569 s_time: 163 penalty: 0 agent_num: 16 done: False
______________________
id: 47 reward: 0.0 service_time: 1413 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 41 reward: -0.024350649350649352 service_time: 1918 s_time: 30 penalty: 0 agent_num: 22 done: False
______________________
id: 40 reward: 0.016917293233082706 service_time: 1661 s_time: -18 penalty: 0 agent_num: 19 done: False
______________________
id: 55 reward: -0.008928571428571428 service_time: 1946 s_time: 11 penalty: 0 agent_num: 22 done: False
______________________
id: 43 reward: -0.01020408163265306 service_time: 1926 s_time: 20 penalty: 0 agent_num: 35 done: False
______________________
id: 49 reward: -0.01683673469387755 service_time: 2013 s_time: 33 penalty: 0 agent_num: 35 done: False
______________________
id: 42 reward: 0.0 service_time: 2054 s_time: 0 penalty: 0 agent_num: 27 done: False
______________________
id: 46 reward: -0.01436335403726708 service_time: 2030 s_time: 37 penalty: 0 agent_num: 46 done: False
______________________
id: 52 reward: 0.027777777777777776 service_time: 1770 s_time: -42 penalty: 0 agent_num: 27 done: False
______________________
id: 54 reward: -0.025793650793650792 service_time: 2117 s_time: 39 penalty: 0 agent_num: 27 done: False
______________________
id: 50 reward: 0.027093596059113302 service_time: 1977 s_time: -44 penalty: 0 agent_num: 29 done: False
______________________
id: 45 reward: -0.017346938775510204 service_time: 2104 s_time: 34 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: 0.0 service_time: 1992 s_time: 0 penalty: 0 agent_num: 42 done: False
______________________
Step:  2160
Pretraining Loss:  tensor(0.0583, device='cuda:0', grad_fn=<MeanBackward0>)
id: 44 reward: -0.03214285714285714 service_time: 1101 s_time: 18 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: -0.06493506493506493 service_time: 970 s_time: 40 penalty: 0 agent_num: 11 done: False
______________________
id: 53 reward: 0.0546875 service_time: 1520 s_time: -49 penalty: 0 agent_num: 16 done: False
______________________
id: 41 reward: -0.01461038961038961 service_time: 1936 s_time: 18 penalty: 0 agent_num: 22 done: False
______________________
id: 55 reward: 0.0008116883116883117 service_time: 1945 s_time: -1 penalty: 0 agent_num: 22 done: False
______________________
id: 43 reward: -0.017857142857142856 service_time: 1961 s_time: 35 penalty: 0 agent_num: 35 done: False
______________________
id: 40 reward: -0.03383458646616541 service_time: 1697 s_time: 36 penalty: 0 agent_num: 19 done: False
______________________
id: 49 reward: -0.020918367346938777 service_time: 2054 s_time: 41 penalty: 0 agent_num: 35 done: False
______________________
id: 47 reward: 0.011160714285714286 service_time: 1403 s_time: -10 penalty: 0 agent_num: 16 done: False
______________________
id: 46 reward: 0.0 service_time: 2030 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 42 reward: -0.08068783068783068 service_time: 2176 s_time: 122 penalty: 0 agent_num: 27 done: False
______________________
id: 48 reward: -0.02806122448979592 service_time: 2058 s_time: 66 penalty: 0 agent_num: 42 done: False
______________________
id: 54 reward: -0.041005291005291 service_time: 2179 s_time: 62 penalty: 0 agent_num: 27 done: False
______________________
id: 52 reward: -0.06415343915343916 service_time: 1867 s_time: 97 penalty: 0 agent_num: 27 done: False
______________________
id: 45 reward: -0.01173469387755102 service_time: 2127 s_time: 23 penalty: 0 agent_num: 35 done: False
______________________
id: 50 reward: 0.012315270935960592 service_time: 1957 s_time: -20 penalty: 0 agent_num: 29 done: False
______________________
Step:  2176
Pretraining Loss:  tensor(0.0587, device='cuda:0', grad_fn=<MeanBackward0>)
id: 44 reward: -0.0625 service_time: 1136 s_time: 35 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: 0.0 service_time: 970 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 53 reward: 0.0011160714285714285 service_time: 1519 s_time: -1 penalty: 0 agent_num: 16 done: False
______________________
id: 47 reward: -0.027901785714285716 service_time: 1428 s_time: 25 penalty: 0 agent_num: 16 done: False
______________________
id: 41 reward: -0.033279220779220776 service_time: 1977 s_time: 41 penalty: 0 agent_num: 22 done: False
______________________
id: 55 reward: 0.0 service_time: 1945 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 40 reward: 0.0018796992481203006 service_time: 1695 s_time: -2 penalty: 0 agent_num: 19 done: False
______________________
id: 43 reward: -0.019387755102040816 service_time: 1999 s_time: 38 penalty: 0 agent_num: 35 done: False
______________________
id: 52 reward: 0.02976190476190476 service_time: 1822 s_time: -45 penalty: 0 agent_num: 27 done: False
______________________
id: 46 reward: -0.020186335403726708 service_time: 2082 s_time: 52 penalty: 0 agent_num: 46 done: False
______________________
id: 50 reward: -0.0006157635467980296 service_time: 1958 s_time: 1 penalty: 0 agent_num: 29 done: False
______________________
id: 49 reward: -0.013775510204081633 service_time: 2081 s_time: 27 penalty: 0 agent_num: 35 done: False
______________________
id: 45 reward: -0.012244897959183673 service_time: 2151 s_time: 24 penalty: 0 agent_num: 35 done: False
______________________
id: 42 reward: -0.10515873015873016 service_time: 2335 s_time: 159 penalty: 0 agent_num: 27 done: False
______________________
id: 48 reward: -0.01020408163265306 service_time: 2082 s_time: 24 penalty: 0 agent_num: 42 done: False
______________________
id: 54 reward: 0.015873015873015872 service_time: 2155 s_time: -24 penalty: 0 agent_num: 27 done: False
______________________
Step:  2192
Pretraining Loss:  tensor(0.0536, device='cuda:0', grad_fn=<MeanBackward0>)
id: 44 reward: -0.05714285714285714 service_time: 1168 s_time: 32 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: 0.0 service_time: 970 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 53 reward: 0.04352678571428571 service_time: 1480 s_time: -39 penalty: 0 agent_num: 16 done: False
______________________
id: 47 reward: -0.03236607142857143 service_time: 1457 s_time: 29 penalty: 0 agent_num: 16 done: False
______________________
id: 55 reward: 0.003246753246753247 service_time: 1941 s_time: -4 penalty: 0 agent_num: 22 done: False
______________________
id: 40 reward: 0.015977443609022556 service_time: 1678 s_time: -17 penalty: 0 agent_num: 19 done: False
______________________
id: 41 reward: -0.033279220779220776 service_time: 2018 s_time: 41 penalty: 0 agent_num: 22 done: False
______________________
id: 52 reward: 0.005291005291005291 service_time: 1814 s_time: -8 penalty: 0 agent_num: 27 done: False
______________________
id: 43 reward: -0.018367346938775512 service_time: 2035 s_time: 36 penalty: 0 agent_num: 35 done: False
______________________
id: 49 reward: -0.0163265306122449 service_time: 2113 s_time: 32 penalty: 0 agent_num: 35 done: False
______________________
id: 46 reward: -0.013975155279503106 service_time: 2118 s_time: 36 penalty: 0 agent_num: 46 done: False
______________________
id: 48 reward: -0.015731292517006803 service_time: 2119 s_time: 37 penalty: 0 agent_num: 42 done: False
______________________
id: 50 reward: 0.017857142857142856 service_time: 1929 s_time: -29 penalty: 0 agent_num: 29 done: False
______________________
id: 45 reward: -0.007142857142857143 service_time: 2165 s_time: 14 penalty: 0 agent_num: 35 done: False
______________________
id: 42 reward: 0.03968253968253968 service_time: 2275 s_time: -60 penalty: 0 agent_num: 27 done: False
______________________
id: 54 reward: -0.061507936507936505 service_time: 2248 s_time: 93 penalty: 0 agent_num: 27 done: False
______________________
Step:  2208
Pretraining Loss:  tensor(0.0606, device='cuda:0', grad_fn=<MeanBackward0>)
id: 44 reward: -0.060714285714285714 service_time: 1202 s_time: 34 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: 0.003246753246753247 service_time: 968 s_time: -2 penalty: 0 agent_num: 11 done: False
______________________
id: 53 reward: -0.06808035714285714 service_time: 1541 s_time: 61 penalty: 0 agent_num: 16 done: False
______________________
id: 41 reward: -0.02922077922077922 service_time: 2054 s_time: 36 penalty: 0 agent_num: 22 done: False
______________________
id: 40 reward: 0.002819548872180451 service_time: 1675 s_time: -3 penalty: 0 agent_num: 19 done: False
______________________
id: 55 reward: -0.04707792207792208 service_time: 1999 s_time: 58 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: 0.0 service_time: 1457 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 42 reward: 0.021825396825396824 service_time: 2242 s_time: -33 penalty: 0 agent_num: 27 done: False
______________________
id: 43 reward: -0.012755102040816327 service_time: 2060 s_time: 25 penalty: 0 agent_num: 35 done: False
______________________
id: 52 reward: -0.04298941798941799 service_time: 1879 s_time: 65 penalty: 0 agent_num: 27 done: False
______________________
id: 49 reward: -0.024489795918367346 service_time: 2161 s_time: 48 penalty: 0 agent_num: 35 done: False
______________________
id: 50 reward: -0.04741379310344827 service_time: 2006 s_time: 77 penalty: 0 agent_num: 29 done: False
______________________
id: 45 reward: -0.0066326530612244895 service_time: 2178 s_time: 13 penalty: 0 agent_num: 35 done: False
______________________
id: 46 reward: -0.017857142857142856 service_time: 2164 s_time: 46 penalty: 0 agent_num: 46 done: False
______________________
id: 54 reward: 0.016534391534391533 service_time: 2223 s_time: -25 penalty: 0 agent_num: 27 done: False
______________________
id: 48 reward: -0.005952380952380952 service_time: 2133 s_time: 14 penalty: 0 agent_num: 42 done: False
______________________
Step:  2224
Pretraining Loss:  tensor(0.0573, device='cuda:0', grad_fn=<MeanBackward0>)
id: 44 reward: 0.0 service_time: 1202 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: -0.1396103896103896 service_time: 1054 s_time: 86 penalty: 0 agent_num: 11 done: False
______________________
id: 53 reward: -0.04352678571428571 service_time: 1580 s_time: 39 penalty: 0 agent_num: 16 done: False
______________________
id: 47 reward: -0.026785714285714284 service_time: 1481 s_time: 24 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: -0.06296992481203008 service_time: 1742 s_time: 67 penalty: 0 agent_num: 19 done: False
______________________
id: 55 reward: 0.012987012987012988 service_time: 1983 s_time: -16 penalty: 0 agent_num: 22 done: False
______________________
id: 41 reward: 0.012175324675324676 service_time: 2039 s_time: -15 penalty: 0 agent_num: 22 done: False
______________________
id: 42 reward: 0.0013227513227513227 service_time: 2240 s_time: -2 penalty: 0 agent_num: 27 done: False
______________________
id: 43 reward: 0.007653061224489796 service_time: 2045 s_time: -15 penalty: 0 agent_num: 35 done: False
______________________
id: 50 reward: 0.019704433497536946 service_time: 1974 s_time: -32 penalty: 0 agent_num: 29 done: False
______________________
id: 49 reward: 0.006122448979591836 service_time: 2149 s_time: -12 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: 0.0 service_time: 2133 s_time: 0 penalty: 0 agent_num: 42 done: False
______________________
id: 46 reward: -0.010869565217391304 service_time: 2192 s_time: 28 penalty: 0 agent_num: 46 done: False
______________________
id: 52 reward: -0.05952380952380952 service_time: 1969 s_time: 90 penalty: 0 agent_num: 27 done: False
______________________
id: 45 reward: -0.0005102040816326531 service_time: 2179 s_time: 1 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: -0.05952380952380952 service_time: 2313 s_time: 90 penalty: 0 agent_num: 27 done: False
______________________
Step:  2240
Pretraining Loss:  tensor(0.0601, device='cuda:0', grad_fn=<MeanBackward0>)
id: 44 reward: 0.0 service_time: 1202 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: 0.0 service_time: 1054 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: -0.026785714285714284 service_time: 1505 s_time: 24 penalty: 0 agent_num: 16 done: False
______________________
id: 53 reward: -0.14285714285714285 service_time: 1708 s_time: 128 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: -0.02819548872180451 service_time: 1772 s_time: 30 penalty: 0 agent_num: 19 done: False
______________________
id: 42 reward: -0.008597883597883597 service_time: 2253 s_time: 13 penalty: 0 agent_num: 27 done: False
______________________
id: 41 reward: 0.002435064935064935 service_time: 2036 s_time: -3 penalty: 0 agent_num: 22 done: False
______________________
id: 55 reward: -0.05925324675324675 service_time: 2056 s_time: 73 penalty: 0 agent_num: 22 done: False
______________________
id: 50 reward: -0.03263546798029557 service_time: 2027 s_time: 53 penalty: 0 agent_num: 29 done: False
______________________
id: 49 reward: -0.026530612244897958 service_time: 2201 s_time: 52 penalty: 0 agent_num: 35 done: False
______________________
id: 45 reward: -0.018367346938775512 service_time: 2215 s_time: 36 penalty: 0 agent_num: 35 done: False
______________________
id: 43 reward: -0.01683673469387755 service_time: 2078 s_time: 33 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: -0.003968253968253968 service_time: 2319 s_time: 6 penalty: 0 agent_num: 27 done: False
______________________
id: 48 reward: -0.015306122448979591 service_time: 2169 s_time: 36 penalty: 0 agent_num: 42 done: False
______________________
id: 46 reward: -0.016692546583850932 service_time: 2235 s_time: 43 penalty: 0 agent_num: 46 done: False
______________________
id: 52 reward: -0.03835978835978836 service_time: 2027 s_time: 58 penalty: 0 agent_num: 27 done: False
______________________
Step:  2256
Pretraining Loss:  tensor(0.0662, device='cuda:0', grad_fn=<MeanBackward0>)
id: 44 reward: 0.0 service_time: 1202 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: 0.0 service_time: 1054 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 53 reward: -0.07254464285714286 service_time: 1773 s_time: 65 penalty: 0 agent_num: 16 done: False
______________________
id: 47 reward: 0.0 service_time: 1505 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: 0.0009398496240601503 service_time: 1771 s_time: -1 penalty: 0 agent_num: 19 done: False
______________________
id: 55 reward: 0.005681818181818182 service_time: 2049 s_time: -7 penalty: 0 agent_num: 22 done: False
______________________
id: 41 reward: -0.03409090909090909 service_time: 2078 s_time: 42 penalty: 0 agent_num: 22 done: False
______________________
id: 42 reward: -0.047619047619047616 service_time: 2325 s_time: 72 penalty: 0 agent_num: 27 done: False
______________________
id: 43 reward: -0.011224489795918367 service_time: 2100 s_time: 22 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: -0.012566137566137565 service_time: 2338 s_time: 19 penalty: 0 agent_num: 27 done: False
______________________
id: 45 reward: -0.02806122448979592 service_time: 2270 s_time: 55 penalty: 0 agent_num: 35 done: False
______________________
id: 52 reward: 0.031746031746031744 service_time: 1979 s_time: -48 penalty: 0 agent_num: 27 done: False
______________________
id: 49 reward: -0.01479591836734694 service_time: 2230 s_time: 29 penalty: 0 agent_num: 35 done: False
______________________
id: 50 reward: -0.007389162561576354 service_time: 2039 s_time: 12 penalty: 0 agent_num: 29 done: False
______________________
id: 48 reward: 0.0 service_time: 2169 s_time: 0 penalty: 0 agent_num: 42 done: False
______________________
id: 46 reward: -0.011645962732919254 service_time: 2265 s_time: 30 penalty: 0 agent_num: 46 done: False
______________________
Step:  2272
Pretraining Loss:  tensor(0.0647, device='cuda:0', grad_fn=<MeanBackward0>)
id: 44 reward: -0.17142857142857143 service_time: 1298 s_time: 96 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: 0.0 service_time: 1054 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 53 reward: -0.03571428571428571 service_time: 1805 s_time: 32 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: -0.05545112781954887 service_time: 1830 s_time: 59 penalty: 0 agent_num: 19 done: False
______________________
id: 47 reward: 0.0 service_time: 1505 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 55 reward: 0.01948051948051948 service_time: 2025 s_time: -24 penalty: 0 agent_num: 22 done: False
______________________
id: 54 reward: 0.0 service_time: 2338 s_time: 0 penalty: 0 agent_num: 27 done: False
______________________
id: 43 reward: -0.02142857142857143 service_time: 2142 s_time: 42 penalty: 0 agent_num: 35 done: False
______________________
id: 41 reward: -0.008928571428571428 service_time: 2089 s_time: 11 penalty: 0 agent_num: 22 done: False
______________________
id: 46 reward: -0.009704968944099378 service_time: 2290 s_time: 25 penalty: 0 agent_num: 46 done: False
______________________
id: 49 reward: -0.00816326530612245 service_time: 2246 s_time: 16 penalty: 0 agent_num: 35 done: False
______________________
id: 50 reward: -0.07450738916256158 service_time: 2160 s_time: 121 penalty: 0 agent_num: 29 done: False
______________________
id: 45 reward: -0.011224489795918367 service_time: 2292 s_time: 22 penalty: 0 agent_num: 35 done: False
______________________
id: 42 reward: -0.03571428571428571 service_time: 2379 s_time: 54 penalty: 0 agent_num: 27 done: False
______________________
id: 48 reward: -0.030612244897959183 service_time: 2241 s_time: 72 penalty: 0 agent_num: 42 done: False
______________________
id: 52 reward: -0.027777777777777776 service_time: 2021 s_time: 42 penalty: 0 agent_num: 27 done: False
______________________
Step:  2288
Pretraining Loss:  tensor(0.0614, device='cuda:0', grad_fn=<MeanBackward0>)
id: 51 reward: -0.05519480519480519 service_time: 1088 s_time: 34 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: -0.17142857142857143 service_time: 1394 s_time: 96 penalty: 0 agent_num: 10 done: False
______________________
id: 53 reward: 0.06696428571428571 service_time: 1745 s_time: -60 penalty: 0 agent_num: 16 done: False
______________________
id: 47 reward: -0.024553571428571428 service_time: 1527 s_time: 22 penalty: 0 agent_num: 16 done: False
______________________
id: 55 reward: -0.13717532467532467 service_time: 2194 s_time: 169 penalty: 0 agent_num: 22 done: False
______________________
id: 54 reward: -0.018518518518518517 service_time: 2366 s_time: 28 penalty: 0 agent_num: 27 done: False
______________________
id: 41 reward: -0.12987012987012986 service_time: 2249 s_time: 160 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: -0.006122448979591836 service_time: 2258 s_time: 12 penalty: 0 agent_num: 35 done: False
______________________
id: 43 reward: -0.0035714285714285713 service_time: 2149 s_time: 7 penalty: 0 agent_num: 35 done: False
______________________
id: 50 reward: -0.03017241379310345 service_time: 2209 s_time: 49 penalty: 0 agent_num: 29 done: False
______________________
id: 42 reward: -0.016534391534391533 service_time: 2404 s_time: 25 penalty: 0 agent_num: 27 done: False
______________________
id: 46 reward: 0.0007763975155279503 service_time: 2288 s_time: -2 penalty: 0 agent_num: 46 done: False
______________________
id: 52 reward: 0.0013227513227513227 service_time: 2019 s_time: -2 penalty: 0 agent_num: 27 done: False
______________________
id: 40 reward: -0.06109022556390977 service_time: 1895 s_time: 65 penalty: 0 agent_num: 19 done: False
______________________
id: 48 reward: 0.0 service_time: 2241 s_time: 0 penalty: 0 agent_num: 42 done: False
______________________
id: 45 reward: -0.02959183673469388 service_time: 2350 s_time: 58 penalty: 0 agent_num: 35 done: False
______________________
Step:  2304
Pretraining Loss:  tensor(0.0659, device='cuda:0', grad_fn=<MeanBackward0>)
id: 51 reward: -0.03896103896103896 service_time: 1112 s_time: 24 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: 0.0 service_time: 1394 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 53 reward: -0.07254464285714286 service_time: 1810 s_time: 65 penalty: 0 agent_num: 16 done: False
______________________
id: 55 reward: 0.017045454545454544 service_time: 2173 s_time: -21 penalty: 0 agent_num: 22 done: False
______________________
id: 40 reward: 0.010338345864661654 service_time: 1884 s_time: -11 penalty: 0 agent_num: 19 done: False
______________________
id: 47 reward: 0.0 service_time: 1527 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 41 reward: -0.007305194805194805 service_time: 2258 s_time: 9 penalty: 0 agent_num: 22 done: False
______________________
id: 54 reward: 0.018518518518518517 service_time: 2338 s_time: -28 penalty: 0 agent_num: 27 done: False
______________________
id: 49 reward: -0.015306122448979591 service_time: 2288 s_time: 30 penalty: 0 agent_num: 35 done: False
______________________
id: 43 reward: -0.014285714285714285 service_time: 2177 s_time: 28 penalty: 0 agent_num: 35 done: False
______________________
id: 50 reward: -0.029556650246305417 service_time: 2257 s_time: 48 penalty: 0 agent_num: 29 done: False
______________________
id: 42 reward: -0.025793650793650792 service_time: 2443 s_time: 39 penalty: 0 agent_num: 27 done: False
______________________
id: 46 reward: -0.020574534161490684 service_time: 2341 s_time: 53 penalty: 0 agent_num: 46 done: False
______________________
id: 48 reward: -0.01913265306122449 service_time: 2286 s_time: 45 penalty: 0 agent_num: 42 done: False
______________________
id: 52 reward: -0.04894179894179894 service_time: 2093 s_time: 74 penalty: 0 agent_num: 27 done: False
______________________
id: 45 reward: -0.004081632653061225 service_time: 2358 s_time: 8 penalty: 0 agent_num: 35 done: False
______________________
Step:  2320
Pretraining Loss:  tensor(0.0619, device='cuda:0', grad_fn=<MeanBackward0>)
id: 51 reward: -0.01461038961038961 service_time: 1121 s_time: 9 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: 0.0 service_time: 1394 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 53 reward: -0.16629464285714285 service_time: 1959 s_time: 149 penalty: 0 agent_num: 16 done: False
______________________
id: 47 reward: -0.03571428571428571 service_time: 1559 s_time: 32 penalty: 0 agent_num: 16 done: False
______________________
id: 55 reward: -0.01461038961038961 service_time: 2191 s_time: 18 penalty: 0 agent_num: 22 done: False
______________________
id: 40 reward: 0.011278195488721804 service_time: 1872 s_time: -12 penalty: 0 agent_num: 19 done: False
______________________
id: 41 reward: 0.0016233766233766235 service_time: 2256 s_time: -2 penalty: 0 agent_num: 22 done: False
______________________
id: 54 reward: 0.00992063492063492 service_time: 2323 s_time: -15 penalty: 0 agent_num: 27 done: False
______________________
id: 46 reward: 0.0007763975155279503 service_time: 2339 s_time: -2 penalty: 0 agent_num: 46 done: False
______________________
id: 52 reward: -0.027116402116402115 service_time: 2134 s_time: 41 penalty: 0 agent_num: 27 done: False
______________________
id: 49 reward: -0.009183673469387756 service_time: 2306 s_time: 18 penalty: 0 agent_num: 35 done: False
______________________
id: 42 reward: 0.0006613756613756613 service_time: 2442 s_time: -1 penalty: 0 agent_num: 27 done: False
______________________
id: 50 reward: -0.06342364532019705 service_time: 2360 s_time: 103 penalty: 0 agent_num: 29 done: False
______________________
id: 43 reward: -0.02959183673469388 service_time: 2235 s_time: 58 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.005952380952380952 service_time: 2300 s_time: 14 penalty: 0 agent_num: 42 done: False
______________________
id: 45 reward: -0.023979591836734693 service_time: 2405 s_time: 47 penalty: 0 agent_num: 35 done: False
______________________
Step:  2336
Pretraining Loss:  tensor(0.0618, device='cuda:0', grad_fn=<MeanBackward0>)
id: 51 reward: 0.01948051948051948 service_time: 1109 s_time: -12 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: 0.12857142857142856 service_time: 1322 s_time: -72 penalty: 0 agent_num: 10 done: False
______________________
id: 53 reward: -0.04352678571428571 service_time: 1998 s_time: 39 penalty: 0 agent_num: 16 done: False
______________________
id: 47 reward: 0.0 service_time: 1559 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 55 reward: -0.06168831168831169 service_time: 2267 s_time: 76 penalty: 0 agent_num: 22 done: False
______________________
id: 40 reward: 0.0 service_time: 1872 s_time: 0 penalty: 0 agent_num: 19 done: False
______________________
id: 42 reward: -0.013888888888888888 service_time: 2463 s_time: 21 penalty: 0 agent_num: 27 done: False
______________________
id: 41 reward: -0.036525974025974024 service_time: 2301 s_time: 45 penalty: 0 agent_num: 22 done: False
______________________
id: 54 reward: -0.015873015873015872 service_time: 2347 s_time: 24 penalty: 0 agent_num: 27 done: False
______________________
id: 49 reward: 0.0 service_time: 2306 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 50 reward: 0.005541871921182266 service_time: 2351 s_time: -9 penalty: 0 agent_num: 29 done: False
______________________
id: 52 reward: 0.0205026455026455 service_time: 2103 s_time: -31 penalty: 0 agent_num: 27 done: False
______________________
id: 46 reward: -0.033385093167701864 service_time: 2425 s_time: 86 penalty: 0 agent_num: 46 done: False
______________________
id: 43 reward: -0.027040816326530614 service_time: 2288 s_time: 53 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.0055272108843537416 service_time: 2313 s_time: 13 penalty: 0 agent_num: 42 done: False
______________________
id: 45 reward: -0.012755102040816327 service_time: 2430 s_time: 25 penalty: 0 agent_num: 35 done: False
______________________
Step:  2352
Pretraining Loss:  tensor(0.0549, device='cuda:0', grad_fn=<MeanBackward0>)
id: 51 reward: -0.025974025974025976 service_time: 1125 s_time: 16 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: -0.1625 service_time: 1413 s_time: 91 penalty: 0 agent_num: 10 done: False
______________________
id: 47 reward: 0.012276785714285714 service_time: 1548 s_time: -11 penalty: 0 agent_num: 16 done: False
______________________
id: 53 reward: -0.027901785714285716 service_time: 2023 s_time: 25 penalty: 0 agent_num: 16 done: False
______________________
id: 55 reward: -0.03977272727272727 service_time: 2316 s_time: 49 penalty: 0 agent_num: 22 done: False
______________________
id: 40 reward: -0.004699248120300752 service_time: 1877 s_time: 5 penalty: 0 agent_num: 19 done: False
______________________
id: 41 reward: 0.008116883116883116 service_time: 2291 s_time: -10 penalty: 0 agent_num: 22 done: False
______________________
id: 42 reward: 0.0006613756613756613 service_time: 2462 s_time: -1 penalty: 0 agent_num: 27 done: False
______________________
id: 49 reward: -0.01989795918367347 service_time: 2345 s_time: 39 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: -0.04431216931216931 service_time: 2414 s_time: 67 penalty: 0 agent_num: 27 done: False
______________________
id: 52 reward: -0.00992063492063492 service_time: 2118 s_time: 15 penalty: 0 agent_num: 27 done: False
______________________
id: 48 reward: -0.017006802721088437 service_time: 2353 s_time: 40 penalty: 0 agent_num: 42 done: False
______________________
id: 45 reward: -0.010714285714285714 service_time: 2451 s_time: 21 penalty: 0 agent_num: 35 done: False
______________________
id: 43 reward: -0.0020408163265306124 service_time: 2292 s_time: 4 penalty: 0 agent_num: 35 done: False
______________________
id: 46 reward: 0.0007763975155279503 service_time: 2423 s_time: -2 penalty: 0 agent_num: 46 done: False
______________________
id: 50 reward: -0.03694581280788178 service_time: 2411 s_time: 60 penalty: 0 agent_num: 29 done: False
______________________
Step:  2368
Pretraining Loss:  tensor(0.0524, device='cuda:0', grad_fn=<MeanBackward0>)
id: 51 reward: 0.0 service_time: 1125 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: -0.12321428571428572 service_time: 1482 s_time: 69 penalty: 0 agent_num: 10 done: False
______________________
id: 47 reward: -0.036830357142857144 service_time: 1581 s_time: 33 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: -0.11278195488721804 service_time: 1997 s_time: 120 penalty: 0 agent_num: 19 done: False
______________________
id: 53 reward: 0.0 service_time: 2023 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 55 reward: 0.018668831168831168 service_time: 2293 s_time: -23 penalty: 0 agent_num: 22 done: False
______________________
id: 41 reward: 0.0 service_time: 2291 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 42 reward: 0.007936507936507936 service_time: 2450 s_time: -12 penalty: 0 agent_num: 27 done: False
______________________
id: 49 reward: -0.02857142857142857 service_time: 2401 s_time: 56 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: -0.032407407407407406 service_time: 2463 s_time: 49 penalty: 0 agent_num: 27 done: False
______________________
id: 52 reward: -0.027116402116402115 service_time: 2159 s_time: 41 penalty: 0 agent_num: 27 done: False
______________________
id: 46 reward: -0.01281055900621118 service_time: 2456 s_time: 33 penalty: 0 agent_num: 46 done: False
______________________
id: 50 reward: -0.02401477832512315 service_time: 2450 s_time: 39 penalty: 0 agent_num: 29 done: False
______________________
id: 43 reward: 0.00510204081632653 service_time: 2282 s_time: -10 penalty: 0 agent_num: 35 done: False
______________________
id: 45 reward: 0.0010204081632653062 service_time: 2449 s_time: -2 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.002976190476190476 service_time: 2360 s_time: 7 penalty: 0 agent_num: 42 done: False
______________________
Step:  2384
Pretraining Loss:  tensor(0.0501, device='cuda:0', grad_fn=<MeanBackward0>)
id: 51 reward: -0.025974025974025976 service_time: 1141 s_time: 16 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: 0.0 service_time: 1482 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 53 reward: -0.021205357142857144 service_time: 2042 s_time: 19 penalty: 0 agent_num: 16 done: False
______________________
id: 47 reward: 0.0 service_time: 1581 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 41 reward: -0.018668831168831168 service_time: 2314 s_time: 23 penalty: 0 agent_num: 22 done: False
______________________
id: 55 reward: -0.017045454545454544 service_time: 2314 s_time: 21 penalty: 0 agent_num: 22 done: False
______________________
id: 42 reward: 0.0 service_time: 2450 s_time: 0 penalty: 0 agent_num: 27 done: False
______________________
id: 40 reward: -0.05357142857142857 service_time: 2054 s_time: 57 penalty: 0 agent_num: 19 done: False
______________________
id: 54 reward: 0.02447089947089947 service_time: 2426 s_time: -37 penalty: 0 agent_num: 27 done: False
______________________
id: 49 reward: -0.018367346938775512 service_time: 2437 s_time: 36 penalty: 0 agent_num: 35 done: False
______________________
id: 52 reward: -0.04828042328042328 service_time: 2232 s_time: 73 penalty: 0 agent_num: 27 done: False
______________________
id: 48 reward: -0.008503401360544218 service_time: 2380 s_time: 20 penalty: 0 agent_num: 42 done: False
______________________
id: 45 reward: -0.036734693877551024 service_time: 2521 s_time: 72 penalty: 0 agent_num: 35 done: False
______________________
id: 50 reward: -0.025246305418719212 service_time: 2491 s_time: 41 penalty: 0 agent_num: 29 done: False
______________________
id: 46 reward: -0.01436335403726708 service_time: 2493 s_time: 37 penalty: 0 agent_num: 46 done: False
______________________
id: 43 reward: -0.020918367346938777 service_time: 2323 s_time: 41 penalty: 0 agent_num: 35 done: False
______________________
Step:  2400
Pretraining Loss:  tensor(0.0560, device='cuda:0', grad_fn=<MeanBackward0>)
id: 44 reward: 0.0 service_time: 1482 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: 0.0 service_time: 1141 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 53 reward: 0.0 service_time: 2042 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 47 reward: -0.03571428571428571 service_time: 1613 s_time: 32 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: -0.02443609022556391 service_time: 2080 s_time: 26 penalty: 0 agent_num: 19 done: False
______________________
id: 55 reward: 0.018668831168831168 service_time: 2291 s_time: -23 penalty: 0 agent_num: 22 done: False
______________________
id: 42 reward: -0.013227513227513227 service_time: 2470 s_time: 20 penalty: 0 agent_num: 27 done: False
______________________
id: 41 reward: -0.04220779220779221 service_time: 2366 s_time: 52 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: -0.013265306122448979 service_time: 2463 s_time: 26 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: -0.062169312169312166 service_time: 2520 s_time: 94 penalty: 0 agent_num: 27 done: False
______________________
id: 52 reward: 0.0 service_time: 2232 s_time: 0 penalty: 0 agent_num: 27 done: False
______________________
id: 46 reward: -0.01125776397515528 service_time: 2522 s_time: 29 penalty: 0 agent_num: 46 done: False
______________________
id: 48 reward: -0.011479591836734694 service_time: 2407 s_time: 27 penalty: 0 agent_num: 42 done: False
______________________
id: 45 reward: -0.015306122448979591 service_time: 2551 s_time: 30 penalty: 0 agent_num: 35 done: False
______________________
id: 50 reward: -0.012315270935960592 service_time: 2511 s_time: 20 penalty: 0 agent_num: 29 done: False
______________________
id: 43 reward: -0.015306122448979591 service_time: 2353 s_time: 30 penalty: 0 agent_num: 35 done: False
______________________
Step:  2416
Pretraining Loss:  tensor(0.0578, device='cuda:0', grad_fn=<MeanBackward0>)
id: 44 reward: -0.03571428571428571 service_time: 1502 s_time: 20 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: 0.0 service_time: 1141 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 53 reward: 0.0 service_time: 2042 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 47 reward: 0.0 service_time: 1613 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: 0.0018796992481203006 service_time: 2078 s_time: -2 penalty: 0 agent_num: 19 done: False
______________________
id: 55 reward: 0.0 service_time: 2291 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 42 reward: -0.015873015873015872 service_time: 2494 s_time: 24 penalty: 0 agent_num: 27 done: False
______________________
id: 41 reward: -0.14935064935064934 service_time: 2550 s_time: 184 penalty: 0 agent_num: 22 done: False
______________________
id: 54 reward: 0.0 service_time: 2520 s_time: 0 penalty: 0 agent_num: 27 done: False
______________________
id: 52 reward: 0.00992063492063492 service_time: 2217 s_time: -15 penalty: 0 agent_num: 27 done: False
______________________
id: 49 reward: -0.004081632653061225 service_time: 2471 s_time: 8 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.007653061224489796 service_time: 2425 s_time: 18 penalty: 0 agent_num: 42 done: False
______________________
id: 45 reward: -0.019387755102040816 service_time: 2589 s_time: 38 penalty: 0 agent_num: 35 done: False
______________________
id: 46 reward: 0.0 service_time: 2522 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 50 reward: -0.023399014778325122 service_time: 2549 s_time: 38 penalty: 0 agent_num: 29 done: False
______________________
id: 43 reward: -0.023979591836734693 service_time: 2400 s_time: 47 penalty: 0 agent_num: 35 done: False
______________________
Step:  2432
Pretraining Loss:  tensor(0.0538, device='cuda:0', grad_fn=<MeanBackward0>)
id: 51 reward: 0.0 service_time: 1141 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: 0.0 service_time: 1502 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 53 reward: 0.0 service_time: 2042 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: -0.05545112781954887 service_time: 2137 s_time: 59 penalty: 0 agent_num: 19 done: False
______________________
id: 47 reward: -0.014508928571428572 service_time: 1626 s_time: 13 penalty: 0 agent_num: 16 done: False
______________________
id: 55 reward: 0.0016233766233766235 service_time: 2289 s_time: -2 penalty: 0 agent_num: 22 done: False
______________________
id: 42 reward: -0.04828042328042328 service_time: 2567 s_time: 73 penalty: 0 agent_num: 27 done: False
______________________
id: 52 reward: 0.00992063492063492 service_time: 2202 s_time: -15 penalty: 0 agent_num: 27 done: False
______________________
id: 49 reward: -0.023979591836734693 service_time: 2518 s_time: 47 penalty: 0 agent_num: 35 done: False
______________________
id: 46 reward: -0.004270186335403727 service_time: 2533 s_time: 11 penalty: 0 agent_num: 46 done: False
______________________
id: 41 reward: -0.0349025974025974 service_time: 2593 s_time: 43 penalty: 0 agent_num: 22 done: False
______________________
id: 54 reward: -0.04298941798941799 service_time: 2585 s_time: 65 penalty: 0 agent_num: 27 done: False
______________________
id: 48 reward: -0.011904761904761904 service_time: 2453 s_time: 28 penalty: 0 agent_num: 42 done: False
______________________
id: 45 reward: -0.008673469387755102 service_time: 2606 s_time: 17 penalty: 0 agent_num: 35 done: False
______________________
id: 50 reward: -0.0332512315270936 service_time: 2603 s_time: 54 penalty: 0 agent_num: 29 done: False
______________________
id: 43 reward: -0.018367346938775512 service_time: 2436 s_time: 36 penalty: 0 agent_num: 35 done: False
______________________
Step:  2448
Pretraining Loss:  tensor(0.0502, device='cuda:0', grad_fn=<MeanBackward0>)
id: 44 reward: 0.0 service_time: 1502 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: -0.060064935064935064 service_time: 1178 s_time: 37 penalty: 0 agent_num: 11 done: False
______________________
id: 53 reward: 0.0 service_time: 2042 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 47 reward: 0.0 service_time: 1626 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 55 reward: -0.04220779220779221 service_time: 2341 s_time: 52 penalty: 0 agent_num: 22 done: False
______________________
id: 41 reward: -0.02353896103896104 service_time: 2622 s_time: 29 penalty: 0 agent_num: 22 done: False
______________________
id: 40 reward: -0.06860902255639098 service_time: 2210 s_time: 73 penalty: 0 agent_num: 19 done: False
______________________
id: 54 reward: 0.01521164021164021 service_time: 2562 s_time: -23 penalty: 0 agent_num: 27 done: False
______________________
id: 42 reward: -0.03373015873015873 service_time: 2618 s_time: 51 penalty: 0 agent_num: 27 done: False
______________________
id: 52 reward: -0.06746031746031746 service_time: 2304 s_time: 102 penalty: 0 agent_num: 27 done: False
______________________
id: 48 reward: 0.00042517006802721087 service_time: 2452 s_time: -1 penalty: 0 agent_num: 42 done: False
______________________
id: 49 reward: -0.00816326530612245 service_time: 2534 s_time: 16 penalty: 0 agent_num: 35 done: False
______________________
id: 45 reward: -0.019387755102040816 service_time: 2644 s_time: 38 penalty: 0 agent_num: 35 done: False
______________________
id: 50 reward: 0.03263546798029557 service_time: 2550 s_time: -53 penalty: 0 agent_num: 29 done: False
______________________
id: 46 reward: -0.014751552795031056 service_time: 2571 s_time: 38 penalty: 0 agent_num: 46 done: False
______________________
id: 43 reward: 0.0 service_time: 2436 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
Step:  2464
Pretraining Loss:  tensor(0.0466, device='cuda:0', grad_fn=<MeanBackward0>)
id: 51 reward: 0.0 service_time: 1178 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: -0.05 service_time: 1530 s_time: 28 penalty: 0 agent_num: 10 done: False
______________________
id: 53 reward: 0.0 service_time: 2042 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: 0.015977443609022556 service_time: 2193 s_time: -17 penalty: 0 agent_num: 19 done: False
______________________
id: 47 reward: -0.012276785714285714 service_time: 1637 s_time: 11 penalty: 0 agent_num: 16 done: False
______________________
id: 55 reward: 0.0 service_time: 2341 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 42 reward: -0.011243386243386243 service_time: 2635 s_time: 17 penalty: 0 agent_num: 27 done: False
______________________
id: 54 reward: 0.0 service_time: 2562 s_time: 0 penalty: 0 agent_num: 27 done: False
______________________
id: 50 reward: -0.011699507389162561 service_time: 2569 s_time: 19 penalty: 0 agent_num: 29 done: False
______________________
id: 41 reward: -0.021915584415584416 service_time: 2649 s_time: 27 penalty: 0 agent_num: 22 done: False
______________________
id: 48 reward: 0.0008503401360544217 service_time: 2450 s_time: -2 penalty: 0 agent_num: 42 done: False
______________________
id: 49 reward: -0.015816326530612244 service_time: 2565 s_time: 31 penalty: 0 agent_num: 35 done: False
______________________
id: 45 reward: -0.018367346938775512 service_time: 2680 s_time: 36 penalty: 0 agent_num: 35 done: False
______________________
id: 46 reward: -0.020186335403726708 service_time: 2623 s_time: 52 penalty: 0 agent_num: 46 done: False
______________________
id: 52 reward: -0.0291005291005291 service_time: 2348 s_time: 44 penalty: 0 agent_num: 27 done: False
______________________
id: 43 reward: -0.0326530612244898 service_time: 2500 s_time: 64 penalty: 0 agent_num: 35 done: False
______________________
Step:  2480
Pretraining Loss:  tensor(0.0487, device='cuda:0', grad_fn=<MeanBackward0>)
id: 44 reward: -0.09285714285714286 service_time: 1582 s_time: 52 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: -0.1038961038961039 service_time: 1242 s_time: 64 penalty: 0 agent_num: 11 done: False
______________________
id: 53 reward: 0.0 service_time: 2042 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: 0.0 service_time: 2193 s_time: 0 penalty: 0 agent_num: 19 done: False
______________________
id: 55 reward: 0.0 service_time: 2341 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 41 reward: 0.002435064935064935 service_time: 2646 s_time: -3 penalty: 0 agent_num: 22 done: False
______________________
id: 54 reward: 0.001984126984126984 service_time: 2559 s_time: -3 penalty: 0 agent_num: 27 done: False
______________________
id: 42 reward: 0.0006613756613756613 service_time: 2634 s_time: -1 penalty: 0 agent_num: 27 done: False
______________________
id: 47 reward: 0.0 service_time: 1637 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 49 reward: -0.008673469387755102 service_time: 2582 s_time: 17 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: 0.0 service_time: 2450 s_time: 0 penalty: 0 agent_num: 42 done: False
______________________
id: 52 reward: -0.0291005291005291 service_time: 2392 s_time: 44 penalty: 0 agent_num: 27 done: False
______________________
id: 45 reward: 0.0005102040816326531 service_time: 2679 s_time: -1 penalty: 0 agent_num: 35 done: False
______________________
id: 46 reward: 0.0 service_time: 2623 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 43 reward: -0.01479591836734694 service_time: 2529 s_time: 29 penalty: 0 agent_num: 35 done: False
______________________
id: 50 reward: -0.0012315270935960591 service_time: 2571 s_time: 2 penalty: 0 agent_num: 29 done: False
______________________
Step:  2496
Pretraining Loss:  tensor(0.0517, device='cuda:0', grad_fn=<MeanBackward0>)
id: 44 reward: -0.05714285714285714 service_time: 1614 s_time: 32 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: 0.0 service_time: 1242 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 53 reward: -0.06808035714285714 service_time: 2103 s_time: 61 penalty: 0 agent_num: 16 done: False
______________________
id: 47 reward: -0.024553571428571428 service_time: 1659 s_time: 22 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: 0.0018796992481203006 service_time: 2191 s_time: -2 penalty: 0 agent_num: 19 done: False
______________________
id: 54 reward: 0.0 service_time: 2559 s_time: 0 penalty: 0 agent_num: 27 done: False
______________________
id: 42 reward: 0.0 service_time: 2634 s_time: 0 penalty: 0 agent_num: 27 done: False
______________________
id: 52 reward: 0.03306878306878307 service_time: 2342 s_time: -50 penalty: 0 agent_num: 27 done: False
______________________
id: 50 reward: 0.027093596059113302 service_time: 2527 s_time: -44 penalty: 0 agent_num: 29 done: False
______________________
id: 41 reward: -0.02922077922077922 service_time: 2682 s_time: 36 penalty: 0 agent_num: 22 done: False
______________________
id: 55 reward: 0.03409090909090909 service_time: 2299 s_time: -42 penalty: 0 agent_num: 22 done: False
______________________
id: 45 reward: 0.0010204081632653062 service_time: 2677 s_time: -2 penalty: 0 agent_num: 35 done: False
______________________
id: 49 reward: -0.015816326530612244 service_time: 2613 s_time: 31 penalty: 0 agent_num: 35 done: False
______________________
id: 43 reward: 0.0020408163265306124 service_time: 2525 s_time: -4 penalty: 0 agent_num: 35 done: False
______________________
id: 46 reward: -0.009316770186335404 service_time: 2647 s_time: 24 penalty: 0 agent_num: 46 done: False
______________________
id: 48 reward: 20.00170068027211 service_time: 2446 s_time: -4 penalty: 0 agent_num: 42 done: True
______________________
Step:  2512
Pretraining Loss:  tensor(0.0549, device='cuda:0', grad_fn=<MeanBackward0>)
id: 44 reward: -0.07678571428571429 service_time: 1657 s_time: 43 penalty: 0 agent_num: 10 done: False
______________________
id: 48 reward: -0.026041666666666668 service_time: 35 s_time: 35 penalty: 0 agent_num: 24 done: False
______________________
id: 51 reward: -0.08116883116883117 service_time: 1292 s_time: 50 penalty: 0 agent_num: 11 done: False
______________________
id: 53 reward: -0.05357142857142857 service_time: 2151 s_time: 48 penalty: 0 agent_num: 16 done: False
______________________
id: 47 reward: 0.0 service_time: 1659 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: -0.02631578947368421 service_time: 2219 s_time: 28 penalty: 0 agent_num: 19 done: False
______________________
id: 55 reward: 0.0 service_time: 2299 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 41 reward: -0.026785714285714284 service_time: 2715 s_time: 33 penalty: 0 agent_num: 22 done: False
______________________
id: 54 reward: 0.0 service_time: 2559 s_time: 0 penalty: 0 agent_num: 27 done: False
______________________
id: 42 reward: -0.013888888888888888 service_time: 2655 s_time: 21 penalty: 0 agent_num: 27 done: False
______________________
id: 49 reward: -0.0035714285714285713 service_time: 2620 s_time: 7 penalty: 0 agent_num: 35 done: False
______________________
id: 43 reward: -0.03571428571428571 service_time: 2595 s_time: 70 penalty: 0 agent_num: 35 done: False
______________________
id: 52 reward: -0.021825396825396824 service_time: 2375 s_time: 33 penalty: 0 agent_num: 27 done: False
______________________
id: 50 reward: -0.020935960591133004 service_time: 2561 s_time: 34 penalty: 0 agent_num: 29 done: False
______________________
id: 45 reward: 20.00204081632653 service_time: 2673 s_time: -4 penalty: 0 agent_num: 35 done: True
______________________
id: 46 reward: 20.00388198757764 service_time: 2637 s_time: -10 penalty: 0 agent_num: 46 done: True
______________________
Step:  2528
Pretraining Loss:  tensor(0.0563, device='cuda:0', grad_fn=<MeanBackward0>)
id: 51 reward: -0.18019480519480519 service_time: 1403 s_time: 111 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: -0.2 service_time: 1769 s_time: 112 penalty: 0 agent_num: 10 done: False
______________________
id: 48 reward: -0.013392857142857142 service_time: 53 s_time: 18 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: -0.012755102040816327 service_time: 20 s_time: 20 penalty: 0 agent_num: 28 done: False
______________________
id: 53 reward: -0.041294642857142856 service_time: 2188 s_time: 37 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: -0.03665413533834586 service_time: 2258 s_time: 39 penalty: 0 agent_num: 19 done: False
______________________
id: 46 reward: -0.008241758241758242 service_time: 18 s_time: 18 penalty: 0 agent_num: 39 done: False
______________________
id: 55 reward: -0.10227272727272728 service_time: 2425 s_time: 126 penalty: 0 agent_num: 22 done: False
______________________
id: 52 reward: 0.0 service_time: 2375 s_time: 0 penalty: 0 agent_num: 27 done: False
______________________
id: 47 reward: -0.05803571428571429 service_time: 1711 s_time: 52 penalty: 0 agent_num: 16 done: False
______________________
id: 41 reward: -0.03409090909090909 service_time: 2757 s_time: 42 penalty: 0 agent_num: 22 done: False
______________________
id: 42 reward: -0.02447089947089947 service_time: 2692 s_time: 37 penalty: 0 agent_num: 27 done: False
______________________
id: 49 reward: 0.0 service_time: 2620 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 43 reward: -0.0005102040816326531 service_time: 2596 s_time: 1 penalty: 0 agent_num: 35 done: False
______________________
id: 50 reward: -0.020320197044334975 service_time: 2594 s_time: 33 penalty: 0 agent_num: 29 done: False
______________________
id: 54 reward: 20.0 service_time: 2559 s_time: 0 penalty: 0 agent_num: 27 done: True
______________________
Step:  2544
Pretraining Loss:  tensor(0.0340, device='cuda:0', grad_fn=<MeanBackward0>)
id: 54 reward: -0.008241758241758242 service_time: 6 s_time: 6 penalty: 0 agent_num: 13 done: False
______________________
id: 51 reward: -0.048701298701298704 service_time: 1433 s_time: 30 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: -0.15892857142857142 service_time: 1858 s_time: 89 penalty: 0 agent_num: 10 done: False
______________________
id: 45 reward: -0.015306122448979591 service_time: 44 s_time: 24 penalty: 0 agent_num: 28 done: False
______________________
id: 48 reward: -0.018601190476190476 service_time: 78 s_time: 25 penalty: 0 agent_num: 24 done: False
______________________
id: 40 reward: -0.03007518796992481 service_time: 2290 s_time: 32 penalty: 0 agent_num: 19 done: False
______________________
id: 55 reward: -0.024350649350649352 service_time: 2455 s_time: 30 penalty: 0 agent_num: 22 done: False
______________________
id: 41 reward: -0.0625 service_time: 2834 s_time: 77 penalty: 0 agent_num: 22 done: False
______________________
id: 46 reward: -0.007326007326007326 service_time: 34 s_time: 16 penalty: 0 agent_num: 39 done: False
______________________
id: 53 reward: -0.08816964285714286 service_time: 2267 s_time: 79 penalty: 0 agent_num: 16 done: False
______________________
id: 49 reward: 0.0005102040816326531 service_time: 2619 s_time: -1 penalty: 0 agent_num: 35 done: False
______________________
id: 47 reward: 0.0 service_time: 1711 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 42 reward: -0.0291005291005291 service_time: 2736 s_time: 44 penalty: 0 agent_num: 27 done: False
______________________
id: 43 reward: -0.024489795918367346 service_time: 2644 s_time: 48 penalty: 0 agent_num: 35 done: False
______________________
id: 50 reward: -0.03017241379310345 service_time: 2643 s_time: 49 penalty: 0 agent_num: 29 done: False
______________________
id: 52 reward: -0.011904761904761904 service_time: 2393 s_time: 18 penalty: 0 agent_num: 27 done: False
______________________
Step:  2560
Pretraining Loss:  tensor(0.0343, device='cuda:0', grad_fn=<MeanBackward0>)
id: 54 reward: -0.034340659340659344 service_time: 31 s_time: 25 penalty: 0 agent_num: 13 done: False
______________________
id: 44 reward: -0.15714285714285714 service_time: 1946 s_time: 88 penalty: 0 agent_num: 10 done: False
______________________
id: 48 reward: -0.002232142857142857 service_time: 81 s_time: 3 penalty: 0 agent_num: 24 done: False
______________________
id: 51 reward: -0.04220779220779221 service_time: 1459 s_time: 26 penalty: 0 agent_num: 11 done: False
______________________
id: 45 reward: -0.02614795918367347 service_time: 85 s_time: 41 penalty: 0 agent_num: 28 done: False
______________________
id: 46 reward: -0.011904761904761904 service_time: 60 s_time: 26 penalty: 0 agent_num: 39 done: False
______________________
id: 41 reward: -0.0349025974025974 service_time: 2877 s_time: 43 penalty: 0 agent_num: 22 done: False
______________________
id: 55 reward: -0.017857142857142856 service_time: 2477 s_time: 22 penalty: 0 agent_num: 22 done: False
______________________
id: 53 reward: -0.13392857142857142 service_time: 2387 s_time: 120 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: -0.07518796992481203 service_time: 2370 s_time: 80 penalty: 0 agent_num: 19 done: False
______________________
id: 52 reward: 0.003968253968253968 service_time: 2387 s_time: -6 penalty: 0 agent_num: 27 done: False
______________________
id: 42 reward: -0.028439153439153438 service_time: 2779 s_time: 43 penalty: 0 agent_num: 27 done: False
______________________
id: 43 reward: -0.0163265306122449 service_time: 2676 s_time: 32 penalty: 0 agent_num: 35 done: False
______________________
id: 47 reward: -0.027901785714285716 service_time: 1736 s_time: 25 penalty: 0 agent_num: 16 done: False
______________________
id: 50 reward: -0.019088669950738917 service_time: 2674 s_time: 31 penalty: 0 agent_num: 29 done: False
______________________
id: 49 reward: 20.0 service_time: 2619 s_time: 0 penalty: 0 agent_num: 35 done: True
______________________
Step:  2576
Pretraining Loss:  tensor(0.0414, device='cuda:0', grad_fn=<MeanBackward0>)
id: 54 reward: -0.034340659340659344 service_time: 56 s_time: 25 penalty: 0 agent_num: 13 done: False
______________________
id: 49 reward: -0.03409090909090909 service_time: 21 s_time: 21 penalty: 0 agent_num: 11 done: False
______________________
id: 51 reward: -0.045454545454545456 service_time: 1487 s_time: 28 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: -0.05892857142857143 service_time: 1979 s_time: 33 penalty: 0 agent_num: 10 done: False
______________________
id: 48 reward: -0.011904761904761904 service_time: 97 s_time: 16 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: 0.01403061224489796 service_time: 63 s_time: -22 penalty: 0 agent_num: 28 done: False
______________________
id: 46 reward: -0.003205128205128205 service_time: 67 s_time: 7 penalty: 0 agent_num: 39 done: False
______________________
id: 40 reward: 0.0 service_time: 2370 s_time: 0 penalty: 0 agent_num: 19 done: False
______________________
id: 41 reward: -0.04707792207792208 service_time: 2935 s_time: 58 penalty: 0 agent_num: 22 done: False
______________________
id: 55 reward: -0.08603896103896104 service_time: 2583 s_time: 106 penalty: 0 agent_num: 22 done: False
______________________
id: 53 reward: -0.060267857142857144 service_time: 2441 s_time: 54 penalty: 0 agent_num: 16 done: False
______________________
id: 47 reward: 0.0011160714285714285 service_time: 1735 s_time: -1 penalty: 0 agent_num: 16 done: False
______________________
id: 43 reward: -0.001530612244897959 service_time: 2679 s_time: 3 penalty: 0 agent_num: 35 done: False
______________________
id: 50 reward: -0.11637931034482758 service_time: 2863 s_time: 189 penalty: 0 agent_num: 29 done: False
______________________
id: 52 reward: -0.06084656084656084 service_time: 2479 s_time: 92 penalty: 0 agent_num: 27 done: False
______________________
id: 42 reward: -0.11838624338624339 service_time: 2958 s_time: 179 penalty: 0 agent_num: 27 done: False
______________________
Step:  2592
Pretraining Loss:  tensor(0.0463, device='cuda:0', grad_fn=<MeanBackward0>)
id: 54 reward: -0.024725274725274724 service_time: 74 s_time: 18 penalty: 0 agent_num: 13 done: False
______________________
id: 44 reward: -0.2017857142857143 service_time: 2092 s_time: 113 penalty: 0 agent_num: 10 done: False
______________________
id: 49 reward: -0.060064935064935064 service_time: 58 s_time: 37 penalty: 0 agent_num: 11 done: False
______________________
id: 51 reward: 0.021103896103896104 service_time: 1474 s_time: -13 penalty: 0 agent_num: 11 done: False
______________________
id: 48 reward: -0.014136904761904762 service_time: 116 s_time: 19 penalty: 0 agent_num: 24 done: False
______________________
id: 40 reward: -0.03007518796992481 service_time: 2402 s_time: 32 penalty: 0 agent_num: 19 done: False
______________________
id: 41 reward: -0.06737012987012987 service_time: 3018 s_time: 83 penalty: 0 agent_num: 22 done: False
______________________
id: 45 reward: -0.04081632653061224 service_time: 127 s_time: 64 penalty: 0 agent_num: 28 done: False
______________________
id: 46 reward: -0.005494505494505495 service_time: 79 s_time: 12 penalty: 0 agent_num: 39 done: False
______________________
id: 55 reward: -0.056818181818181816 service_time: 2653 s_time: 70 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: -0.015625 service_time: 1749 s_time: 14 penalty: 0 agent_num: 16 done: False
______________________
id: 52 reward: 0.03306878306878307 service_time: 2429 s_time: -50 penalty: 0 agent_num: 27 done: False
______________________
id: 43 reward: 0.0010204081632653062 service_time: 2677 s_time: -2 penalty: 0 agent_num: 35 done: False
______________________
id: 53 reward: -0.20200892857142858 service_time: 2622 s_time: 181 penalty: 0 agent_num: 16 done: False
______________________
id: 42 reward: -0.06878306878306878 service_time: 3062 s_time: 104 penalty: 0 agent_num: 27 done: False
______________________
id: 50 reward: -0.013546798029556651 service_time: 2885 s_time: 22 penalty: 0 agent_num: 29 done: False
______________________
Step:  2608
Pretraining Loss:  tensor(0.0590, device='cuda:0', grad_fn=<MeanBackward0>)
id: 54 reward: -0.028846153846153848 service_time: 95 s_time: 21 penalty: 0 agent_num: 13 done: False
______________________
id: 44 reward: -0.09642857142857143 service_time: 2146 s_time: 54 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: 0.0 service_time: 1474 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 48 reward: -0.005952380952380952 service_time: 124 s_time: 8 penalty: 0 agent_num: 24 done: False
______________________
id: 55 reward: -0.04788961038961039 service_time: 2712 s_time: 59 penalty: 0 agent_num: 22 done: False
______________________
id: 46 reward: -0.005494505494505495 service_time: 91 s_time: 12 penalty: 0 agent_num: 39 done: False
______________________
id: 45 reward: -0.01403061224489796 service_time: 149 s_time: 22 penalty: 0 agent_num: 28 done: False
______________________
id: 49 reward: -0.0698051948051948 service_time: 101 s_time: 43 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: 0.0 service_time: 1749 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 53 reward: -0.1015625 service_time: 2713 s_time: 91 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: -0.07236842105263158 service_time: 2479 s_time: 77 penalty: 0 agent_num: 19 done: False
______________________
id: 52 reward: -0.051587301587301584 service_time: 2507 s_time: 78 penalty: 0 agent_num: 27 done: False
______________________
id: 41 reward: -0.1891233766233766 service_time: 3251 s_time: 233 penalty: 0 agent_num: 22 done: False
______________________
id: 43 reward: 0.0005102040816326531 service_time: 2676 s_time: -1 penalty: 0 agent_num: 35 done: False
______________________
id: 50 reward: 0.0024630541871921183 service_time: 2881 s_time: -4 penalty: 0 agent_num: 29 done: False
______________________
id: 42 reward: 0.005291005291005291 service_time: 3054 s_time: -8 penalty: 0 agent_num: 27 done: False
______________________
Step:  2624
Pretraining Loss:  tensor(0.0444, device='cuda:0', grad_fn=<MeanBackward0>)
id: 54 reward: -0.017857142857142856 service_time: 108 s_time: 13 penalty: 0 agent_num: 13 done: False
______________________
id: 44 reward: -0.10357142857142858 service_time: 2204 s_time: 58 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: 0.0 service_time: 1474 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 53 reward: -0.15959821428571427 service_time: 2856 s_time: 143 penalty: 0 agent_num: 16 done: False
______________________
id: 48 reward: -0.023809523809523808 service_time: 156 s_time: 32 penalty: 0 agent_num: 24 done: False
______________________
id: 46 reward: -0.021062271062271064 service_time: 137 s_time: 46 penalty: 0 agent_num: 39 done: False
______________________
id: 49 reward: -0.048701298701298704 service_time: 131 s_time: 30 penalty: 0 agent_num: 11 done: False
______________________
id: 52 reward: -0.021164021164021163 service_time: 2539 s_time: 32 penalty: 0 agent_num: 27 done: False
______________________
id: 47 reward: 0.0 service_time: 1749 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 45 reward: -0.01594387755102041 service_time: 174 s_time: 25 penalty: 0 agent_num: 28 done: False
______________________
id: 55 reward: -0.04383116883116883 service_time: 2766 s_time: 54 penalty: 0 agent_num: 22 done: False
______________________
id: 43 reward: -0.001530612244897959 service_time: 2679 s_time: 3 penalty: 0 agent_num: 35 done: False
______________________
id: 40 reward: -0.125 service_time: 2612 s_time: 133 penalty: 0 agent_num: 19 done: False
______________________
id: 50 reward: -0.0166256157635468 service_time: 2908 s_time: 27 penalty: 0 agent_num: 29 done: False
______________________
id: 41 reward: -0.07142857142857142 service_time: 3339 s_time: 88 penalty: 0 agent_num: 22 done: False
______________________
id: 42 reward: 0.001984126984126984 service_time: 3051 s_time: -3 penalty: 0 agent_num: 27 done: False
______________________
Step:  2640
Pretraining Loss:  tensor(0.0469, device='cuda:0', grad_fn=<MeanBackward0>)
id: 54 reward: -0.04395604395604396 service_time: 140 s_time: 32 penalty: 0 agent_num: 13 done: False
______________________
id: 44 reward: -0.16785714285714284 service_time: 2298 s_time: 94 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: 0.0 service_time: 1474 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 48 reward: -0.03273809523809524 service_time: 200 s_time: 44 penalty: 0 agent_num: 24 done: False
______________________
id: 40 reward: -0.16165413533834586 service_time: 2784 s_time: 172 penalty: 0 agent_num: 19 done: False
______________________
id: 49 reward: -0.0762987012987013 service_time: 178 s_time: 47 penalty: 0 agent_num: 11 done: False
______________________
id: 53 reward: -0.10491071428571429 service_time: 2950 s_time: 94 penalty: 0 agent_num: 16 done: False
______________________
id: 46 reward: -0.011446886446886446 service_time: 162 s_time: 25 penalty: 0 agent_num: 39 done: False
______________________
id: 43 reward: 0.001530612244897959 service_time: 2676 s_time: -3 penalty: 0 agent_num: 35 done: False
______________________
id: 45 reward: -0.026785714285714284 service_time: 216 s_time: 42 penalty: 0 agent_num: 28 done: False
______________________
id: 55 reward: -0.12743506493506493 service_time: 2923 s_time: 157 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: -0.04017857142857143 service_time: 1785 s_time: 36 penalty: 0 agent_num: 16 done: False
______________________
id: 50 reward: -0.03633004926108374 service_time: 2967 s_time: 59 penalty: 0 agent_num: 29 done: False
______________________
id: 52 reward: -0.05886243386243386 service_time: 2628 s_time: 89 penalty: 0 agent_num: 27 done: False
______________________
id: 42 reward: 0.0 service_time: 3051 s_time: 0 penalty: 0 agent_num: 27 done: False
______________________
id: 41 reward: 0.0 service_time: 3339 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
Step:  2656
Pretraining Loss:  tensor(0.0506, device='cuda:0', grad_fn=<MeanBackward0>)
id: 54 reward: -0.04807692307692308 service_time: 175 s_time: 35 penalty: 0 agent_num: 13 done: False
______________________
id: 44 reward: -0.20892857142857144 service_time: 2415 s_time: 117 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: 0.0 service_time: 1474 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 53 reward: -0.15290178571428573 service_time: 3087 s_time: 137 penalty: 0 agent_num: 16 done: False
______________________
id: 55 reward: -0.07954545454545454 service_time: 3021 s_time: 98 penalty: 0 agent_num: 22 done: False
______________________
id: 40 reward: -0.106203007518797 service_time: 2897 s_time: 113 penalty: 0 agent_num: 19 done: False
______________________
id: 48 reward: 0.0 service_time: 200 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 47 reward: -0.046875 service_time: 1827 s_time: 42 penalty: 0 agent_num: 16 done: False
______________________
id: 42 reward: 0.0 service_time: 3051 s_time: 0 penalty: 0 agent_num: 27 done: False
______________________
id: 43 reward: 0.0 service_time: 2676 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 49 reward: -0.040584415584415584 service_time: 203 s_time: 25 penalty: 0 agent_num: 11 done: False
______________________
id: 46 reward: -0.018772893772893772 service_time: 203 s_time: 41 penalty: 0 agent_num: 39 done: False
______________________
id: 41 reward: 0.0 service_time: 3339 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 45 reward: 0.0012755102040816326 service_time: 214 s_time: -2 penalty: 0 agent_num: 28 done: False
______________________
id: 50 reward: 0.003078817733990148 service_time: 2962 s_time: -5 penalty: 0 agent_num: 29 done: False
______________________
id: 52 reward: -0.0582010582010582 service_time: 2716 s_time: 88 penalty: 0 agent_num: 27 done: False
______________________
Step:  2672
Pretraining Loss:  tensor(0.0529, device='cuda:0', grad_fn=<MeanBackward0>)
id: 54 reward: -0.03021978021978022 service_time: 197 s_time: 22 penalty: 0 agent_num: 13 done: False
______________________
id: 51 reward: -0.16233766233766234 service_time: 1574 s_time: 100 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: -0.056818181818181816 service_time: 238 s_time: 35 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: -0.14285714285714285 service_time: 2495 s_time: 80 penalty: 0 agent_num: 10 done: False
______________________
id: 53 reward: -0.07700892857142858 service_time: 3156 s_time: 69 penalty: 0 agent_num: 16 done: False
______________________
id: 48 reward: -0.014136904761904762 service_time: 219 s_time: 19 penalty: 0 agent_num: 24 done: False
______________________
id: 47 reward: -0.04799107142857143 service_time: 1870 s_time: 43 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: -0.07894736842105263 service_time: 2981 s_time: 84 penalty: 0 agent_num: 19 done: False
______________________
id: 45 reward: -0.028698979591836735 service_time: 259 s_time: 45 penalty: 0 agent_num: 28 done: False
______________________
id: 46 reward: -0.009615384615384616 service_time: 224 s_time: 21 penalty: 0 agent_num: 39 done: False
______________________
id: 41 reward: 0.0 service_time: 3339 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 50 reward: 0.0018472906403940886 service_time: 2959 s_time: -3 penalty: 0 agent_num: 29 done: False
______________________
id: 55 reward: -0.060876623376623376 service_time: 3096 s_time: 75 penalty: 0 agent_num: 22 done: False
______________________
id: 42 reward: -0.0006613756613756613 service_time: 3052 s_time: 1 penalty: 0 agent_num: 27 done: False
______________________
id: 52 reward: -0.016534391534391533 service_time: 2741 s_time: 25 penalty: 0 agent_num: 27 done: False
______________________
id: 43 reward: 20.00408163265306 service_time: 2668 s_time: -8 penalty: 0 agent_num: 35 done: True
______________________
Step:  2688
Pretraining Loss:  tensor(0.0480, device='cuda:0', grad_fn=<MeanBackward0>)
id: 54 reward: 0.0 service_time: 197 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 44 reward: -0.1375 service_time: 2572 s_time: 77 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: -0.12012987012987013 service_time: 1648 s_time: 74 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: -0.06818181818181818 service_time: 280 s_time: 42 penalty: 0 agent_num: 11 done: False
______________________
id: 53 reward: -0.12834821428571427 service_time: 3271 s_time: 115 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: -0.040413533834586464 service_time: 3024 s_time: 43 penalty: 0 agent_num: 19 done: False
______________________
id: 48 reward: -0.026785714285714284 service_time: 255 s_time: 36 penalty: 0 agent_num: 24 done: False
______________________
id: 47 reward: -0.017857142857142856 service_time: 1886 s_time: 16 penalty: 0 agent_num: 16 done: False
______________________
id: 43 reward: -0.008116883116883116 service_time: 20 s_time: 20 penalty: 0 agent_num: 44 done: False
______________________
id: 42 reward: 0.0 service_time: 3052 s_time: 0 penalty: 0 agent_num: 27 done: False
______________________
id: 45 reward: -0.028698979591836735 service_time: 304 s_time: 45 penalty: 0 agent_num: 28 done: False
______________________
id: 46 reward: 0.0 service_time: 224 s_time: 0 penalty: 0 agent_num: 39 done: False
______________________
id: 41 reward: 0.0 service_time: 3339 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 50 reward: 0.0 service_time: 2959 s_time: 0 penalty: 0 agent_num: 29 done: False
______________________
id: 55 reward: -0.06574675324675325 service_time: 3177 s_time: 81 penalty: 0 agent_num: 22 done: False
______________________
id: 52 reward: -0.022486772486772486 service_time: 2775 s_time: 34 penalty: 0 agent_num: 27 done: False
______________________
Step:  2704
Pretraining Loss:  tensor(0.0389, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.03896103896103896 service_time: 304 s_time: 24 penalty: 0 agent_num: 11 done: False
______________________
id: 54 reward: -0.05631868131868132 service_time: 238 s_time: 41 penalty: 0 agent_num: 13 done: False
______________________
id: 44 reward: -0.1357142857142857 service_time: 2648 s_time: 76 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: -0.37337662337662336 service_time: 1878 s_time: 230 penalty: 0 agent_num: 11 done: False
______________________
id: 48 reward: -0.03050595238095238 service_time: 296 s_time: 41 penalty: 0 agent_num: 24 done: False
______________________
id: 47 reward: -0.030133928571428572 service_time: 1913 s_time: 27 penalty: 0 agent_num: 16 done: False
______________________
id: 43 reward: -0.01948051948051948 service_time: 68 s_time: 48 penalty: 0 agent_num: 44 done: False
______________________
id: 40 reward: -0.07894736842105263 service_time: 3108 s_time: 84 penalty: 0 agent_num: 19 done: False
______________________
id: 45 reward: 0.0 service_time: 304 s_time: 0 penalty: 0 agent_num: 28 done: False
______________________
id: 53 reward: -0.15513392857142858 service_time: 3410 s_time: 139 penalty: 0 agent_num: 16 done: False
______________________
id: 41 reward: 0.0 service_time: 3339 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 46 reward: -0.023809523809523808 service_time: 276 s_time: 52 penalty: 0 agent_num: 39 done: False
______________________
id: 42 reward: 0.0 service_time: 3052 s_time: 0 penalty: 0 agent_num: 27 done: False
______________________
id: 50 reward: 0.0006157635467980296 service_time: 2958 s_time: -1 penalty: 0 agent_num: 29 done: False
______________________
id: 55 reward: -0.15422077922077923 service_time: 3367 s_time: 190 penalty: 0 agent_num: 22 done: False
______________________
id: 52 reward: -0.007936507936507936 service_time: 2787 s_time: 12 penalty: 0 agent_num: 27 done: False
______________________
Step:  2720
Pretraining Loss:  tensor(0.0485, device='cuda:0', grad_fn=<MeanBackward0>)
id: 54 reward: -0.054945054945054944 service_time: 278 s_time: 40 penalty: 0 agent_num: 13 done: False
______________________
id: 49 reward: 0.0 service_time: 304 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: -0.14642857142857144 service_time: 2730 s_time: 82 penalty: 0 agent_num: 10 done: False
______________________
id: 53 reward: -0.13950892857142858 service_time: 3535 s_time: 125 penalty: 0 agent_num: 16 done: False
______________________
id: 47 reward: -0.030133928571428572 service_time: 1940 s_time: 27 penalty: 0 agent_num: 16 done: False
______________________
id: 51 reward: -0.08279220779220779 service_time: 1929 s_time: 51 penalty: 0 agent_num: 11 done: False
______________________
id: 43 reward: 0.0 service_time: 68 s_time: 0 penalty: 0 agent_num: 44 done: False
______________________
id: 48 reward: -0.011904761904761904 service_time: 312 s_time: 16 penalty: 0 agent_num: 24 done: False
______________________
id: 40 reward: -0.26597744360902253 service_time: 3391 s_time: 283 penalty: 0 agent_num: 19 done: False
______________________
id: 41 reward: 0.0 service_time: 3339 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 45 reward: -0.019770408163265307 service_time: 335 s_time: 31 penalty: 0 agent_num: 28 done: False
______________________
id: 46 reward: 0.0 service_time: 276 s_time: 0 penalty: 0 agent_num: 39 done: False
______________________
id: 42 reward: 0.0 service_time: 3052 s_time: 0 penalty: 0 agent_num: 27 done: False
______________________
id: 55 reward: 0.002435064935064935 service_time: 3364 s_time: -3 penalty: 0 agent_num: 22 done: False
______________________
id: 52 reward: -0.017857142857142856 service_time: 2814 s_time: 27 penalty: 0 agent_num: 27 done: False
______________________
id: 50 reward: 20.004926108374384 service_time: 2950 s_time: -8 penalty: 0 agent_num: 29 done: True
______________________
Step:  2736
Pretraining Loss:  tensor(0.0408, device='cuda:0', grad_fn=<MeanBackward0>)
id: 44 reward: -0.3535714285714286 service_time: 2928 s_time: 198 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: -0.19967532467532467 service_time: 2052 s_time: 123 penalty: 0 agent_num: 11 done: False
______________________
id: 54 reward: -0.06043956043956044 service_time: 322 s_time: 44 penalty: 0 agent_num: 13 done: False
______________________
id: 48 reward: -0.006696428571428571 service_time: 321 s_time: 9 penalty: 0 agent_num: 24 done: False
______________________
id: 50 reward: -0.01447876447876448 service_time: 30 s_time: 30 penalty: 0 agent_num: 37 done: False
______________________
id: 40 reward: -0.1287593984962406 service_time: 3528 s_time: 137 penalty: 0 agent_num: 19 done: False
______________________
id: 49 reward: -0.11038961038961038 service_time: 372 s_time: 68 penalty: 0 agent_num: 11 done: False
______________________
id: 53 reward: -0.15513392857142858 service_time: 3674 s_time: 139 penalty: 0 agent_num: 16 done: False
______________________
id: 45 reward: -0.029336734693877552 service_time: 381 s_time: 46 penalty: 0 agent_num: 28 done: False
______________________
id: 47 reward: -0.020089285714285716 service_time: 1958 s_time: 18 penalty: 0 agent_num: 16 done: False
______________________
id: 43 reward: -0.010146103896103896 service_time: 93 s_time: 25 penalty: 0 agent_num: 44 done: False
______________________
id: 55 reward: 0.00487012987012987 service_time: 3358 s_time: -6 penalty: 0 agent_num: 22 done: False
______________________
id: 46 reward: -0.014194139194139194 service_time: 307 s_time: 31 penalty: 0 agent_num: 39 done: False
______________________
id: 42 reward: 0.0 service_time: 3052 s_time: 0 penalty: 0 agent_num: 27 done: False
______________________
id: 52 reward: -0.03439153439153439 service_time: 2866 s_time: 52 penalty: 0 agent_num: 27 done: False
______________________
id: 41 reward: 20.001623376623378 service_time: 3337 s_time: -2 penalty: 0 agent_num: 22 done: True
______________________
Step:  2752
Pretraining Loss:  tensor(0.0481, device='cuda:0', grad_fn=<MeanBackward0>)
id: 44 reward: -0.24107142857142858 service_time: 3063 s_time: 135 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: -0.07954545454545454 service_time: 2101 s_time: 49 penalty: 0 agent_num: 11 done: False
______________________
id: 41 reward: -0.021205357142857144 service_time: 38 s_time: 38 penalty: 0 agent_num: 32 done: False
______________________
id: 53 reward: -0.16964285714285715 service_time: 3826 s_time: 152 penalty: 0 agent_num: 16 done: False
______________________
id: 50 reward: -0.019787644787644786 service_time: 71 s_time: 41 penalty: 0 agent_num: 37 done: False
______________________
id: 47 reward: 0.0 service_time: 1958 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 48 reward: -0.023809523809523808 service_time: 353 s_time: 32 penalty: 0 agent_num: 24 done: False
______________________
id: 43 reward: -0.022321428571428572 service_time: 148 s_time: 55 penalty: 0 agent_num: 44 done: False
______________________
id: 42 reward: 0.0 service_time: 3052 s_time: 0 penalty: 0 agent_num: 27 done: False
______________________
id: 40 reward: -0.07518796992481203 service_time: 3608 s_time: 80 penalty: 0 agent_num: 19 done: False
______________________
id: 45 reward: -0.01721938775510204 service_time: 408 s_time: 27 penalty: 0 agent_num: 28 done: False
______________________
id: 55 reward: 0.0008116883116883117 service_time: 3357 s_time: -1 penalty: 0 agent_num: 22 done: False
______________________
id: 46 reward: -0.028388278388278388 service_time: 369 s_time: 62 penalty: 0 agent_num: 39 done: False
______________________
id: 49 reward: 0.01948051948051948 service_time: 360 s_time: -12 penalty: 0 agent_num: 11 done: False
______________________
id: 54 reward: -0.042582417582417584 service_time: 353 s_time: 31 penalty: 0 agent_num: 13 done: False
______________________
id: 52 reward: -0.06878306878306878 service_time: 2970 s_time: 104 penalty: 0 agent_num: 27 done: False
______________________
Step:  2768
Pretraining Loss:  tensor(0.0378, device='cuda:0', grad_fn=<MeanBackward0>)
id: 44 reward: -0.20714285714285716 service_time: 3179 s_time: 116 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: -0.12824675324675325 service_time: 2180 s_time: 79 penalty: 0 agent_num: 11 done: False
______________________
id: 41 reward: 0.0 service_time: 38 s_time: 0 penalty: 0 agent_num: 32 done: False
______________________
id: 48 reward: -0.020089285714285716 service_time: 380 s_time: 27 penalty: 0 agent_num: 24 done: False
______________________
id: 49 reward: 0.003246753246753247 service_time: 358 s_time: -2 penalty: 0 agent_num: 11 done: False
______________________
id: 50 reward: -0.013030888030888031 service_time: 98 s_time: 27 penalty: 0 agent_num: 37 done: False
______________________
id: 40 reward: -0.07518796992481203 service_time: 3688 s_time: 80 penalty: 0 agent_num: 19 done: False
______________________
id: 53 reward: -0.16629464285714285 service_time: 3975 s_time: 149 penalty: 0 agent_num: 16 done: False
______________________
id: 47 reward: -0.044642857142857144 service_time: 1998 s_time: 40 penalty: 0 agent_num: 16 done: False
______________________
id: 45 reward: -0.010841836734693877 service_time: 425 s_time: 17 penalty: 0 agent_num: 28 done: False
______________________
id: 55 reward: 0.0 service_time: 3357 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 43 reward: 0.0 service_time: 148 s_time: 0 penalty: 0 agent_num: 44 done: False
______________________
id: 54 reward: 0.006868131868131868 service_time: 348 s_time: -5 penalty: 0 agent_num: 13 done: False
______________________
id: 46 reward: -0.015567765567765568 service_time: 403 s_time: 34 penalty: 0 agent_num: 39 done: False
______________________
id: 52 reward: -0.03902116402116402 service_time: 3029 s_time: 59 penalty: 0 agent_num: 27 done: False
______________________
id: 42 reward: 20.0 service_time: 3052 s_time: 0 penalty: 0 agent_num: 27 done: True
______________________
Step:  2784
Pretraining Loss:  tensor(0.0434, device='cuda:0', grad_fn=<MeanBackward0>)
id: 51 reward: -0.18181818181818182 service_time: 2292 s_time: 112 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: -0.1625 service_time: 3270 s_time: 91 penalty: 0 agent_num: 10 done: False
______________________
id: 49 reward: 0.07467532467532467 service_time: 312 s_time: -46 penalty: 0 agent_num: 11 done: False
______________________
id: 41 reward: -0.013950892857142858 service_time: 63 s_time: 25 penalty: 0 agent_num: 32 done: False
______________________
id: 53 reward: -0.0859375 service_time: 4052 s_time: 77 penalty: 0 agent_num: 16 done: False
______________________
id: 48 reward: -0.028273809523809524 service_time: 418 s_time: 38 penalty: 0 agent_num: 24 done: False
______________________
id: 50 reward: -0.015444015444015444 service_time: 130 s_time: 32 penalty: 0 agent_num: 37 done: False
______________________
id: 47 reward: 0.0 service_time: 1998 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 42 reward: -0.012917933130699088 service_time: 34 s_time: 34 penalty: 0 agent_num: 47 done: False
______________________
id: 43 reward: -0.022321428571428572 service_time: 203 s_time: 55 penalty: 0 agent_num: 44 done: False
______________________
id: 45 reward: -0.008928571428571428 service_time: 439 s_time: 14 penalty: 0 agent_num: 28 done: False
______________________
id: 54 reward: 0.042582417582417584 service_time: 317 s_time: -31 penalty: 0 agent_num: 13 done: False
______________________
id: 40 reward: -0.19548872180451127 service_time: 3896 s_time: 208 penalty: 0 agent_num: 19 done: False
______________________
id: 46 reward: -0.010073260073260074 service_time: 425 s_time: 22 penalty: 0 agent_num: 39 done: False
______________________
id: 52 reward: 0.008597883597883597 service_time: 3016 s_time: -13 penalty: 0 agent_num: 27 done: False
______________________
id: 55 reward: 20.003246753246753 service_time: 3353 s_time: -4 penalty: 0 agent_num: 22 done: True
______________________
Step:  2800
Pretraining Loss:  tensor(0.0340, device='cuda:0', grad_fn=<MeanBackward0>)
id: 55 reward: -0.02261904761904762 service_time: 19 s_time: 19 penalty: 0 agent_num: 15 done: False
______________________
id: 49 reward: 0.016233766233766232 service_time: 302 s_time: -10 penalty: 0 agent_num: 11 done: False
______________________
id: 54 reward: 0.0260989010989011 service_time: 298 s_time: -19 penalty: 0 agent_num: 13 done: False
______________________
id: 44 reward: -0.20357142857142857 service_time: 3384 s_time: 114 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: -0.26136363636363635 service_time: 2453 s_time: 161 penalty: 0 agent_num: 11 done: False
______________________
id: 41 reward: -0.03515625 service_time: 126 s_time: 63 penalty: 0 agent_num: 32 done: False
______________________
id: 47 reward: -0.044642857142857144 service_time: 2038 s_time: 40 penalty: 0 agent_num: 16 done: False
______________________
id: 50 reward: -0.013996138996138996 service_time: 159 s_time: 29 penalty: 0 agent_num: 37 done: False
______________________
id: 45 reward: 0.0 service_time: 439 s_time: 0 penalty: 0 agent_num: 28 done: False
______________________
id: 40 reward: 0.0037593984962406013 service_time: 3892 s_time: -4 penalty: 0 agent_num: 19 done: False
______________________
id: 42 reward: -0.013297872340425532 service_time: 69 s_time: 35 penalty: 0 agent_num: 47 done: False
______________________
id: 53 reward: -0.17075892857142858 service_time: 4205 s_time: 153 penalty: 0 agent_num: 16 done: False
______________________
id: 43 reward: 0.0 service_time: 203 s_time: 0 penalty: 0 agent_num: 44 done: False
______________________
id: 48 reward: -0.01711309523809524 service_time: 441 s_time: 23 penalty: 0 agent_num: 24 done: False
______________________
id: 46 reward: -0.01098901098901099 service_time: 449 s_time: 24 penalty: 0 agent_num: 39 done: False
______________________
id: 52 reward: 0.0 service_time: 3016 s_time: 0 penalty: 0 agent_num: 27 done: False
______________________
Step:  2816
Pretraining Loss:  tensor(0.0324, device='cuda:0', grad_fn=<MeanBackward0>)
id: 55 reward: -0.008333333333333333 service_time: 26 s_time: 7 penalty: 0 agent_num: 15 done: False
______________________
id: 49 reward: 0.00974025974025974 service_time: 296 s_time: -6 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: -0.32321428571428573 service_time: 3565 s_time: 181 penalty: 0 agent_num: 10 done: False
______________________
id: 54 reward: 0.013736263736263736 service_time: 288 s_time: -10 penalty: 0 agent_num: 13 done: False
______________________
id: 51 reward: -0.49512987012987014 service_time: 2758 s_time: 305 penalty: 0 agent_num: 11 done: False
______________________
id: 41 reward: -0.006696428571428571 service_time: 138 s_time: 12 penalty: 0 agent_num: 32 done: False
______________________
id: 47 reward: -0.022321428571428572 service_time: 2058 s_time: 20 penalty: 0 agent_num: 16 done: False
______________________
id: 48 reward: -0.011904761904761904 service_time: 457 s_time: 16 penalty: 0 agent_num: 24 done: False
______________________
id: 42 reward: -0.004939209726443769 service_time: 82 s_time: 13 penalty: 0 agent_num: 47 done: False
______________________
id: 45 reward: -0.023596938775510203 service_time: 476 s_time: 37 penalty: 0 agent_num: 28 done: False
______________________
id: 53 reward: -0.13504464285714285 service_time: 4326 s_time: 121 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: 0.014097744360902255 service_time: 3877 s_time: -15 penalty: 0 agent_num: 19 done: False
______________________
id: 43 reward: -0.009334415584415584 service_time: 226 s_time: 23 penalty: 0 agent_num: 44 done: False
______________________
id: 50 reward: -0.00916988416988417 service_time: 178 s_time: 19 penalty: 0 agent_num: 37 done: False
______________________
id: 52 reward: 0.0 service_time: 3016 s_time: 0 penalty: 0 agent_num: 27 done: False
______________________
id: 46 reward: 0.0 service_time: 449 s_time: 0 penalty: 0 agent_num: 39 done: False
______________________
Step:  2832
Pretraining Loss:  tensor(0.0352, device='cuda:0', grad_fn=<MeanBackward0>)
id: 55 reward: -0.023809523809523808 service_time: 46 s_time: 20 penalty: 0 agent_num: 15 done: False
______________________
id: 49 reward: 0.0 service_time: 296 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 51 reward: -0.11363636363636363 service_time: 2828 s_time: 70 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: -0.34285714285714286 service_time: 3757 s_time: 192 penalty: 0 agent_num: 10 done: False
______________________
id: 54 reward: -0.07005494505494506 service_time: 339 s_time: 51 penalty: 0 agent_num: 13 done: False
______________________
id: 48 reward: -0.017857142857142856 service_time: 481 s_time: 24 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: -0.01721938775510204 service_time: 503 s_time: 27 penalty: 0 agent_num: 28 done: False
______________________
id: 41 reward: -0.016741071428571428 service_time: 168 s_time: 30 penalty: 0 agent_num: 32 done: False
______________________
id: 50 reward: -0.0111003861003861 service_time: 201 s_time: 23 penalty: 0 agent_num: 37 done: False
______________________
id: 47 reward: -0.0011160714285714285 service_time: 2059 s_time: 1 penalty: 0 agent_num: 16 done: False
______________________
id: 42 reward: -0.003419452887537994 service_time: 91 s_time: 9 penalty: 0 agent_num: 47 done: False
______________________
id: 40 reward: 0.004699248120300752 service_time: 3872 s_time: -5 penalty: 0 agent_num: 19 done: False
______________________
id: 43 reward: -0.0036525974025974025 service_time: 235 s_time: 9 penalty: 0 agent_num: 44 done: False
______________________
id: 46 reward: -0.022893772893772892 service_time: 499 s_time: 50 penalty: 0 agent_num: 39 done: False
______________________
id: 52 reward: 0.0 service_time: 3016 s_time: 0 penalty: 0 agent_num: 27 done: False
______________________
id: 53 reward: -0.09821428571428571 service_time: 4414 s_time: 88 penalty: 0 agent_num: 16 done: False
______________________
Step:  2848
Pretraining Loss:  tensor(0.0362, device='cuda:0', grad_fn=<MeanBackward0>)
id: 55 reward: -0.02738095238095238 service_time: 69 s_time: 23 penalty: 0 agent_num: 15 done: False
______________________
id: 49 reward: 0.0 service_time: 296 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 51 reward: -0.47564935064935066 service_time: 3121 s_time: 293 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: -0.29464285714285715 service_time: 3922 s_time: 165 penalty: 0 agent_num: 10 done: False
______________________
id: 47 reward: 0.0033482142857142855 service_time: 2056 s_time: -3 penalty: 0 agent_num: 16 done: False
______________________
id: 48 reward: -0.006696428571428571 service_time: 490 s_time: 9 penalty: 0 agent_num: 24 done: False
______________________
id: 41 reward: -0.009486607142857142 service_time: 185 s_time: 17 penalty: 0 agent_num: 32 done: False
______________________
id: 54 reward: 0.0 service_time: 339 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 45 reward: -0.009566326530612245 service_time: 518 s_time: 15 penalty: 0 agent_num: 28 done: False
______________________
id: 52 reward: 0.0013227513227513227 service_time: 3014 s_time: -2 penalty: 0 agent_num: 27 done: False
______________________
id: 40 reward: 0.0009398496240601503 service_time: 3871 s_time: -1 penalty: 0 agent_num: 19 done: False
______________________
id: 50 reward: 0.0 service_time: 201 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 42 reward: -0.008358662613981762 service_time: 113 s_time: 22 penalty: 0 agent_num: 47 done: False
______________________
id: 43 reward: -0.012581168831168832 service_time: 266 s_time: 31 penalty: 0 agent_num: 44 done: False
______________________
id: 53 reward: -0.16629464285714285 service_time: 4563 s_time: 149 penalty: 0 agent_num: 16 done: False
______________________
id: 46 reward: -0.011904761904761904 service_time: 525 s_time: 26 penalty: 0 agent_num: 39 done: False
______________________
Step:  2864
Pretraining Loss:  tensor(0.0402, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.0 service_time: 296 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 55 reward: -0.025 service_time: 90 s_time: 21 penalty: 0 agent_num: 15 done: False
______________________
id: 51 reward: -0.375 service_time: 3352 s_time: 231 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: -0.3142857142857143 service_time: 4098 s_time: 176 penalty: 0 agent_num: 10 done: False
______________________
id: 54 reward: 0.0 service_time: 339 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 41 reward: -0.0078125 service_time: 199 s_time: 14 penalty: 0 agent_num: 32 done: False
______________________
id: 48 reward: -0.021577380952380952 service_time: 519 s_time: 29 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: -0.024872448979591837 service_time: 557 s_time: 39 penalty: 0 agent_num: 28 done: False
______________________
id: 47 reward: -0.033482142857142856 service_time: 2086 s_time: 30 penalty: 0 agent_num: 16 done: False
______________________
id: 53 reward: -0.31808035714285715 service_time: 4848 s_time: 285 penalty: 0 agent_num: 16 done: False
______________________
id: 42 reward: -0.010638297872340425 service_time: 141 s_time: 28 penalty: 0 agent_num: 47 done: False
______________________
id: 43 reward: -0.009334415584415584 service_time: 289 s_time: 23 penalty: 0 agent_num: 44 done: False
______________________
id: 46 reward: 0.0 service_time: 525 s_time: 0 penalty: 0 agent_num: 39 done: False
______________________
id: 50 reward: -0.030405405405405407 service_time: 264 s_time: 63 penalty: 0 agent_num: 37 done: False
______________________
id: 40 reward: 20.00093984962406 service_time: 3870 s_time: -1 penalty: 0 agent_num: 19 done: True
______________________
id: 52 reward: 20.0 service_time: 3014 s_time: 0 penalty: 0 agent_num: 27 done: True
______________________
Step:  2880
Pretraining Loss:  tensor(0.0357, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.017857142857142856 service_time: 285 s_time: -11 penalty: 0 agent_num: 11 done: False
______________________
id: 55 reward: -0.04285714285714286 service_time: 126 s_time: 36 penalty: 0 agent_num: 15 done: False
______________________
id: 44 reward: -0.32321428571428573 service_time: 4279 s_time: 181 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: -0.14935064935064934 service_time: 3444 s_time: 92 penalty: 0 agent_num: 11 done: False
______________________
id: 54 reward: -0.054945054945054944 service_time: 379 s_time: 40 penalty: 0 agent_num: 13 done: False
______________________
id: 48 reward: 0.0 service_time: 519 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 40 reward: -0.009398496240601503 service_time: 20 s_time: 20 penalty: 0 agent_num: 38 done: False
______________________
id: 47 reward: 0.0078125 service_time: 2079 s_time: -7 penalty: 0 agent_num: 16 done: False
______________________
id: 45 reward: -0.029974489795918366 service_time: 604 s_time: 47 penalty: 0 agent_num: 28 done: False
______________________
id: 52 reward: -0.016183035714285716 service_time: 29 s_time: 29 penalty: 0 agent_num: 32 done: False
______________________
id: 53 reward: -0.19084821428571427 service_time: 5019 s_time: 171 penalty: 0 agent_num: 16 done: False
______________________
id: 43 reward: -0.007711038961038961 service_time: 308 s_time: 19 penalty: 0 agent_num: 44 done: False
______________________
id: 41 reward: -0.026227678571428572 service_time: 246 s_time: 47 penalty: 0 agent_num: 32 done: False
______________________
id: 42 reward: -0.00911854103343465 service_time: 165 s_time: 24 penalty: 0 agent_num: 47 done: False
______________________
id: 46 reward: -0.018772893772893772 service_time: 566 s_time: 41 penalty: 0 agent_num: 39 done: False
______________________
id: 50 reward: -0.010617760617760617 service_time: 286 s_time: 22 penalty: 0 agent_num: 37 done: False
______________________
Step:  2896
Pretraining Loss:  tensor(0.0283, device='cuda:0', grad_fn=<MeanBackward0>)
id: 55 reward: -0.034523809523809526 service_time: 155 s_time: 29 penalty: 0 agent_num: 15 done: False
______________________
id: 49 reward: 0.0 service_time: 285 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 54 reward: 0.0027472527472527475 service_time: 377 s_time: -2 penalty: 0 agent_num: 13 done: False
______________________
id: 44 reward: -0.28035714285714286 service_time: 4436 s_time: 157 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: -0.1444805194805195 service_time: 3533 s_time: 89 penalty: 0 agent_num: 11 done: False
______________________
id: 52 reward: -0.012834821428571428 service_time: 52 s_time: 23 penalty: 0 agent_num: 32 done: False
______________________
id: 41 reward: -0.0027901785714285715 service_time: 251 s_time: 5 penalty: 0 agent_num: 32 done: False
______________________
id: 48 reward: -0.04985119047619048 service_time: 586 s_time: 67 penalty: 0 agent_num: 24 done: False
______________________
id: 47 reward: 0.0 service_time: 2079 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 45 reward: -0.012755102040816327 service_time: 624 s_time: 20 penalty: 0 agent_num: 28 done: False
______________________
id: 53 reward: -0.17633928571428573 service_time: 5177 s_time: 158 penalty: 0 agent_num: 16 done: False
______________________
id: 46 reward: -0.020604395604395604 service_time: 611 s_time: 45 penalty: 0 agent_num: 39 done: False
______________________
id: 43 reward: -0.006899350649350649 service_time: 325 s_time: 17 penalty: 0 agent_num: 44 done: False
______________________
id: 40 reward: -0.01550751879699248 service_time: 53 s_time: 33 penalty: 0 agent_num: 38 done: False
______________________
id: 50 reward: -0.013030888030888031 service_time: 313 s_time: 27 penalty: 0 agent_num: 37 done: False
______________________
id: 42 reward: -0.01405775075987842 service_time: 202 s_time: 37 penalty: 0 agent_num: 47 done: False
______________________
Step:  2912
Pretraining Loss:  tensor(0.0368, device='cuda:0', grad_fn=<MeanBackward0>)
id: 55 reward: -0.02023809523809524 service_time: 172 s_time: 17 penalty: 0 agent_num: 15 done: False
______________________
id: 49 reward: -0.03896103896103896 service_time: 309 s_time: 24 penalty: 0 agent_num: 11 done: False
______________________
id: 51 reward: -0.28084415584415584 service_time: 3706 s_time: 173 penalty: 0 agent_num: 11 done: False
______________________
id: 54 reward: -0.07005494505494506 service_time: 428 s_time: 51 penalty: 0 agent_num: 13 done: False
______________________
id: 53 reward: -0.11160714285714286 service_time: 5277 s_time: 100 penalty: 0 agent_num: 16 done: False
______________________
id: 52 reward: -0.02734375 service_time: 101 s_time: 49 penalty: 0 agent_num: 32 done: False
______________________
id: 45 reward: -0.017857142857142856 service_time: 652 s_time: 28 penalty: 0 agent_num: 28 done: False
______________________
id: 48 reward: 0.0 service_time: 586 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 40 reward: -0.010808270676691729 service_time: 76 s_time: 23 penalty: 0 agent_num: 38 done: False
______________________
id: 41 reward: -0.011160714285714286 service_time: 271 s_time: 20 penalty: 0 agent_num: 32 done: False
______________________
id: 44 reward: -0.2625 service_time: 4583 s_time: 147 penalty: 0 agent_num: 10 done: False
______________________
id: 42 reward: -0.007598784194528876 service_time: 222 s_time: 20 penalty: 0 agent_num: 47 done: False
______________________
id: 43 reward: -0.007305194805194805 service_time: 343 s_time: 18 penalty: 0 agent_num: 44 done: False
______________________
id: 47 reward: -0.015625 service_time: 2093 s_time: 14 penalty: 0 agent_num: 16 done: False
______________________
id: 46 reward: -0.013278388278388278 service_time: 640 s_time: 29 penalty: 0 agent_num: 39 done: False
______________________
id: 50 reward: -0.005791505791505791 service_time: 325 s_time: 12 penalty: 0 agent_num: 37 done: False
______________________
Step:  2928
Pretraining Loss:  tensor(0.0407, device='cuda:0', grad_fn=<MeanBackward0>)
id: 55 reward: -0.02738095238095238 service_time: 195 s_time: 23 penalty: 0 agent_num: 15 done: False
______________________
id: 49 reward: 0.0 service_time: 309 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: -0.2 service_time: 4695 s_time: 112 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: -0.24512987012987014 service_time: 3857 s_time: 151 penalty: 0 agent_num: 11 done: False
______________________
id: 53 reward: -0.2109375 service_time: 5466 s_time: 189 penalty: 0 agent_num: 16 done: False
______________________
id: 52 reward: 0.0 service_time: 101 s_time: 0 penalty: 0 agent_num: 32 done: False
______________________
id: 47 reward: -0.03459821428571429 service_time: 2124 s_time: 31 penalty: 0 agent_num: 16 done: False
______________________
id: 41 reward: -0.017857142857142856 service_time: 303 s_time: 32 penalty: 0 agent_num: 32 done: False
______________________
id: 40 reward: 0.0 service_time: 76 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 45 reward: -0.021045918367346938 service_time: 685 s_time: 33 penalty: 0 agent_num: 28 done: False
______________________
id: 54 reward: 0.038461538461538464 service_time: 400 s_time: -28 penalty: 0 agent_num: 13 done: False
______________________
id: 48 reward: -0.05654761904761905 service_time: 662 s_time: 76 penalty: 0 agent_num: 24 done: False
______________________
id: 43 reward: 0.0 service_time: 343 s_time: 0 penalty: 0 agent_num: 44 done: False
______________________
id: 46 reward: -0.007326007326007326 service_time: 656 s_time: 16 penalty: 0 agent_num: 39 done: False
______________________
id: 42 reward: -0.006458966565349544 service_time: 239 s_time: 17 penalty: 0 agent_num: 47 done: False
______________________
id: 50 reward: -0.0019305019305019305 service_time: 329 s_time: 4 penalty: 0 agent_num: 37 done: False
______________________
Step:  2944
Pretraining Loss:  tensor(0.0344, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.0 service_time: 309 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 55 reward: -0.05119047619047619 service_time: 238 s_time: 43 penalty: 0 agent_num: 15 done: False
______________________
id: 54 reward: 0.01510989010989011 service_time: 389 s_time: -11 penalty: 0 agent_num: 13 done: False
______________________
id: 51 reward: -0.577922077922078 service_time: 4213 s_time: 356 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: -0.32857142857142857 service_time: 4879 s_time: 184 penalty: 0 agent_num: 10 done: False
______________________
id: 52 reward: -0.028459821428571428 service_time: 152 s_time: 51 penalty: 0 agent_num: 32 done: False
______________________
id: 45 reward: -0.02295918367346939 service_time: 721 s_time: 36 penalty: 0 agent_num: 28 done: False
______________________
id: 47 reward: 0.0 service_time: 2124 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 41 reward: 0.0 service_time: 303 s_time: 0 penalty: 0 agent_num: 32 done: False
______________________
id: 53 reward: -0.1875 service_time: 5634 s_time: 168 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: -0.009868421052631578 service_time: 97 s_time: 21 penalty: 0 agent_num: 38 done: False
______________________
id: 48 reward: -0.01636904761904762 service_time: 684 s_time: 22 penalty: 0 agent_num: 24 done: False
______________________
id: 42 reward: -0.009878419452887538 service_time: 265 s_time: 26 penalty: 0 agent_num: 47 done: False
______________________
id: 46 reward: -0.007783882783882784 service_time: 673 s_time: 17 penalty: 0 agent_num: 39 done: False
______________________
id: 43 reward: -0.021103896103896104 service_time: 395 s_time: 52 penalty: 0 agent_num: 44 done: False
______________________
id: 50 reward: 0.0 service_time: 329 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
Step:  2960
Pretraining Loss:  tensor(0.0556, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.0 service_time: 309 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 55 reward: -0.04880952380952381 service_time: 279 s_time: 41 penalty: 0 agent_num: 15 done: False
______________________
id: 54 reward: -0.057692307692307696 service_time: 431 s_time: 42 penalty: 0 agent_num: 13 done: False
______________________
id: 52 reward: -0.018973214285714284 service_time: 186 s_time: 34 penalty: 0 agent_num: 32 done: False
______________________
id: 51 reward: -0.2840909090909091 service_time: 4388 s_time: 175 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: -0.025669642857142856 service_time: 2147 s_time: 23 penalty: 0 agent_num: 16 done: False
______________________
id: 41 reward: -0.03236607142857143 service_time: 361 s_time: 58 penalty: 0 agent_num: 32 done: False
______________________
id: 53 reward: -0.17299107142857142 service_time: 5789 s_time: 155 penalty: 0 agent_num: 16 done: False
______________________
id: 45 reward: -0.01403061224489796 service_time: 743 s_time: 22 penalty: 0 agent_num: 28 done: False
______________________
id: 40 reward: -0.02443609022556391 service_time: 149 s_time: 52 penalty: 0 agent_num: 38 done: False
______________________
id: 43 reward: -0.012987012987012988 service_time: 427 s_time: 32 penalty: 0 agent_num: 44 done: False
______________________
id: 48 reward: -0.019345238095238096 service_time: 710 s_time: 26 penalty: 0 agent_num: 24 done: False
______________________
id: 42 reward: -0.013677811550151976 service_time: 301 s_time: 36 penalty: 0 agent_num: 47 done: False
______________________
id: 46 reward: -0.017857142857142856 service_time: 712 s_time: 39 penalty: 0 agent_num: 39 done: False
______________________
id: 50 reward: -0.025096525096525095 service_time: 381 s_time: 52 penalty: 0 agent_num: 37 done: False
______________________
id: 44 reward: -0.24821428571428572 service_time: 5018 s_time: 139 penalty: 0 agent_num: 10 done: False
______________________
Step:  2976
Pretraining Loss:  tensor(0.0523, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.017857142857142856 service_time: 320 s_time: 11 penalty: 0 agent_num: 11 done: False
______________________
id: 55 reward: -0.02857142857142857 service_time: 303 s_time: 24 penalty: 0 agent_num: 15 done: False
______________________
id: 44 reward: -0.32321428571428573 service_time: 5199 s_time: 181 penalty: 0 agent_num: 10 done: False
______________________
id: 54 reward: -0.046703296703296704 service_time: 465 s_time: 34 penalty: 0 agent_num: 13 done: False
______________________
id: 51 reward: -0.24512987012987014 service_time: 4539 s_time: 151 penalty: 0 agent_num: 11 done: False
______________________
id: 41 reward: -0.015066964285714286 service_time: 388 s_time: 27 penalty: 0 agent_num: 32 done: False
______________________
id: 47 reward: 0.0 service_time: 2147 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 52 reward: -0.005580357142857143 service_time: 196 s_time: 10 penalty: 0 agent_num: 32 done: False
______________________
id: 45 reward: -0.023596938775510203 service_time: 780 s_time: 37 penalty: 0 agent_num: 28 done: False
______________________
id: 40 reward: -0.005169172932330827 service_time: 160 s_time: 11 penalty: 0 agent_num: 38 done: False
______________________
id: 53 reward: 0.0 service_time: 5789 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 43 reward: -0.006087662337662338 service_time: 442 s_time: 15 penalty: 0 agent_num: 44 done: False
______________________
id: 42 reward: -0.011778115501519757 service_time: 332 s_time: 31 penalty: 0 agent_num: 47 done: False
______________________
id: 46 reward: -0.022893772893772892 service_time: 762 s_time: 50 penalty: 0 agent_num: 39 done: False
______________________
id: 48 reward: -0.005208333333333333 service_time: 717 s_time: 7 penalty: 0 agent_num: 24 done: False
______________________
id: 50 reward: -0.019787644787644786 service_time: 422 s_time: 41 penalty: 0 agent_num: 37 done: False
______________________
Step:  2992
Pretraining Loss:  tensor(0.0463, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.0 service_time: 320 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 51 reward: -0.21266233766233766 service_time: 4670 s_time: 131 penalty: 0 agent_num: 11 done: False
______________________
id: 55 reward: -0.04404761904761905 service_time: 340 s_time: 37 penalty: 0 agent_num: 15 done: False
______________________
id: 54 reward: 0.0027472527472527475 service_time: 463 s_time: -2 penalty: 0 agent_num: 13 done: False
______________________
id: 44 reward: -0.3375 service_time: 5388 s_time: 189 penalty: 0 agent_num: 10 done: False
______________________
id: 52 reward: -0.010044642857142858 service_time: 214 s_time: 18 penalty: 0 agent_num: 32 done: False
______________________
id: 41 reward: -0.011160714285714286 service_time: 408 s_time: 20 penalty: 0 agent_num: 32 done: False
______________________
id: 53 reward: 0.024553571428571428 service_time: 5767 s_time: -22 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: -0.009868421052631578 service_time: 181 s_time: 21 penalty: 0 agent_num: 38 done: False
______________________
id: 45 reward: -0.00701530612244898 service_time: 791 s_time: 11 penalty: 0 agent_num: 28 done: False
______________________
id: 47 reward: 0.0 service_time: 2147 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 48 reward: -0.026041666666666668 service_time: 752 s_time: 35 penalty: 0 agent_num: 24 done: False
______________________
id: 43 reward: -0.015016233766233766 service_time: 479 s_time: 37 penalty: 0 agent_num: 44 done: False
______________________
id: 42 reward: -0.009878419452887538 service_time: 358 s_time: 26 penalty: 0 agent_num: 47 done: False
______________________
id: 46 reward: -0.006868131868131868 service_time: 777 s_time: 15 penalty: 0 agent_num: 39 done: False
______________________
id: 50 reward: -0.007722007722007722 service_time: 438 s_time: 16 penalty: 0 agent_num: 37 done: False
______________________
Step:  3008
Pretraining Loss:  tensor(0.0478, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.0 service_time: 320 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 54 reward: 0.04120879120879121 service_time: 433 s_time: -30 penalty: 0 agent_num: 13 done: False
______________________
id: 55 reward: -0.02976190476190476 service_time: 365 s_time: 25 penalty: 0 agent_num: 15 done: False
______________________
id: 51 reward: -0.2288961038961039 service_time: 4811 s_time: 141 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: -0.38571428571428573 service_time: 5604 s_time: 216 penalty: 0 agent_num: 10 done: False
______________________
id: 52 reward: -0.005022321428571429 service_time: 223 s_time: 9 penalty: 0 agent_num: 32 done: False
______________________
id: 41 reward: 0.0 service_time: 408 s_time: 0 penalty: 0 agent_num: 32 done: False
______________________
id: 40 reward: 0.0 service_time: 181 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 45 reward: -0.02614795918367347 service_time: 832 s_time: 41 penalty: 0 agent_num: 28 done: False
______________________
id: 43 reward: 0.0 service_time: 479 s_time: 0 penalty: 0 agent_num: 44 done: False
______________________
id: 53 reward: 0.002232142857142857 service_time: 5765 s_time: -2 penalty: 0 agent_num: 16 done: False
______________________
id: 48 reward: -0.021577380952380952 service_time: 781 s_time: 29 penalty: 0 agent_num: 24 done: False
______________________
id: 47 reward: -0.0390625 service_time: 2182 s_time: 35 penalty: 0 agent_num: 16 done: False
______________________
id: 46 reward: 0.0 service_time: 777 s_time: 0 penalty: 0 agent_num: 39 done: False
______________________
id: 50 reward: -0.005791505791505791 service_time: 450 s_time: 12 penalty: 0 agent_num: 37 done: False
______________________
id: 42 reward: -0.010258358662613981 service_time: 385 s_time: 27 penalty: 0 agent_num: 47 done: False
______________________
Step:  3024
Pretraining Loss:  tensor(0.0460, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.0 service_time: 320 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 54 reward: 0.0027472527472527475 service_time: 431 s_time: -2 penalty: 0 agent_num: 13 done: False
______________________
id: 55 reward: -0.014285714285714285 service_time: 377 s_time: 12 penalty: 0 agent_num: 15 done: False
______________________
id: 51 reward: -0.2483766233766234 service_time: 4964 s_time: 153 penalty: 0 agent_num: 11 done: False
______________________
id: 53 reward: 0.002232142857142857 service_time: 5763 s_time: -2 penalty: 0 agent_num: 16 done: False
______________________
id: 52 reward: 0.0 service_time: 223 s_time: 0 penalty: 0 agent_num: 32 done: False
______________________
id: 40 reward: -0.013157894736842105 service_time: 209 s_time: 28 penalty: 0 agent_num: 38 done: False
______________________
id: 41 reward: -0.03125 service_time: 464 s_time: 56 penalty: 0 agent_num: 32 done: False
______________________
id: 47 reward: 0.002232142857142857 service_time: 2180 s_time: -2 penalty: 0 agent_num: 16 done: False
______________________
id: 44 reward: -0.35535714285714287 service_time: 5803 s_time: 199 penalty: 0 agent_num: 10 done: False
______________________
id: 48 reward: -0.018601190476190476 service_time: 806 s_time: 25 penalty: 0 agent_num: 24 done: False
______________________
id: 42 reward: 0.0 service_time: 385 s_time: 0 penalty: 0 agent_num: 47 done: False
______________________
id: 46 reward: -0.005494505494505495 service_time: 789 s_time: 12 penalty: 0 agent_num: 39 done: False
______________________
id: 50 reward: -0.006756756756756757 service_time: 464 s_time: 14 penalty: 0 agent_num: 37 done: False
______________________
id: 43 reward: -0.032467532467532464 service_time: 559 s_time: 80 penalty: 0 agent_num: 44 done: False
______________________
id: 45 reward: -0.02806122448979592 service_time: 876 s_time: 44 penalty: 0 agent_num: 28 done: False
______________________
Step:  3040
Pretraining Loss:  tensor(0.0695, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.0 service_time: 320 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 54 reward: -0.06318681318681318 service_time: 477 s_time: 46 penalty: 0 agent_num: 13 done: False
______________________
id: 51 reward: -0.20454545454545456 service_time: 5090 s_time: 126 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: -0.2785714285714286 service_time: 5959 s_time: 156 penalty: 0 agent_num: 10 done: False
______________________
id: 55 reward: -0.055952380952380955 service_time: 424 s_time: 47 penalty: 0 agent_num: 15 done: False
______________________
id: 52 reward: -0.030133928571428572 service_time: 277 s_time: 54 penalty: 0 agent_num: 32 done: False
______________________
id: 47 reward: -0.04352678571428571 service_time: 2219 s_time: 39 penalty: 0 agent_num: 16 done: False
______________________
id: 41 reward: 0.0011160714285714285 service_time: 462 s_time: -2 penalty: 0 agent_num: 32 done: False
______________________
id: 40 reward: -0.007988721804511278 service_time: 226 s_time: 17 penalty: 0 agent_num: 38 done: False
______________________
id: 45 reward: 0.021045918367346938 service_time: 843 s_time: -33 penalty: 0 agent_num: 28 done: False
______________________
id: 42 reward: -0.014817629179331307 service_time: 424 s_time: 39 penalty: 0 agent_num: 47 done: False
______________________
id: 48 reward: -0.023065476190476192 service_time: 837 s_time: 31 penalty: 0 agent_num: 24 done: False
______________________
id: 46 reward: -0.003205128205128205 service_time: 796 s_time: 7 penalty: 0 agent_num: 39 done: False
______________________
id: 43 reward: 0.0 service_time: 559 s_time: 0 penalty: 0 agent_num: 44 done: False
______________________
id: 50 reward: -0.019787644787644786 service_time: 505 s_time: 41 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: 20.0 service_time: 5763 s_time: 0 penalty: 0 agent_num: 16 done: True
______________________
Step:  3056
Pretraining Loss:  tensor(0.0529, device='cuda:0', grad_fn=<MeanBackward0>)
id: 44 reward: -0.4089285714285714 service_time: 6188 s_time: 229 penalty: 0 agent_num: 10 done: False
______________________
id: 53 reward: -0.004310344827586207 service_time: 7 s_time: 7 penalty: 0 agent_num: 29 done: False
______________________
id: 51 reward: -0.2597402597402597 service_time: 5250 s_time: 160 penalty: 0 agent_num: 11 done: False
______________________
id: 54 reward: 0.0027472527472527475 service_time: 475 s_time: -2 penalty: 0 agent_num: 13 done: False
______________________
id: 49 reward: 0.0 service_time: 320 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 55 reward: 0.0 service_time: 424 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 41 reward: -0.018415178571428572 service_time: 495 s_time: 33 penalty: 0 agent_num: 32 done: False
______________________
id: 47 reward: -0.012276785714285714 service_time: 2230 s_time: 11 penalty: 0 agent_num: 16 done: False
______________________
id: 52 reward: -0.016183035714285716 service_time: 306 s_time: 29 penalty: 0 agent_num: 32 done: False
______________________
id: 40 reward: -0.01738721804511278 service_time: 263 s_time: 37 penalty: 0 agent_num: 38 done: False
______________________
id: 48 reward: -0.013392857142857142 service_time: 855 s_time: 18 penalty: 0 agent_num: 24 done: False
______________________
id: 42 reward: -0.02507598784194529 service_time: 490 s_time: 66 penalty: 0 agent_num: 47 done: False
______________________
id: 45 reward: -0.051658163265306124 service_time: 924 s_time: 81 penalty: 0 agent_num: 28 done: False
______________________
id: 43 reward: -0.012987012987012988 service_time: 591 s_time: 32 penalty: 0 agent_num: 44 done: False
______________________
id: 46 reward: -0.025183150183150184 service_time: 851 s_time: 55 penalty: 0 agent_num: 39 done: False
______________________
id: 50 reward: 0.0019305019305019305 service_time: 501 s_time: -4 penalty: 0 agent_num: 37 done: False
______________________
Step:  3072
Pretraining Loss:  tensor(0.0565, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.025974025974025976 service_time: 336 s_time: 16 penalty: 0 agent_num: 11 done: False
______________________
id: 54 reward: -0.034340659340659344 service_time: 500 s_time: 25 penalty: 0 agent_num: 13 done: False
______________________
id: 55 reward: 0.02142857142857143 service_time: 406 s_time: -18 penalty: 0 agent_num: 15 done: False
______________________
id: 44 reward: -0.2875 service_time: 6349 s_time: 161 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: -0.31655844155844154 service_time: 5445 s_time: 195 penalty: 0 agent_num: 11 done: False
______________________
id: 53 reward: -0.0166256157635468 service_time: 34 s_time: 27 penalty: 0 agent_num: 29 done: False
______________________
id: 41 reward: -0.016183035714285716 service_time: 524 s_time: 29 penalty: 0 agent_num: 32 done: False
______________________
id: 47 reward: -0.0234375 service_time: 2251 s_time: 21 penalty: 0 agent_num: 16 done: False
______________________
id: 52 reward: -0.016183035714285716 service_time: 335 s_time: 29 penalty: 0 agent_num: 32 done: False
______________________
id: 45 reward: 0.001913265306122449 service_time: 921 s_time: -3 penalty: 0 agent_num: 28 done: False
______________________
id: 50 reward: -0.013996138996138996 service_time: 530 s_time: 29 penalty: 0 agent_num: 37 done: False
______________________
id: 40 reward: -0.014097744360902255 service_time: 293 s_time: 30 penalty: 0 agent_num: 38 done: False
______________________
id: 42 reward: -0.00303951367781155 service_time: 498 s_time: 8 penalty: 0 agent_num: 47 done: False
______________________
id: 43 reward: 0.0 service_time: 591 s_time: 0 penalty: 0 agent_num: 44 done: False
______________________
id: 48 reward: -0.024553571428571428 service_time: 888 s_time: 33 penalty: 0 agent_num: 24 done: False
______________________
id: 46 reward: -0.0173992673992674 service_time: 889 s_time: 38 penalty: 0 agent_num: 39 done: False
______________________
Step:  3088
Pretraining Loss:  tensor(0.0470, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.13474025974025974 service_time: 419 s_time: 83 penalty: 0 agent_num: 11 done: False
______________________
id: 54 reward: -0.03708791208791209 service_time: 527 s_time: 27 penalty: 0 agent_num: 13 done: False
______________________
id: 55 reward: 0.0 service_time: 406 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 51 reward: -0.25 service_time: 5599 s_time: 154 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: -0.40535714285714286 service_time: 6576 s_time: 227 penalty: 0 agent_num: 10 done: False
______________________
id: 53 reward: -0.011699507389162561 service_time: 53 s_time: 19 penalty: 0 agent_num: 29 done: False
______________________
id: 40 reward: -0.005639097744360902 service_time: 305 s_time: 12 penalty: 0 agent_num: 38 done: False
______________________
id: 45 reward: -0.01403061224489796 service_time: 943 s_time: 22 penalty: 0 agent_num: 28 done: False
______________________
id: 52 reward: 0.0 service_time: 335 s_time: 0 penalty: 0 agent_num: 32 done: False
______________________
id: 47 reward: 0.0 service_time: 2251 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 41 reward: -0.018973214285714284 service_time: 558 s_time: 34 penalty: 0 agent_num: 32 done: False
______________________
id: 42 reward: 0.0 service_time: 498 s_time: 0 penalty: 0 agent_num: 47 done: False
______________________
id: 46 reward: -0.01282051282051282 service_time: 917 s_time: 28 penalty: 0 agent_num: 39 done: False
______________________
id: 48 reward: -0.028273809523809524 service_time: 926 s_time: 38 penalty: 0 agent_num: 24 done: False
______________________
id: 43 reward: -0.006087662337662338 service_time: 606 s_time: 15 penalty: 0 agent_num: 44 done: False
______________________
id: 50 reward: -0.020752895752895753 service_time: 573 s_time: 43 penalty: 0 agent_num: 37 done: False
______________________
Step:  3104
Pretraining Loss:  tensor(0.0506, device='cuda:0', grad_fn=<MeanBackward0>)
id: 54 reward: 0.0 service_time: 527 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 44 reward: -0.36964285714285716 service_time: 6783 s_time: 207 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: -0.2224025974025974 service_time: 5736 s_time: 137 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: -0.048701298701298704 service_time: 449 s_time: 30 penalty: 0 agent_num: 11 done: False
______________________
id: 55 reward: -0.07857142857142857 service_time: 472 s_time: 66 penalty: 0 agent_num: 15 done: False
______________________
id: 53 reward: -0.010467980295566502 service_time: 70 s_time: 17 penalty: 0 agent_num: 29 done: False
______________________
id: 47 reward: -0.05022321428571429 service_time: 2296 s_time: 45 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: -0.011278195488721804 service_time: 329 s_time: 24 penalty: 0 agent_num: 38 done: False
______________________
id: 52 reward: -0.01171875 service_time: 356 s_time: 21 penalty: 0 agent_num: 32 done: False
______________________
id: 41 reward: -0.010044642857142858 service_time: 576 s_time: 18 penalty: 0 agent_num: 32 done: False
______________________
id: 48 reward: -0.026785714285714284 service_time: 962 s_time: 36 penalty: 0 agent_num: 24 done: False
______________________
id: 42 reward: -0.02127659574468085 service_time: 554 s_time: 56 penalty: 0 agent_num: 47 done: False
______________________
id: 50 reward: -0.017857142857142856 service_time: 610 s_time: 37 penalty: 0 agent_num: 37 done: False
______________________
id: 46 reward: -0.01282051282051282 service_time: 945 s_time: 28 penalty: 0 agent_num: 39 done: False
______________________
id: 45 reward: -0.05803571428571429 service_time: 1034 s_time: 91 penalty: 0 agent_num: 28 done: False
______________________
id: 43 reward: -0.025974025974025976 service_time: 670 s_time: 64 penalty: 0 agent_num: 44 done: False
______________________
Step:  3120
Pretraining Loss:  tensor(0.0552, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.11201298701298701 service_time: 518 s_time: 69 penalty: 0 agent_num: 11 done: False
______________________
id: 51 reward: -0.3555194805194805 service_time: 5955 s_time: 219 penalty: 0 agent_num: 11 done: False
______________________
id: 53 reward: 0.0 service_time: 70 s_time: 0 penalty: 0 agent_num: 29 done: False
______________________
id: 54 reward: -0.03708791208791209 service_time: 554 s_time: 27 penalty: 0 agent_num: 13 done: False
______________________
id: 44 reward: -0.38035714285714284 service_time: 6996 s_time: 213 penalty: 0 agent_num: 10 done: False
______________________
id: 47 reward: 0.0 service_time: 2296 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: -0.013157894736842105 service_time: 357 s_time: 28 penalty: 0 agent_num: 38 done: False
______________________
id: 55 reward: 0.0 service_time: 472 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 52 reward: -0.028459821428571428 service_time: 407 s_time: 51 penalty: 0 agent_num: 32 done: False
______________________
id: 42 reward: 0.0 service_time: 554 s_time: 0 penalty: 0 agent_num: 47 done: False
______________________
id: 41 reward: -0.015066964285714286 service_time: 603 s_time: 27 penalty: 0 agent_num: 32 done: False
______________________
id: 45 reward: -0.022321428571428572 service_time: 1069 s_time: 35 penalty: 0 agent_num: 28 done: False
______________________
id: 48 reward: -0.023809523809523808 service_time: 994 s_time: 32 penalty: 0 agent_num: 24 done: False
______________________
id: 50 reward: -0.008204633204633204 service_time: 627 s_time: 17 penalty: 0 agent_num: 37 done: False
______________________
id: 46 reward: -0.011446886446886446 service_time: 970 s_time: 25 penalty: 0 agent_num: 39 done: False
______________________
id: 43 reward: -0.011363636363636364 service_time: 698 s_time: 28 penalty: 0 agent_num: 44 done: False
______________________
Step:  3136
Pretraining Loss:  tensor(0.0572, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.017857142857142856 service_time: 529 s_time: 11 penalty: 0 agent_num: 11 done: False
______________________
id: 54 reward: 0.0 service_time: 554 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 51 reward: -0.349025974025974 service_time: 6170 s_time: 215 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: -0.38571428571428573 service_time: 7212 s_time: 216 penalty: 0 agent_num: 10 done: False
______________________
id: 55 reward: 0.0 service_time: 472 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 47 reward: -0.029017857142857144 service_time: 2322 s_time: 26 penalty: 0 agent_num: 16 done: False
______________________
id: 48 reward: -0.01636904761904762 service_time: 1016 s_time: 22 penalty: 0 agent_num: 24 done: False
______________________
id: 40 reward: 0.0 service_time: 357 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 52 reward: 0.002232142857142857 service_time: 403 s_time: -4 penalty: 0 agent_num: 32 done: False
______________________
id: 41 reward: -0.018973214285714284 service_time: 637 s_time: 34 penalty: 0 agent_num: 32 done: False
______________________
id: 53 reward: -0.04125615763546798 service_time: 137 s_time: 67 penalty: 0 agent_num: 29 done: False
______________________
id: 42 reward: -0.003799392097264438 service_time: 564 s_time: 10 penalty: 0 agent_num: 47 done: False
______________________
id: 46 reward: -0.018315018315018316 service_time: 1010 s_time: 40 penalty: 0 agent_num: 39 done: False
______________________
id: 43 reward: 0.0008116883116883117 service_time: 696 s_time: -2 penalty: 0 agent_num: 44 done: False
______________________
id: 50 reward: 0.0009652509652509653 service_time: 625 s_time: -2 penalty: 0 agent_num: 37 done: False
______________________
id: 45 reward: -0.03380102040816327 service_time: 1122 s_time: 53 penalty: 0 agent_num: 28 done: False
______________________
Step:  3152
Pretraining Loss:  tensor(0.0738, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.12987012987012986 service_time: 609 s_time: 80 penalty: 0 agent_num: 11 done: False
______________________
id: 54 reward: -0.04532967032967033 service_time: 587 s_time: 33 penalty: 0 agent_num: 13 done: False
______________________
id: 51 reward: -0.40584415584415584 service_time: 6420 s_time: 250 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: -0.38035714285714284 service_time: 7425 s_time: 213 penalty: 0 agent_num: 10 done: False
______________________
id: 53 reward: 0.0 service_time: 137 s_time: 0 penalty: 0 agent_num: 29 done: False
______________________
id: 47 reward: -0.014508928571428572 service_time: 2335 s_time: 13 penalty: 0 agent_num: 16 done: False
______________________
id: 55 reward: 0.0 service_time: 472 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 40 reward: -0.010338345864661654 service_time: 379 s_time: 22 penalty: 0 agent_num: 38 done: False
______________________
id: 41 reward: -0.012834821428571428 service_time: 660 s_time: 23 penalty: 0 agent_num: 32 done: False
______________________
id: 42 reward: -0.00911854103343465 service_time: 588 s_time: 24 penalty: 0 agent_num: 47 done: False
______________________
id: 48 reward: -0.026785714285714284 service_time: 1052 s_time: 36 penalty: 0 agent_num: 24 done: False
______________________
id: 52 reward: -0.017299107142857144 service_time: 434 s_time: 31 penalty: 0 agent_num: 32 done: False
______________________
id: 50 reward: -0.012065637065637066 service_time: 650 s_time: 25 penalty: 0 agent_num: 37 done: False
______________________
id: 43 reward: -0.007711038961038961 service_time: 715 s_time: 19 penalty: 0 agent_num: 44 done: False
______________________
id: 45 reward: -0.02614795918367347 service_time: 1163 s_time: 41 penalty: 0 agent_num: 28 done: False
______________________
id: 46 reward: -0.003663003663003663 service_time: 1018 s_time: 8 penalty: 0 agent_num: 39 done: False
______________________
Step:  3168
Pretraining Loss:  tensor(0.0659, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.04220779220779221 service_time: 635 s_time: 26 penalty: 0 agent_num: 11 done: False
______________________
id: 54 reward: -0.046703296703296704 service_time: 621 s_time: 34 penalty: 0 agent_num: 13 done: False
______________________
id: 44 reward: -0.3607142857142857 service_time: 7627 s_time: 202 penalty: 0 agent_num: 10 done: False
______________________
id: 55 reward: 0.0 service_time: 472 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 47 reward: -0.0234375 service_time: 2356 s_time: 21 penalty: 0 agent_num: 16 done: False
______________________
id: 52 reward: -0.005022321428571429 service_time: 443 s_time: 9 penalty: 0 agent_num: 32 done: False
______________________
id: 51 reward: -0.30844155844155846 service_time: 6610 s_time: 190 penalty: 0 agent_num: 11 done: False
______________________
id: 41 reward: -0.020089285714285716 service_time: 696 s_time: 36 penalty: 0 agent_num: 32 done: False
______________________
id: 48 reward: 0.000744047619047619 service_time: 1051 s_time: -1 penalty: 0 agent_num: 24 done: False
______________________
id: 40 reward: 0.0 service_time: 379 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 53 reward: -0.03633004926108374 service_time: 196 s_time: 59 penalty: 0 agent_num: 29 done: False
______________________
id: 45 reward: 0.01721938775510204 service_time: 1136 s_time: -27 penalty: 0 agent_num: 28 done: False
______________________
id: 43 reward: 0.0 service_time: 715 s_time: 0 penalty: 0 agent_num: 44 done: False
______________________
id: 42 reward: -0.022036474164133738 service_time: 646 s_time: 58 penalty: 0 agent_num: 47 done: False
______________________
id: 46 reward: 0.0009157509157509158 service_time: 1016 s_time: -2 penalty: 0 agent_num: 39 done: False
______________________
id: 50 reward: -0.01447876447876448 service_time: 680 s_time: 30 penalty: 0 agent_num: 37 done: False
______________________
------------------------------------
| time/                 |          |
|    fps                | 8        |
|    iterations         | 200      |
|    time_elapsed       | 372      |
|    total_timesteps    | 3200     |
| train/                |          |
|    entropy_loss       | 0.0581   |
|    explained_variance | -4.91    |
|    learning_rate      | 1e-05    |
|    n_updates          | 199      |
|    policy_loss        | 0.0659   |
|    value_loss         | 0.127    |
------------------------------------
Step:  3184
Pretraining Loss:  tensor(0.0647, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.0016233766233766235 service_time: 634 s_time: -1 penalty: 0 agent_num: 11 done: False
______________________
id: 54 reward: 0.009615384615384616 service_time: 614 s_time: -7 penalty: 0 agent_num: 13 done: False
______________________
id: 51 reward: -0.3587662337662338 service_time: 6831 s_time: 221 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: -0.41785714285714287 service_time: 7861 s_time: 234 penalty: 0 agent_num: 10 done: False
______________________
id: 53 reward: -0.0006157635467980296 service_time: 197 s_time: 1 penalty: 0 agent_num: 29 done: False
______________________
id: 55 reward: 0.01904761904761905 service_time: 456 s_time: -16 penalty: 0 agent_num: 15 done: False
______________________
id: 47 reward: 0.0 service_time: 2356 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: -0.007988721804511278 service_time: 396 s_time: 17 penalty: 0 agent_num: 38 done: False
______________________
id: 52 reward: -0.025669642857142856 service_time: 489 s_time: 46 penalty: 0 agent_num: 32 done: False
______________________
id: 41 reward: -0.010602678571428572 service_time: 715 s_time: 19 penalty: 0 agent_num: 32 done: False
______________________
id: 42 reward: -0.0121580547112462 service_time: 678 s_time: 32 penalty: 0 agent_num: 47 done: False
______________________
id: 45 reward: -0.0274234693877551 service_time: 1179 s_time: 43 penalty: 0 agent_num: 28 done: False
______________________
id: 43 reward: -0.009334415584415584 service_time: 738 s_time: 23 penalty: 0 agent_num: 44 done: False
______________________
id: 50 reward: 0.002413127413127413 service_time: 675 s_time: -5 penalty: 0 agent_num: 37 done: False
______________________
id: 46 reward: -0.030677655677655676 service_time: 1083 s_time: 67 penalty: 0 agent_num: 39 done: False
______________________
id: 48 reward: -0.023065476190476192 service_time: 1082 s_time: 31 penalty: 0 agent_num: 24 done: False
______________________
Step:  3200
Pretraining Loss:  tensor(0.0796, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.017857142857142856 service_time: 623 s_time: -11 penalty: 0 agent_num: 11 done: False
______________________
id: 54 reward: -0.08516483516483517 service_time: 676 s_time: 62 penalty: 0 agent_num: 13 done: False
______________________
id: 44 reward: -0.4303571428571429 service_time: 8102 s_time: 241 penalty: 0 agent_num: 10 done: False
______________________
id: 55 reward: -0.1 service_time: 540 s_time: 84 penalty: 0 agent_num: 15 done: False
______________________
id: 51 reward: -0.39285714285714285 service_time: 7073 s_time: 242 penalty: 0 agent_num: 11 done: False
______________________
id: 53 reward: 0.0012315270935960591 service_time: 195 s_time: -2 penalty: 0 agent_num: 29 done: False
______________________
id: 47 reward: -0.014508928571428572 service_time: 2369 s_time: 13 penalty: 0 agent_num: 16 done: False
______________________
id: 52 reward: 0.0 service_time: 489 s_time: 0 penalty: 0 agent_num: 32 done: False
______________________
id: 40 reward: -0.005169172932330827 service_time: 407 s_time: 11 penalty: 0 agent_num: 38 done: False
______________________
id: 41 reward: -0.012834821428571428 service_time: 738 s_time: 23 penalty: 0 agent_num: 32 done: False
______________________
id: 48 reward: -0.000744047619047619 service_time: 1083 s_time: 1 penalty: 0 agent_num: 24 done: False
______________________
id: 50 reward: -0.008204633204633204 service_time: 692 s_time: 17 penalty: 0 agent_num: 37 done: False
______________________
id: 43 reward: -0.01461038961038961 service_time: 774 s_time: 36 penalty: 0 agent_num: 44 done: False
______________________
id: 42 reward: -0.012917933130699088 service_time: 712 s_time: 34 penalty: 0 agent_num: 47 done: False
______________________
id: 45 reward: -0.021683673469387755 service_time: 1213 s_time: 34 penalty: 0 agent_num: 28 done: False
______________________
id: 46 reward: -0.012362637362637362 service_time: 1110 s_time: 27 penalty: 0 agent_num: 39 done: False
______________________
Step:  3216
Pretraining Loss:  tensor(0.0664, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.003246753246753247 service_time: 621 s_time: -2 penalty: 0 agent_num: 11 done: False
______________________
id: 55 reward: -0.025 service_time: 561 s_time: 21 penalty: 0 agent_num: 15 done: False
______________________
id: 54 reward: 0.0 service_time: 676 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 44 reward: -0.49464285714285716 service_time: 8379 s_time: 277 penalty: 0 agent_num: 10 done: False
______________________
id: 53 reward: -0.02832512315270936 service_time: 241 s_time: 46 penalty: 0 agent_num: 29 done: False
______________________
id: 52 reward: -0.011160714285714286 service_time: 509 s_time: 20 penalty: 0 agent_num: 32 done: False
______________________
id: 40 reward: 0.0 service_time: 407 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 51 reward: -0.3425324675324675 service_time: 7284 s_time: 211 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: 0.0 service_time: 2369 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 45 reward: -0.02614795918367347 service_time: 1254 s_time: 41 penalty: 0 agent_num: 28 done: False
______________________
id: 41 reward: -0.017299107142857144 service_time: 769 s_time: 31 penalty: 0 agent_num: 32 done: False
______________________
id: 43 reward: -0.008116883116883116 service_time: 794 s_time: 20 penalty: 0 agent_num: 44 done: False
______________________
id: 50 reward: -0.00916988416988417 service_time: 711 s_time: 19 penalty: 0 agent_num: 37 done: False
______________________
id: 42 reward: -0.00037993920972644377 service_time: 713 s_time: 1 penalty: 0 agent_num: 47 done: False
______________________
id: 46 reward: -0.011904761904761904 service_time: 1136 s_time: 26 penalty: 0 agent_num: 39 done: False
______________________
id: 48 reward: -0.027529761904761904 service_time: 1120 s_time: 37 penalty: 0 agent_num: 24 done: False
______________________
Step:  3232
Pretraining Loss:  tensor(0.0821, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.0 service_time: 621 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 55 reward: 0.002380952380952381 service_time: 559 s_time: -2 penalty: 0 agent_num: 15 done: False
______________________
id: 54 reward: -0.054945054945054944 service_time: 716 s_time: 40 penalty: 0 agent_num: 13 done: False
______________________
id: 53 reward: -0.024630541871921183 service_time: 281 s_time: 40 penalty: 0 agent_num: 29 done: False
______________________
id: 47 reward: -0.036830357142857144 service_time: 2402 s_time: 33 penalty: 0 agent_num: 16 done: False
______________________
id: 51 reward: -0.4301948051948052 service_time: 7549 s_time: 265 penalty: 0 agent_num: 11 done: False
______________________
id: 40 reward: -0.008928571428571428 service_time: 426 s_time: 19 penalty: 0 agent_num: 38 done: False
______________________
id: 41 reward: -0.005580357142857143 service_time: 779 s_time: 10 penalty: 0 agent_num: 32 done: False
______________________
id: 44 reward: 0.0 service_time: 8379 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 52 reward: -0.03627232142857143 service_time: 574 s_time: 65 penalty: 0 agent_num: 32 done: False
______________________
id: 43 reward: -0.00974025974025974 service_time: 818 s_time: 24 penalty: 0 agent_num: 44 done: False
______________________
id: 50 reward: -0.03137065637065637 service_time: 776 s_time: 65 penalty: 0 agent_num: 37 done: False
______________________
id: 45 reward: -0.015306122448979591 service_time: 1278 s_time: 24 penalty: 0 agent_num: 28 done: False
______________________
id: 48 reward: 0.01636904761904762 service_time: 1098 s_time: -22 penalty: 0 agent_num: 24 done: False
______________________
id: 42 reward: -0.0022796352583586625 service_time: 719 s_time: 6 penalty: 0 agent_num: 47 done: False
______________________
id: 46 reward: -0.01510989010989011 service_time: 1169 s_time: 33 penalty: 0 agent_num: 39 done: False
______________________
Step:  3248
Pretraining Loss:  tensor(0.0915, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.0 service_time: 621 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 54 reward: 0.0027472527472527475 service_time: 714 s_time: -2 penalty: 0 agent_num: 13 done: False
______________________
id: 55 reward: 0.03571428571428571 service_time: 529 s_time: -30 penalty: 0 agent_num: 15 done: False
______________________
id: 44 reward: 0.0 service_time: 8379 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 40 reward: -0.008458646616541353 service_time: 444 s_time: 18 penalty: 0 agent_num: 38 done: False
______________________
id: 41 reward: 0.0 service_time: 779 s_time: 0 penalty: 0 agent_num: 32 done: False
______________________
id: 47 reward: 0.0 service_time: 2402 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 45 reward: -0.019770408163265307 service_time: 1309 s_time: 31 penalty: 0 agent_num: 28 done: False
______________________
id: 42 reward: 0.0 service_time: 719 s_time: 0 penalty: 0 agent_num: 47 done: False
______________________
id: 52 reward: 0.0005580357142857143 service_time: 573 s_time: -1 penalty: 0 agent_num: 32 done: False
______________________
id: 53 reward: -0.02832512315270936 service_time: 327 s_time: 46 penalty: 0 agent_num: 29 done: False
______________________
id: 50 reward: -0.0014478764478764478 service_time: 779 s_time: 3 penalty: 0 agent_num: 37 done: False
______________________
id: 43 reward: -0.00487012987012987 service_time: 830 s_time: 12 penalty: 0 agent_num: 44 done: False
______________________
id: 48 reward: -0.09821428571428571 service_time: 1230 s_time: 132 penalty: 0 agent_num: 24 done: False
______________________
id: 46 reward: -0.016483516483516484 service_time: 1205 s_time: 36 penalty: 0 agent_num: 39 done: False
______________________
id: 51 reward: 20.0 service_time: 7549 s_time: 0 penalty: 0 agent_num: 11 done: True
______________________
Step:  3264
Pretraining Loss:  tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)
id: 51 reward: -0.027678571428571427 service_time: 31 s_time: 31 penalty: 0 agent_num: 20 done: False
______________________
id: 49 reward: 0.0 service_time: 621 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 55 reward: 0.0 service_time: 529 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 54 reward: 0.016483516483516484 service_time: 702 s_time: -12 penalty: 0 agent_num: 13 done: False
______________________
id: 53 reward: -0.029556650246305417 service_time: 375 s_time: 48 penalty: 0 agent_num: 29 done: False
______________________
id: 47 reward: -0.036830357142857144 service_time: 2435 s_time: 33 penalty: 0 agent_num: 16 done: False
______________________
id: 48 reward: 0.0 service_time: 1230 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 52 reward: -0.049107142857142856 service_time: 661 s_time: 88 penalty: 0 agent_num: 32 done: False
______________________
id: 45 reward: -0.009566326530612245 service_time: 1324 s_time: 15 penalty: 0 agent_num: 28 done: False
______________________
id: 50 reward: -0.0028957528957528956 service_time: 785 s_time: 6 penalty: 0 agent_num: 37 done: False
______________________
id: 41 reward: -0.024553571428571428 service_time: 823 s_time: 44 penalty: 0 agent_num: 32 done: False
______________________
id: 40 reward: -0.009398496240601503 service_time: 464 s_time: 20 penalty: 0 agent_num: 38 done: False
______________________
id: 43 reward: -0.013798701298701298 service_time: 864 s_time: 34 penalty: 0 agent_num: 44 done: False
______________________
id: 42 reward: -0.02127659574468085 service_time: 775 s_time: 56 penalty: 0 agent_num: 47 done: False
______________________
id: 46 reward: 0.0018315018315018315 service_time: 1201 s_time: -4 penalty: 0 agent_num: 39 done: False
______________________
id: 44 reward: 20.0 service_time: 8379 s_time: 0 penalty: 0 agent_num: 10 done: True
______________________
Step:  3280
Pretraining Loss:  tensor(0.0752, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.0 service_time: 621 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 51 reward: -0.0125 service_time: 45 s_time: 14 penalty: 0 agent_num: 20 done: False
______________________
id: 55 reward: -0.025 service_time: 550 s_time: 21 penalty: 0 agent_num: 15 done: False
______________________
id: 54 reward: -0.07142857142857142 service_time: 754 s_time: 52 penalty: 0 agent_num: 13 done: False
______________________
id: 53 reward: -0.0049261083743842365 service_time: 383 s_time: 8 penalty: 0 agent_num: 29 done: False
______________________
id: 44 reward: -0.008540372670807454 service_time: 22 s_time: 22 penalty: 0 agent_num: 46 done: False
______________________
id: 40 reward: -0.022556390977443608 service_time: 512 s_time: 48 penalty: 0 agent_num: 38 done: False
______________________
id: 50 reward: -0.010617760617760617 service_time: 807 s_time: 22 penalty: 0 agent_num: 37 done: False
______________________
id: 47 reward: 0.005580357142857143 service_time: 2430 s_time: -5 penalty: 0 agent_num: 16 done: False
______________________
id: 41 reward: -0.025111607142857144 service_time: 868 s_time: 45 penalty: 0 agent_num: 32 done: False
______________________
id: 45 reward: -0.03188775510204082 service_time: 1374 s_time: 50 penalty: 0 agent_num: 28 done: False
______________________
id: 43 reward: -0.002029220779220779 service_time: 869 s_time: 5 penalty: 0 agent_num: 44 done: False
______________________
id: 42 reward: -0.015197568389057751 service_time: 815 s_time: 40 penalty: 0 agent_num: 47 done: False
______________________
id: 52 reward: -0.015625 service_time: 689 s_time: 28 penalty: 0 agent_num: 32 done: False
______________________
id: 48 reward: -0.026785714285714284 service_time: 1266 s_time: 36 penalty: 0 agent_num: 24 done: False
______________________
id: 46 reward: -0.040293040293040296 service_time: 1289 s_time: 88 penalty: 0 agent_num: 39 done: False
______________________
Step:  3296
Pretraining Loss:  tensor(0.0310, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.040584415584415584 service_time: 646 s_time: 25 penalty: 0 agent_num: 11 done: False
______________________
id: 51 reward: -0.015178571428571428 service_time: 62 s_time: 17 penalty: 0 agent_num: 20 done: False
______________________
id: 54 reward: 0.013736263736263736 service_time: 744 s_time: -10 penalty: 0 agent_num: 13 done: False
______________________
id: 55 reward: 0.02023809523809524 service_time: 533 s_time: -17 penalty: 0 agent_num: 15 done: False
______________________
id: 47 reward: 0.0011160714285714285 service_time: 2429 s_time: -1 penalty: 0 agent_num: 16 done: False
______________________
id: 44 reward: -0.014751552795031056 service_time: 60 s_time: 38 penalty: 0 agent_num: 46 done: False
______________________
id: 50 reward: -0.016409266409266408 service_time: 841 s_time: 34 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: -0.017241379310344827 service_time: 411 s_time: 28 penalty: 0 agent_num: 29 done: False
______________________
id: 41 reward: -0.010044642857142858 service_time: 886 s_time: 18 penalty: 0 agent_num: 32 done: False
______________________
id: 45 reward: 0.0006377551020408163 service_time: 1373 s_time: -1 penalty: 0 agent_num: 28 done: False
______________________
id: 52 reward: -0.0078125 service_time: 703 s_time: 14 penalty: 0 agent_num: 32 done: False
______________________
id: 48 reward: 0.027529761904761904 service_time: 1229 s_time: -37 penalty: 0 agent_num: 24 done: False
______________________
id: 40 reward: -0.01268796992481203 service_time: 539 s_time: 27 penalty: 0 agent_num: 38 done: False
______________________
id: 43 reward: -0.012581168831168832 service_time: 900 s_time: 31 penalty: 0 agent_num: 44 done: False
______________________
id: 42 reward: 0.0 service_time: 815 s_time: 0 penalty: 0 agent_num: 47 done: False
______________________
id: 46 reward: -0.014194139194139194 service_time: 1320 s_time: 31 penalty: 0 agent_num: 39 done: False
______________________
Step:  3312
Pretraining Loss:  tensor(0.0296, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.0 service_time: 646 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 54 reward: 0.0027472527472527475 service_time: 742 s_time: -2 penalty: 0 agent_num: 13 done: False
______________________
id: 55 reward: -0.04880952380952381 service_time: 574 s_time: 41 penalty: 0 agent_num: 15 done: False
______________________
id: 51 reward: -0.017857142857142856 service_time: 82 s_time: 20 penalty: 0 agent_num: 20 done: False
______________________
id: 47 reward: -0.0390625 service_time: 2464 s_time: 35 penalty: 0 agent_num: 16 done: False
______________________
id: 53 reward: -0.014778325123152709 service_time: 435 s_time: 24 penalty: 0 agent_num: 29 done: False
______________________
id: 48 reward: 0.0 service_time: 1229 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 40 reward: -0.015037593984962405 service_time: 571 s_time: 32 penalty: 0 agent_num: 38 done: False
______________________
id: 50 reward: -0.010617760617760617 service_time: 863 s_time: 22 penalty: 0 agent_num: 37 done: False
______________________
id: 45 reward: -0.05038265306122449 service_time: 1452 s_time: 79 penalty: 0 agent_num: 28 done: False
______________________
id: 52 reward: -0.015625 service_time: 731 s_time: 28 penalty: 0 agent_num: 32 done: False
______________________
id: 44 reward: 0.0 service_time: 60 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 41 reward: -0.013950892857142858 service_time: 911 s_time: 25 penalty: 0 agent_num: 32 done: False
______________________
id: 42 reward: -0.015197568389057751 service_time: 855 s_time: 40 penalty: 0 agent_num: 47 done: False
______________________
id: 43 reward: -0.013798701298701298 service_time: 934 s_time: 34 penalty: 0 agent_num: 44 done: False
______________________
id: 46 reward: -0.0022893772893772895 service_time: 1325 s_time: 5 penalty: 0 agent_num: 39 done: False
______________________
Step:  3328
Pretraining Loss:  tensor(0.0314, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.0 service_time: 646 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 54 reward: -0.04395604395604396 service_time: 774 s_time: 32 penalty: 0 agent_num: 13 done: False
______________________
id: 51 reward: -0.024107142857142858 service_time: 109 s_time: 27 penalty: 0 agent_num: 20 done: False
______________________
id: 55 reward: 0.0 service_time: 574 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 53 reward: -0.023399014778325122 service_time: 473 s_time: 38 penalty: 0 agent_num: 29 done: False
______________________
id: 50 reward: -0.015926640926640926 service_time: 896 s_time: 33 penalty: 0 agent_num: 37 done: False
______________________
id: 40 reward: 0.0 service_time: 571 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 52 reward: -0.006696428571428571 service_time: 743 s_time: 12 penalty: 0 agent_num: 32 done: False
______________________
id: 44 reward: -0.017857142857142856 service_time: 106 s_time: 46 penalty: 0 agent_num: 46 done: False
______________________
id: 47 reward: 0.0 service_time: 2464 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 45 reward: -0.016581632653061226 service_time: 1478 s_time: 26 penalty: 0 agent_num: 28 done: False
______________________
id: 48 reward: 0.0 service_time: 1229 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 42 reward: -0.007978723404255319 service_time: 876 s_time: 21 penalty: 0 agent_num: 47 done: False
______________________
id: 43 reward: -0.004058441558441558 service_time: 944 s_time: 10 penalty: 0 agent_num: 44 done: False
______________________
id: 41 reward: -0.029575892857142856 service_time: 964 s_time: 53 penalty: 0 agent_num: 32 done: False
______________________
id: 46 reward: 0.0 service_time: 1325 s_time: 0 penalty: 0 agent_num: 39 done: False
______________________
Step:  3344
Pretraining Loss:  tensor(0.0294, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.0 service_time: 646 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 54 reward: 0.020604395604395604 service_time: 759 s_time: -15 penalty: 0 agent_num: 13 done: False
______________________
id: 51 reward: -0.0375 service_time: 151 s_time: 42 penalty: 0 agent_num: 20 done: False
______________________
id: 55 reward: 0.0 service_time: 574 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 47 reward: -0.012276785714285714 service_time: 2475 s_time: 11 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: -0.006109022556390977 service_time: 584 s_time: 13 penalty: 0 agent_num: 38 done: False
______________________
id: 53 reward: -0.020320197044334975 service_time: 506 s_time: 33 penalty: 0 agent_num: 29 done: False
______________________
id: 45 reward: 0.007653061224489796 service_time: 1466 s_time: -12 penalty: 0 agent_num: 28 done: False
______________________
id: 43 reward: -0.006493506493506494 service_time: 960 s_time: 16 penalty: 0 agent_num: 44 done: False
______________________
id: 48 reward: -0.03125 service_time: 1271 s_time: 42 penalty: 0 agent_num: 24 done: False
______________________
id: 44 reward: 0.0007763975155279503 service_time: 104 s_time: -2 penalty: 0 agent_num: 46 done: False
______________________
id: 41 reward: -0.01953125 service_time: 999 s_time: 35 penalty: 0 agent_num: 32 done: False
______________________
id: 52 reward: -0.0078125 service_time: 757 s_time: 14 penalty: 0 agent_num: 32 done: False
______________________
id: 50 reward: -0.014961389961389961 service_time: 927 s_time: 31 penalty: 0 agent_num: 37 done: False
______________________
id: 42 reward: -0.006458966565349544 service_time: 893 s_time: 17 penalty: 0 agent_num: 47 done: False
______________________
id: 46 reward: -0.023809523809523808 service_time: 1377 s_time: 52 penalty: 0 agent_num: 39 done: False
______________________
Step:  3360
Pretraining Loss:  tensor(0.0296, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.06655844155844155 service_time: 687 s_time: 41 penalty: 0 agent_num: 11 done: False
______________________
id: 54 reward: 0.0 service_time: 759 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 51 reward: -0.016964285714285713 service_time: 170 s_time: 19 penalty: 0 agent_num: 20 done: False
______________________
id: 55 reward: -0.03571428571428571 service_time: 604 s_time: 30 penalty: 0 agent_num: 15 done: False
______________________
id: 47 reward: -0.024553571428571428 service_time: 2497 s_time: 22 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: 0.0 service_time: 584 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 53 reward: 0.0 service_time: 506 s_time: 0 penalty: 0 agent_num: 29 done: False
______________________
id: 48 reward: -0.005952380952380952 service_time: 1279 s_time: 8 penalty: 0 agent_num: 24 done: False
______________________
id: 41 reward: -0.028459821428571428 service_time: 1050 s_time: 51 penalty: 0 agent_num: 32 done: False
______________________
id: 44 reward: -0.008540372670807454 service_time: 126 s_time: 22 penalty: 0 agent_num: 46 done: False
______________________
id: 45 reward: -0.01721938775510204 service_time: 1493 s_time: 27 penalty: 0 agent_num: 28 done: False
______________________
id: 52 reward: -0.02734375 service_time: 806 s_time: 49 penalty: 0 agent_num: 32 done: False
______________________
id: 50 reward: 0.00048262548262548264 service_time: 926 s_time: -1 penalty: 0 agent_num: 37 done: False
______________________
id: 42 reward: -0.0007598784194528875 service_time: 895 s_time: 2 penalty: 0 agent_num: 47 done: False
______________________
id: 43 reward: -0.010957792207792208 service_time: 987 s_time: 27 penalty: 0 agent_num: 44 done: False
______________________
id: 46 reward: -0.01098901098901099 service_time: 1401 s_time: 24 penalty: 0 agent_num: 39 done: False
______________________
Step:  3376
Pretraining Loss:  tensor(0.0283, device='cuda:0', grad_fn=<MeanBackward0>)
id: 54 reward: -0.038461538461538464 service_time: 787 s_time: 28 penalty: 0 agent_num: 13 done: False
______________________
id: 51 reward: 0.0 service_time: 170 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 49 reward: 0.0 service_time: 687 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 55 reward: 0.0380952380952381 service_time: 572 s_time: -32 penalty: 0 agent_num: 15 done: False
______________________
id: 53 reward: -0.02586206896551724 service_time: 548 s_time: 42 penalty: 0 agent_num: 29 done: False
______________________
id: 47 reward: 0.0 service_time: 2497 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 50 reward: -0.026061776061776062 service_time: 980 s_time: 54 penalty: 0 agent_num: 37 done: False
______________________
id: 48 reward: -0.01488095238095238 service_time: 1299 s_time: 20 penalty: 0 agent_num: 24 done: False
______________________
id: 52 reward: -0.012276785714285714 service_time: 828 s_time: 22 penalty: 0 agent_num: 32 done: False
______________________
id: 43 reward: 0.0 service_time: 987 s_time: 0 penalty: 0 agent_num: 44 done: False
______________________
id: 42 reward: -0.007218844984802432 service_time: 914 s_time: 19 penalty: 0 agent_num: 47 done: False
______________________
id: 41 reward: -0.020089285714285716 service_time: 1086 s_time: 36 penalty: 0 agent_num: 32 done: False
______________________
id: 45 reward: -0.02806122448979592 service_time: 1537 s_time: 44 penalty: 0 agent_num: 28 done: False
______________________
id: 40 reward: -0.007518796992481203 service_time: 600 s_time: 16 penalty: 0 agent_num: 38 done: False
______________________
id: 44 reward: -0.027950310559006212 service_time: 198 s_time: 72 penalty: 0 agent_num: 46 done: False
______________________
id: 46 reward: -0.020604395604395604 service_time: 1446 s_time: 45 penalty: 0 agent_num: 39 done: False
______________________
Step:  3392
Pretraining Loss:  tensor(0.0355, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.07305194805194805 service_time: 732 s_time: 45 penalty: 0 agent_num: 11 done: False
______________________
id: 54 reward: -0.04945054945054945 service_time: 823 s_time: 36 penalty: 0 agent_num: 13 done: False
______________________
id: 55 reward: 0.02023809523809524 service_time: 555 s_time: -17 penalty: 0 agent_num: 15 done: False
______________________
id: 51 reward: -0.01607142857142857 service_time: 188 s_time: 18 penalty: 0 agent_num: 20 done: False
______________________
id: 47 reward: -0.014508928571428572 service_time: 2510 s_time: 13 penalty: 0 agent_num: 16 done: False
______________________
id: 50 reward: 0.0 service_time: 980 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 48 reward: -0.020089285714285716 service_time: 1326 s_time: 27 penalty: 0 agent_num: 24 done: False
______________________
id: 40 reward: -0.010338345864661654 service_time: 622 s_time: 22 penalty: 0 agent_num: 38 done: False
______________________
id: 45 reward: -0.006377551020408163 service_time: 1547 s_time: 10 penalty: 0 agent_num: 28 done: False
______________________
id: 43 reward: -0.022321428571428572 service_time: 1042 s_time: 55 penalty: 0 agent_num: 44 done: False
______________________
id: 44 reward: -0.012422360248447204 service_time: 230 s_time: 32 penalty: 0 agent_num: 46 done: False
______________________
id: 52 reward: -0.009486607142857142 service_time: 845 s_time: 17 penalty: 0 agent_num: 32 done: False
______________________
id: 42 reward: -0.02811550151975684 service_time: 988 s_time: 74 penalty: 0 agent_num: 47 done: False
______________________
id: 53 reward: -0.020935960591133004 service_time: 582 s_time: 34 penalty: 0 agent_num: 29 done: False
______________________
id: 41 reward: -0.0033482142857142855 service_time: 1092 s_time: 6 penalty: 0 agent_num: 32 done: False
______________________
id: 46 reward: 0.0 service_time: 1446 s_time: 0 penalty: 0 agent_num: 39 done: False
______________________
Step:  3408
Pretraining Loss:  tensor(0.0367, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.14772727272727273 service_time: 823 s_time: 91 penalty: 0 agent_num: 11 done: False
______________________
id: 55 reward: -0.036904761904761905 service_time: 586 s_time: 31 penalty: 0 agent_num: 15 done: False
______________________
id: 54 reward: -0.1565934065934066 service_time: 937 s_time: 114 penalty: 0 agent_num: 13 done: False
______________________
id: 51 reward: -0.04642857142857143 service_time: 240 s_time: 52 penalty: 0 agent_num: 20 done: False
______________________
id: 48 reward: -0.050595238095238096 service_time: 1394 s_time: 68 penalty: 0 agent_num: 24 done: False
______________________
id: 47 reward: -0.044642857142857144 service_time: 2550 s_time: 40 penalty: 0 agent_num: 16 done: False
______________________
id: 50 reward: -0.004343629343629344 service_time: 989 s_time: 9 penalty: 0 agent_num: 37 done: False
______________________
id: 40 reward: -0.009398496240601503 service_time: 642 s_time: 20 penalty: 0 agent_num: 38 done: False
______________________
id: 45 reward: -0.01403061224489796 service_time: 1569 s_time: 22 penalty: 0 agent_num: 28 done: False
______________________
id: 43 reward: -0.00974025974025974 service_time: 1066 s_time: 24 penalty: 0 agent_num: 44 done: False
______________________
id: 53 reward: -0.017241379310344827 service_time: 610 s_time: 28 penalty: 0 agent_num: 29 done: False
______________________
id: 42 reward: -0.00911854103343465 service_time: 1012 s_time: 24 penalty: 0 agent_num: 47 done: False
______________________
id: 41 reward: -0.022321428571428572 service_time: 1132 s_time: 40 penalty: 0 agent_num: 32 done: False
______________________
id: 52 reward: -0.022321428571428572 service_time: 885 s_time: 40 penalty: 0 agent_num: 32 done: False
______________________
id: 44 reward: -0.01203416149068323 service_time: 261 s_time: 31 penalty: 0 agent_num: 46 done: False
______________________
id: 46 reward: -0.006868131868131868 service_time: 1461 s_time: 15 penalty: 0 agent_num: 39 done: False
______________________
Step:  3424
Pretraining Loss:  tensor(0.0398, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.0 service_time: 823 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 55 reward: -0.06904761904761905 service_time: 644 s_time: 58 penalty: 0 agent_num: 15 done: False
______________________
id: 54 reward: -0.04807692307692308 service_time: 972 s_time: 35 penalty: 0 agent_num: 13 done: False
______________________
id: 48 reward: 0.022321428571428572 service_time: 1364 s_time: -30 penalty: 0 agent_num: 24 done: False
______________________
id: 51 reward: -0.01875 service_time: 261 s_time: 21 penalty: 0 agent_num: 20 done: False
______________________
id: 47 reward: 0.0 service_time: 2550 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 45 reward: -0.01403061224489796 service_time: 1591 s_time: 22 penalty: 0 agent_num: 28 done: False
______________________
id: 40 reward: 0.0 service_time: 642 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 50 reward: -0.018822393822393823 service_time: 1028 s_time: 39 penalty: 0 agent_num: 37 done: False
______________________
id: 52 reward: -0.017857142857142856 service_time: 917 s_time: 32 penalty: 0 agent_num: 32 done: False
______________________
id: 43 reward: -0.008116883116883116 service_time: 1086 s_time: 20 penalty: 0 agent_num: 44 done: False
______________________
id: 44 reward: 0.0 service_time: 261 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 42 reward: -0.008738601823708206 service_time: 1035 s_time: 23 penalty: 0 agent_num: 47 done: False
______________________
id: 53 reward: -0.023399014778325122 service_time: 648 s_time: 38 penalty: 0 agent_num: 29 done: False
______________________
id: 41 reward: -0.0234375 service_time: 1174 s_time: 42 penalty: 0 agent_num: 32 done: False
______________________
id: 46 reward: -0.022893772893772892 service_time: 1511 s_time: 50 penalty: 0 agent_num: 39 done: False
______________________
Step:  3440
Pretraining Loss:  tensor(0.0444, device='cuda:0', grad_fn=<MeanBackward0>)
id: 54 reward: 0.04807692307692308 service_time: 937 s_time: -35 penalty: 0 agent_num: 13 done: False
______________________
id: 55 reward: 0.0 service_time: 644 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 49 reward: -0.03409090909090909 service_time: 844 s_time: 21 penalty: 0 agent_num: 11 done: False
______________________
id: 48 reward: 0.001488095238095238 service_time: 1362 s_time: -2 penalty: 0 agent_num: 24 done: False
______________________
id: 47 reward: 0.0 service_time: 2550 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: 0.0 service_time: 642 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 51 reward: 0.0 service_time: 261 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 45 reward: 0.0031887755102040817 service_time: 1586 s_time: -5 penalty: 0 agent_num: 28 done: False
______________________
id: 50 reward: -0.02413127413127413 service_time: 1078 s_time: 50 penalty: 0 agent_num: 37 done: False
______________________
id: 43 reward: 0.002029220779220779 service_time: 1081 s_time: -5 penalty: 0 agent_num: 44 done: False
______________________
id: 53 reward: -0.011699507389162561 service_time: 667 s_time: 19 penalty: 0 agent_num: 29 done: False
______________________
id: 41 reward: 0.0027901785714285715 service_time: 1169 s_time: -5 penalty: 0 agent_num: 32 done: False
______________________
id: 44 reward: -0.020186335403726708 service_time: 313 s_time: 52 penalty: 0 agent_num: 46 done: False
______________________
id: 42 reward: 0.004559270516717325 service_time: 1023 s_time: -12 penalty: 0 agent_num: 47 done: False
______________________
id: 52 reward: -0.014508928571428572 service_time: 943 s_time: 26 penalty: 0 agent_num: 32 done: False
______________________
id: 46 reward: 0.004578754578754579 service_time: 1501 s_time: -10 penalty: 0 agent_num: 39 done: False
______________________
Step:  3456
Pretraining Loss:  tensor(0.0345, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.04220779220779221 service_time: 870 s_time: 26 penalty: 0 agent_num: 11 done: False
______________________
id: 55 reward: -0.04047619047619048 service_time: 678 s_time: 34 penalty: 0 agent_num: 15 done: False
______________________
id: 54 reward: 0.0 service_time: 937 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 48 reward: -0.046130952380952384 service_time: 1424 s_time: 62 penalty: 0 agent_num: 24 done: False
______________________
id: 51 reward: -0.0125 service_time: 275 s_time: 14 penalty: 0 agent_num: 20 done: False
______________________
id: 40 reward: -0.015977443609022556 service_time: 676 s_time: 34 penalty: 0 agent_num: 38 done: False
______________________
id: 50 reward: -0.016409266409266408 service_time: 1112 s_time: 34 penalty: 0 agent_num: 37 done: False
______________________
id: 47 reward: -0.04241071428571429 service_time: 2588 s_time: 38 penalty: 0 agent_num: 16 done: False
______________________
id: 53 reward: -0.022167487684729065 service_time: 703 s_time: 36 penalty: 0 agent_num: 29 done: False
______________________
id: 44 reward: -0.013198757763975156 service_time: 347 s_time: 34 penalty: 0 agent_num: 46 done: False
______________________
id: 41 reward: -0.026227678571428572 service_time: 1216 s_time: 47 penalty: 0 agent_num: 32 done: False
______________________
id: 52 reward: 0.0011160714285714285 service_time: 941 s_time: -2 penalty: 0 agent_num: 32 done: False
______________________
id: 45 reward: -0.05803571428571429 service_time: 1677 s_time: 91 penalty: 0 agent_num: 28 done: False
______________________
id: 42 reward: -0.010258358662613981 service_time: 1050 s_time: 27 penalty: 0 agent_num: 47 done: False
______________________
id: 43 reward: -0.015827922077922076 service_time: 1120 s_time: 39 penalty: 0 agent_num: 44 done: False
______________________
id: 46 reward: -0.030677655677655676 service_time: 1568 s_time: 67 penalty: 0 agent_num: 39 done: False
______________________
Step:  3472
Pretraining Loss:  tensor(0.0421, device='cuda:0', grad_fn=<MeanBackward0>)
id: 54 reward: 0.0 service_time: 937 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 55 reward: -0.04880952380952381 service_time: 719 s_time: 41 penalty: 0 agent_num: 15 done: False
______________________
id: 49 reward: -0.06493506493506493 service_time: 910 s_time: 40 penalty: 0 agent_num: 11 done: False
______________________
id: 51 reward: -0.020535714285714286 service_time: 298 s_time: 23 penalty: 0 agent_num: 20 done: False
______________________
id: 47 reward: 0.0 service_time: 2588 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 48 reward: -0.009672619047619048 service_time: 1437 s_time: 13 penalty: 0 agent_num: 24 done: False
______________________
id: 40 reward: -0.011748120300751879 service_time: 701 s_time: 25 penalty: 0 agent_num: 38 done: False
______________________
id: 52 reward: -0.015625 service_time: 969 s_time: 28 penalty: 0 agent_num: 32 done: False
______________________
id: 53 reward: -0.009236453201970444 service_time: 718 s_time: 15 penalty: 0 agent_num: 29 done: False
______________________
id: 42 reward: -0.018617021276595744 service_time: 1099 s_time: 49 penalty: 0 agent_num: 47 done: False
______________________
id: 43 reward: -0.008928571428571428 service_time: 1142 s_time: 22 penalty: 0 agent_num: 44 done: False
______________________
id: 44 reward: -0.008152173913043478 service_time: 368 s_time: 21 penalty: 0 agent_num: 46 done: False
______________________
id: 41 reward: -0.01953125 service_time: 1251 s_time: 35 penalty: 0 agent_num: 32 done: False
______________________
id: 50 reward: -0.008687258687258687 service_time: 1130 s_time: 18 penalty: 0 agent_num: 37 done: False
______________________
id: 46 reward: -0.015567765567765568 service_time: 1602 s_time: 34 penalty: 0 agent_num: 39 done: False
______________________
id: 45 reward: -0.039540816326530615 service_time: 1739 s_time: 62 penalty: 0 agent_num: 28 done: False
______________________
Step:  3488
Pretraining Loss:  tensor(0.0341, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.0 service_time: 910 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 55 reward: -0.03214285714285714 service_time: 746 s_time: 27 penalty: 0 agent_num: 15 done: False
______________________
id: 54 reward: 0.0 service_time: 937 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 51 reward: 0.0017857142857142857 service_time: 296 s_time: -2 penalty: 0 agent_num: 20 done: False
______________________
id: 48 reward: -0.06919642857142858 service_time: 1530 s_time: 93 penalty: 0 agent_num: 24 done: False
______________________
id: 40 reward: -0.011278195488721804 service_time: 725 s_time: 24 penalty: 0 agent_num: 38 done: False
______________________
id: 47 reward: -0.0234375 service_time: 2609 s_time: 21 penalty: 0 agent_num: 16 done: False
______________________
id: 44 reward: -0.01358695652173913 service_time: 403 s_time: 35 penalty: 0 agent_num: 46 done: False
______________________
id: 45 reward: 0.017857142857142856 service_time: 1711 s_time: -28 penalty: 0 agent_num: 28 done: False
______________________
id: 42 reward: -0.016717325227963525 service_time: 1143 s_time: 44 penalty: 0 agent_num: 47 done: False
______________________
id: 41 reward: -0.013950892857142858 service_time: 1276 s_time: 25 penalty: 0 agent_num: 32 done: False
______________________
id: 53 reward: -0.019088669950738917 service_time: 749 s_time: 31 penalty: 0 agent_num: 29 done: False
______________________
id: 43 reward: 0.0008116883116883117 service_time: 1140 s_time: -2 penalty: 0 agent_num: 44 done: False
______________________
id: 52 reward: -0.0234375 service_time: 1011 s_time: 42 penalty: 0 agent_num: 32 done: False
______________________
id: 50 reward: -0.017374517374517374 service_time: 1166 s_time: 36 penalty: 0 agent_num: 37 done: False
______________________
id: 46 reward: -0.011904761904761904 service_time: 1628 s_time: 26 penalty: 0 agent_num: 39 done: False
______________________
Step:  3504
Pretraining Loss:  tensor(0.0367, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.0 service_time: 910 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 55 reward: -0.06666666666666667 service_time: 802 s_time: 56 penalty: 0 agent_num: 15 done: False
______________________
id: 51 reward: -0.027678571428571427 service_time: 327 s_time: 31 penalty: 0 agent_num: 20 done: False
______________________
id: 54 reward: -0.04945054945054945 service_time: 973 s_time: 36 penalty: 0 agent_num: 13 done: False
______________________
id: 48 reward: 0.01488095238095238 service_time: 1510 s_time: -20 penalty: 0 agent_num: 24 done: False
______________________
id: 53 reward: -0.012315270935960592 service_time: 769 s_time: 20 penalty: 0 agent_num: 29 done: False
______________________
id: 40 reward: 0.0 service_time: 725 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 47 reward: 0.0 service_time: 2609 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 41 reward: -0.002232142857142857 service_time: 1280 s_time: 4 penalty: 0 agent_num: 32 done: False
______________________
id: 52 reward: 0.01171875 service_time: 990 s_time: -21 penalty: 0 agent_num: 32 done: False
______________________
id: 43 reward: -0.015016233766233766 service_time: 1177 s_time: 37 penalty: 0 agent_num: 44 done: False
______________________
id: 45 reward: 0.0012755102040816326 service_time: 1709 s_time: -2 penalty: 0 agent_num: 28 done: False
______________________
id: 50 reward: -0.013030888030888031 service_time: 1193 s_time: 27 penalty: 0 agent_num: 37 done: False
______________________
id: 46 reward: -0.016483516483516484 service_time: 1664 s_time: 36 penalty: 0 agent_num: 39 done: False
______________________
id: 44 reward: -0.009704968944099378 service_time: 428 s_time: 25 penalty: 0 agent_num: 46 done: False
______________________
id: 42 reward: -0.005319148936170213 service_time: 1157 s_time: 14 penalty: 0 agent_num: 47 done: False
______________________
Step:  3520
Pretraining Loss:  tensor(0.0337, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.0 service_time: 910 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 54 reward: -0.08241758241758242 service_time: 1033 s_time: 60 penalty: 0 agent_num: 13 done: False
______________________
id: 55 reward: -0.1357142857142857 service_time: 916 s_time: 114 penalty: 0 agent_num: 15 done: False
______________________
id: 51 reward: -0.019642857142857142 service_time: 349 s_time: 22 penalty: 0 agent_num: 20 done: False
______________________
id: 47 reward: -0.027901785714285716 service_time: 2634 s_time: 25 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: 0.0 service_time: 725 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 48 reward: 0.002976190476190476 service_time: 1506 s_time: -4 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: -0.002551020408163265 service_time: 1713 s_time: 4 penalty: 0 agent_num: 28 done: False
______________________
id: 53 reward: -0.004310344827586207 service_time: 776 s_time: 7 penalty: 0 agent_num: 29 done: False
______________________
id: 52 reward: -0.027901785714285716 service_time: 1040 s_time: 50 penalty: 0 agent_num: 32 done: False
______________________
id: 42 reward: -0.00303951367781155 service_time: 1165 s_time: 8 penalty: 0 agent_num: 47 done: False
______________________
id: 41 reward: -0.021763392857142856 service_time: 1319 s_time: 39 penalty: 0 agent_num: 32 done: False
______________________
id: 44 reward: 0.0 service_time: 428 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 43 reward: 0.0008116883116883117 service_time: 1175 s_time: -2 penalty: 0 agent_num: 44 done: False
______________________
id: 50 reward: -0.017374517374517374 service_time: 1229 s_time: 36 penalty: 0 agent_num: 37 done: False
______________________
id: 46 reward: -0.004120879120879121 service_time: 1673 s_time: 9 penalty: 0 agent_num: 39 done: False
______________________
Step:  3536
Pretraining Loss:  tensor(0.0361, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.048701298701298704 service_time: 940 s_time: 30 penalty: 0 agent_num: 11 done: False
______________________
id: 55 reward: 0.030952380952380953 service_time: 890 s_time: -26 penalty: 0 agent_num: 15 done: False
______________________
id: 54 reward: 0.028846153846153848 service_time: 1012 s_time: -21 penalty: 0 agent_num: 13 done: False
______________________
id: 51 reward: -0.013392857142857142 service_time: 364 s_time: 15 penalty: 0 agent_num: 20 done: False
______________________
id: 47 reward: -0.03459821428571429 service_time: 2665 s_time: 31 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: -0.008458646616541353 service_time: 743 s_time: 18 penalty: 0 agent_num: 38 done: False
______________________
id: 53 reward: -0.005541871921182266 service_time: 785 s_time: 9 penalty: 0 agent_num: 29 done: False
______________________
id: 48 reward: -0.046130952380952384 service_time: 1568 s_time: 62 penalty: 0 agent_num: 24 done: False
______________________
id: 41 reward: -0.007254464285714286 service_time: 1332 s_time: 13 penalty: 0 agent_num: 32 done: False
______________________
id: 43 reward: -0.024756493506493508 service_time: 1236 s_time: 61 penalty: 0 agent_num: 44 done: False
______________________
id: 52 reward: -0.013392857142857142 service_time: 1064 s_time: 24 penalty: 0 agent_num: 32 done: False
______________________
id: 50 reward: -0.007722007722007722 service_time: 1245 s_time: 16 penalty: 0 agent_num: 37 done: False
______________________
id: 46 reward: -0.004120879120879121 service_time: 1682 s_time: 9 penalty: 0 agent_num: 39 done: False
______________________
id: 44 reward: -0.024844720496894408 service_time: 492 s_time: 64 penalty: 0 agent_num: 46 done: False
______________________
id: 42 reward: 0.0 service_time: 1165 s_time: 0 penalty: 0 agent_num: 47 done: False
______________________
id: 45 reward: -0.058673469387755105 service_time: 1805 s_time: 92 penalty: 0 agent_num: 28 done: False
______________________
Step:  3552
Pretraining Loss:  tensor(0.0365, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.08603896103896104 service_time: 993 s_time: 53 penalty: 0 agent_num: 11 done: False
______________________
id: 51 reward: -0.03482142857142857 service_time: 403 s_time: 39 penalty: 0 agent_num: 20 done: False
______________________
id: 54 reward: 0.0013736263736263737 service_time: 1011 s_time: -1 penalty: 0 agent_num: 13 done: False
______________________
id: 55 reward: 0.05 service_time: 848 s_time: -42 penalty: 0 agent_num: 15 done: False
______________________
id: 47 reward: -0.024553571428571428 service_time: 2687 s_time: 22 penalty: 0 agent_num: 16 done: False
______________________
id: 45 reward: 0.024872448979591837 service_time: 1766 s_time: -39 penalty: 0 agent_num: 28 done: False
______________________
id: 41 reward: -0.012834821428571428 service_time: 1355 s_time: 23 penalty: 0 agent_num: 32 done: False
______________________
id: 53 reward: -0.020320197044334975 service_time: 818 s_time: 33 penalty: 0 agent_num: 29 done: False
______________________
id: 48 reward: -0.018601190476190476 service_time: 1593 s_time: 25 penalty: 0 agent_num: 24 done: False
______________________
id: 52 reward: -0.018415178571428572 service_time: 1097 s_time: 33 penalty: 0 agent_num: 32 done: False
______________________
id: 50 reward: -0.019787644787644786 service_time: 1286 s_time: 41 penalty: 0 agent_num: 37 done: False
______________________
id: 43 reward: 0.0008116883116883117 service_time: 1234 s_time: -2 penalty: 0 agent_num: 44 done: False
______________________
id: 42 reward: -0.012917933130699088 service_time: 1199 s_time: 34 penalty: 0 agent_num: 47 done: False
______________________
id: 44 reward: 0.0 service_time: 492 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 40 reward: -0.01926691729323308 service_time: 784 s_time: 41 penalty: 0 agent_num: 38 done: False
______________________
id: 46 reward: -0.012362637362637362 service_time: 1709 s_time: 27 penalty: 0 agent_num: 39 done: False
______________________
Step:  3568
Pretraining Loss:  tensor(0.0393, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.02922077922077922 service_time: 975 s_time: -18 penalty: 0 agent_num: 11 done: False
______________________
id: 55 reward: 0.0 service_time: 848 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 51 reward: 0.0 service_time: 403 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 54 reward: 0.0027472527472527475 service_time: 1009 s_time: -2 penalty: 0 agent_num: 13 done: False
______________________
id: 47 reward: -0.020089285714285716 service_time: 2705 s_time: 18 penalty: 0 agent_num: 16 done: False
______________________
id: 53 reward: -0.013546798029556651 service_time: 840 s_time: 22 penalty: 0 agent_num: 29 done: False
______________________
id: 48 reward: 0.0 service_time: 1593 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: -0.01211734693877551 service_time: 1785 s_time: 19 penalty: 0 agent_num: 28 done: False
______________________
id: 52 reward: -0.013950892857142858 service_time: 1122 s_time: 25 penalty: 0 agent_num: 32 done: False
______________________
id: 41 reward: -0.013392857142857142 service_time: 1379 s_time: 24 penalty: 0 agent_num: 32 done: False
______________________
id: 40 reward: 0.0 service_time: 784 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 43 reward: -0.021103896103896104 service_time: 1286 s_time: 52 penalty: 0 agent_num: 44 done: False
______________________
id: 50 reward: -0.015444015444015444 service_time: 1318 s_time: 32 penalty: 0 agent_num: 37 done: False
______________________
id: 46 reward: -0.009157509157509158 service_time: 1729 s_time: 20 penalty: 0 agent_num: 39 done: False
______________________
id: 42 reward: -0.007218844984802432 service_time: 1218 s_time: 19 penalty: 0 agent_num: 47 done: False
______________________
id: 44 reward: -0.029891304347826088 service_time: 569 s_time: 77 penalty: 0 agent_num: 46 done: False
______________________
Step:  3584
Pretraining Loss:  tensor(0.0495, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.00487012987012987 service_time: 972 s_time: -3 penalty: 0 agent_num: 11 done: False
______________________
id: 54 reward: -0.038461538461538464 service_time: 1037 s_time: 28 penalty: 0 agent_num: 13 done: False
______________________
id: 55 reward: -0.03214285714285714 service_time: 875 s_time: 27 penalty: 0 agent_num: 15 done: False
______________________
id: 47 reward: 0.0 service_time: 2705 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 48 reward: -0.03422619047619048 service_time: 1639 s_time: 46 penalty: 0 agent_num: 24 done: False
______________________
id: 53 reward: -0.011083743842364532 service_time: 858 s_time: 18 penalty: 0 agent_num: 29 done: False
______________________
id: 51 reward: -0.03214285714285714 service_time: 439 s_time: 36 penalty: 0 agent_num: 20 done: False
______________________
id: 41 reward: 0.0011160714285714285 service_time: 1377 s_time: -2 penalty: 0 agent_num: 32 done: False
______________________
id: 52 reward: 0.0 service_time: 1122 s_time: 0 penalty: 0 agent_num: 32 done: False
______________________
id: 43 reward: 0.0 service_time: 1286 s_time: 0 penalty: 0 agent_num: 44 done: False
______________________
id: 45 reward: -0.03188775510204082 service_time: 1835 s_time: 50 penalty: 0 agent_num: 28 done: False
______________________
id: 42 reward: -0.011398176291793313 service_time: 1248 s_time: 30 penalty: 0 agent_num: 47 done: False
______________________
id: 40 reward: -0.004699248120300752 service_time: 794 s_time: 10 penalty: 0 agent_num: 38 done: False
______________________
id: 50 reward: -0.019787644787644786 service_time: 1359 s_time: 41 penalty: 0 agent_num: 37 done: False
______________________
id: 46 reward: -0.004578754578754579 service_time: 1739 s_time: 10 penalty: 0 agent_num: 39 done: False
______________________
id: 44 reward: -0.004658385093167702 service_time: 581 s_time: 12 penalty: 0 agent_num: 46 done: False
______________________
Step:  3600
Pretraining Loss:  tensor(0.0509, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.0 service_time: 972 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 54 reward: 0.013736263736263736 service_time: 1027 s_time: -10 penalty: 0 agent_num: 13 done: False
______________________
id: 55 reward: 0.007142857142857143 service_time: 869 s_time: -6 penalty: 0 agent_num: 15 done: False
______________________
id: 51 reward: -0.013392857142857142 service_time: 454 s_time: 15 penalty: 0 agent_num: 20 done: False
______________________
id: 48 reward: -0.023065476190476192 service_time: 1670 s_time: 31 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: -0.0274234693877551 service_time: 1878 s_time: 43 penalty: 0 agent_num: 28 done: False
______________________
id: 53 reward: -0.017241379310344827 service_time: 886 s_time: 28 penalty: 0 agent_num: 29 done: False
______________________
id: 47 reward: -0.025669642857142856 service_time: 2728 s_time: 23 penalty: 0 agent_num: 16 done: False
______________________
id: 52 reward: -0.040736607142857144 service_time: 1195 s_time: 73 penalty: 0 agent_num: 32 done: False
______________________
id: 43 reward: -0.013798701298701298 service_time: 1320 s_time: 34 penalty: 0 agent_num: 44 done: False
______________________
id: 40 reward: -0.01738721804511278 service_time: 831 s_time: 37 penalty: 0 agent_num: 38 done: False
______________________
id: 41 reward: -0.014508928571428572 service_time: 1403 s_time: 26 penalty: 0 agent_num: 32 done: False
______________________
id: 42 reward: -0.011018237082066869 service_time: 1277 s_time: 29 penalty: 0 agent_num: 47 done: False
______________________
id: 44 reward: 0.0 service_time: 581 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 46 reward: -0.013278388278388278 service_time: 1768 s_time: 29 penalty: 0 agent_num: 39 done: False
______________________
id: 50 reward: -0.02364864864864865 service_time: 1408 s_time: 49 penalty: 0 agent_num: 37 done: False
______________________
Step:  3616
Pretraining Loss:  tensor(0.0491, device='cuda:0', grad_fn=<MeanBackward0>)
id: 54 reward: -0.1813186813186813 service_time: 1159 s_time: 132 penalty: 0 agent_num: 13 done: False
______________________
id: 49 reward: -0.048701298701298704 service_time: 1002 s_time: 30 penalty: 0 agent_num: 11 done: False
______________________
id: 55 reward: 0.0 service_time: 869 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 47 reward: -0.030133928571428572 service_time: 2755 s_time: 27 penalty: 0 agent_num: 16 done: False
______________________
id: 45 reward: -0.013392857142857142 service_time: 1899 s_time: 21 penalty: 0 agent_num: 28 done: False
______________________
id: 51 reward: 0.0 service_time: 454 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 48 reward: 0.002232142857142857 service_time: 1667 s_time: -3 penalty: 0 agent_num: 24 done: False
______________________
id: 52 reward: -0.021763392857142856 service_time: 1234 s_time: 39 penalty: 0 agent_num: 32 done: False
______________________
id: 44 reward: -0.017857142857142856 service_time: 627 s_time: 46 penalty: 0 agent_num: 46 done: False
______________________
id: 43 reward: 0.0 service_time: 1320 s_time: 0 penalty: 0 agent_num: 44 done: False
______________________
id: 53 reward: -0.033866995073891626 service_time: 941 s_time: 55 penalty: 0 agent_num: 29 done: False
______________________
id: 40 reward: -0.017857142857142856 service_time: 869 s_time: 38 penalty: 0 agent_num: 38 done: False
______________________
id: 46 reward: 0.0 service_time: 1768 s_time: 0 penalty: 0 agent_num: 39 done: False
______________________
id: 42 reward: -0.0056990881458966565 service_time: 1292 s_time: 15 penalty: 0 agent_num: 47 done: False
______________________
id: 41 reward: -0.03571428571428571 service_time: 1467 s_time: 64 penalty: 0 agent_num: 32 done: False
______________________
id: 50 reward: -0.008687258687258687 service_time: 1426 s_time: 18 penalty: 0 agent_num: 37 done: False
______________________
Step:  3632
Pretraining Loss:  tensor(0.0450, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.0 service_time: 1002 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 55 reward: -0.14642857142857144 service_time: 992 s_time: 123 penalty: 0 agent_num: 15 done: False
______________________
id: 51 reward: -0.03214285714285714 service_time: 490 s_time: 36 penalty: 0 agent_num: 20 done: False
______________________
id: 54 reward: 0.03983516483516483 service_time: 1130 s_time: -29 penalty: 0 agent_num: 13 done: False
______________________
id: 48 reward: -0.020833333333333332 service_time: 1695 s_time: 28 penalty: 0 agent_num: 24 done: False
______________________
id: 47 reward: 0.0 service_time: 2755 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 53 reward: -0.019704433497536946 service_time: 973 s_time: 32 penalty: 0 agent_num: 29 done: False
______________________
id: 45 reward: 0.0274234693877551 service_time: 1856 s_time: -43 penalty: 0 agent_num: 28 done: False
______________________
id: 43 reward: -0.007305194805194805 service_time: 1338 s_time: 18 penalty: 0 agent_num: 44 done: False
______________________
id: 52 reward: -0.012834821428571428 service_time: 1257 s_time: 23 penalty: 0 agent_num: 32 done: False
______________________
id: 46 reward: -0.005036630036630037 service_time: 1779 s_time: 11 penalty: 0 agent_num: 39 done: False
______________________
id: 40 reward: 0.0018796992481203006 service_time: 865 s_time: -4 penalty: 0 agent_num: 38 done: False
______________________
id: 42 reward: -0.010258358662613981 service_time: 1319 s_time: 27 penalty: 0 agent_num: 47 done: False
______________________
id: 41 reward: -0.013392857142857142 service_time: 1491 s_time: 24 penalty: 0 agent_num: 32 done: False
______________________
id: 50 reward: -0.0033783783783783786 service_time: 1433 s_time: 7 penalty: 0 agent_num: 37 done: False
______________________
id: 44 reward: -0.009704968944099378 service_time: 652 s_time: 25 penalty: 0 agent_num: 46 done: False
______________________
Step:  3648
Pretraining Loss:  tensor(0.0470, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.07467532467532467 service_time: 1048 s_time: 46 penalty: 0 agent_num: 11 done: False
______________________
id: 54 reward: -0.08241758241758242 service_time: 1190 s_time: 60 penalty: 0 agent_num: 13 done: False
______________________
id: 55 reward: 0.02857142857142857 service_time: 968 s_time: -24 penalty: 0 agent_num: 15 done: False
______________________
id: 47 reward: -0.03571428571428571 service_time: 2787 s_time: 32 penalty: 0 agent_num: 16 done: False
______________________
id: 51 reward: -0.027678571428571427 service_time: 521 s_time: 31 penalty: 0 agent_num: 20 done: False
______________________
id: 45 reward: -0.02423469387755102 service_time: 1894 s_time: 38 penalty: 0 agent_num: 28 done: False
______________________
id: 48 reward: -0.1056547619047619 service_time: 1837 s_time: 142 penalty: 0 agent_num: 24 done: False
______________________
id: 46 reward: -0.007326007326007326 service_time: 1795 s_time: 16 penalty: 0 agent_num: 39 done: False
______________________
id: 44 reward: -0.013198757763975156 service_time: 686 s_time: 34 penalty: 0 agent_num: 46 done: False
______________________
id: 43 reward: -0.024756493506493508 service_time: 1399 s_time: 61 penalty: 0 agent_num: 44 done: False
______________________
id: 40 reward: -0.010808270676691729 service_time: 888 s_time: 23 penalty: 0 agent_num: 38 done: False
______________________
id: 52 reward: -0.026227678571428572 service_time: 1304 s_time: 47 penalty: 0 agent_num: 32 done: False
______________________
id: 53 reward: -0.008620689655172414 service_time: 987 s_time: 14 penalty: 0 agent_num: 29 done: False
______________________
id: 41 reward: 0.0 service_time: 1491 s_time: 0 penalty: 0 agent_num: 32 done: False
______________________
id: 42 reward: 0.00037993920972644377 service_time: 1318 s_time: -1 penalty: 0 agent_num: 47 done: False
______________________
id: 50 reward: -0.01447876447876448 service_time: 1463 s_time: 30 penalty: 0 agent_num: 37 done: False
______________________
Step:  3664
Pretraining Loss:  tensor(0.0532, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.045454545454545456 service_time: 1020 s_time: -28 penalty: 0 agent_num: 11 done: False
______________________
id: 55 reward: 0.08095238095238096 service_time: 900 s_time: -68 penalty: 0 agent_num: 15 done: False
______________________
id: 54 reward: -0.09615384615384616 service_time: 1260 s_time: 70 penalty: 0 agent_num: 13 done: False
______________________
id: 51 reward: 0.0035714285714285713 service_time: 517 s_time: -4 penalty: 0 agent_num: 20 done: False
______________________
id: 47 reward: 0.0 service_time: 2787 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 45 reward: -0.039540816326530615 service_time: 1956 s_time: 62 penalty: 0 agent_num: 28 done: False
______________________
id: 53 reward: -0.01539408866995074 service_time: 1012 s_time: 25 penalty: 0 agent_num: 29 done: False
______________________
id: 52 reward: -0.013950892857142858 service_time: 1329 s_time: 25 penalty: 0 agent_num: 32 done: False
______________________
id: 46 reward: -0.01282051282051282 service_time: 1823 s_time: 28 penalty: 0 agent_num: 39 done: False
______________________
id: 43 reward: -0.012581168831168832 service_time: 1430 s_time: 31 penalty: 0 agent_num: 44 done: False
______________________
id: 48 reward: -0.034970238095238096 service_time: 1884 s_time: 47 penalty: 0 agent_num: 24 done: False
______________________
id: 40 reward: -0.022086466165413533 service_time: 935 s_time: 47 penalty: 0 agent_num: 38 done: False
______________________
id: 42 reward: -0.007218844984802432 service_time: 1337 s_time: 19 penalty: 0 agent_num: 47 done: False
______________________
id: 44 reward: -0.0038819875776397515 service_time: 696 s_time: 10 penalty: 0 agent_num: 46 done: False
______________________
id: 50 reward: 0.002413127413127413 service_time: 1458 s_time: -5 penalty: 0 agent_num: 37 done: False
______________________
id: 41 reward: -0.03627232142857143 service_time: 1556 s_time: 65 penalty: 0 agent_num: 32 done: False
______________________
Step:  3680
Pretraining Loss:  tensor(0.0507, device='cuda:0', grad_fn=<MeanBackward0>)
id: 54 reward: -0.03296703296703297 service_time: 1284 s_time: 24 penalty: 0 agent_num: 13 done: False
______________________
id: 49 reward: 0.03571428571428571 service_time: 998 s_time: -22 penalty: 0 agent_num: 11 done: False
______________________
id: 55 reward: 0.015476190476190477 service_time: 887 s_time: -13 penalty: 0 agent_num: 15 done: False
______________________
id: 51 reward: -0.033035714285714286 service_time: 554 s_time: 37 penalty: 0 agent_num: 20 done: False
______________________
id: 48 reward: 0.018601190476190476 service_time: 1859 s_time: -25 penalty: 0 agent_num: 24 done: False
______________________
id: 47 reward: -0.0011160714285714285 service_time: 2788 s_time: 1 penalty: 0 agent_num: 16 done: False
______________________
id: 45 reward: -0.03635204081632653 service_time: 2013 s_time: 57 penalty: 0 agent_num: 28 done: False
______________________
id: 43 reward: 0.0 service_time: 1430 s_time: 0 penalty: 0 agent_num: 44 done: False
______________________
id: 46 reward: 0.0004578754578754579 service_time: 1822 s_time: -1 penalty: 0 agent_num: 39 done: False
______________________
id: 52 reward: -0.010602678571428572 service_time: 1348 s_time: 19 penalty: 0 agent_num: 32 done: False
______________________
id: 53 reward: -0.01416256157635468 service_time: 1035 s_time: 23 penalty: 0 agent_num: 29 done: False
______________________
id: 40 reward: 0.0 service_time: 935 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 44 reward: -0.01203416149068323 service_time: 727 s_time: 31 penalty: 0 agent_num: 46 done: False
______________________
id: 42 reward: -0.01633738601823708 service_time: 1380 s_time: 43 penalty: 0 agent_num: 47 done: False
______________________
id: 41 reward: -0.013950892857142858 service_time: 1581 s_time: 25 penalty: 0 agent_num: 32 done: False
______________________
id: 50 reward: -0.023166023166023165 service_time: 1506 s_time: 48 penalty: 0 agent_num: 37 done: False
______________________
Step:  3696
Pretraining Loss:  tensor(0.0484, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.03409090909090909 service_time: 1019 s_time: 21 penalty: 0 agent_num: 11 done: False
______________________
id: 54 reward: 0.0 service_time: 1284 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 55 reward: -0.13690476190476192 service_time: 1002 s_time: 115 penalty: 0 agent_num: 15 done: False
______________________
id: 47 reward: -0.03571428571428571 service_time: 2820 s_time: 32 penalty: 0 agent_num: 16 done: False
______________________
id: 45 reward: 0.02040816326530612 service_time: 1981 s_time: -32 penalty: 0 agent_num: 28 done: False
______________________
id: 48 reward: -0.03571428571428571 service_time: 1907 s_time: 48 penalty: 0 agent_num: 24 done: False
______________________
id: 51 reward: -0.054464285714285715 service_time: 615 s_time: 61 penalty: 0 agent_num: 20 done: False
______________________
id: 46 reward: -0.03021978021978022 service_time: 1888 s_time: 66 penalty: 0 agent_num: 39 done: False
______________________
id: 43 reward: -0.018262987012987012 service_time: 1475 s_time: 45 penalty: 0 agent_num: 44 done: False
______________________
id: 40 reward: -0.013157894736842105 service_time: 963 s_time: 28 penalty: 0 agent_num: 38 done: False
______________________
id: 52 reward: 0.002232142857142857 service_time: 1344 s_time: -4 penalty: 0 agent_num: 32 done: False
______________________
id: 42 reward: -0.00911854103343465 service_time: 1404 s_time: 24 penalty: 0 agent_num: 47 done: False
______________________
id: 44 reward: -0.01281055900621118 service_time: 760 s_time: 33 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: -0.008004926108374385 service_time: 1048 s_time: 13 penalty: 0 agent_num: 29 done: False
______________________
id: 50 reward: 0.0014478764478764478 service_time: 1503 s_time: -3 penalty: 0 agent_num: 37 done: False
______________________
id: 41 reward: -0.008928571428571428 service_time: 1597 s_time: 16 penalty: 0 agent_num: 32 done: False
______________________
Step:  3712
Pretraining Loss:  tensor(0.0484, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.05194805194805195 service_time: 1051 s_time: 32 penalty: 0 agent_num: 11 done: False
______________________
id: 55 reward: -0.07380952380952381 service_time: 1064 s_time: 62 penalty: 0 agent_num: 15 done: False
______________________
id: 54 reward: 0.0 service_time: 1284 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 51 reward: 0.0125 service_time: 601 s_time: -14 penalty: 0 agent_num: 20 done: False
______________________
id: 48 reward: 0.03125 service_time: 1865 s_time: -42 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: -0.04017857142857143 service_time: 2044 s_time: 63 penalty: 0 agent_num: 28 done: False
______________________
id: 47 reward: -0.0011160714285714285 service_time: 2821 s_time: 1 penalty: 0 agent_num: 16 done: False
______________________
id: 53 reward: -0.014778325123152709 service_time: 1072 s_time: 24 penalty: 0 agent_num: 29 done: False
______________________
id: 40 reward: 0.0 service_time: 963 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 52 reward: -0.033482142857142856 service_time: 1404 s_time: 60 penalty: 0 agent_num: 32 done: False
______________________
id: 50 reward: -0.020752895752895753 service_time: 1546 s_time: 43 penalty: 0 agent_num: 37 done: False
______________________
id: 43 reward: -0.0174512987012987 service_time: 1518 s_time: 43 penalty: 0 agent_num: 44 done: False
______________________
id: 44 reward: -0.008152173913043478 service_time: 781 s_time: 21 penalty: 0 agent_num: 46 done: False
______________________
id: 46 reward: -0.0086996336996337 service_time: 1907 s_time: 19 penalty: 0 agent_num: 39 done: False
______________________
id: 42 reward: -0.011398176291793313 service_time: 1434 s_time: 30 penalty: 0 agent_num: 47 done: False
______________________
id: 41 reward: -0.013950892857142858 service_time: 1622 s_time: 25 penalty: 0 agent_num: 32 done: False
______________________
Step:  3728
Pretraining Loss:  tensor(0.0449, device='cuda:0', grad_fn=<MeanBackward0>)
id: 54 reward: 0.012362637362637362 service_time: 1275 s_time: -9 penalty: 0 agent_num: 13 done: False
______________________
id: 49 reward: -0.0633116883116883 service_time: 1090 s_time: 39 penalty: 0 agent_num: 11 done: False
______________________
id: 55 reward: 0.0 service_time: 1064 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 47 reward: 0.002232142857142857 service_time: 2819 s_time: -2 penalty: 0 agent_num: 16 done: False
______________________
id: 45 reward: 0.002551020408163265 service_time: 2040 s_time: -4 penalty: 0 agent_num: 28 done: False
______________________
id: 48 reward: -0.022321428571428572 service_time: 1895 s_time: 30 penalty: 0 agent_num: 24 done: False
______________________
id: 51 reward: -0.019642857142857142 service_time: 623 s_time: 22 penalty: 0 agent_num: 20 done: False
______________________
id: 53 reward: 0.0012315270935960591 service_time: 1070 s_time: -2 penalty: 0 agent_num: 29 done: False
______________________
id: 46 reward: -0.015567765567765568 service_time: 1941 s_time: 34 penalty: 0 agent_num: 39 done: False
______________________
id: 40 reward: -0.01268796992481203 service_time: 990 s_time: 27 penalty: 0 agent_num: 38 done: False
______________________
id: 50 reward: -0.008687258687258687 service_time: 1564 s_time: 18 penalty: 0 agent_num: 37 done: False
______________________
id: 43 reward: 0.0 service_time: 1518 s_time: 0 penalty: 0 agent_num: 44 done: False
______________________
id: 52 reward: -0.017857142857142856 service_time: 1436 s_time: 32 penalty: 0 agent_num: 32 done: False
______________________
id: 42 reward: -0.00911854103343465 service_time: 1458 s_time: 24 penalty: 0 agent_num: 47 done: False
______________________
id: 44 reward: -0.011645962732919254 service_time: 811 s_time: 30 penalty: 0 agent_num: 46 done: False
______________________
id: 41 reward: -0.022879464285714284 service_time: 1663 s_time: 41 penalty: 0 agent_num: 32 done: False
______________________
Step:  3744
Pretraining Loss:  tensor(0.0528, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.025974025974025976 service_time: 1106 s_time: 16 penalty: 0 agent_num: 11 done: False
______________________
id: 51 reward: 0.0 service_time: 623 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 54 reward: 0.0673076923076923 service_time: 1226 s_time: -49 penalty: 0 agent_num: 13 done: False
______________________
id: 55 reward: 0.0 service_time: 1064 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 45 reward: 0.009566326530612245 service_time: 2025 s_time: -15 penalty: 0 agent_num: 28 done: False
______________________
id: 47 reward: 20.0 service_time: 2819 s_time: 0 penalty: 0 agent_num: 16 done: True
______________________
id: 48 reward: -0.010416666666666666 service_time: 1909 s_time: 14 penalty: 0 agent_num: 24 done: False
______________________
id: 53 reward: -0.02894088669950739 service_time: 1117 s_time: 47 penalty: 0 agent_num: 29 done: False
______________________
id: 40 reward: -0.008458646616541353 service_time: 1008 s_time: 18 penalty: 0 agent_num: 38 done: False
______________________
id: 43 reward: -0.008522727272727272 service_time: 1539 s_time: 21 penalty: 0 agent_num: 44 done: False
______________________
id: 50 reward: 0.004826254826254826 service_time: 1554 s_time: -10 penalty: 0 agent_num: 37 done: False
______________________
id: 46 reward: -0.010073260073260074 service_time: 1963 s_time: 22 penalty: 0 agent_num: 39 done: False
______________________
id: 44 reward: -0.005822981366459627 service_time: 826 s_time: 15 penalty: 0 agent_num: 46 done: False
______________________
id: 42 reward: 0.0007598784194528875 service_time: 1456 s_time: -2 penalty: 0 agent_num: 47 done: False
______________________
id: 52 reward: -0.016183035714285716 service_time: 1465 s_time: 29 penalty: 0 agent_num: 32 done: False
______________________
id: 41 reward: -0.012276785714285714 service_time: 1685 s_time: 22 penalty: 0 agent_num: 32 done: False
______________________
Step:  3760
Pretraining Loss:  tensor(0.0485, device='cuda:0', grad_fn=<MeanBackward0>)
id: 47 reward: -0.03361344537815126 service_time: 32 s_time: 32 penalty: 0 agent_num: 17 done: False
______________________
id: 54 reward: -0.07554945054945054 service_time: 1281 s_time: 55 penalty: 0 agent_num: 13 done: False
______________________
id: 49 reward: 0.00487012987012987 service_time: 1103 s_time: -3 penalty: 0 agent_num: 11 done: False
______________________
id: 55 reward: 0.0 service_time: 1064 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 51 reward: -0.026785714285714284 service_time: 653 s_time: 30 penalty: 0 agent_num: 20 done: False
______________________
id: 48 reward: 0.0 service_time: 1909 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 46 reward: 0.0009157509157509158 service_time: 1961 s_time: -2 penalty: 0 agent_num: 39 done: False
______________________
id: 40 reward: 0.0 service_time: 1008 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 52 reward: -0.008370535714285714 service_time: 1480 s_time: 15 penalty: 0 agent_num: 32 done: False
______________________
id: 44 reward: 0.0 service_time: 826 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: -0.03017241379310345 service_time: 1166 s_time: 49 penalty: 0 agent_num: 29 done: False
______________________
id: 43 reward: -0.02150974025974026 service_time: 1592 s_time: 53 penalty: 0 agent_num: 44 done: False
______________________
id: 45 reward: -0.03125 service_time: 2074 s_time: 49 penalty: 0 agent_num: 28 done: False
______________________
id: 50 reward: -0.026544401544401543 service_time: 1609 s_time: 55 penalty: 0 agent_num: 37 done: False
______________________
id: 42 reward: -0.0243161094224924 service_time: 1520 s_time: 64 penalty: 0 agent_num: 47 done: False
______________________
id: 41 reward: -0.01171875 service_time: 1706 s_time: 21 penalty: 0 agent_num: 32 done: False
______________________
Step:  3776
Pretraining Loss:  tensor(0.0519, device='cuda:0', grad_fn=<MeanBackward0>)
id: 47 reward: -0.022058823529411766 service_time: 53 s_time: 21 penalty: 0 agent_num: 17 done: False
______________________
id: 49 reward: 0.0016233766233766235 service_time: 1102 s_time: -1 penalty: 0 agent_num: 11 done: False
______________________
id: 54 reward: -0.06868131868131869 service_time: 1331 s_time: 50 penalty: 0 agent_num: 13 done: False
______________________
id: 51 reward: -0.017857142857142856 service_time: 673 s_time: 20 penalty: 0 agent_num: 20 done: False
______________________
id: 55 reward: 0.0 service_time: 1064 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 48 reward: -0.023809523809523808 service_time: 1941 s_time: 32 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: 0.0 service_time: 2074 s_time: 0 penalty: 0 agent_num: 28 done: False
______________________
id: 50 reward: -0.008204633204633204 service_time: 1626 s_time: 17 penalty: 0 agent_num: 37 done: False
______________________
id: 46 reward: -0.020604395604395604 service_time: 2006 s_time: 45 penalty: 0 agent_num: 39 done: False
______________________
id: 53 reward: -0.01847290640394089 service_time: 1196 s_time: 30 penalty: 0 agent_num: 29 done: False
______________________
id: 40 reward: -0.008928571428571428 service_time: 1027 s_time: 19 penalty: 0 agent_num: 38 done: False
______________________
id: 44 reward: -0.012422360248447204 service_time: 858 s_time: 32 penalty: 0 agent_num: 46 done: False
______________________
id: 43 reward: 0.0 service_time: 1592 s_time: 0 penalty: 0 agent_num: 44 done: False
______________________
id: 42 reward: -0.0056990881458966565 service_time: 1535 s_time: 15 penalty: 0 agent_num: 47 done: False
______________________
id: 52 reward: -0.01171875 service_time: 1501 s_time: 21 penalty: 0 agent_num: 32 done: False
______________________
id: 41 reward: -0.006138392857142857 service_time: 1717 s_time: 11 penalty: 0 agent_num: 32 done: False
______________________
Step:  3792
Pretraining Loss:  tensor(0.0442, device='cuda:0', grad_fn=<MeanBackward0>)
id: 47 reward: -0.026260504201680673 service_time: 78 s_time: 25 penalty: 0 agent_num: 17 done: False
______________________
id: 49 reward: 0.0 service_time: 1102 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 54 reward: 0.04395604395604396 service_time: 1299 s_time: -32 penalty: 0 agent_num: 13 done: False
______________________
id: 51 reward: 0.0 service_time: 673 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 55 reward: -0.030952380952380953 service_time: 1090 s_time: 26 penalty: 0 agent_num: 15 done: False
______________________
id: 48 reward: -0.017857142857142856 service_time: 1965 s_time: 24 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: -0.017857142857142856 service_time: 2102 s_time: 28 penalty: 0 agent_num: 28 done: False
______________________
id: 46 reward: -0.0004578754578754579 service_time: 2007 s_time: 1 penalty: 0 agent_num: 39 done: False
______________________
id: 52 reward: -0.03125 service_time: 1557 s_time: 56 penalty: 0 agent_num: 32 done: False
______________________
id: 40 reward: -0.011748120300751879 service_time: 1052 s_time: 25 penalty: 0 agent_num: 38 done: False
______________________
id: 53 reward: -0.021551724137931036 service_time: 1231 s_time: 35 penalty: 0 agent_num: 29 done: False
______________________
id: 44 reward: -0.007375776397515528 service_time: 877 s_time: 19 penalty: 0 agent_num: 46 done: False
______________________
id: 43 reward: -0.004464285714285714 service_time: 1603 s_time: 11 penalty: 0 agent_num: 44 done: False
______________________
id: 50 reward: 0.0 service_time: 1626 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 42 reward: -0.012537993920972644 service_time: 1568 s_time: 33 penalty: 0 agent_num: 47 done: False
______________________
id: 41 reward: -0.011160714285714286 service_time: 1737 s_time: 20 penalty: 0 agent_num: 32 done: False
______________________
Step:  3808
Pretraining Loss:  tensor(0.0407, device='cuda:0', grad_fn=<MeanBackward0>)
id: 47 reward: -0.012605042016806723 service_time: 90 s_time: 12 penalty: 0 agent_num: 17 done: False
______________________
id: 49 reward: -0.2435064935064935 service_time: 1252 s_time: 150 penalty: 0 agent_num: 11 done: False
______________________
id: 54 reward: 0.054945054945054944 service_time: 1259 s_time: -40 penalty: 0 agent_num: 13 done: False
______________________
id: 55 reward: -0.02738095238095238 service_time: 1113 s_time: 23 penalty: 0 agent_num: 15 done: False
______________________
id: 48 reward: 0.0 service_time: 1965 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: -0.03380102040816327 service_time: 2155 s_time: 53 penalty: 0 agent_num: 28 done: False
______________________
id: 46 reward: -0.011904761904761904 service_time: 2033 s_time: 26 penalty: 0 agent_num: 39 done: False
______________________
id: 53 reward: -0.0006157635467980296 service_time: 1232 s_time: 1 penalty: 0 agent_num: 29 done: False
______________________
id: 50 reward: -0.021235521235521235 service_time: 1670 s_time: 44 penalty: 0 agent_num: 37 done: False
______________________
id: 43 reward: -0.026379870129870128 service_time: 1668 s_time: 65 penalty: 0 agent_num: 44 done: False
______________________
id: 40 reward: 0.0 service_time: 1052 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 42 reward: -0.0060790273556231 service_time: 1584 s_time: 16 penalty: 0 agent_num: 47 done: False
______________________
id: 44 reward: -0.017080745341614908 service_time: 921 s_time: 44 penalty: 0 agent_num: 46 done: False
______________________
id: 51 reward: -0.048214285714285716 service_time: 727 s_time: 54 penalty: 0 agent_num: 20 done: False
______________________
id: 41 reward: -0.010602678571428572 service_time: 1756 s_time: 19 penalty: 0 agent_num: 32 done: False
______________________
id: 52 reward: -0.016183035714285716 service_time: 1586 s_time: 29 penalty: 0 agent_num: 32 done: False
______________________
Step:  3824
Pretraining Loss:  tensor(0.0462, device='cuda:0', grad_fn=<MeanBackward0>)
id: 47 reward: -0.012605042016806723 service_time: 102 s_time: 12 penalty: 0 agent_num: 17 done: False
______________________
id: 49 reward: -0.02922077922077922 service_time: 1270 s_time: 18 penalty: 0 agent_num: 11 done: False
______________________
id: 55 reward: 0.005952380952380952 service_time: 1108 s_time: -5 penalty: 0 agent_num: 15 done: False
______________________
id: 54 reward: 0.0 service_time: 1259 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 51 reward: -0.022321428571428572 service_time: 752 s_time: 25 penalty: 0 agent_num: 20 done: False
______________________
id: 48 reward: -0.01488095238095238 service_time: 1985 s_time: 20 penalty: 0 agent_num: 24 done: False
______________________
id: 53 reward: -0.017241379310344827 service_time: 1260 s_time: 28 penalty: 0 agent_num: 29 done: False
______________________
id: 45 reward: 0.0006377551020408163 service_time: 2154 s_time: -1 penalty: 0 agent_num: 28 done: False
______________________
id: 46 reward: -0.012362637362637362 service_time: 2060 s_time: 27 penalty: 0 agent_num: 39 done: False
______________________
id: 52 reward: -0.01171875 service_time: 1607 s_time: 21 penalty: 0 agent_num: 32 done: False
______________________
id: 40 reward: -0.018796992481203006 service_time: 1092 s_time: 40 penalty: 0 agent_num: 38 done: False
______________________
id: 44 reward: 0.0 service_time: 921 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 43 reward: -0.006899350649350649 service_time: 1685 s_time: 17 penalty: 0 agent_num: 44 done: False
______________________
id: 50 reward: -0.006756756756756757 service_time: 1684 s_time: 14 penalty: 0 agent_num: 37 done: False
______________________
id: 41 reward: -0.021763392857142856 service_time: 1795 s_time: 39 penalty: 0 agent_num: 32 done: False
______________________
id: 42 reward: -0.013297872340425532 service_time: 1619 s_time: 35 penalty: 0 agent_num: 47 done: False
______________________
Step:  3840
Pretraining Loss:  tensor(0.0444, device='cuda:0', grad_fn=<MeanBackward0>)
id: 47 reward: -0.02100840336134454 service_time: 122 s_time: 20 penalty: 0 agent_num: 17 done: False
______________________
id: 49 reward: 0.0698051948051948 service_time: 1227 s_time: -43 penalty: 0 agent_num: 11 done: False
______________________
id: 51 reward: 0.0 service_time: 752 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 55 reward: 0.0 service_time: 1108 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 54 reward: 0.0 service_time: 1259 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 45 reward: 0.012755102040816327 service_time: 2134 s_time: -20 penalty: 0 agent_num: 28 done: False
______________________
id: 48 reward: -0.06473214285714286 service_time: 2072 s_time: 87 penalty: 0 agent_num: 24 done: False
______________________
id: 50 reward: 0.0033783783783783786 service_time: 1677 s_time: -7 penalty: 0 agent_num: 37 done: False
______________________
id: 43 reward: -0.005275974025974026 service_time: 1698 s_time: 13 penalty: 0 agent_num: 44 done: False
______________________
id: 46 reward: -0.013278388278388278 service_time: 2089 s_time: 29 penalty: 0 agent_num: 39 done: False
______________________
id: 52 reward: -0.012834821428571428 service_time: 1630 s_time: 23 penalty: 0 agent_num: 32 done: False
______________________
id: 40 reward: 0.0 service_time: 1092 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 42 reward: -0.00037993920972644377 service_time: 1620 s_time: 1 penalty: 0 agent_num: 47 done: False
______________________
id: 53 reward: -0.025246305418719212 service_time: 1301 s_time: 41 penalty: 0 agent_num: 29 done: False
______________________
id: 44 reward: -0.01048136645962733 service_time: 948 s_time: 27 penalty: 0 agent_num: 46 done: False
______________________
id: 41 reward: 0.0011160714285714285 service_time: 1793 s_time: -2 penalty: 0 agent_num: 32 done: False
______________________
Step:  3856
Pretraining Loss:  tensor(0.0467, device='cuda:0', grad_fn=<MeanBackward0>)
id: 54 reward: -0.14697802197802198 service_time: 1366 s_time: 107 penalty: 0 agent_num: 13 done: False
______________________
id: 49 reward: 0.0 service_time: 1227 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: -0.022058823529411766 service_time: 143 s_time: 21 penalty: 0 agent_num: 17 done: False
______________________
id: 51 reward: -0.022321428571428572 service_time: 777 s_time: 25 penalty: 0 agent_num: 20 done: False
______________________
id: 55 reward: -0.05119047619047619 service_time: 1151 s_time: 43 penalty: 0 agent_num: 15 done: False
______________________
id: 52 reward: 0.0011160714285714285 service_time: 1628 s_time: -2 penalty: 0 agent_num: 32 done: False
______________________
id: 48 reward: 0.001488095238095238 service_time: 2070 s_time: -2 penalty: 0 agent_num: 24 done: False
______________________
id: 40 reward: -0.018796992481203006 service_time: 1132 s_time: 40 penalty: 0 agent_num: 38 done: False
______________________
id: 46 reward: -0.005952380952380952 service_time: 2102 s_time: 13 penalty: 0 agent_num: 39 done: False
______________________
id: 44 reward: -0.015139751552795032 service_time: 987 s_time: 39 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: -0.03633004926108374 service_time: 1360 s_time: 59 penalty: 0 agent_num: 29 done: False
______________________
id: 43 reward: -0.015016233766233766 service_time: 1735 s_time: 37 penalty: 0 agent_num: 44 done: False
______________________
id: 50 reward: -0.029922779922779922 service_time: 1739 s_time: 62 penalty: 0 agent_num: 37 done: False
______________________
id: 42 reward: -0.023556231003039513 service_time: 1682 s_time: 62 penalty: 0 agent_num: 47 done: False
______________________
id: 41 reward: -0.03627232142857143 service_time: 1858 s_time: 65 penalty: 0 agent_num: 32 done: False
______________________
id: 45 reward: -0.10459183673469388 service_time: 2298 s_time: 164 penalty: 0 agent_num: 28 done: False
______________________
Step:  3872
Pretraining Loss:  tensor(0.0433, device='cuda:0', grad_fn=<MeanBackward0>)
id: 54 reward: -0.04120879120879121 service_time: 1396 s_time: 30 penalty: 0 agent_num: 13 done: False
______________________
id: 47 reward: -0.0430672268907563 service_time: 184 s_time: 41 penalty: 0 agent_num: 17 done: False
______________________
id: 49 reward: 0.0 service_time: 1227 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 55 reward: -0.02738095238095238 service_time: 1174 s_time: 23 penalty: 0 agent_num: 15 done: False
______________________
id: 51 reward: -0.04017857142857143 service_time: 822 s_time: 45 penalty: 0 agent_num: 20 done: False
______________________
id: 48 reward: 0.04241071428571429 service_time: 2013 s_time: -57 penalty: 0 agent_num: 24 done: False
______________________
id: 53 reward: 0.004310344827586207 service_time: 1353 s_time: -7 penalty: 0 agent_num: 29 done: False
______________________
id: 45 reward: 0.01211734693877551 service_time: 2279 s_time: -19 penalty: 0 agent_num: 28 done: False
______________________
id: 46 reward: 0.0004578754578754579 service_time: 2101 s_time: -1 penalty: 0 agent_num: 39 done: False
______________________
id: 43 reward: 0.002435064935064935 service_time: 1729 s_time: -6 penalty: 0 agent_num: 44 done: False
______________________
id: 40 reward: 0.0 service_time: 1132 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 50 reward: -0.009652509652509652 service_time: 1759 s_time: 20 penalty: 0 agent_num: 37 done: False
______________________
id: 52 reward: -0.026227678571428572 service_time: 1675 s_time: 47 penalty: 0 agent_num: 32 done: False
______________________
id: 44 reward: -0.009704968944099378 service_time: 1012 s_time: 25 penalty: 0 agent_num: 46 done: False
______________________
id: 42 reward: 0.0 service_time: 1682 s_time: 0 penalty: 0 agent_num: 47 done: False
______________________
id: 41 reward: -0.018973214285714284 service_time: 1892 s_time: 34 penalty: 0 agent_num: 32 done: False
______________________
Step:  3888
Pretraining Loss:  tensor(0.0397, device='cuda:0', grad_fn=<MeanBackward0>)
id: 54 reward: -0.028846153846153848 service_time: 1417 s_time: 21 penalty: 0 agent_num: 13 done: False
______________________
id: 47 reward: -0.022058823529411766 service_time: 205 s_time: 21 penalty: 0 agent_num: 17 done: False
______________________
id: 49 reward: 0.08928571428571429 service_time: 1172 s_time: -55 penalty: 0 agent_num: 11 done: False
______________________
id: 51 reward: -0.030357142857142857 service_time: 856 s_time: 34 penalty: 0 agent_num: 20 done: False
______________________
id: 55 reward: -0.17261904761904762 service_time: 1319 s_time: 145 penalty: 0 agent_num: 15 done: False
______________________
id: 48 reward: 0.000744047619047619 service_time: 2012 s_time: -1 penalty: 0 agent_num: 24 done: False
______________________
id: 40 reward: -0.008928571428571428 service_time: 1151 s_time: 19 penalty: 0 agent_num: 38 done: False
______________________
id: 46 reward: -0.022435897435897436 service_time: 2150 s_time: 49 penalty: 0 agent_num: 39 done: False
______________________
id: 44 reward: -0.004658385093167702 service_time: 1024 s_time: 12 penalty: 0 agent_num: 46 done: False
______________________
id: 50 reward: -0.007722007722007722 service_time: 1775 s_time: 16 penalty: 0 agent_num: 37 done: False
______________________
id: 43 reward: -0.02556818181818182 service_time: 1792 s_time: 63 penalty: 0 agent_num: 44 done: False
______________________
id: 42 reward: -0.024696048632218845 service_time: 1747 s_time: 65 penalty: 0 agent_num: 47 done: False
______________________
id: 45 reward: -0.08290816326530612 service_time: 2409 s_time: 130 penalty: 0 agent_num: 28 done: False
______________________
id: 53 reward: -0.03571428571428571 service_time: 1411 s_time: 58 penalty: 0 agent_num: 29 done: False
______________________
id: 41 reward: -0.017299107142857144 service_time: 1923 s_time: 31 penalty: 0 agent_num: 32 done: False
______________________
id: 52 reward: -0.0016741071428571428 service_time: 1678 s_time: 3 penalty: 0 agent_num: 32 done: False
______________________
Step:  3904
Pretraining Loss:  tensor(0.0476, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.0 service_time: 1172 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 54 reward: 0.016483516483516484 service_time: 1405 s_time: -12 penalty: 0 agent_num: 13 done: False
______________________
id: 51 reward: 0.0 service_time: 856 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 55 reward: -0.03333333333333333 service_time: 1347 s_time: 28 penalty: 0 agent_num: 15 done: False
______________________
id: 47 reward: -0.03991596638655462 service_time: 243 s_time: 38 penalty: 0 agent_num: 17 done: False
______________________
id: 48 reward: -0.11086309523809523 service_time: 2161 s_time: 149 penalty: 0 agent_num: 24 done: False
______________________
id: 46 reward: 0.0 service_time: 2150 s_time: 0 penalty: 0 agent_num: 39 done: False
______________________
id: 53 reward: -0.01600985221674877 service_time: 1437 s_time: 26 penalty: 0 agent_num: 29 done: False
______________________
id: 44 reward: -0.009316770186335404 service_time: 1048 s_time: 24 penalty: 0 agent_num: 46 done: False
______________________
id: 40 reward: -0.018796992481203006 service_time: 1191 s_time: 40 penalty: 0 agent_num: 38 done: False
______________________
id: 43 reward: -0.01176948051948052 service_time: 1821 s_time: 29 penalty: 0 agent_num: 44 done: False
______________________
id: 50 reward: -0.015444015444015444 service_time: 1807 s_time: 32 penalty: 0 agent_num: 37 done: False
______________________
id: 52 reward: -0.024553571428571428 service_time: 1722 s_time: 44 penalty: 0 agent_num: 32 done: False
______________________
id: 41 reward: -0.009486607142857142 service_time: 1940 s_time: 17 penalty: 0 agent_num: 32 done: False
______________________
id: 45 reward: -0.002551020408163265 service_time: 2413 s_time: 4 penalty: 0 agent_num: 28 done: False
______________________
id: 42 reward: -0.003799392097264438 service_time: 1757 s_time: 10 penalty: 0 agent_num: 47 done: False
______________________
Step:  3920
Pretraining Loss:  tensor(0.0548, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.15746753246753248 service_time: 1269 s_time: 97 penalty: 0 agent_num: 11 done: False
______________________
id: 54 reward: -0.05357142857142857 service_time: 1444 s_time: 39 penalty: 0 agent_num: 13 done: False
______________________
id: 55 reward: 0.04880952380952381 service_time: 1306 s_time: -41 penalty: 0 agent_num: 15 done: False
______________________
id: 51 reward: -0.027678571428571427 service_time: 887 s_time: 31 penalty: 0 agent_num: 20 done: False
______________________
id: 47 reward: -0.0273109243697479 service_time: 269 s_time: 26 penalty: 0 agent_num: 17 done: False
______________________
id: 48 reward: 0.011160714285714286 service_time: 2146 s_time: -15 penalty: 0 agent_num: 24 done: False
______________________
id: 40 reward: -0.007518796992481203 service_time: 1207 s_time: 16 penalty: 0 agent_num: 38 done: False
______________________
id: 53 reward: -0.03140394088669951 service_time: 1488 s_time: 51 penalty: 0 agent_num: 29 done: False
______________________
id: 52 reward: -0.017857142857142856 service_time: 1754 s_time: 32 penalty: 0 agent_num: 32 done: False
______________________
id: 43 reward: -0.01176948051948052 service_time: 1850 s_time: 29 penalty: 0 agent_num: 44 done: False
______________________
id: 46 reward: -0.03159340659340659 service_time: 2219 s_time: 69 penalty: 0 agent_num: 39 done: False
______________________
id: 41 reward: 0.0011160714285714285 service_time: 1938 s_time: -2 penalty: 0 agent_num: 32 done: False
______________________
id: 44 reward: -0.006599378881987578 service_time: 1065 s_time: 17 penalty: 0 agent_num: 46 done: False
______________________
id: 42 reward: -0.007978723404255319 service_time: 1778 s_time: 21 penalty: 0 agent_num: 47 done: False
______________________
id: 50 reward: -0.013513513513513514 service_time: 1835 s_time: 28 penalty: 0 agent_num: 37 done: False
______________________
id: 45 reward: -0.015306122448979591 service_time: 2437 s_time: 24 penalty: 0 agent_num: 28 done: False
______________________
Step:  3936
Pretraining Loss:  tensor(0.0475, device='cuda:0', grad_fn=<MeanBackward0>)
id: 54 reward: 0.0260989010989011 service_time: 1425 s_time: -19 penalty: 0 agent_num: 13 done: False
______________________
id: 49 reward: 0.0 service_time: 1269 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 55 reward: -0.017857142857142856 service_time: 1321 s_time: 15 penalty: 0 agent_num: 15 done: False
______________________
id: 51 reward: -0.01875 service_time: 908 s_time: 21 penalty: 0 agent_num: 20 done: False
______________________
id: 48 reward: -0.011904761904761904 service_time: 2162 s_time: 16 penalty: 0 agent_num: 24 done: False
______________________
id: 47 reward: -0.03571428571428571 service_time: 303 s_time: 34 penalty: 0 agent_num: 17 done: False
______________________
id: 44 reward: 0.0 service_time: 1065 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 40 reward: 0.0 service_time: 1207 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 43 reward: -0.010146103896103896 service_time: 1875 s_time: 25 penalty: 0 agent_num: 44 done: False
______________________
id: 50 reward: 0.0 service_time: 1835 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 52 reward: -0.005022321428571429 service_time: 1763 s_time: 9 penalty: 0 agent_num: 32 done: False
______________________
id: 53 reward: -0.0166256157635468 service_time: 1515 s_time: 27 penalty: 0 agent_num: 29 done: False
______________________
id: 42 reward: -0.008358662613981762 service_time: 1800 s_time: 22 penalty: 0 agent_num: 47 done: False
______________________
id: 41 reward: -0.030133928571428572 service_time: 1992 s_time: 54 penalty: 0 agent_num: 32 done: False
______________________
id: 46 reward: -0.014194139194139194 service_time: 2250 s_time: 31 penalty: 0 agent_num: 39 done: False
______________________
id: 45 reward: -0.03762755102040816 service_time: 2496 s_time: 59 penalty: 0 agent_num: 28 done: False
______________________
Step:  3952
Pretraining Loss:  tensor(0.0515, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.0 service_time: 1269 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 55 reward: 0.023809523809523808 service_time: 1301 s_time: -20 penalty: 0 agent_num: 15 done: False
______________________
id: 54 reward: -0.020604395604395604 service_time: 1440 s_time: 15 penalty: 0 agent_num: 13 done: False
______________________
id: 48 reward: -0.03422619047619048 service_time: 2208 s_time: 46 penalty: 0 agent_num: 24 done: False
______________________
id: 51 reward: -0.025892857142857145 service_time: 937 s_time: 29 penalty: 0 agent_num: 20 done: False
______________________
id: 45 reward: -0.025510204081632654 service_time: 2536 s_time: 40 penalty: 0 agent_num: 28 done: False
______________________
id: 47 reward: -0.026260504201680673 service_time: 328 s_time: 25 penalty: 0 agent_num: 17 done: False
______________________
id: 40 reward: 0.0 service_time: 1207 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 44 reward: -0.005822981366459627 service_time: 1080 s_time: 15 penalty: 0 agent_num: 46 done: False
______________________
id: 52 reward: -0.008928571428571428 service_time: 1779 s_time: 16 penalty: 0 agent_num: 32 done: False
______________________
id: 50 reward: -0.03088803088803089 service_time: 1899 s_time: 64 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: 0.004310344827586207 service_time: 1508 s_time: -7 penalty: 0 agent_num: 29 done: False
______________________
id: 41 reward: -0.007254464285714286 service_time: 2005 s_time: 13 penalty: 0 agent_num: 32 done: False
______________________
id: 43 reward: 0.0 service_time: 1875 s_time: 0 penalty: 0 agent_num: 44 done: False
______________________
id: 42 reward: -0.001519756838905775 service_time: 1804 s_time: 4 penalty: 0 agent_num: 47 done: False
______________________
id: 46 reward: -0.01510989010989011 service_time: 2283 s_time: 33 penalty: 0 agent_num: 39 done: False
______________________
Step:  3968
Pretraining Loss:  tensor(0.0537, device='cuda:0', grad_fn=<MeanBackward0>)
id: 55 reward: 0.0 service_time: 1301 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 49 reward: 0.0 service_time: 1269 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 54 reward: 0.0 service_time: 1440 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 51 reward: 0.0 service_time: 937 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 47 reward: -0.011554621848739496 service_time: 339 s_time: 11 penalty: 0 agent_num: 17 done: False
______________________
id: 45 reward: 0.014668367346938776 service_time: 2513 s_time: -23 penalty: 0 agent_num: 28 done: False
______________________
id: 48 reward: -0.020089285714285716 service_time: 2235 s_time: 27 penalty: 0 agent_num: 24 done: False
______________________
id: 44 reward: -0.005822981366459627 service_time: 1095 s_time: 15 penalty: 0 agent_num: 46 done: False
______________________
id: 40 reward: -0.009398496240601503 service_time: 1227 s_time: 20 penalty: 0 agent_num: 38 done: False
______________________
id: 50 reward: -0.008687258687258687 service_time: 1917 s_time: 18 penalty: 0 agent_num: 37 done: False
______________________
id: 43 reward: -0.012987012987012988 service_time: 1907 s_time: 32 penalty: 0 agent_num: 44 done: False
______________________
id: 52 reward: -0.007254464285714286 service_time: 1792 s_time: 13 penalty: 0 agent_num: 32 done: False
______________________
id: 53 reward: -0.038177339901477834 service_time: 1570 s_time: 62 penalty: 0 agent_num: 29 done: False
______________________
id: 46 reward: -0.013278388278388278 service_time: 2312 s_time: 29 penalty: 0 agent_num: 39 done: False
______________________
id: 42 reward: -0.007598784194528876 service_time: 1824 s_time: 20 penalty: 0 agent_num: 47 done: False
______________________
id: 41 reward: 0.0 service_time: 2005 s_time: 0 penalty: 0 agent_num: 32 done: False
______________________
Step:  3984
Pretraining Loss:  tensor(0.0495, device='cuda:0', grad_fn=<MeanBackward0>)
id: 54 reward: -0.04120879120879121 service_time: 1470 s_time: 30 penalty: 0 agent_num: 13 done: False
______________________
id: 55 reward: 0.016666666666666666 service_time: 1287 s_time: -14 penalty: 0 agent_num: 15 done: False
______________________
id: 49 reward: -0.04383116883116883 service_time: 1296 s_time: 27 penalty: 0 agent_num: 11 done: False
______________________
id: 51 reward: 0.0008928571428571428 service_time: 936 s_time: -1 penalty: 0 agent_num: 20 done: False
______________________
id: 47 reward: -0.046218487394957986 service_time: 383 s_time: 44 penalty: 0 agent_num: 17 done: False
______________________
id: 48 reward: 0.009672619047619048 service_time: 2222 s_time: -13 penalty: 0 agent_num: 24 done: False
______________________
id: 40 reward: -0.009868421052631578 service_time: 1248 s_time: 21 penalty: 0 agent_num: 38 done: False
______________________
id: 44 reward: -0.016692546583850932 service_time: 1138 s_time: 43 penalty: 0 agent_num: 46 done: False
______________________
id: 50 reward: -0.007722007722007722 service_time: 1933 s_time: 16 penalty: 0 agent_num: 37 done: False
______________________
id: 46 reward: 0.0013736263736263737 service_time: 2309 s_time: -3 penalty: 0 agent_num: 39 done: False
______________________
id: 42 reward: -0.0056990881458966565 service_time: 1839 s_time: 15 penalty: 0 agent_num: 47 done: False
______________________
id: 41 reward: -0.009486607142857142 service_time: 2022 s_time: 17 penalty: 0 agent_num: 32 done: False
______________________
id: 52 reward: 0.0011160714285714285 service_time: 1790 s_time: -2 penalty: 0 agent_num: 32 done: False
______________________
id: 53 reward: -0.020935960591133004 service_time: 1604 s_time: 34 penalty: 0 agent_num: 29 done: False
______________________
id: 43 reward: 0.0 service_time: 1907 s_time: 0 penalty: 0 agent_num: 44 done: False
______________________
id: 45 reward: -0.02423469387755102 service_time: 2551 s_time: 38 penalty: 0 agent_num: 28 done: False
______________________
Step:  4000
Pretraining Loss:  tensor(0.0489, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.022727272727272728 service_time: 1282 s_time: -14 penalty: 0 agent_num: 11 done: False
______________________
id: 54 reward: 0.0027472527472527475 service_time: 1468 s_time: -2 penalty: 0 agent_num: 13 done: False
______________________
id: 55 reward: 0.0 service_time: 1287 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 51 reward: -0.03660714285714286 service_time: 977 s_time: 41 penalty: 0 agent_num: 20 done: False
______________________
id: 48 reward: -0.06101190476190476 service_time: 2304 s_time: 82 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: -0.03188775510204082 service_time: 2601 s_time: 50 penalty: 0 agent_num: 28 done: False
______________________
id: 47 reward: -0.014705882352941176 service_time: 397 s_time: 14 penalty: 0 agent_num: 17 done: False
______________________
id: 40 reward: 0.0018796992481203006 service_time: 1244 s_time: -4 penalty: 0 agent_num: 38 done: False
______________________
id: 44 reward: 0.0 service_time: 1138 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 52 reward: -0.01953125 service_time: 1825 s_time: 35 penalty: 0 agent_num: 32 done: False
______________________
id: 43 reward: -0.006493506493506494 service_time: 1923 s_time: 16 penalty: 0 agent_num: 44 done: False
______________________
id: 50 reward: -0.015444015444015444 service_time: 1965 s_time: 32 penalty: 0 agent_num: 37 done: False
______________________
id: 42 reward: 0.0 service_time: 1839 s_time: 0 penalty: 0 agent_num: 47 done: False
______________________
id: 53 reward: -0.020320197044334975 service_time: 1637 s_time: 33 penalty: 0 agent_num: 29 done: False
______________________
id: 41 reward: -0.04743303571428571 service_time: 2107 s_time: 85 penalty: 0 agent_num: 32 done: False
______________________
id: 46 reward: -0.02197802197802198 service_time: 2357 s_time: 48 penalty: 0 agent_num: 39 done: False
______________________
Step:  4016
Pretraining Loss:  tensor(0.0465, device='cuda:0', grad_fn=<MeanBackward0>)
id: 54 reward: -0.03296703296703297 service_time: 1492 s_time: 24 penalty: 0 agent_num: 13 done: False
______________________
id: 49 reward: -0.14772727272727273 service_time: 1373 s_time: 91 penalty: 0 agent_num: 11 done: False
______________________
id: 55 reward: -0.041666666666666664 service_time: 1322 s_time: 35 penalty: 0 agent_num: 15 done: False
______________________
id: 47 reward: 0.0 service_time: 397 s_time: 0 penalty: 0 agent_num: 17 done: False
______________________
id: 51 reward: -0.025 service_time: 1005 s_time: 28 penalty: 0 agent_num: 20 done: False
______________________
id: 48 reward: -0.018601190476190476 service_time: 2329 s_time: 25 penalty: 0 agent_num: 24 done: False
______________________
id: 40 reward: -0.005639097744360902 service_time: 1256 s_time: 12 penalty: 0 agent_num: 38 done: False
______________________
id: 52 reward: -0.016183035714285716 service_time: 1854 s_time: 29 penalty: 0 agent_num: 32 done: False
______________________
id: 46 reward: -0.010073260073260074 service_time: 2379 s_time: 22 penalty: 0 agent_num: 39 done: False
______________________
id: 44 reward: -0.016692546583850932 service_time: 1181 s_time: 43 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: -0.020320197044334975 service_time: 1670 s_time: 33 penalty: 0 agent_num: 29 done: False
______________________
id: 50 reward: -0.00916988416988417 service_time: 1984 s_time: 19 penalty: 0 agent_num: 37 done: False
______________________
id: 45 reward: -0.016581632653061226 service_time: 2627 s_time: 26 penalty: 0 agent_num: 28 done: False
______________________
id: 42 reward: -0.02811550151975684 service_time: 1913 s_time: 74 penalty: 0 agent_num: 47 done: False
______________________
id: 43 reward: -0.023944805194805196 service_time: 1982 s_time: 59 penalty: 0 agent_num: 44 done: False
______________________
id: 41 reward: 0.0 service_time: 2107 s_time: 0 penalty: 0 agent_num: 32 done: False
______________________
Step:  4032
Pretraining Loss:  tensor(0.0523, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.08441558441558442 service_time: 1425 s_time: 52 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: -0.04411764705882353 service_time: 439 s_time: 42 penalty: 0 agent_num: 17 done: False
______________________
id: 54 reward: -0.03021978021978022 service_time: 1514 s_time: 22 penalty: 0 agent_num: 13 done: False
______________________
id: 55 reward: -0.08571428571428572 service_time: 1394 s_time: 72 penalty: 0 agent_num: 15 done: False
______________________
id: 51 reward: 0.0 service_time: 1005 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 40 reward: -0.008928571428571428 service_time: 1275 s_time: 19 penalty: 0 agent_num: 38 done: False
______________________
id: 53 reward: -0.022167487684729065 service_time: 1706 s_time: 36 penalty: 0 agent_num: 29 done: False
______________________
id: 48 reward: -0.024553571428571428 service_time: 2362 s_time: 33 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: -0.018494897959183673 service_time: 2656 s_time: 29 penalty: 0 agent_num: 28 done: False
______________________
id: 44 reward: -0.008152173913043478 service_time: 1202 s_time: 21 penalty: 0 agent_num: 46 done: False
______________________
id: 50 reward: 0.008204633204633204 service_time: 1967 s_time: -17 penalty: 0 agent_num: 37 done: False
______________________
id: 52 reward: -0.017299107142857144 service_time: 1885 s_time: 31 penalty: 0 agent_num: 32 done: False
______________________
id: 43 reward: -0.01176948051948052 service_time: 2011 s_time: 29 penalty: 0 agent_num: 44 done: False
______________________
id: 42 reward: -0.004939209726443769 service_time: 1926 s_time: 13 penalty: 0 agent_num: 47 done: False
______________________
id: 46 reward: -0.011904761904761904 service_time: 2405 s_time: 26 penalty: 0 agent_num: 39 done: False
______________________
id: 41 reward: -0.015066964285714286 service_time: 2134 s_time: 27 penalty: 0 agent_num: 32 done: False
______________________
Step:  4048
Pretraining Loss:  tensor(0.0447, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.03896103896103896 service_time: 1449 s_time: 24 penalty: 0 agent_num: 11 done: False
______________________
id: 54 reward: -0.03983516483516483 service_time: 1543 s_time: 29 penalty: 0 agent_num: 13 done: False
______________________
id: 55 reward: -0.04642857142857143 service_time: 1433 s_time: 39 penalty: 0 agent_num: 15 done: False
______________________
id: 47 reward: -0.04726890756302521 service_time: 484 s_time: 45 penalty: 0 agent_num: 17 done: False
______________________
id: 48 reward: -0.023809523809523808 service_time: 2394 s_time: 32 penalty: 0 agent_num: 24 done: False
______________________
id: 51 reward: 0.0 service_time: 1005 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 40 reward: -0.016917293233082706 service_time: 1311 s_time: 36 penalty: 0 agent_num: 38 done: False
______________________
id: 44 reward: -0.005434782608695652 service_time: 1216 s_time: 14 penalty: 0 agent_num: 46 done: False
______________________
id: 52 reward: 0.0 service_time: 1885 s_time: 0 penalty: 0 agent_num: 32 done: False
______________________
id: 42 reward: -0.009498480243161094 service_time: 1951 s_time: 25 penalty: 0 agent_num: 47 done: False
______________________
id: 46 reward: -0.010531135531135532 service_time: 2428 s_time: 23 penalty: 0 agent_num: 39 done: False
______________________
id: 50 reward: -0.02027027027027027 service_time: 2009 s_time: 42 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: -0.019088669950738917 service_time: 1737 s_time: 31 penalty: 0 agent_num: 29 done: False
______________________
id: 41 reward: -0.025669642857142856 service_time: 2180 s_time: 46 penalty: 0 agent_num: 32 done: False
______________________
id: 43 reward: -0.008116883116883116 service_time: 2031 s_time: 20 penalty: 0 agent_num: 44 done: False
______________________
id: 45 reward: -0.013392857142857142 service_time: 2677 s_time: 21 penalty: 0 agent_num: 28 done: False
______________________
Step:  4064
Pretraining Loss:  tensor(0.0539, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.0016233766233766235 service_time: 1448 s_time: -1 penalty: 0 agent_num: 11 done: False
______________________
id: 55 reward: -0.06785714285714285 service_time: 1490 s_time: 57 penalty: 0 agent_num: 15 done: False
______________________
id: 54 reward: -0.08104395604395605 service_time: 1602 s_time: 59 penalty: 0 agent_num: 13 done: False
______________________
id: 47 reward: 0.037815126050420166 service_time: 448 s_time: -36 penalty: 0 agent_num: 17 done: False
______________________
id: 51 reward: -0.025 service_time: 1033 s_time: 28 penalty: 0 agent_num: 20 done: False
______________________
id: 48 reward: 0.015625 service_time: 2373 s_time: -21 penalty: 0 agent_num: 24 done: False
______________________
id: 41 reward: 0.0 service_time: 2180 s_time: 0 penalty: 0 agent_num: 32 done: False
______________________
id: 53 reward: -0.022167487684729065 service_time: 1773 s_time: 36 penalty: 0 agent_num: 29 done: False
______________________
id: 45 reward: -0.02295918367346939 service_time: 2713 s_time: 36 penalty: 0 agent_num: 28 done: False
______________________
id: 50 reward: 0.0 service_time: 2009 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 40 reward: 0.0 service_time: 1311 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 42 reward: 0.0 service_time: 1951 s_time: 0 penalty: 0 agent_num: 47 done: False
______________________
id: 52 reward: -0.008928571428571428 service_time: 1901 s_time: 16 penalty: 0 agent_num: 32 done: False
______________________
id: 46 reward: -0.005952380952380952 service_time: 2441 s_time: 13 penalty: 0 agent_num: 39 done: False
______________________
id: 44 reward: 0.0 service_time: 1216 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 43 reward: -0.018262987012987012 service_time: 2076 s_time: 45 penalty: 0 agent_num: 44 done: False
______________________
Step:  4080
Pretraining Loss:  tensor(0.0380, device='cuda:0', grad_fn=<MeanBackward0>)
id: 54 reward: 0.0 service_time: 1602 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 49 reward: 0.0 service_time: 1448 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 55 reward: 0.0 service_time: 1490 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 47 reward: 0.0 service_time: 448 s_time: 0 penalty: 0 agent_num: 17 done: False
______________________
id: 48 reward: -0.03422619047619048 service_time: 2419 s_time: 46 penalty: 0 agent_num: 24 done: False
______________________
id: 51 reward: -0.0375 service_time: 1075 s_time: 42 penalty: 0 agent_num: 20 done: False
______________________
id: 46 reward: -0.005952380952380952 service_time: 2454 s_time: 13 penalty: 0 agent_num: 39 done: False
______________________
id: 44 reward: -0.010093167701863354 service_time: 1242 s_time: 26 penalty: 0 agent_num: 46 done: False
______________________
id: 40 reward: -0.017857142857142856 service_time: 1349 s_time: 38 penalty: 0 agent_num: 38 done: False
______________________
id: 52 reward: -0.022879464285714284 service_time: 1942 s_time: 41 penalty: 0 agent_num: 32 done: False
______________________
id: 41 reward: -0.03627232142857143 service_time: 2245 s_time: 65 penalty: 0 agent_num: 32 done: False
______________________
id: 50 reward: -0.020752895752895753 service_time: 2052 s_time: 43 penalty: 0 agent_num: 37 done: False
______________________
id: 42 reward: -0.020516717325227963 service_time: 2005 s_time: 54 penalty: 0 agent_num: 47 done: False
______________________
id: 53 reward: -0.017241379310344827 service_time: 1801 s_time: 28 penalty: 0 agent_num: 29 done: False
______________________
id: 43 reward: 0.0008116883116883117 service_time: 2074 s_time: -2 penalty: 0 agent_num: 44 done: False
______________________
id: 45 reward: -0.018494897959183673 service_time: 2742 s_time: 29 penalty: 0 agent_num: 28 done: False
______________________
Step:  4096
Pretraining Loss:  tensor(0.0450, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.05844155844155844 service_time: 1484 s_time: 36 penalty: 0 agent_num: 11 done: False
______________________
id: 54 reward: -0.08104395604395605 service_time: 1661 s_time: 59 penalty: 0 agent_num: 13 done: False
______________________
id: 47 reward: 0.0 service_time: 448 s_time: 0 penalty: 0 agent_num: 17 done: False
______________________
id: 55 reward: 0.0 service_time: 1490 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 51 reward: 0.0 service_time: 1075 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 53 reward: -0.03017241379310345 service_time: 1850 s_time: 49 penalty: 0 agent_num: 29 done: False
______________________
id: 45 reward: -0.016581632653061226 service_time: 2768 s_time: 26 penalty: 0 agent_num: 28 done: False
______________________
id: 48 reward: -0.06770833333333333 service_time: 2510 s_time: 91 penalty: 0 agent_num: 24 done: False
______________________
id: 50 reward: -0.009652509652509652 service_time: 2072 s_time: 20 penalty: 0 agent_num: 37 done: False
______________________
id: 41 reward: -0.0005580357142857143 service_time: 2246 s_time: 1 penalty: 0 agent_num: 32 done: False
______________________
id: 52 reward: 0.0 service_time: 1942 s_time: 0 penalty: 0 agent_num: 32 done: False
______________________
id: 44 reward: -0.010869565217391304 service_time: 1270 s_time: 28 penalty: 0 agent_num: 46 done: False
______________________
id: 46 reward: -0.016483516483516484 service_time: 2490 s_time: 36 penalty: 0 agent_num: 39 done: False
______________________
id: 40 reward: -0.013157894736842105 service_time: 1377 s_time: 28 penalty: 0 agent_num: 38 done: False
______________________
id: 42 reward: 0.0 service_time: 2005 s_time: 0 penalty: 0 agent_num: 47 done: False
______________________
id: 43 reward: -0.021103896103896104 service_time: 2126 s_time: 52 penalty: 0 agent_num: 44 done: False
______________________
Step:  4112
Pretraining Loss:  tensor(0.0555, device='cuda:0', grad_fn=<MeanBackward0>)
id: 54 reward: 0.028846153846153848 service_time: 1640 s_time: -21 penalty: 0 agent_num: 13 done: False
______________________
id: 49 reward: -0.1525974025974026 service_time: 1578 s_time: 94 penalty: 0 agent_num: 11 done: False
______________________
id: 55 reward: -0.05357142857142857 service_time: 1535 s_time: 45 penalty: 0 agent_num: 15 done: False
______________________
id: 47 reward: -0.04201680672268908 service_time: 488 s_time: 40 penalty: 0 agent_num: 17 done: False
______________________
id: 44 reward: 0.0 service_time: 1270 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 51 reward: -0.03660714285714286 service_time: 1116 s_time: 41 penalty: 0 agent_num: 20 done: False
______________________
id: 40 reward: 0.0 service_time: 1377 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 50 reward: -0.019787644787644786 service_time: 2113 s_time: 41 penalty: 0 agent_num: 37 done: False
______________________
id: 46 reward: -0.014194139194139194 service_time: 2521 s_time: 31 penalty: 0 agent_num: 39 done: False
______________________
id: 42 reward: -0.015197568389057751 service_time: 2045 s_time: 40 penalty: 0 agent_num: 47 done: False
______________________
id: 52 reward: -0.01953125 service_time: 1977 s_time: 35 penalty: 0 agent_num: 32 done: False
______________________
id: 53 reward: -0.034482758620689655 service_time: 1906 s_time: 56 penalty: 0 agent_num: 29 done: False
______________________
id: 48 reward: -0.12946428571428573 service_time: 2684 s_time: 174 penalty: 0 agent_num: 24 done: False
______________________
id: 41 reward: -0.017299107142857144 service_time: 2277 s_time: 31 penalty: 0 agent_num: 32 done: False
______________________
id: 45 reward: -0.0274234693877551 service_time: 2811 s_time: 43 penalty: 0 agent_num: 28 done: False
______________________
id: 43 reward: -0.010551948051948052 service_time: 2152 s_time: 26 penalty: 0 agent_num: 44 done: False
______________________
Step:  4128
Pretraining Loss:  tensor(0.0563, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.0 service_time: 1578 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 54 reward: -0.04120879120879121 service_time: 1670 s_time: 30 penalty: 0 agent_num: 13 done: False
______________________
id: 55 reward: 0.0 service_time: 1535 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 47 reward: 0.0 service_time: 488 s_time: 0 penalty: 0 agent_num: 17 done: False
______________________
id: 50 reward: -0.015926640926640926 service_time: 2146 s_time: 33 penalty: 0 agent_num: 37 done: False
______________________
id: 41 reward: -0.005022321428571429 service_time: 2286 s_time: 9 penalty: 0 agent_num: 32 done: False
______________________
id: 44 reward: -0.02562111801242236 service_time: 1336 s_time: 66 penalty: 0 agent_num: 46 done: False
______________________
id: 51 reward: -0.027678571428571427 service_time: 1147 s_time: 31 penalty: 0 agent_num: 20 done: False
______________________
id: 52 reward: -0.016183035714285716 service_time: 2006 s_time: 29 penalty: 0 agent_num: 32 done: False
______________________
id: 42 reward: 0.0 service_time: 2045 s_time: 0 penalty: 0 agent_num: 47 done: False
______________________
id: 40 reward: -0.013157894736842105 service_time: 1405 s_time: 28 penalty: 0 agent_num: 38 done: False
______________________
id: 45 reward: -0.025510204081632654 service_time: 2851 s_time: 40 penalty: 0 agent_num: 28 done: False
______________________
id: 53 reward: -0.023399014778325122 service_time: 1944 s_time: 38 penalty: 0 agent_num: 29 done: False
______________________
id: 46 reward: -0.005952380952380952 service_time: 2534 s_time: 13 penalty: 0 agent_num: 39 done: False
______________________
id: 48 reward: -0.028273809523809524 service_time: 2722 s_time: 38 penalty: 0 agent_num: 24 done: False
______________________
id: 43 reward: -0.012987012987012988 service_time: 2184 s_time: 32 penalty: 0 agent_num: 44 done: False
______________________
Step:  4144
Pretraining Loss:  tensor(0.0555, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.0 service_time: 1578 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 54 reward: -0.03571428571428571 service_time: 1696 s_time: 26 penalty: 0 agent_num: 13 done: False
______________________
id: 55 reward: 0.0 service_time: 1535 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 47 reward: 0.0273109243697479 service_time: 462 s_time: -26 penalty: 0 agent_num: 17 done: False
______________________
id: 40 reward: 0.0009398496240601503 service_time: 1403 s_time: -2 penalty: 0 agent_num: 38 done: False
______________________
id: 48 reward: -0.07217261904761904 service_time: 2819 s_time: 97 penalty: 0 agent_num: 24 done: False
______________________
id: 51 reward: 0.008035714285714285 service_time: 1138 s_time: -9 penalty: 0 agent_num: 20 done: False
______________________
id: 46 reward: -0.0086996336996337 service_time: 2553 s_time: 19 penalty: 0 agent_num: 39 done: False
______________________
id: 44 reward: -0.006211180124223602 service_time: 1352 s_time: 16 penalty: 0 agent_num: 46 done: False
______________________
id: 41 reward: -0.01171875 service_time: 2307 s_time: 21 penalty: 0 agent_num: 32 done: False
______________________
id: 42 reward: -0.008358662613981762 service_time: 2067 s_time: 22 penalty: 0 agent_num: 47 done: False
______________________
id: 53 reward: 0.0018472906403940886 service_time: 1941 s_time: -3 penalty: 0 agent_num: 29 done: False
______________________
id: 50 reward: -0.008687258687258687 service_time: 2164 s_time: 18 penalty: 0 agent_num: 37 done: False
______________________
id: 52 reward: -0.020647321428571428 service_time: 2043 s_time: 37 penalty: 0 agent_num: 32 done: False
______________________
id: 45 reward: 0.0012755102040816326 service_time: 2849 s_time: -2 penalty: 0 agent_num: 28 done: False
______________________
id: 43 reward: -0.008928571428571428 service_time: 2206 s_time: 22 penalty: 0 agent_num: 44 done: False
______________________
Step:  4160
Pretraining Loss:  tensor(0.0515, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.0 service_time: 1578 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: -0.026260504201680673 service_time: 487 s_time: 25 penalty: 0 agent_num: 17 done: False
______________________
id: 55 reward: -0.05238095238095238 service_time: 1579 s_time: 44 penalty: 0 agent_num: 15 done: False
______________________
id: 54 reward: -0.03021978021978022 service_time: 1718 s_time: 22 penalty: 0 agent_num: 13 done: False
______________________
id: 51 reward: 0.0 service_time: 1138 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 41 reward: -0.015625 service_time: 2335 s_time: 28 penalty: 0 agent_num: 32 done: False
______________________
id: 40 reward: -0.008458646616541353 service_time: 1421 s_time: 18 penalty: 0 agent_num: 38 done: False
______________________
id: 44 reward: -0.006599378881987578 service_time: 1369 s_time: 17 penalty: 0 agent_num: 46 done: False
______________________
id: 52 reward: -0.016741071428571428 service_time: 2073 s_time: 30 penalty: 0 agent_num: 32 done: False
______________________
id: 50 reward: 0.0019305019305019305 service_time: 2160 s_time: -4 penalty: 0 agent_num: 37 done: False
______________________
id: 48 reward: 0.05282738095238095 service_time: 2748 s_time: -71 penalty: 0 agent_num: 24 done: False
______________________
id: 46 reward: -0.01510989010989011 service_time: 2586 s_time: 33 penalty: 0 agent_num: 39 done: False
______________________
id: 42 reward: -0.02127659574468085 service_time: 2123 s_time: 56 penalty: 0 agent_num: 47 done: False
______________________
id: 45 reward: -0.029336734693877552 service_time: 2895 s_time: 46 penalty: 0 agent_num: 28 done: False
______________________
id: 43 reward: 0.0 service_time: 2206 s_time: 0 penalty: 0 agent_num: 44 done: False
______________________
id: 53 reward: -0.046182266009852216 service_time: 2016 s_time: 75 penalty: 0 agent_num: 29 done: False
______________________
Step:  4176
Pretraining Loss:  tensor(0.0539, device='cuda:0', grad_fn=<MeanBackward0>)
id: 54 reward: -0.042582417582417584 service_time: 1749 s_time: 31 penalty: 0 agent_num: 13 done: False
______________________
id: 55 reward: 0.0 service_time: 1579 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 49 reward: -0.09253246753246754 service_time: 1635 s_time: 57 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: -0.0273109243697479 service_time: 513 s_time: 26 penalty: 0 agent_num: 17 done: False
______________________
id: 51 reward: -0.025 service_time: 1166 s_time: 28 penalty: 0 agent_num: 20 done: False
______________________
id: 40 reward: -0.012218045112781954 service_time: 1447 s_time: 26 penalty: 0 agent_num: 38 done: False
______________________
id: 48 reward: 0.019345238095238096 service_time: 2722 s_time: -26 penalty: 0 agent_num: 24 done: False
______________________
id: 46 reward: -0.008241758241758242 service_time: 2604 s_time: 18 penalty: 0 agent_num: 39 done: False
______________________
id: 52 reward: 0.0 service_time: 2073 s_time: 0 penalty: 0 agent_num: 32 done: False
______________________
id: 53 reward: -0.0067733990147783255 service_time: 2027 s_time: 11 penalty: 0 agent_num: 29 done: False
______________________
id: 41 reward: -0.017857142857142856 service_time: 2367 s_time: 32 penalty: 0 agent_num: 32 done: False
______________________
id: 44 reward: -0.002329192546583851 service_time: 1375 s_time: 6 penalty: 0 agent_num: 46 done: False
______________________
id: 50 reward: -0.03523166023166023 service_time: 2233 s_time: 73 penalty: 0 agent_num: 37 done: False
______________________
id: 42 reward: -0.006458966565349544 service_time: 2140 s_time: 17 penalty: 0 agent_num: 47 done: False
______________________
id: 45 reward: 0.0012755102040816326 service_time: 2893 s_time: -2 penalty: 0 agent_num: 28 done: False
______________________
id: 43 reward: -0.016233766233766232 service_time: 2246 s_time: 40 penalty: 0 agent_num: 44 done: False
______________________
Step:  4192
Pretraining Loss:  tensor(0.0497, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.03896103896103896 service_time: 1659 s_time: 24 penalty: 0 agent_num: 11 done: False
______________________
id: 54 reward: 0.0 service_time: 1749 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 55 reward: 0.0 service_time: 1579 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 47 reward: -0.08298319327731092 service_time: 592 s_time: 79 penalty: 0 agent_num: 17 done: False
______________________
id: 51 reward: 0.0 service_time: 1166 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 52 reward: -0.017857142857142856 service_time: 2105 s_time: 32 penalty: 0 agent_num: 32 done: False
______________________
id: 44 reward: 0.0007763975155279503 service_time: 1373 s_time: -2 penalty: 0 agent_num: 46 done: False
______________________
id: 48 reward: 0.023065476190476192 service_time: 2691 s_time: -31 penalty: 0 agent_num: 24 done: False
______________________
id: 40 reward: -0.013157894736842105 service_time: 1475 s_time: 28 penalty: 0 agent_num: 38 done: False
______________________
id: 46 reward: -0.009615384615384616 service_time: 2625 s_time: 21 penalty: 0 agent_num: 39 done: False
______________________
id: 45 reward: -0.026785714285714284 service_time: 2935 s_time: 42 penalty: 0 agent_num: 28 done: False
______________________
id: 50 reward: 0.0 service_time: 2233 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 42 reward: 0.001519756838905775 service_time: 2136 s_time: -4 penalty: 0 agent_num: 47 done: False
______________________
id: 41 reward: -0.022321428571428572 service_time: 2407 s_time: 40 penalty: 0 agent_num: 32 done: False
______________________
id: 43 reward: -0.021915584415584416 service_time: 2300 s_time: 54 penalty: 0 agent_num: 44 done: False
______________________
id: 53 reward: 0.0024630541871921183 service_time: 2023 s_time: -4 penalty: 0 agent_num: 29 done: False
______________________
Step:  4208
Pretraining Loss:  tensor(0.0523, device='cuda:0', grad_fn=<MeanBackward0>)
id: 55 reward: -0.07738095238095238 service_time: 1644 s_time: 65 penalty: 0 agent_num: 15 done: False
______________________
id: 54 reward: 0.0 service_time: 1749 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 49 reward: -0.18668831168831168 service_time: 1774 s_time: 115 penalty: 0 agent_num: 11 done: False
______________________
id: 51 reward: -0.027678571428571427 service_time: 1197 s_time: 31 penalty: 0 agent_num: 20 done: False
______________________
id: 47 reward: -0.0430672268907563 service_time: 633 s_time: 41 penalty: 0 agent_num: 17 done: False
______________________
id: 48 reward: -0.07589285714285714 service_time: 2793 s_time: 102 penalty: 0 agent_num: 24 done: False
______________________
id: 40 reward: 0.0 service_time: 1475 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 52 reward: -0.03459821428571429 service_time: 2167 s_time: 62 penalty: 0 agent_num: 32 done: False
______________________
id: 46 reward: -0.006868131868131868 service_time: 2640 s_time: 15 penalty: 0 agent_num: 39 done: False
______________________
id: 41 reward: -0.010044642857142858 service_time: 2425 s_time: 18 penalty: 0 agent_num: 32 done: False
______________________
id: 53 reward: -0.023399014778325122 service_time: 2061 s_time: 38 penalty: 0 agent_num: 29 done: False
______________________
id: 42 reward: -0.008358662613981762 service_time: 2158 s_time: 22 penalty: 0 agent_num: 47 done: False
______________________
id: 44 reward: -0.01436335403726708 service_time: 1410 s_time: 37 penalty: 0 agent_num: 46 done: False
______________________
id: 45 reward: -0.012755102040816327 service_time: 2955 s_time: 20 penalty: 0 agent_num: 28 done: False
______________________
id: 50 reward: -0.02895752895752896 service_time: 2293 s_time: 60 penalty: 0 agent_num: 37 done: False
______________________
id: 43 reward: 0.0 service_time: 2300 s_time: 0 penalty: 0 agent_num: 44 done: False
______________________
Step:  4224
Pretraining Loss:  tensor(0.0468, device='cuda:0', grad_fn=<MeanBackward0>)
id: 54 reward: -0.013736263736263736 service_time: 1759 s_time: 10 penalty: 0 agent_num: 13 done: False
______________________
id: 55 reward: -0.02142857142857143 service_time: 1662 s_time: 18 penalty: 0 agent_num: 15 done: False
______________________
id: 49 reward: 0.0 service_time: 1774 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: -0.06827731092436974 service_time: 698 s_time: 65 penalty: 0 agent_num: 17 done: False
______________________
id: 51 reward: -0.033035714285714286 service_time: 1234 s_time: 37 penalty: 0 agent_num: 20 done: False
______________________
id: 52 reward: -0.01171875 service_time: 2188 s_time: 21 penalty: 0 agent_num: 32 done: False
______________________
id: 46 reward: -0.01098901098901099 service_time: 2664 s_time: 24 penalty: 0 agent_num: 39 done: False
______________________
id: 45 reward: 0.028698979591836735 service_time: 2910 s_time: -45 penalty: 0 agent_num: 28 done: False
______________________
id: 41 reward: -0.013392857142857142 service_time: 2449 s_time: 24 penalty: 0 agent_num: 32 done: False
______________________
id: 53 reward: 0.0006157635467980296 service_time: 2060 s_time: -1 penalty: 0 agent_num: 29 done: False
______________________
id: 42 reward: -0.014437689969604863 service_time: 2196 s_time: 38 penalty: 0 agent_num: 47 done: False
______________________
id: 48 reward: 0.041666666666666664 service_time: 2737 s_time: -56 penalty: 0 agent_num: 24 done: False
______________________
id: 40 reward: -0.01832706766917293 service_time: 1514 s_time: 39 penalty: 0 agent_num: 38 done: False
______________________
id: 43 reward: -0.020698051948051948 service_time: 2351 s_time: 51 penalty: 0 agent_num: 44 done: False
______________________
id: 44 reward: -0.02096273291925466 service_time: 1464 s_time: 54 penalty: 0 agent_num: 46 done: False
______________________
id: 50 reward: -0.008204633204633204 service_time: 2310 s_time: 17 penalty: 0 agent_num: 37 done: False
______________________
Step:  4240
Pretraining Loss:  tensor(0.0462, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.10551948051948051 service_time: 1709 s_time: -65 penalty: 0 agent_num: 11 done: False
______________________
id: 54 reward: -0.08104395604395605 service_time: 1818 s_time: 59 penalty: 0 agent_num: 13 done: False
______________________
id: 55 reward: 0.0 service_time: 1662 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 47 reward: -0.014705882352941176 service_time: 712 s_time: 14 penalty: 0 agent_num: 17 done: False
______________________
id: 53 reward: -0.03940886699507389 service_time: 2124 s_time: 64 penalty: 0 agent_num: 29 done: False
______________________
id: 40 reward: -0.01268796992481203 service_time: 1541 s_time: 27 penalty: 0 agent_num: 38 done: False
______________________
id: 52 reward: -0.013392857142857142 service_time: 2212 s_time: 24 penalty: 0 agent_num: 32 done: False
______________________
id: 51 reward: -0.04375 service_time: 1283 s_time: 49 penalty: 0 agent_num: 20 done: False
______________________
id: 41 reward: -0.012276785714285714 service_time: 2471 s_time: 22 penalty: 0 agent_num: 32 done: False
______________________
id: 45 reward: -0.026785714285714284 service_time: 2952 s_time: 42 penalty: 0 agent_num: 28 done: False
______________________
id: 42 reward: 0.0 service_time: 2196 s_time: 0 penalty: 0 agent_num: 47 done: False
______________________
id: 48 reward: -0.06101190476190476 service_time: 2819 s_time: 82 penalty: 0 agent_num: 24 done: False
______________________
id: 50 reward: -0.012548262548262547 service_time: 2336 s_time: 26 penalty: 0 agent_num: 37 done: False
______________________
id: 46 reward: -0.019230769230769232 service_time: 2706 s_time: 42 penalty: 0 agent_num: 39 done: False
______________________
id: 44 reward: 0.00038819875776397513 service_time: 1463 s_time: -1 penalty: 0 agent_num: 46 done: False
______________________
id: 43 reward: -0.008928571428571428 service_time: 2373 s_time: 22 penalty: 0 agent_num: 44 done: False
______________________
Step:  4256
Pretraining Loss:  tensor(0.0445, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.03409090909090909 service_time: 1730 s_time: 21 penalty: 0 agent_num: 11 done: False
______________________
id: 54 reward: -0.21153846153846154 service_time: 1972 s_time: 154 penalty: 0 agent_num: 13 done: False
______________________
id: 47 reward: -0.03991596638655462 service_time: 750 s_time: 38 penalty: 0 agent_num: 17 done: False
______________________
id: 55 reward: -0.02857142857142857 service_time: 1686 s_time: 24 penalty: 0 agent_num: 15 done: False
______________________
id: 45 reward: -0.03125 service_time: 3001 s_time: 49 penalty: 0 agent_num: 28 done: False
______________________
id: 52 reward: -0.017299107142857144 service_time: 2243 s_time: 31 penalty: 0 agent_num: 32 done: False
______________________
id: 48 reward: -0.06770833333333333 service_time: 2910 s_time: 91 penalty: 0 agent_num: 24 done: False
______________________
id: 40 reward: -0.011278195488721804 service_time: 1565 s_time: 24 penalty: 0 agent_num: 38 done: False
______________________
id: 51 reward: -0.01607142857142857 service_time: 1301 s_time: 18 penalty: 0 agent_num: 20 done: False
______________________
id: 41 reward: -0.021205357142857144 service_time: 2509 s_time: 38 penalty: 0 agent_num: 32 done: False
______________________
id: 42 reward: -0.02127659574468085 service_time: 2252 s_time: 56 penalty: 0 agent_num: 47 done: False
______________________
id: 53 reward: -0.0067733990147783255 service_time: 2135 s_time: 11 penalty: 0 agent_num: 29 done: False
______________________
id: 46 reward: 0.0004578754578754579 service_time: 2705 s_time: -1 penalty: 0 agent_num: 39 done: False
______________________
id: 43 reward: -0.012175324675324676 service_time: 2403 s_time: 30 penalty: 0 agent_num: 44 done: False
______________________
id: 44 reward: -0.01203416149068323 service_time: 1494 s_time: 31 penalty: 0 agent_num: 46 done: False
______________________
id: 50 reward: -0.013030888030888031 service_time: 2363 s_time: 27 penalty: 0 agent_num: 37 done: False
______________________
Step:  4272
Pretraining Loss:  tensor(0.0445, device='cuda:0', grad_fn=<MeanBackward0>)
id: 55 reward: 0.0 service_time: 1686 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 49 reward: 0.0 service_time: 1730 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: 0.0010504201680672268 service_time: 749 s_time: -1 penalty: 0 agent_num: 17 done: False
______________________
id: 54 reward: 0.005494505494505495 service_time: 1968 s_time: -4 penalty: 0 agent_num: 13 done: False
______________________
id: 51 reward: -0.008035714285714285 service_time: 1310 s_time: 9 penalty: 0 agent_num: 20 done: False
______________________
id: 48 reward: 0.04389880952380952 service_time: 2851 s_time: -59 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: -0.02040816326530612 service_time: 3033 s_time: 32 penalty: 0 agent_num: 28 done: False
______________________
id: 40 reward: -0.011748120300751879 service_time: 1590 s_time: 25 penalty: 0 agent_num: 38 done: False
______________________
id: 41 reward: -0.013392857142857142 service_time: 2533 s_time: 24 penalty: 0 agent_num: 32 done: False
______________________
id: 52 reward: -0.021763392857142856 service_time: 2282 s_time: 39 penalty: 0 agent_num: 32 done: False
______________________
id: 42 reward: -0.0056990881458966565 service_time: 2267 s_time: 15 penalty: 0 agent_num: 47 done: False
______________________
id: 50 reward: 0.0 service_time: 2363 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 46 reward: -0.019688644688644688 service_time: 2748 s_time: 43 penalty: 0 agent_num: 39 done: False
______________________
id: 43 reward: -0.008116883116883116 service_time: 2423 s_time: 20 penalty: 0 agent_num: 44 done: False
______________________
id: 53 reward: -0.01539408866995074 service_time: 2160 s_time: 25 penalty: 0 agent_num: 29 done: False
______________________
id: 44 reward: -0.0015527950310559005 service_time: 1498 s_time: 4 penalty: 0 agent_num: 46 done: False
______________________
Step:  4288
Pretraining Loss:  tensor(0.0397, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.0 service_time: 1730 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 54 reward: -0.06043956043956044 service_time: 2012 s_time: 44 penalty: 0 agent_num: 13 done: False
______________________
id: 47 reward: 0.0 service_time: 749 s_time: 0 penalty: 0 agent_num: 17 done: False
______________________
id: 55 reward: 0.002380952380952381 service_time: 1684 s_time: -2 penalty: 0 agent_num: 15 done: False
______________________
id: 48 reward: 0.025297619047619048 service_time: 2817 s_time: -34 penalty: 0 agent_num: 24 done: False
______________________
id: 51 reward: 0.0 service_time: 1310 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 40 reward: -0.0042293233082706765 service_time: 1599 s_time: 9 penalty: 0 agent_num: 38 done: False
______________________
id: 41 reward: -0.020089285714285716 service_time: 2569 s_time: 36 penalty: 0 agent_num: 32 done: False
______________________
id: 46 reward: -0.005036630036630037 service_time: 2759 s_time: 11 penalty: 0 agent_num: 39 done: False
______________________
id: 45 reward: -0.016581632653061226 service_time: 3059 s_time: 26 penalty: 0 agent_num: 28 done: False
______________________
id: 42 reward: -0.010258358662613981 service_time: 2294 s_time: 27 penalty: 0 agent_num: 47 done: False
______________________
id: 52 reward: -0.013950892857142858 service_time: 2307 s_time: 25 penalty: 0 agent_num: 32 done: False
______________________
id: 43 reward: -0.012175324675324676 service_time: 2453 s_time: 30 penalty: 0 agent_num: 44 done: False
______________________
id: 50 reward: -0.03474903474903475 service_time: 2435 s_time: 72 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: -0.020935960591133004 service_time: 2194 s_time: 34 penalty: 0 agent_num: 29 done: False
______________________
id: 44 reward: -0.029114906832298136 service_time: 1573 s_time: 75 penalty: 0 agent_num: 46 done: False
______________________
Step:  4304
Pretraining Loss:  tensor(0.0412, device='cuda:0', grad_fn=<MeanBackward0>)
id: 54 reward: 0.042582417582417584 service_time: 1981 s_time: -31 penalty: 0 agent_num: 13 done: False
______________________
id: 47 reward: -0.04201680672268908 service_time: 789 s_time: 40 penalty: 0 agent_num: 17 done: False
______________________
id: 49 reward: 0.0 service_time: 1730 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 51 reward: -0.02857142857142857 service_time: 1342 s_time: 32 penalty: 0 agent_num: 20 done: False
______________________
id: 55 reward: -0.1523809523809524 service_time: 1812 s_time: 128 penalty: 0 agent_num: 15 done: False
______________________
id: 48 reward: 0.009672619047619048 service_time: 2804 s_time: -13 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: -0.03826530612244898 service_time: 3119 s_time: 60 penalty: 0 agent_num: 28 done: False
______________________
id: 40 reward: 0.0 service_time: 1599 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 41 reward: -0.011160714285714286 service_time: 2589 s_time: 20 penalty: 0 agent_num: 32 done: False
______________________
id: 52 reward: -0.013950892857142858 service_time: 2332 s_time: 25 penalty: 0 agent_num: 32 done: False
______________________
id: 42 reward: 0.0 service_time: 2294 s_time: 0 penalty: 0 agent_num: 47 done: False
______________________
id: 46 reward: 0.0 service_time: 2759 s_time: 0 penalty: 0 agent_num: 39 done: False
______________________
id: 53 reward: -0.023399014778325122 service_time: 2232 s_time: 38 penalty: 0 agent_num: 29 done: False
______________________
id: 50 reward: -0.012065637065637066 service_time: 2460 s_time: 25 penalty: 0 agent_num: 37 done: False
______________________
id: 43 reward: -0.007711038961038961 service_time: 2472 s_time: 19 penalty: 0 agent_num: 44 done: False
______________________
id: 44 reward: -0.009316770186335404 service_time: 1597 s_time: 24 penalty: 0 agent_num: 46 done: False
______________________
Step:  4320
Pretraining Loss:  tensor(0.0424, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.0 service_time: 1730 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 55 reward: 0.0 service_time: 1812 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 54 reward: 0.02197802197802198 service_time: 1965 s_time: -16 penalty: 0 agent_num: 13 done: False
______________________
id: 48 reward: -0.03050595238095238 service_time: 2845 s_time: 41 penalty: 0 agent_num: 24 done: False
______________________
id: 51 reward: 0.0 service_time: 1342 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 47 reward: 0.0063025210084033615 service_time: 783 s_time: -6 penalty: 0 agent_num: 17 done: False
______________________
id: 41 reward: -0.017857142857142856 service_time: 2621 s_time: 32 penalty: 0 agent_num: 32 done: False
______________________
id: 40 reward: -0.016917293233082706 service_time: 1635 s_time: 36 penalty: 0 agent_num: 38 done: False
______________________
id: 45 reward: -0.0031887755102040817 service_time: 3124 s_time: 5 penalty: 0 agent_num: 28 done: False
______________________
id: 52 reward: -0.016183035714285716 service_time: 2361 s_time: 29 penalty: 0 agent_num: 32 done: False
______________________
id: 46 reward: -0.007783882783882784 service_time: 2776 s_time: 17 penalty: 0 agent_num: 39 done: False
______________________
id: 42 reward: -0.01937689969604863 service_time: 2345 s_time: 51 penalty: 0 agent_num: 47 done: False
______________________
id: 53 reward: 0.020320197044334975 service_time: 2199 s_time: -33 penalty: 0 agent_num: 29 done: False
______________________
id: 43 reward: -0.010551948051948052 service_time: 2498 s_time: 26 penalty: 0 agent_num: 44 done: False
______________________
id: 50 reward: -0.0222007722007722 service_time: 2506 s_time: 46 penalty: 0 agent_num: 37 done: False
______________________
id: 44 reward: -0.010093167701863354 service_time: 1623 s_time: 26 penalty: 0 agent_num: 46 done: False
______________________
Step:  4336
Pretraining Loss:  tensor(0.0531, device='cuda:0', grad_fn=<MeanBackward0>)
id: 54 reward: 0.0 service_time: 1965 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 55 reward: 0.05238095238095238 service_time: 1768 s_time: -44 penalty: 0 agent_num: 15 done: False
______________________
id: 49 reward: 0.0 service_time: 1730 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: 0.01680672268907563 service_time: 767 s_time: -16 penalty: 0 agent_num: 17 done: False
______________________
id: 51 reward: -0.033035714285714286 service_time: 1379 s_time: 37 penalty: 0 agent_num: 20 done: False
______________________
id: 48 reward: 0.0 service_time: 2845 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: -0.015306122448979591 service_time: 3148 s_time: 24 penalty: 0 agent_num: 28 done: False
______________________
id: 41 reward: -0.016741071428571428 service_time: 2651 s_time: 30 penalty: 0 agent_num: 32 done: False
______________________
id: 52 reward: -0.017857142857142856 service_time: 2393 s_time: 32 penalty: 0 agent_num: 32 done: False
______________________
id: 40 reward: -0.013157894736842105 service_time: 1663 s_time: 28 penalty: 0 agent_num: 38 done: False
______________________
id: 46 reward: -0.024267399267399268 service_time: 2829 s_time: 53 penalty: 0 agent_num: 39 done: False
______________________
id: 42 reward: -0.010258358662613981 service_time: 2372 s_time: 27 penalty: 0 agent_num: 47 done: False
______________________
id: 53 reward: 0.01600985221674877 service_time: 2173 s_time: -26 penalty: 0 agent_num: 29 done: False
______________________
id: 50 reward: -0.004343629343629344 service_time: 2515 s_time: 9 penalty: 0 agent_num: 37 done: False
______________________
id: 44 reward: -0.009704968944099378 service_time: 1648 s_time: 25 penalty: 0 agent_num: 46 done: False
______________________
id: 43 reward: -0.012175324675324676 service_time: 2528 s_time: 30 penalty: 0 agent_num: 44 done: False
______________________
Step:  4352
Pretraining Loss:  tensor(0.0461, device='cuda:0', grad_fn=<MeanBackward0>)
id: 55 reward: 0.0 service_time: 1768 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 49 reward: -0.12337662337662338 service_time: 1806 s_time: 76 penalty: 0 agent_num: 11 done: False
______________________
id: 54 reward: 0.0027472527472527475 service_time: 1963 s_time: -2 penalty: 0 agent_num: 13 done: False
______________________
id: 47 reward: -0.04096638655462185 service_time: 806 s_time: 39 penalty: 0 agent_num: 17 done: False
______________________
id: 41 reward: -0.017857142857142856 service_time: 2683 s_time: 32 penalty: 0 agent_num: 32 done: False
______________________
id: 48 reward: 0.003720238095238095 service_time: 2840 s_time: -5 penalty: 0 agent_num: 24 done: False
______________________
id: 51 reward: -0.019642857142857142 service_time: 1401 s_time: 22 penalty: 0 agent_num: 20 done: False
______________________
id: 46 reward: -0.011446886446886446 service_time: 2854 s_time: 25 penalty: 0 agent_num: 39 done: False
______________________
id: 40 reward: 0.00046992481203007516 service_time: 1662 s_time: -1 penalty: 0 agent_num: 38 done: False
______________________
id: 52 reward: 0.0 service_time: 2393 s_time: 0 penalty: 0 agent_num: 32 done: False
______________________
id: 45 reward: 0.008290816326530613 service_time: 3135 s_time: -13 penalty: 0 agent_num: 28 done: False
______________________
id: 42 reward: -0.008738601823708206 service_time: 2395 s_time: 23 penalty: 0 agent_num: 47 done: False
______________________
id: 50 reward: -0.011583011583011582 service_time: 2539 s_time: 24 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: -0.020320197044334975 service_time: 2206 s_time: 33 penalty: 0 agent_num: 29 done: False
______________________
id: 43 reward: 0.0 service_time: 2528 s_time: 0 penalty: 0 agent_num: 44 done: False
______________________
id: 44 reward: -0.009316770186335404 service_time: 1672 s_time: 24 penalty: 0 agent_num: 46 done: False
______________________
Step:  4368
Pretraining Loss:  tensor(0.0443, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.275974025974026 service_time: 1976 s_time: 170 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: -0.0273109243697479 service_time: 832 s_time: 26 penalty: 0 agent_num: 17 done: False
______________________
id: 54 reward: -0.08379120879120878 service_time: 2024 s_time: 61 penalty: 0 agent_num: 13 done: False
______________________
id: 51 reward: 0.0 service_time: 1401 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 55 reward: -0.08214285714285714 service_time: 1837 s_time: 69 penalty: 0 agent_num: 15 done: False
______________________
id: 48 reward: -0.06324404761904762 service_time: 2925 s_time: 85 penalty: 0 agent_num: 24 done: False
______________________
id: 41 reward: -0.017857142857142856 service_time: 2715 s_time: 32 penalty: 0 agent_num: 32 done: False
______________________
id: 52 reward: -0.012834821428571428 service_time: 2416 s_time: 23 penalty: 0 agent_num: 32 done: False
______________________
id: 50 reward: -0.01833976833976834 service_time: 2577 s_time: 38 penalty: 0 agent_num: 37 done: False
______________________
id: 46 reward: -0.0086996336996337 service_time: 2873 s_time: 19 penalty: 0 agent_num: 39 done: False
______________________
id: 42 reward: -0.008738601823708206 service_time: 2418 s_time: 23 penalty: 0 agent_num: 47 done: False
______________________
id: 40 reward: -0.005169172932330827 service_time: 1673 s_time: 11 penalty: 0 agent_num: 38 done: False
______________________
id: 45 reward: -0.058673469387755105 service_time: 3227 s_time: 92 penalty: 0 agent_num: 28 done: False
______________________
id: 44 reward: 0.0019409937888198758 service_time: 1667 s_time: -5 penalty: 0 agent_num: 46 done: False
______________________
id: 43 reward: -0.0174512987012987 service_time: 2571 s_time: 43 penalty: 0 agent_num: 44 done: False
______________________
id: 53 reward: 0.0012315270935960591 service_time: 2204 s_time: -2 penalty: 0 agent_num: 29 done: False
______________________
Step:  4384
Pretraining Loss:  tensor(0.0399, device='cuda:0', grad_fn=<MeanBackward0>)
id: 47 reward: 0.011554621848739496 service_time: 821 s_time: -11 penalty: 0 agent_num: 17 done: False
______________________
id: 54 reward: -0.0673076923076923 service_time: 2073 s_time: 49 penalty: 0 agent_num: 13 done: False
______________________
id: 49 reward: 0.0 service_time: 1976 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 55 reward: 0.0 service_time: 1837 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 48 reward: -0.06696428571428571 service_time: 3015 s_time: 90 penalty: 0 agent_num: 24 done: False
______________________
id: 51 reward: -0.03660714285714286 service_time: 1442 s_time: 41 penalty: 0 agent_num: 20 done: False
______________________
id: 52 reward: -0.011160714285714286 service_time: 2436 s_time: 20 penalty: 0 agent_num: 32 done: False
______________________
id: 40 reward: -0.01268796992481203 service_time: 1700 s_time: 27 penalty: 0 agent_num: 38 done: False
______________________
id: 53 reward: -0.062192118226600986 service_time: 2305 s_time: 101 penalty: 0 agent_num: 29 done: False
______________________
id: 41 reward: -0.025669642857142856 service_time: 2761 s_time: 46 penalty: 0 agent_num: 32 done: False
______________________
id: 46 reward: -0.01282051282051282 service_time: 2901 s_time: 28 penalty: 0 agent_num: 39 done: False
______________________
id: 50 reward: 0.0 service_time: 2577 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 42 reward: -0.003799392097264438 service_time: 2428 s_time: 10 penalty: 0 agent_num: 47 done: False
______________________
id: 43 reward: -0.011363636363636364 service_time: 2599 s_time: 28 penalty: 0 agent_num: 44 done: False
______________________
id: 45 reward: 0.008928571428571428 service_time: 3213 s_time: -14 penalty: 0 agent_num: 28 done: False
______________________
id: 44 reward: -0.020574534161490684 service_time: 1720 s_time: 53 penalty: 0 agent_num: 46 done: False
______________________
Step:  4400
Pretraining Loss:  tensor(0.0466, device='cuda:0', grad_fn=<MeanBackward0>)
id: 55 reward: 0.0 service_time: 1837 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 49 reward: 0.0 service_time: 1976 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: 0.0 service_time: 821 s_time: 0 penalty: 0 agent_num: 17 done: False
______________________
id: 54 reward: 0.0 service_time: 2073 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 51 reward: 0.0 service_time: 1442 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 48 reward: -0.078125 service_time: 3120 s_time: 105 penalty: 0 agent_num: 24 done: False
______________________
id: 40 reward: 0.0 service_time: 1700 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 41 reward: 0.004464285714285714 service_time: 2753 s_time: -8 penalty: 0 agent_num: 32 done: False
______________________
id: 46 reward: -0.00641025641025641 service_time: 2915 s_time: 14 penalty: 0 agent_num: 39 done: False
______________________
id: 42 reward: 0.0 service_time: 2428 s_time: 0 penalty: 0 agent_num: 47 done: False
______________________
id: 53 reward: 0.0024630541871921183 service_time: 2301 s_time: -4 penalty: 0 agent_num: 29 done: False
______________________
id: 50 reward: -0.03909266409266409 service_time: 2658 s_time: 81 penalty: 0 agent_num: 37 done: False
______________________
id: 43 reward: 0.00040584415584415587 service_time: 2598 s_time: -1 penalty: 0 agent_num: 44 done: False
______________________
id: 45 reward: -0.029336734693877552 service_time: 3259 s_time: 46 penalty: 0 agent_num: 28 done: False
______________________
id: 52 reward: -0.02734375 service_time: 2485 s_time: 49 penalty: 0 agent_num: 32 done: False
______________________
id: 44 reward: -0.006987577639751553 service_time: 1738 s_time: 18 penalty: 0 agent_num: 46 done: False
______________________
Step:  4416
Pretraining Loss:  tensor(0.0440, device='cuda:0', grad_fn=<MeanBackward0>)
id: 54 reward: 0.0 service_time: 2073 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 47 reward: -0.02415966386554622 service_time: 844 s_time: 23 penalty: 0 agent_num: 17 done: False
______________________
id: 49 reward: -0.022727272727272728 service_time: 1990 s_time: 14 penalty: 0 agent_num: 11 done: False
______________________
id: 55 reward: -0.12261904761904761 service_time: 1940 s_time: 103 penalty: 0 agent_num: 15 done: False
______________________
id: 48 reward: -0.012648809523809524 service_time: 3137 s_time: 17 penalty: 0 agent_num: 24 done: False
______________________
id: 51 reward: 0.0 service_time: 1442 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 46 reward: -0.014194139194139194 service_time: 2946 s_time: 31 penalty: 0 agent_num: 39 done: False
______________________
id: 40 reward: -0.008458646616541353 service_time: 1718 s_time: 18 penalty: 0 agent_num: 38 done: False
______________________
id: 53 reward: -0.02770935960591133 service_time: 2346 s_time: 45 penalty: 0 agent_num: 29 done: False
______________________
id: 50 reward: -0.015926640926640926 service_time: 2691 s_time: 33 penalty: 0 agent_num: 37 done: False
______________________
id: 41 reward: -0.03404017857142857 service_time: 2814 s_time: 61 penalty: 0 agent_num: 32 done: False
______________________
id: 52 reward: -0.025111607142857144 service_time: 2530 s_time: 45 penalty: 0 agent_num: 32 done: False
______________________
id: 42 reward: -0.011018237082066869 service_time: 2457 s_time: 29 penalty: 0 agent_num: 47 done: False
______________________
id: 43 reward: -0.006087662337662338 service_time: 2613 s_time: 15 penalty: 0 agent_num: 44 done: False
______________________
id: 45 reward: -0.01913265306122449 service_time: 3289 s_time: 30 penalty: 0 agent_num: 28 done: False
______________________
id: 44 reward: -0.010093167701863354 service_time: 1764 s_time: 26 penalty: 0 agent_num: 46 done: False
______________________
Step:  4432
Pretraining Loss:  tensor(0.0471, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.003246753246753247 service_time: 1988 s_time: -2 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: 0.0 service_time: 844 s_time: 0 penalty: 0 agent_num: 17 done: False
______________________
id: 54 reward: 0.0 service_time: 2073 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 55 reward: -0.12857142857142856 service_time: 2048 s_time: 108 penalty: 0 agent_num: 15 done: False
______________________
id: 48 reward: 0.0 service_time: 3137 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 40 reward: 0.0 service_time: 1718 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 51 reward: -0.029464285714285714 service_time: 1475 s_time: 33 penalty: 0 agent_num: 20 done: False
______________________
id: 46 reward: -0.0004578754578754579 service_time: 2947 s_time: 1 penalty: 0 agent_num: 39 done: False
______________________
id: 41 reward: -0.01953125 service_time: 2849 s_time: 35 penalty: 0 agent_num: 32 done: False
______________________
id: 42 reward: -0.014817629179331307 service_time: 2496 s_time: 39 penalty: 0 agent_num: 47 done: False
______________________
id: 43 reward: -0.01176948051948052 service_time: 2642 s_time: 29 penalty: 0 agent_num: 44 done: False
______________________
id: 45 reward: -0.009566326530612245 service_time: 3304 s_time: 15 penalty: 0 agent_num: 28 done: False
______________________
id: 52 reward: 0.0 service_time: 2530 s_time: 0 penalty: 0 agent_num: 32 done: False
______________________
id: 50 reward: -0.019305019305019305 service_time: 2731 s_time: 40 penalty: 0 agent_num: 37 done: False
______________________
id: 44 reward: -0.0011645962732919255 service_time: 1767 s_time: 3 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: -0.0018472906403940886 service_time: 2349 s_time: 3 penalty: 0 agent_num: 29 done: False
______________________
Step:  4448
Pretraining Loss:  tensor(0.0410, device='cuda:0', grad_fn=<MeanBackward0>)
id: 54 reward: 0.009615384615384616 service_time: 2066 s_time: -7 penalty: 0 agent_num: 13 done: False
______________________
id: 49 reward: -0.037337662337662336 service_time: 2011 s_time: 23 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: 0.0 service_time: 844 s_time: 0 penalty: 0 agent_num: 17 done: False
______________________
id: 55 reward: 0.10833333333333334 service_time: 1957 s_time: -91 penalty: 0 agent_num: 15 done: False
______________________
id: 51 reward: -0.03214285714285714 service_time: 1511 s_time: 36 penalty: 0 agent_num: 20 done: False
______________________
id: 48 reward: 0.019345238095238096 service_time: 3111 s_time: -26 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: -0.001913265306122449 service_time: 3307 s_time: 3 penalty: 0 agent_num: 28 done: False
______________________
id: 40 reward: -0.01268796992481203 service_time: 1745 s_time: 27 penalty: 0 agent_num: 38 done: False
______________________
id: 41 reward: -0.013950892857142858 service_time: 2874 s_time: 25 penalty: 0 agent_num: 32 done: False
______________________
id: 50 reward: -0.015444015444015444 service_time: 2763 s_time: 32 penalty: 0 agent_num: 37 done: False
______________________
id: 46 reward: -0.040293040293040296 service_time: 3035 s_time: 88 penalty: 0 agent_num: 39 done: False
______________________
id: 42 reward: -0.017857142857142856 service_time: 2543 s_time: 47 penalty: 0 agent_num: 47 done: False
______________________
id: 43 reward: -0.024350649350649352 service_time: 2702 s_time: 60 penalty: 0 agent_num: 44 done: False
______________________
id: 53 reward: -0.05295566502463054 service_time: 2435 s_time: 86 penalty: 0 agent_num: 29 done: False
______________________
id: 52 reward: -0.056919642857142856 service_time: 2632 s_time: 102 penalty: 0 agent_num: 32 done: False
______________________
id: 44 reward: -0.018633540372670808 service_time: 1815 s_time: 48 penalty: 0 agent_num: 46 done: False
______________________
Step:  4464
Pretraining Loss:  tensor(0.0368, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.0 service_time: 2011 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: 0.0 service_time: 844 s_time: 0 penalty: 0 agent_num: 17 done: False
______________________
id: 55 reward: -0.030952380952380953 service_time: 1983 s_time: 26 penalty: 0 agent_num: 15 done: False
______________________
id: 54 reward: -0.08653846153846154 service_time: 2129 s_time: 63 penalty: 0 agent_num: 13 done: False
______________________
id: 41 reward: -0.025111607142857144 service_time: 2919 s_time: 45 penalty: 0 agent_num: 32 done: False
______________________
id: 48 reward: -0.02976190476190476 service_time: 3151 s_time: 40 penalty: 0 agent_num: 24 done: False
______________________
id: 51 reward: -0.011607142857142858 service_time: 1524 s_time: 13 penalty: 0 agent_num: 20 done: False
______________________
id: 40 reward: -0.015037593984962405 service_time: 1777 s_time: 32 penalty: 0 agent_num: 38 done: False
______________________
id: 53 reward: -0.05357142857142857 service_time: 2522 s_time: 87 penalty: 0 agent_num: 29 done: False
______________________
id: 46 reward: -0.0086996336996337 service_time: 3054 s_time: 19 penalty: 0 agent_num: 39 done: False
______________________
id: 45 reward: 0.0 service_time: 3307 s_time: 0 penalty: 0 agent_num: 28 done: False
______________________
id: 43 reward: -0.012987012987012988 service_time: 2734 s_time: 32 penalty: 0 agent_num: 44 done: False
______________________
id: 50 reward: -0.010135135135135136 service_time: 2784 s_time: 21 penalty: 0 agent_num: 37 done: False
______________________
id: 42 reward: -0.012917933130699088 service_time: 2577 s_time: 34 penalty: 0 agent_num: 47 done: False
______________________
id: 44 reward: -0.005046583850931677 service_time: 1828 s_time: 13 penalty: 0 agent_num: 46 done: False
______________________
id: 52 reward: -0.00390625 service_time: 2639 s_time: 7 penalty: 0 agent_num: 32 done: False
______________________
Step:  4480
Pretraining Loss:  tensor(0.0408, device='cuda:0', grad_fn=<MeanBackward0>)
id: 54 reward: -0.15521978021978022 service_time: 2242 s_time: 113 penalty: 0 agent_num: 13 done: False
______________________
id: 55 reward: -0.04880952380952381 service_time: 2024 s_time: 41 penalty: 0 agent_num: 15 done: False
______________________
id: 49 reward: 0.0 service_time: 2011 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: -0.031512605042016806 service_time: 874 s_time: 30 penalty: 0 agent_num: 17 done: False
______________________
id: 51 reward: 0.0 service_time: 1524 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 48 reward: -0.004464285714285714 service_time: 3157 s_time: 6 penalty: 0 agent_num: 24 done: False
______________________
id: 50 reward: -0.017857142857142856 service_time: 2821 s_time: 37 penalty: 0 agent_num: 37 done: False
______________________
id: 43 reward: -0.007305194805194805 service_time: 2752 s_time: 18 penalty: 0 agent_num: 44 done: False
______________________
id: 46 reward: 0.0 service_time: 3054 s_time: 0 penalty: 0 agent_num: 39 done: False
______________________
id: 40 reward: 0.0009398496240601503 service_time: 1775 s_time: -2 penalty: 0 agent_num: 38 done: False
______________________
id: 41 reward: 0.0 service_time: 2919 s_time: 0 penalty: 0 agent_num: 32 done: False
______________________
id: 45 reward: -0.03380102040816327 service_time: 3360 s_time: 53 penalty: 0 agent_num: 28 done: False
______________________
id: 44 reward: 0.0 service_time: 1828 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 42 reward: -0.013677811550151976 service_time: 2613 s_time: 36 penalty: 0 agent_num: 47 done: False
______________________
id: 52 reward: -0.011160714285714286 service_time: 2659 s_time: 20 penalty: 0 agent_num: 32 done: False
______________________
id: 53 reward: -0.03940886699507389 service_time: 2586 s_time: 64 penalty: 0 agent_num: 29 done: False
______________________
Step:  4496
Pretraining Loss:  tensor(0.0436, device='cuda:0', grad_fn=<MeanBackward0>)
id: 47 reward: -0.01995798319327731 service_time: 893 s_time: 19 penalty: 0 agent_num: 17 done: False
______________________
id: 49 reward: -0.16558441558441558 service_time: 2113 s_time: 102 penalty: 0 agent_num: 11 done: False
______________________
id: 55 reward: -0.08095238095238096 service_time: 2092 s_time: 68 penalty: 0 agent_num: 15 done: False
______________________
id: 54 reward: -0.30631868131868134 service_time: 2465 s_time: 223 penalty: 0 agent_num: 13 done: False
______________________
id: 48 reward: 0.009672619047619048 service_time: 3144 s_time: -13 penalty: 0 agent_num: 24 done: False
______________________
id: 51 reward: -0.026785714285714284 service_time: 1554 s_time: 30 penalty: 0 agent_num: 20 done: False
______________________
id: 40 reward: -0.010808270676691729 service_time: 1798 s_time: 23 penalty: 0 agent_num: 38 done: False
______________________
id: 43 reward: -0.013392857142857142 service_time: 2785 s_time: 33 penalty: 0 agent_num: 44 done: False
______________________
id: 41 reward: -0.015625 service_time: 2947 s_time: 28 penalty: 0 agent_num: 32 done: False
______________________
id: 46 reward: -0.03388278388278388 service_time: 3128 s_time: 74 penalty: 0 agent_num: 39 done: False
______________________
id: 52 reward: 0.0 service_time: 2659 s_time: 0 penalty: 0 agent_num: 32 done: False
______________________
id: 50 reward: -0.013030888030888031 service_time: 2848 s_time: 27 penalty: 0 agent_num: 37 done: False
______________________
id: 42 reward: -0.01405775075987842 service_time: 2650 s_time: 37 penalty: 0 agent_num: 47 done: False
______________________
id: 44 reward: -0.006987577639751553 service_time: 1846 s_time: 18 penalty: 0 agent_num: 46 done: False
______________________
id: 45 reward: -0.036989795918367346 service_time: 3418 s_time: 58 penalty: 0 agent_num: 28 done: False
______________________
id: 53 reward: 0.01416256157635468 service_time: 2563 s_time: -23 penalty: 0 agent_num: 29 done: False
______________________
Step:  4512
Pretraining Loss:  tensor(0.0394, device='cuda:0', grad_fn=<MeanBackward0>)
id: 55 reward: -0.041666666666666664 service_time: 2127 s_time: 35 penalty: 0 agent_num: 15 done: False
______________________
id: 47 reward: -0.03991596638655462 service_time: 931 s_time: 38 penalty: 0 agent_num: 17 done: False
______________________
id: 49 reward: 0.0 service_time: 2113 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 54 reward: -0.13324175824175824 service_time: 2562 s_time: 97 penalty: 0 agent_num: 13 done: False
______________________
id: 48 reward: -0.022321428571428572 service_time: 3174 s_time: 30 penalty: 0 agent_num: 24 done: False
______________________
id: 51 reward: 0.008928571428571428 service_time: 1544 s_time: -10 penalty: 0 agent_num: 20 done: False
______________________
id: 40 reward: 0.0 service_time: 1798 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 50 reward: -0.012065637065637066 service_time: 2873 s_time: 25 penalty: 0 agent_num: 37 done: False
______________________
id: 41 reward: -0.025669642857142856 service_time: 2993 s_time: 46 penalty: 0 agent_num: 32 done: False
______________________
id: 46 reward: -0.010531135531135532 service_time: 3151 s_time: 23 penalty: 0 agent_num: 39 done: False
______________________
id: 42 reward: 0.0 service_time: 2650 s_time: 0 penalty: 0 agent_num: 47 done: False
______________________
id: 44 reward: -0.018245341614906832 service_time: 1893 s_time: 47 penalty: 0 agent_num: 46 done: False
______________________
id: 45 reward: -0.0274234693877551 service_time: 3461 s_time: 43 penalty: 0 agent_num: 28 done: False
______________________
id: 53 reward: -0.03078817733990148 service_time: 2613 s_time: 50 penalty: 0 agent_num: 29 done: False
______________________
id: 43 reward: -0.007305194805194805 service_time: 2803 s_time: 18 penalty: 0 agent_num: 44 done: False
______________________
id: 52 reward: -0.03236607142857143 service_time: 2717 s_time: 58 penalty: 0 agent_num: 32 done: False
______________________
Step:  4528
Pretraining Loss:  tensor(0.0429, device='cuda:0', grad_fn=<MeanBackward0>)
id: 47 reward: -0.04201680672268908 service_time: 971 s_time: 40 penalty: 0 agent_num: 17 done: False
______________________
id: 49 reward: 0.0 service_time: 2113 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 54 reward: 0.0 service_time: 2562 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 55 reward: 0.007142857142857143 service_time: 2121 s_time: -6 penalty: 0 agent_num: 15 done: False
______________________
id: 48 reward: 0.010416666666666666 service_time: 3160 s_time: -14 penalty: 0 agent_num: 24 done: False
______________________
id: 51 reward: -0.033928571428571426 service_time: 1582 s_time: 38 penalty: 0 agent_num: 20 done: False
______________________
id: 40 reward: -0.007988721804511278 service_time: 1815 s_time: 17 penalty: 0 agent_num: 38 done: False
______________________
id: 50 reward: -0.0019305019305019305 service_time: 2877 s_time: 4 penalty: 0 agent_num: 37 done: False
______________________
id: 43 reward: -0.010957792207792208 service_time: 2830 s_time: 27 penalty: 0 agent_num: 44 done: False
______________________
id: 52 reward: -0.010044642857142858 service_time: 2735 s_time: 18 penalty: 0 agent_num: 32 done: False
______________________
id: 45 reward: -0.00701530612244898 service_time: 3472 s_time: 11 penalty: 0 agent_num: 28 done: False
______________________
id: 44 reward: -0.011645962732919254 service_time: 1923 s_time: 30 penalty: 0 agent_num: 46 done: False
______________________
id: 41 reward: -0.010044642857142858 service_time: 3011 s_time: 18 penalty: 0 agent_num: 32 done: False
______________________
id: 46 reward: -0.017857142857142856 service_time: 3190 s_time: 39 penalty: 0 agent_num: 39 done: False
______________________
id: 42 reward: -0.02621580547112462 service_time: 2719 s_time: 69 penalty: 0 agent_num: 47 done: False
______________________
id: 53 reward: -0.03571428571428571 service_time: 2671 s_time: 58 penalty: 0 agent_num: 29 done: False
______________________
Step:  4544
Pretraining Loss:  tensor(0.0379, device='cuda:0', grad_fn=<MeanBackward0>)
id: 54 reward: 0.0 service_time: 2562 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 47 reward: -0.03991596638655462 service_time: 1009 s_time: 38 penalty: 0 agent_num: 17 done: False
______________________
id: 55 reward: 0.0 service_time: 2121 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 49 reward: 0.0 service_time: 2113 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 51 reward: -0.02857142857142857 service_time: 1614 s_time: 32 penalty: 0 agent_num: 20 done: False
______________________
id: 48 reward: -0.03273809523809524 service_time: 3204 s_time: 44 penalty: 0 agent_num: 24 done: False
______________________
id: 41 reward: -0.025111607142857144 service_time: 3056 s_time: 45 penalty: 0 agent_num: 32 done: False
______________________
id: 50 reward: -0.009652509652509652 service_time: 2897 s_time: 20 penalty: 0 agent_num: 37 done: False
______________________
id: 40 reward: -0.011278195488721804 service_time: 1839 s_time: 24 penalty: 0 agent_num: 38 done: False
______________________
id: 43 reward: -0.004464285714285714 service_time: 2841 s_time: 11 penalty: 0 agent_num: 44 done: False
______________________
id: 44 reward: 0.0 service_time: 1923 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 45 reward: -0.025510204081632654 service_time: 3512 s_time: 40 penalty: 0 agent_num: 28 done: False
______________________
id: 42 reward: -0.010258358662613981 service_time: 2746 s_time: 27 penalty: 0 agent_num: 47 done: False
______________________
id: 53 reward: -0.0006157635467980296 service_time: 2672 s_time: 1 penalty: 0 agent_num: 29 done: False
______________________
id: 46 reward: 0.0009157509157509158 service_time: 3188 s_time: -2 penalty: 0 agent_num: 39 done: False
______________________
id: 52 reward: -0.008370535714285714 service_time: 2750 s_time: 15 penalty: 0 agent_num: 32 done: False
______________________
Step:  4560
Pretraining Loss:  tensor(0.0404, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.027597402597402596 service_time: 2130 s_time: 17 penalty: 0 agent_num: 11 done: False
______________________
id: 55 reward: -0.1357142857142857 service_time: 2235 s_time: 114 penalty: 0 agent_num: 15 done: False
______________________
id: 47 reward: 0.0 service_time: 1009 s_time: 0 penalty: 0 agent_num: 17 done: False
______________________
id: 54 reward: 0.0 service_time: 2562 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 48 reward: -0.033482142857142856 service_time: 3249 s_time: 45 penalty: 0 agent_num: 24 done: False
______________________
id: 40 reward: 0.0014097744360902255 service_time: 1836 s_time: -3 penalty: 0 agent_num: 38 done: False
______________________
id: 51 reward: -0.019642857142857142 service_time: 1636 s_time: 22 penalty: 0 agent_num: 20 done: False
______________________
id: 43 reward: -0.0036525974025974025 service_time: 2850 s_time: 9 penalty: 0 agent_num: 44 done: False
______________________
id: 41 reward: -0.014508928571428572 service_time: 3082 s_time: 26 penalty: 0 agent_num: 32 done: False
______________________
id: 52 reward: 0.002232142857142857 service_time: 2746 s_time: -4 penalty: 0 agent_num: 32 done: False
______________________
id: 50 reward: -0.013513513513513514 service_time: 2925 s_time: 28 penalty: 0 agent_num: 37 done: False
______________________
id: 44 reward: -0.008540372670807454 service_time: 1945 s_time: 22 penalty: 0 agent_num: 46 done: False
______________________
id: 42 reward: -0.005319148936170213 service_time: 2760 s_time: 14 penalty: 0 agent_num: 47 done: False
______________________
id: 45 reward: 0.0 service_time: 3512 s_time: 0 penalty: 0 agent_num: 28 done: False
______________________
id: 46 reward: -0.02564102564102564 service_time: 3244 s_time: 56 penalty: 0 agent_num: 39 done: False
______________________
id: 53 reward: 0.0166256157635468 service_time: 2645 s_time: -27 penalty: 0 agent_num: 29 done: False
______________________
Step:  4576
Pretraining Loss:  tensor(0.0369, device='cuda:0', grad_fn=<MeanBackward0>)
id: 54 reward: 0.125 service_time: 2471 s_time: -91 penalty: 0 agent_num: 13 done: False
______________________
id: 47 reward: 0.03466386554621849 service_time: 976 s_time: -33 penalty: 0 agent_num: 17 done: False
______________________
id: 49 reward: -0.04220779220779221 service_time: 2156 s_time: 26 penalty: 0 agent_num: 11 done: False
______________________
id: 55 reward: 0.0 service_time: 2235 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 51 reward: 0.0 service_time: 1636 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 48 reward: 0.0 service_time: 3249 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 40 reward: -0.01550751879699248 service_time: 1869 s_time: 33 penalty: 0 agent_num: 38 done: False
______________________
id: 41 reward: -0.010044642857142858 service_time: 3100 s_time: 18 penalty: 0 agent_num: 32 done: False
______________________
id: 50 reward: -0.00723938223938224 service_time: 2940 s_time: 15 penalty: 0 agent_num: 37 done: False
______________________
id: 43 reward: -0.008522727272727272 service_time: 2871 s_time: 21 penalty: 0 agent_num: 44 done: False
______________________
id: 52 reward: -0.032924107142857144 service_time: 2805 s_time: 59 penalty: 0 agent_num: 32 done: False
______________________
id: 53 reward: -0.022167487684729065 service_time: 2681 s_time: 36 penalty: 0 agent_num: 29 done: False
______________________
id: 45 reward: -0.03316326530612245 service_time: 3564 s_time: 52 penalty: 0 agent_num: 28 done: False
______________________
id: 44 reward: -0.01125776397515528 service_time: 1974 s_time: 29 penalty: 0 agent_num: 46 done: False
______________________
id: 46 reward: -0.004578754578754579 service_time: 3254 s_time: 10 penalty: 0 agent_num: 39 done: False
______________________
id: 42 reward: -0.013297872340425532 service_time: 2795 s_time: 35 penalty: 0 agent_num: 47 done: False
______________________
Step:  4592
Pretraining Loss:  tensor(0.0379, device='cuda:0', grad_fn=<MeanBackward0>)
id: 47 reward: 0.0021008403361344537 service_time: 974 s_time: -2 penalty: 0 agent_num: 17 done: False
______________________
id: 54 reward: -0.04395604395604396 service_time: 2503 s_time: 32 penalty: 0 agent_num: 13 done: False
______________________
id: 55 reward: 0.016666666666666666 service_time: 2221 s_time: -14 penalty: 0 agent_num: 15 done: False
______________________
id: 49 reward: -0.07142857142857142 service_time: 2200 s_time: 44 penalty: 0 agent_num: 11 done: False
______________________
id: 51 reward: -0.029464285714285714 service_time: 1669 s_time: 33 penalty: 0 agent_num: 20 done: False
______________________
id: 48 reward: -0.03720238095238095 service_time: 3299 s_time: 50 penalty: 0 agent_num: 24 done: False
______________________
id: 40 reward: -0.01362781954887218 service_time: 1898 s_time: 29 penalty: 0 agent_num: 38 done: False
______________________
id: 41 reward: -0.015625 service_time: 3128 s_time: 28 penalty: 0 agent_num: 32 done: False
______________________
id: 43 reward: -0.01461038961038961 service_time: 2907 s_time: 36 penalty: 0 agent_num: 44 done: False
______________________
id: 50 reward: -0.017374517374517374 service_time: 2976 s_time: 36 penalty: 0 agent_num: 37 done: False
______________________
id: 45 reward: -0.015306122448979591 service_time: 3588 s_time: 24 penalty: 0 agent_num: 28 done: False
______________________
id: 44 reward: 0.0 service_time: 1974 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 42 reward: -0.012917933130699088 service_time: 2829 s_time: 34 penalty: 0 agent_num: 47 done: False
______________________
id: 52 reward: -0.028459821428571428 service_time: 2856 s_time: 51 penalty: 0 agent_num: 32 done: False
______________________
id: 53 reward: -0.033866995073891626 service_time: 2736 s_time: 55 penalty: 0 agent_num: 29 done: False
______________________
id: 46 reward: -0.023809523809523808 service_time: 3306 s_time: 52 penalty: 0 agent_num: 39 done: False
______________________
Step:  4608
Pretraining Loss:  tensor(0.0374, device='cuda:0', grad_fn=<MeanBackward0>)
id: 47 reward: 0.0 service_time: 974 s_time: 0 penalty: 0 agent_num: 17 done: False
______________________
id: 54 reward: -0.03296703296703297 service_time: 2527 s_time: 24 penalty: 0 agent_num: 13 done: False
______________________
id: 55 reward: -0.047619047619047616 service_time: 2261 s_time: 40 penalty: 0 agent_num: 15 done: False
______________________
id: 49 reward: -0.19480519480519481 service_time: 2320 s_time: 120 penalty: 0 agent_num: 11 done: False
______________________
id: 51 reward: -0.020535714285714286 service_time: 1692 s_time: 23 penalty: 0 agent_num: 20 done: False
______________________
id: 48 reward: -0.025297619047619048 service_time: 3333 s_time: 34 penalty: 0 agent_num: 24 done: False
______________________
id: 40 reward: 0.0 service_time: 1898 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 52 reward: -0.009486607142857142 service_time: 2873 s_time: 17 penalty: 0 agent_num: 32 done: False
______________________
id: 45 reward: -0.007653061224489796 service_time: 3600 s_time: 12 penalty: 0 agent_num: 28 done: False
______________________
id: 41 reward: -0.016741071428571428 service_time: 3158 s_time: 30 penalty: 0 agent_num: 32 done: False
______________________
id: 44 reward: -0.011645962732919254 service_time: 2004 s_time: 30 penalty: 0 agent_num: 46 done: False
______________________
id: 43 reward: -0.018262987012987012 service_time: 2952 s_time: 45 penalty: 0 agent_num: 44 done: False
______________________
id: 53 reward: 0.0006157635467980296 service_time: 2735 s_time: -1 penalty: 0 agent_num: 29 done: False
______________________
id: 42 reward: -0.01633738601823708 service_time: 2872 s_time: 43 penalty: 0 agent_num: 47 done: False
______________________
id: 50 reward: -0.021235521235521235 service_time: 3020 s_time: 44 penalty: 0 agent_num: 37 done: False
______________________
id: 46 reward: 0.0 service_time: 3306 s_time: 0 penalty: 0 agent_num: 39 done: False
______________________
Step:  4624
Pretraining Loss:  tensor(0.0402, device='cuda:0', grad_fn=<MeanBackward0>)
id: 47 reward: 0.0 service_time: 974 s_time: 0 penalty: 0 agent_num: 17 done: False
______________________
id: 54 reward: -0.03159340659340659 service_time: 2550 s_time: 23 penalty: 0 agent_num: 13 done: False
______________________
id: 49 reward: 0.11688311688311688 service_time: 2248 s_time: -72 penalty: 0 agent_num: 11 done: False
______________________
id: 55 reward: -0.0880952380952381 service_time: 2335 s_time: 74 penalty: 0 agent_num: 15 done: False
______________________
id: 48 reward: -0.019345238095238096 service_time: 3359 s_time: 26 penalty: 0 agent_num: 24 done: False
______________________
id: 51 reward: -0.029464285714285714 service_time: 1725 s_time: 33 penalty: 0 agent_num: 20 done: False
______________________
id: 40 reward: -0.015037593984962405 service_time: 1930 s_time: 32 penalty: 0 agent_num: 38 done: False
______________________
id: 50 reward: 0.0 service_time: 3020 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 41 reward: -0.0027901785714285715 service_time: 3163 s_time: 5 penalty: 0 agent_num: 32 done: False
______________________
id: 45 reward: -0.025510204081632654 service_time: 3640 s_time: 40 penalty: 0 agent_num: 28 done: False
______________________
id: 43 reward: -0.010146103896103896 service_time: 2977 s_time: 25 penalty: 0 agent_num: 44 done: False
______________________
id: 44 reward: -0.006987577639751553 service_time: 2022 s_time: 18 penalty: 0 agent_num: 46 done: False
______________________
id: 42 reward: -0.009498480243161094 service_time: 2897 s_time: 25 penalty: 0 agent_num: 47 done: False
______________________
id: 52 reward: -0.009486607142857142 service_time: 2890 s_time: 17 penalty: 0 agent_num: 32 done: False
______________________
id: 53 reward: -0.10837438423645321 service_time: 2911 s_time: 176 penalty: 0 agent_num: 29 done: False
______________________
id: 46 reward: -0.020146520146520148 service_time: 3350 s_time: 44 penalty: 0 agent_num: 39 done: False
______________________
Step:  4640
Pretraining Loss:  tensor(0.0407, device='cuda:0', grad_fn=<MeanBackward0>)
id: 47 reward: -0.01680672268907563 service_time: 990 s_time: 16 penalty: 0 agent_num: 17 done: False
______________________
id: 54 reward: 0.0 service_time: 2550 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 55 reward: 0.0 service_time: 2335 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 49 reward: -0.1331168831168831 service_time: 2330 s_time: 82 penalty: 0 agent_num: 11 done: False
______________________
id: 48 reward: 0.033482142857142856 service_time: 3314 s_time: -45 penalty: 0 agent_num: 24 done: False
______________________
id: 51 reward: -0.033928571428571426 service_time: 1763 s_time: 38 penalty: 0 agent_num: 20 done: False
______________________
id: 40 reward: -0.011278195488721804 service_time: 1954 s_time: 24 penalty: 0 agent_num: 38 done: False
______________________
id: 45 reward: -0.025510204081632654 service_time: 3680 s_time: 40 penalty: 0 agent_num: 28 done: False
______________________
id: 41 reward: -0.0033482142857142855 service_time: 3169 s_time: 6 penalty: 0 agent_num: 32 done: False
______________________
id: 52 reward: -0.015625 service_time: 2918 s_time: 28 penalty: 0 agent_num: 32 done: False
______________________
id: 44 reward: -0.003105590062111801 service_time: 2030 s_time: 8 penalty: 0 agent_num: 46 done: False
______________________
id: 43 reward: -0.007711038961038961 service_time: 2996 s_time: 19 penalty: 0 agent_num: 44 done: False
______________________
id: 42 reward: -0.012537993920972644 service_time: 2930 s_time: 33 penalty: 0 agent_num: 47 done: False
______________________
id: 50 reward: -0.018822393822393823 service_time: 3059 s_time: 39 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: -0.012315270935960592 service_time: 2931 s_time: 20 penalty: 0 agent_num: 29 done: False
______________________
id: 46 reward: 0.0 service_time: 3350 s_time: 0 penalty: 0 agent_num: 39 done: False
______________________
Step:  4656
Pretraining Loss:  tensor(0.0407, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.0 service_time: 2330 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: 0.0 service_time: 990 s_time: 0 penalty: 0 agent_num: 17 done: False
______________________
id: 54 reward: -0.16895604395604397 service_time: 2673 s_time: 123 penalty: 0 agent_num: 13 done: False
______________________
id: 55 reward: 0.023809523809523808 service_time: 2315 s_time: -20 penalty: 0 agent_num: 15 done: False
______________________
id: 51 reward: -0.0008928571428571428 service_time: 1764 s_time: 1 penalty: 0 agent_num: 20 done: False
______________________
id: 48 reward: -0.08854166666666667 service_time: 3433 s_time: 119 penalty: 0 agent_num: 24 done: False
______________________
id: 40 reward: -0.011278195488721804 service_time: 1978 s_time: 24 penalty: 0 agent_num: 38 done: False
______________________
id: 41 reward: -0.004464285714285714 service_time: 3177 s_time: 8 penalty: 0 agent_num: 32 done: False
______________________
id: 45 reward: -0.001913265306122449 service_time: 3683 s_time: 3 penalty: 0 agent_num: 28 done: False
______________________
id: 43 reward: -0.007711038961038961 service_time: 3015 s_time: 19 penalty: 0 agent_num: 44 done: False
______________________
id: 42 reward: 0.0 service_time: 2930 s_time: 0 penalty: 0 agent_num: 47 done: False
______________________
id: 50 reward: -0.02557915057915058 service_time: 3112 s_time: 53 penalty: 0 agent_num: 37 done: False
______________________
id: 44 reward: -0.01048136645962733 service_time: 2057 s_time: 27 penalty: 0 agent_num: 46 done: False
______________________
id: 52 reward: 0.00390625 service_time: 2911 s_time: -7 penalty: 0 agent_num: 32 done: False
______________________
id: 53 reward: 0.0024630541871921183 service_time: 2927 s_time: -4 penalty: 0 agent_num: 29 done: False
______________________
id: 46 reward: -0.019688644688644688 service_time: 3393 s_time: 43 penalty: 0 agent_num: 39 done: False
______________________
Step:  4672
Pretraining Loss:  tensor(0.0399, device='cuda:0', grad_fn=<MeanBackward0>)
id: 47 reward: -0.022058823529411766 service_time: 1011 s_time: 21 penalty: 0 agent_num: 17 done: False
______________________
id: 49 reward: -0.24025974025974026 service_time: 2478 s_time: 148 penalty: 0 agent_num: 11 done: False
______________________
id: 54 reward: 0.0 service_time: 2673 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 51 reward: -0.024107142857142858 service_time: 1791 s_time: 27 penalty: 0 agent_num: 20 done: False
______________________
id: 55 reward: -0.13452380952380952 service_time: 2428 s_time: 113 penalty: 0 agent_num: 15 done: False
______________________
id: 48 reward: -0.005208333333333333 service_time: 3440 s_time: 7 penalty: 0 agent_num: 24 done: False
______________________
id: 40 reward: 0.0 service_time: 1978 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 45 reward: -0.042091836734693876 service_time: 3749 s_time: 66 penalty: 0 agent_num: 28 done: False
______________________
id: 43 reward: -0.005681818181818182 service_time: 3029 s_time: 14 penalty: 0 agent_num: 44 done: False
______________________
id: 41 reward: 0.0027901785714285715 service_time: 3172 s_time: -5 penalty: 0 agent_num: 32 done: False
______________________
id: 53 reward: -0.01293103448275862 service_time: 2948 s_time: 21 penalty: 0 agent_num: 29 done: False
______________________
id: 50 reward: 0.00048262548262548264 service_time: 3111 s_time: -1 penalty: 0 agent_num: 37 done: False
______________________
id: 52 reward: -0.029575892857142856 service_time: 2964 s_time: 53 penalty: 0 agent_num: 32 done: False
______________________
id: 44 reward: 0.0 service_time: 2057 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 42 reward: -0.006458966565349544 service_time: 2947 s_time: 17 penalty: 0 agent_num: 47 done: False
______________________
id: 46 reward: -0.028846153846153848 service_time: 3456 s_time: 63 penalty: 0 agent_num: 39 done: False
______________________
Step:  4688
Pretraining Loss:  tensor(0.0479, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.07305194805194805 service_time: 2523 s_time: 45 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: 0.0 service_time: 1011 s_time: 0 penalty: 0 agent_num: 17 done: False
______________________
id: 54 reward: -0.038461538461538464 service_time: 2701 s_time: 28 penalty: 0 agent_num: 13 done: False
______________________
id: 48 reward: 0.017857142857142856 service_time: 3416 s_time: -24 penalty: 0 agent_num: 24 done: False
______________________
id: 51 reward: -0.024107142857142858 service_time: 1818 s_time: 27 penalty: 0 agent_num: 20 done: False
______________________
id: 55 reward: 0.004761904761904762 service_time: 2424 s_time: -4 penalty: 0 agent_num: 15 done: False
______________________
id: 41 reward: -0.021205357142857144 service_time: 3210 s_time: 38 penalty: 0 agent_num: 32 done: False
______________________
id: 40 reward: -0.007988721804511278 service_time: 1995 s_time: 17 penalty: 0 agent_num: 38 done: False
______________________
id: 44 reward: -0.021350931677018632 service_time: 2112 s_time: 55 penalty: 0 agent_num: 46 done: False
______________________
id: 42 reward: -0.016717325227963525 service_time: 2991 s_time: 44 penalty: 0 agent_num: 47 done: False
______________________
id: 43 reward: -0.011363636363636364 service_time: 3057 s_time: 28 penalty: 0 agent_num: 44 done: False
______________________
id: 53 reward: -0.03263546798029557 service_time: 3001 s_time: 53 penalty: 0 agent_num: 29 done: False
______________________
id: 45 reward: -0.017857142857142856 service_time: 3777 s_time: 28 penalty: 0 agent_num: 28 done: False
______________________
id: 50 reward: -0.01833976833976834 service_time: 3149 s_time: 38 penalty: 0 agent_num: 37 done: False
______________________
id: 52 reward: -0.01171875 service_time: 2985 s_time: 21 penalty: 0 agent_num: 32 done: False
______________________
id: 46 reward: 0.0 service_time: 3456 s_time: 0 penalty: 0 agent_num: 39 done: False
______________________
Step:  4704
Pretraining Loss:  tensor(0.0396, device='cuda:0', grad_fn=<MeanBackward0>)
id: 47 reward: -0.03466386554621849 service_time: 1044 s_time: 33 penalty: 0 agent_num: 17 done: False
______________________
id: 49 reward: 0.0 service_time: 2523 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 54 reward: -0.04395604395604396 service_time: 2733 s_time: 32 penalty: 0 agent_num: 13 done: False
______________________
id: 51 reward: -0.033035714285714286 service_time: 1855 s_time: 37 penalty: 0 agent_num: 20 done: False
______________________
id: 48 reward: -0.07961309523809523 service_time: 3523 s_time: 107 penalty: 0 agent_num: 24 done: False
______________________
id: 55 reward: 0.07142857142857142 service_time: 2364 s_time: -60 penalty: 0 agent_num: 15 done: False
______________________
id: 41 reward: -0.024553571428571428 service_time: 3254 s_time: 44 penalty: 0 agent_num: 32 done: False
______________________
id: 40 reward: 0.0 service_time: 1995 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 43 reward: -0.017857142857142856 service_time: 3101 s_time: 44 penalty: 0 agent_num: 44 done: False
______________________
id: 50 reward: -0.019305019305019305 service_time: 3189 s_time: 40 penalty: 0 agent_num: 37 done: False
______________________
id: 44 reward: 0.0 service_time: 2112 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 45 reward: -0.015306122448979591 service_time: 3801 s_time: 24 penalty: 0 agent_num: 28 done: False
______________________
id: 42 reward: 0.0 service_time: 2991 s_time: 0 penalty: 0 agent_num: 47 done: False
______________________
id: 52 reward: -0.012276785714285714 service_time: 3007 s_time: 22 penalty: 0 agent_num: 32 done: False
______________________
id: 53 reward: 0.0 service_time: 3001 s_time: 0 penalty: 0 agent_num: 29 done: False
______________________
id: 46 reward: -0.019230769230769232 service_time: 3498 s_time: 42 penalty: 0 agent_num: 39 done: False
______________________
Step:  4720
Pretraining Loss:  tensor(0.0443, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.0 service_time: 2523 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: -0.14180672268907563 service_time: 1179 s_time: 135 penalty: 0 agent_num: 17 done: False
______________________
id: 55 reward: -0.030952380952380953 service_time: 2390 s_time: 26 penalty: 0 agent_num: 15 done: False
______________________
id: 54 reward: 0.0 service_time: 2733 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 51 reward: -0.010714285714285714 service_time: 1867 s_time: 12 penalty: 0 agent_num: 20 done: False
______________________
id: 41 reward: -0.018973214285714284 service_time: 3288 s_time: 34 penalty: 0 agent_num: 32 done: False
______________________
id: 48 reward: -0.0974702380952381 service_time: 3654 s_time: 131 penalty: 0 agent_num: 24 done: False
______________________
id: 43 reward: -0.00974025974025974 service_time: 3125 s_time: 24 penalty: 0 agent_num: 44 done: False
______________________
id: 44 reward: -0.019798136645962732 service_time: 2163 s_time: 51 penalty: 0 agent_num: 46 done: False
______________________
id: 42 reward: -0.018996960486322188 service_time: 3041 s_time: 50 penalty: 0 agent_num: 47 done: False
______________________
id: 40 reward: -0.022556390977443608 service_time: 2043 s_time: 48 penalty: 0 agent_num: 38 done: False
______________________
id: 50 reward: 0.0 service_time: 3189 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: 0.022167487684729065 service_time: 2965 s_time: -36 penalty: 0 agent_num: 29 done: False
______________________
id: 52 reward: -0.030133928571428572 service_time: 3061 s_time: 54 penalty: 0 agent_num: 32 done: False
______________________
id: 45 reward: -0.028698979591836735 service_time: 3846 s_time: 45 penalty: 0 agent_num: 28 done: False
______________________
id: 46 reward: -0.029304029304029304 service_time: 3562 s_time: 64 penalty: 0 agent_num: 39 done: False
______________________
Step:  4736
Pretraining Loss:  tensor(0.0474, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.0 service_time: 2523 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 54 reward: 0.019230769230769232 service_time: 2719 s_time: -14 penalty: 0 agent_num: 13 done: False
______________________
id: 47 reward: -0.06512605042016807 service_time: 1241 s_time: 62 penalty: 0 agent_num: 17 done: False
______________________
id: 51 reward: -0.02857142857142857 service_time: 1899 s_time: 32 penalty: 0 agent_num: 20 done: False
______________________
id: 48 reward: -0.023809523809523808 service_time: 3686 s_time: 32 penalty: 0 agent_num: 24 done: False
______________________
id: 55 reward: -0.07380952380952381 service_time: 2452 s_time: 62 penalty: 0 agent_num: 15 done: False
______________________
id: 41 reward: -0.015625 service_time: 3316 s_time: 28 penalty: 0 agent_num: 32 done: False
______________________
id: 40 reward: 0.0018796992481203006 service_time: 2039 s_time: -4 penalty: 0 agent_num: 38 done: False
______________________
id: 43 reward: -0.008522727272727272 service_time: 3146 s_time: 21 penalty: 0 agent_num: 44 done: False
______________________
id: 45 reward: -0.015306122448979591 service_time: 3870 s_time: 24 penalty: 0 agent_num: 28 done: False
______________________
id: 50 reward: -0.01833976833976834 service_time: 3227 s_time: 38 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: 0.0 service_time: 2965 s_time: 0 penalty: 0 agent_num: 29 done: False
______________________
id: 42 reward: -0.007598784194528876 service_time: 3061 s_time: 20 penalty: 0 agent_num: 47 done: False
______________________
id: 44 reward: -0.009704968944099378 service_time: 2188 s_time: 25 penalty: 0 agent_num: 46 done: False
______________________
id: 52 reward: -0.020647321428571428 service_time: 3098 s_time: 37 penalty: 0 agent_num: 32 done: False
______________________
id: 46 reward: -0.0173992673992674 service_time: 3600 s_time: 38 penalty: 0 agent_num: 39 done: False
______________________
Step:  4752
Pretraining Loss:  tensor(0.0500, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.12012987012987013 service_time: 2449 s_time: -74 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: 0.005252100840336135 service_time: 1236 s_time: -5 penalty: 0 agent_num: 17 done: False
______________________
id: 55 reward: 0.0 service_time: 2452 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 54 reward: 0.0 service_time: 2719 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 51 reward: 0.0017857142857142857 service_time: 1897 s_time: -2 penalty: 0 agent_num: 20 done: False
______________________
id: 41 reward: 0.002232142857142857 service_time: 3312 s_time: -4 penalty: 0 agent_num: 32 done: False
______________________
id: 50 reward: -0.003861003861003861 service_time: 3235 s_time: 8 penalty: 0 agent_num: 37 done: False
______________________
id: 48 reward: -0.043154761904761904 service_time: 3744 s_time: 58 penalty: 0 agent_num: 24 done: False
______________________
id: 42 reward: 0.0 service_time: 3061 s_time: 0 penalty: 0 agent_num: 47 done: False
______________________
id: 40 reward: -0.014097744360902255 service_time: 2069 s_time: 30 penalty: 0 agent_num: 38 done: False
______________________
id: 43 reward: -0.011363636363636364 service_time: 3174 s_time: 28 penalty: 0 agent_num: 44 done: False
______________________
id: 44 reward: -0.007763975155279503 service_time: 2208 s_time: 20 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: 0.01293103448275862 service_time: 2944 s_time: -21 penalty: 0 agent_num: 29 done: False
______________________
id: 52 reward: -0.010044642857142858 service_time: 3116 s_time: 18 penalty: 0 agent_num: 32 done: False
______________________
id: 45 reward: -0.022321428571428572 service_time: 3905 s_time: 35 penalty: 0 agent_num: 28 done: False
______________________
id: 46 reward: -0.016483516483516484 service_time: 3636 s_time: 36 penalty: 0 agent_num: 39 done: False
______________________
Step:  4768
Pretraining Loss:  tensor(0.0428, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.07792207792207792 service_time: 2497 s_time: 48 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: -0.09978991596638656 service_time: 1331 s_time: 95 penalty: 0 agent_num: 17 done: False
______________________
id: 54 reward: 0.0 service_time: 2719 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 55 reward: 0.0 service_time: 2452 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 51 reward: -0.04196428571428571 service_time: 1944 s_time: 47 penalty: 0 agent_num: 20 done: False
______________________
id: 41 reward: -0.017857142857142856 service_time: 3344 s_time: 32 penalty: 0 agent_num: 32 done: False
______________________
id: 45 reward: 0.0012755102040816326 service_time: 3903 s_time: -2 penalty: 0 agent_num: 28 done: False
______________________
id: 40 reward: 0.0 service_time: 2069 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 43 reward: -0.010146103896103896 service_time: 3199 s_time: 25 penalty: 0 agent_num: 44 done: False
______________________
id: 50 reward: -0.006274131274131274 service_time: 3248 s_time: 13 penalty: 0 agent_num: 37 done: False
______________________
id: 44 reward: -0.006211180124223602 service_time: 2224 s_time: 16 penalty: 0 agent_num: 46 done: False
______________________
id: 48 reward: 0.002232142857142857 service_time: 3741 s_time: -3 penalty: 0 agent_num: 24 done: False
______________________
id: 42 reward: -0.021656534954407294 service_time: 3118 s_time: 57 penalty: 0 agent_num: 47 done: False
______________________
id: 53 reward: -0.017241379310344827 service_time: 2972 s_time: 28 penalty: 0 agent_num: 29 done: False
______________________
id: 52 reward: -0.02734375 service_time: 3165 s_time: 49 penalty: 0 agent_num: 32 done: False
______________________
id: 46 reward: -0.0009157509157509158 service_time: 3638 s_time: 2 penalty: 0 agent_num: 39 done: False
______________________
------------------------------------
| time/                 |          |
|    fps                | 9        |
|    iterations         | 300      |
|    time_elapsed       | 498      |
|    total_timesteps    | 4800     |
| train/                |          |
|    entropy_loss       | 0.0547   |
|    explained_variance | -57.2    |
|    learning_rate      | 1e-05    |
|    n_updates          | 299      |
|    policy_loss        | 0.0428   |
|    value_loss         | 0.158    |
------------------------------------
Step:  4784
Pretraining Loss:  tensor(0.0417, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.0 service_time: 2497 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: -0.005252100840336135 service_time: 1336 s_time: 5 penalty: 0 agent_num: 17 done: False
______________________
id: 54 reward: 0.0 service_time: 2719 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 55 reward: 0.016666666666666666 service_time: 2438 s_time: -14 penalty: 0 agent_num: 15 done: False
______________________
id: 51 reward: 0.0017857142857142857 service_time: 1942 s_time: -2 penalty: 0 agent_num: 20 done: False
______________________
id: 48 reward: 0.020089285714285716 service_time: 3714 s_time: -27 penalty: 0 agent_num: 24 done: False
______________________
id: 41 reward: -0.04799107142857143 service_time: 3430 s_time: 86 penalty: 0 agent_num: 32 done: False
______________________
id: 50 reward: -0.013996138996138996 service_time: 3277 s_time: 29 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: -0.0018472906403940886 service_time: 2975 s_time: 3 penalty: 0 agent_num: 29 done: False
______________________
id: 44 reward: 0.0 service_time: 2224 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 40 reward: -0.010338345864661654 service_time: 2091 s_time: 22 penalty: 0 agent_num: 38 done: False
______________________
id: 43 reward: -0.008928571428571428 service_time: 3221 s_time: 22 penalty: 0 agent_num: 44 done: False
______________________
id: 42 reward: -0.016717325227963525 service_time: 3162 s_time: 44 penalty: 0 agent_num: 47 done: False
______________________
id: 52 reward: -0.018973214285714284 service_time: 3199 s_time: 34 penalty: 0 agent_num: 32 done: False
______________________
id: 45 reward: -0.0274234693877551 service_time: 3946 s_time: 43 penalty: 0 agent_num: 28 done: False
______________________
id: 46 reward: -0.013736263736263736 service_time: 3668 s_time: 30 penalty: 0 agent_num: 39 done: False
______________________
Step:  4800
Pretraining Loss:  tensor(0.0424, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.0 service_time: 2497 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 54 reward: 0.0 service_time: 2719 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 47 reward: 0.0 service_time: 1336 s_time: 0 penalty: 0 agent_num: 17 done: False
______________________
id: 51 reward: 0.0026785714285714286 service_time: 1939 s_time: -3 penalty: 0 agent_num: 20 done: False
______________________
id: 55 reward: 0.0 service_time: 2438 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 48 reward: 0.018601190476190476 service_time: 3689 s_time: -25 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: -0.035076530612244895 service_time: 4001 s_time: 55 penalty: 0 agent_num: 28 done: False
______________________
id: 41 reward: -0.011160714285714286 service_time: 3450 s_time: 20 penalty: 0 agent_num: 32 done: False
______________________
id: 40 reward: -0.01550751879699248 service_time: 2124 s_time: 33 penalty: 0 agent_num: 38 done: False
______________________
id: 53 reward: -0.10591133004926108 service_time: 3147 s_time: 172 penalty: 0 agent_num: 29 done: False
______________________
id: 50 reward: 0.0 service_time: 3277 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 43 reward: -0.016639610389610388 service_time: 3262 s_time: 41 penalty: 0 agent_num: 44 done: False
______________________
id: 44 reward: -0.018633540372670808 service_time: 2272 s_time: 48 penalty: 0 agent_num: 46 done: False
______________________
id: 42 reward: -0.008358662613981762 service_time: 3184 s_time: 22 penalty: 0 agent_num: 47 done: False
______________________
id: 52 reward: -0.00390625 service_time: 3206 s_time: 7 penalty: 0 agent_num: 32 done: False
______________________
id: 46 reward: 0.003205128205128205 service_time: 3661 s_time: -7 penalty: 0 agent_num: 39 done: False
______________________
Step:  4816
Pretraining Loss:  tensor(0.0421, device='cuda:0', grad_fn=<MeanBackward0>)
id: 47 reward: 0.0 service_time: 1336 s_time: 0 penalty: 0 agent_num: 17 done: False
______________________
id: 49 reward: -0.14123376623376624 service_time: 2584 s_time: 87 penalty: 0 agent_num: 11 done: False
______________________
id: 54 reward: 0.0 service_time: 2719 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 55 reward: 0.0 service_time: 2438 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 51 reward: 0.0008928571428571428 service_time: 1938 s_time: -1 penalty: 0 agent_num: 20 done: False
______________________
id: 48 reward: -0.033482142857142856 service_time: 3734 s_time: 45 penalty: 0 agent_num: 24 done: False
______________________
id: 41 reward: 0.0016741071428571428 service_time: 3447 s_time: -3 penalty: 0 agent_num: 32 done: False
______________________
id: 50 reward: -0.03426640926640927 service_time: 3348 s_time: 71 penalty: 0 agent_num: 37 done: False
______________________
id: 40 reward: 0.0 service_time: 2124 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 44 reward: 0.0007763975155279503 service_time: 2270 s_time: -2 penalty: 0 agent_num: 46 done: False
______________________
id: 42 reward: -0.0056990881458966565 service_time: 3199 s_time: 15 penalty: 0 agent_num: 47 done: False
______________________
id: 43 reward: -0.009334415584415584 service_time: 3285 s_time: 23 penalty: 0 agent_num: 44 done: False
______________________
id: 52 reward: -0.015066964285714286 service_time: 3233 s_time: 27 penalty: 0 agent_num: 32 done: False
______________________
id: 53 reward: -0.06711822660098522 service_time: 3256 s_time: 109 penalty: 0 agent_num: 29 done: False
______________________
id: 46 reward: -0.014194139194139194 service_time: 3692 s_time: 31 penalty: 0 agent_num: 39 done: False
______________________
id: 45 reward: -0.039540816326530615 service_time: 4063 s_time: 62 penalty: 0 agent_num: 28 done: False
______________________
Step:  4832
Pretraining Loss:  tensor(0.0406, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.0 service_time: 2584 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: 0.0 service_time: 1336 s_time: 0 penalty: 0 agent_num: 17 done: False
______________________
id: 54 reward: 0.0 service_time: 2719 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 51 reward: -0.033928571428571426 service_time: 1976 s_time: 38 penalty: 0 agent_num: 20 done: False
______________________
id: 55 reward: 0.0 service_time: 2438 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 50 reward: -0.008204633204633204 service_time: 3365 s_time: 17 penalty: 0 agent_num: 37 done: False
______________________
id: 40 reward: -0.0042293233082706765 service_time: 2133 s_time: 9 penalty: 0 agent_num: 38 done: False
______________________
id: 41 reward: -0.01953125 service_time: 3482 s_time: 35 penalty: 0 agent_num: 32 done: False
______________________
id: 53 reward: -0.03201970443349754 service_time: 3308 s_time: 52 penalty: 0 agent_num: 29 done: False
______________________
id: 44 reward: -0.01358695652173913 service_time: 2305 s_time: 35 penalty: 0 agent_num: 46 done: False
______________________
id: 43 reward: -0.008928571428571428 service_time: 3307 s_time: 22 penalty: 0 agent_num: 44 done: False
______________________
id: 42 reward: -0.011778115501519757 service_time: 3230 s_time: 31 penalty: 0 agent_num: 47 done: False
______________________
id: 48 reward: -0.06770833333333333 service_time: 3825 s_time: 91 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: -0.02806122448979592 service_time: 4107 s_time: 44 penalty: 0 agent_num: 28 done: False
______________________
id: 52 reward: -0.006696428571428571 service_time: 3245 s_time: 12 penalty: 0 agent_num: 32 done: False
______________________
id: 46 reward: -0.00641025641025641 service_time: 3706 s_time: 14 penalty: 0 agent_num: 39 done: False
______________________
Step:  4848
Pretraining Loss:  tensor(0.0432, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.03571428571428571 service_time: 2562 s_time: -22 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: -0.0273109243697479 service_time: 1362 s_time: 26 penalty: 0 agent_num: 17 done: False
______________________
id: 55 reward: 0.002380952380952381 service_time: 2436 s_time: -2 penalty: 0 agent_num: 15 done: False
______________________
id: 54 reward: -0.03983516483516483 service_time: 2748 s_time: 29 penalty: 0 agent_num: 13 done: False
______________________
id: 51 reward: 0.0017857142857142857 service_time: 1974 s_time: -2 penalty: 0 agent_num: 20 done: False
______________________
id: 41 reward: -0.016741071428571428 service_time: 3512 s_time: 30 penalty: 0 agent_num: 32 done: False
______________________
id: 48 reward: -0.020833333333333332 service_time: 3853 s_time: 28 penalty: 0 agent_num: 24 done: False
______________________
id: 50 reward: -0.012065637065637066 service_time: 3390 s_time: 25 penalty: 0 agent_num: 37 done: False
______________________
id: 44 reward: -0.01436335403726708 service_time: 2342 s_time: 37 penalty: 0 agent_num: 46 done: False
______________________
id: 40 reward: -0.015977443609022556 service_time: 2167 s_time: 34 penalty: 0 agent_num: 38 done: False
______________________
id: 43 reward: -0.0008116883116883117 service_time: 3309 s_time: 2 penalty: 0 agent_num: 44 done: False
______________________
id: 52 reward: -0.008370535714285714 service_time: 3260 s_time: 15 penalty: 0 agent_num: 32 done: False
______________________
id: 42 reward: -0.014817629179331307 service_time: 3269 s_time: 39 penalty: 0 agent_num: 47 done: False
______________________
id: 53 reward: 0.012315270935960592 service_time: 3288 s_time: -20 penalty: 0 agent_num: 29 done: False
______________________
id: 46 reward: -0.005494505494505495 service_time: 3718 s_time: 12 penalty: 0 agent_num: 39 done: False
______________________
id: 45 reward: -0.01913265306122449 service_time: 4137 s_time: 30 penalty: 0 agent_num: 28 done: False
______________________
Step:  4864
Pretraining Loss:  tensor(0.0474, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.06818181818181818 service_time: 2604 s_time: 42 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: 0.0 service_time: 1362 s_time: 0 penalty: 0 agent_num: 17 done: False
______________________
id: 54 reward: 0.0 service_time: 2748 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 51 reward: -0.01875 service_time: 1995 s_time: 21 penalty: 0 agent_num: 20 done: False
______________________
id: 55 reward: -0.0761904761904762 service_time: 2500 s_time: 64 penalty: 0 agent_num: 15 done: False
______________________
id: 41 reward: -0.018973214285714284 service_time: 3546 s_time: 34 penalty: 0 agent_num: 32 done: False
______________________
id: 50 reward: -0.013030888030888031 service_time: 3417 s_time: 27 penalty: 0 agent_num: 37 done: False
______________________
id: 40 reward: -0.0037593984962406013 service_time: 2175 s_time: 8 penalty: 0 agent_num: 38 done: False
______________________
id: 52 reward: -0.012834821428571428 service_time: 3283 s_time: 23 penalty: 0 agent_num: 32 done: False
______________________
id: 43 reward: -0.026379870129870128 service_time: 3374 s_time: 65 penalty: 0 agent_num: 44 done: False
______________________
id: 53 reward: -0.023399014778325122 service_time: 3326 s_time: 38 penalty: 0 agent_num: 29 done: False
______________________
id: 44 reward: -0.007763975155279503 service_time: 2362 s_time: 20 penalty: 0 agent_num: 46 done: False
______________________
id: 42 reward: -0.001899696048632219 service_time: 3274 s_time: 5 penalty: 0 agent_num: 47 done: False
______________________
id: 48 reward: -0.05654761904761905 service_time: 3929 s_time: 76 penalty: 0 agent_num: 24 done: False
______________________
id: 46 reward: -0.017857142857142856 service_time: 3757 s_time: 39 penalty: 0 agent_num: 39 done: False
______________________
id: 45 reward: -0.02295918367346939 service_time: 4173 s_time: 36 penalty: 0 agent_num: 28 done: False
______________________
Step:  4880
Pretraining Loss:  tensor(0.0469, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.07954545454545454 service_time: 2653 s_time: 49 penalty: 0 agent_num: 11 done: False
______________________
id: 54 reward: 0.0 service_time: 2748 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 55 reward: 0.0 service_time: 2500 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 47 reward: 0.0 service_time: 1362 s_time: 0 penalty: 0 agent_num: 17 done: False
______________________
id: 48 reward: 0.002976190476190476 service_time: 3925 s_time: -4 penalty: 0 agent_num: 24 done: False
______________________
id: 51 reward: -0.03482142857142857 service_time: 2034 s_time: 39 penalty: 0 agent_num: 20 done: False
______________________
id: 41 reward: -0.013392857142857142 service_time: 3570 s_time: 24 penalty: 0 agent_num: 32 done: False
______________________
id: 50 reward: -0.006274131274131274 service_time: 3430 s_time: 13 penalty: 0 agent_num: 37 done: False
______________________
id: 40 reward: -0.01456766917293233 service_time: 2206 s_time: 31 penalty: 0 agent_num: 38 done: False
______________________
id: 44 reward: -0.010093167701863354 service_time: 2388 s_time: 26 penalty: 0 agent_num: 46 done: False
______________________
id: 52 reward: -0.008928571428571428 service_time: 3299 s_time: 16 penalty: 0 agent_num: 32 done: False
______________________
id: 46 reward: -0.0086996336996337 service_time: 3776 s_time: 19 penalty: 0 agent_num: 39 done: False
______________________
id: 43 reward: -0.008522727272727272 service_time: 3395 s_time: 21 penalty: 0 agent_num: 44 done: False
______________________
id: 42 reward: -0.011778115501519757 service_time: 3305 s_time: 31 penalty: 0 agent_num: 47 done: False
______________________
id: 53 reward: -0.007389162561576354 service_time: 3338 s_time: 12 penalty: 0 agent_num: 29 done: False
______________________
id: 45 reward: 0.024872448979591837 service_time: 4134 s_time: -39 penalty: 0 agent_num: 28 done: False
______________________
Step:  4896
Pretraining Loss:  tensor(0.0455, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.0 service_time: 2653 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 54 reward: -0.12637362637362637 service_time: 2840 s_time: 92 penalty: 0 agent_num: 13 done: False
______________________
id: 55 reward: -0.010714285714285714 service_time: 2509 s_time: 9 penalty: 0 agent_num: 15 done: False
______________________
id: 47 reward: -0.045168067226890755 service_time: 1405 s_time: 43 penalty: 0 agent_num: 17 done: False
______________________
id: 51 reward: -0.038392857142857145 service_time: 2077 s_time: 43 penalty: 0 agent_num: 20 done: False
______________________
id: 53 reward: -0.04495073891625616 service_time: 3411 s_time: 73 penalty: 0 agent_num: 29 done: False
______________________
id: 40 reward: 0.002349624060150376 service_time: 2201 s_time: -5 penalty: 0 agent_num: 38 done: False
______________________
id: 45 reward: 0.014668367346938776 service_time: 4111 s_time: -23 penalty: 0 agent_num: 28 done: False
______________________
id: 41 reward: -0.015625 service_time: 3598 s_time: 28 penalty: 0 agent_num: 32 done: False
______________________
id: 48 reward: -0.08779761904761904 service_time: 4043 s_time: 118 penalty: 0 agent_num: 24 done: False
______________________
id: 44 reward: -0.006211180124223602 service_time: 2404 s_time: 16 penalty: 0 agent_num: 46 done: False
______________________
id: 52 reward: 0.0 service_time: 3299 s_time: 0 penalty: 0 agent_num: 32 done: False
______________________
id: 50 reward: -0.011583011583011582 service_time: 3454 s_time: 24 penalty: 0 agent_num: 37 done: False
______________________
id: 43 reward: 0.0008116883116883117 service_time: 3393 s_time: -2 penalty: 0 agent_num: 44 done: False
______________________
id: 42 reward: 0.003419452887537994 service_time: 3296 s_time: -9 penalty: 0 agent_num: 47 done: False
______________________
id: 46 reward: -0.008241758241758242 service_time: 3794 s_time: 18 penalty: 0 agent_num: 39 done: False
______________________
Step:  4912
Pretraining Loss:  tensor(0.0410, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.125 service_time: 2730 s_time: 77 penalty: 0 agent_num: 11 done: False
______________________
id: 55 reward: 0.0 service_time: 2509 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 54 reward: -0.19230769230769232 service_time: 2980 s_time: 140 penalty: 0 agent_num: 13 done: False
______________________
id: 47 reward: -0.08823529411764706 service_time: 1489 s_time: 84 penalty: 0 agent_num: 17 done: False
______________________
id: 51 reward: -0.024107142857142858 service_time: 2104 s_time: 27 penalty: 0 agent_num: 20 done: False
______________________
id: 41 reward: -0.016183035714285716 service_time: 3627 s_time: 29 penalty: 0 agent_num: 32 done: False
______________________
id: 50 reward: 0.0 service_time: 3454 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 40 reward: -0.01550751879699248 service_time: 2234 s_time: 33 penalty: 0 agent_num: 38 done: False
______________________
id: 44 reward: -0.007375776397515528 service_time: 2423 s_time: 19 penalty: 0 agent_num: 46 done: False
______________________
id: 46 reward: -0.005952380952380952 service_time: 3807 s_time: 13 penalty: 0 agent_num: 39 done: False
______________________
id: 52 reward: -0.03125 service_time: 3355 s_time: 56 penalty: 0 agent_num: 32 done: False
______________________
id: 43 reward: -0.022727272727272728 service_time: 3449 s_time: 56 penalty: 0 agent_num: 44 done: False
______________________
id: 48 reward: -0.1130952380952381 service_time: 4195 s_time: 152 penalty: 0 agent_num: 24 done: False
______________________
id: 42 reward: -0.015957446808510637 service_time: 3338 s_time: 42 penalty: 0 agent_num: 47 done: False
______________________
id: 53 reward: 0.04741379310344827 service_time: 3334 s_time: -77 penalty: 0 agent_num: 29 done: False
______________________
id: 45 reward: -0.05994897959183673 service_time: 4205 s_time: 94 penalty: 0 agent_num: 28 done: False
______________________
Step:  4928
Pretraining Loss:  tensor(0.0455, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.25811688311688313 service_time: 2889 s_time: 159 penalty: 0 agent_num: 11 done: False
______________________
id: 54 reward: 0.0013736263736263737 service_time: 2979 s_time: -1 penalty: 0 agent_num: 13 done: False
______________________
id: 55 reward: -0.030952380952380953 service_time: 2535 s_time: 26 penalty: 0 agent_num: 15 done: False
______________________
id: 51 reward: 0.0026785714285714286 service_time: 2101 s_time: -3 penalty: 0 agent_num: 20 done: False
______________________
id: 47 reward: 0.0 service_time: 1489 s_time: 0 penalty: 0 agent_num: 17 done: False
______________________
id: 41 reward: -0.012276785714285714 service_time: 3649 s_time: 22 penalty: 0 agent_num: 32 done: False
______________________
id: 40 reward: 0.0 service_time: 2234 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 53 reward: 0.011083743842364532 service_time: 3316 s_time: -18 penalty: 0 agent_num: 29 done: False
______________________
id: 50 reward: -0.03909266409266409 service_time: 3535 s_time: 81 penalty: 0 agent_num: 37 done: False
______________________
id: 44 reward: 0.0 service_time: 2423 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 43 reward: -0.008116883116883116 service_time: 3469 s_time: 20 penalty: 0 agent_num: 44 done: False
______________________
id: 48 reward: -0.07217261904761904 service_time: 4292 s_time: 97 penalty: 0 agent_num: 24 done: False
______________________
id: 42 reward: -0.0121580547112462 service_time: 3370 s_time: 32 penalty: 0 agent_num: 47 done: False
______________________
id: 46 reward: 0.004120879120879121 service_time: 3798 s_time: -9 penalty: 0 agent_num: 39 done: False
______________________
id: 52 reward: -0.03571428571428571 service_time: 3419 s_time: 64 penalty: 0 agent_num: 32 done: False
______________________
id: 45 reward: 0.0 service_time: 4205 s_time: 0 penalty: 0 agent_num: 28 done: False
______________________
Step:  4944
Pretraining Loss:  tensor(0.0396, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.0 service_time: 2889 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: 0.0063025210084033615 service_time: 1483 s_time: -6 penalty: 0 agent_num: 17 done: False
______________________
id: 54 reward: -0.04395604395604396 service_time: 3011 s_time: 32 penalty: 0 agent_num: 13 done: False
______________________
id: 55 reward: -0.03214285714285714 service_time: 2562 s_time: 27 penalty: 0 agent_num: 15 done: False
______________________
id: 51 reward: -0.022321428571428572 service_time: 2126 s_time: 25 penalty: 0 agent_num: 20 done: False
______________________
id: 41 reward: 0.0 service_time: 3649 s_time: 0 penalty: 0 agent_num: 32 done: False
______________________
id: 40 reward: -0.009398496240601503 service_time: 2254 s_time: 20 penalty: 0 agent_num: 38 done: False
______________________
id: 50 reward: -0.013030888030888031 service_time: 3562 s_time: 27 penalty: 0 agent_num: 37 done: False
______________________
id: 44 reward: -0.008152173913043478 service_time: 2444 s_time: 21 penalty: 0 agent_num: 46 done: False
______________________
id: 46 reward: 0.003205128205128205 service_time: 3791 s_time: -7 penalty: 0 agent_num: 39 done: False
______________________
id: 48 reward: -0.03869047619047619 service_time: 4344 s_time: 52 penalty: 0 agent_num: 24 done: False
______________________
id: 52 reward: -0.027901785714285716 service_time: 3469 s_time: 50 penalty: 0 agent_num: 32 done: False
______________________
id: 43 reward: 0.0 service_time: 3469 s_time: 0 penalty: 0 agent_num: 44 done: False
______________________
id: 53 reward: 0.009236453201970444 service_time: 3301 s_time: -15 penalty: 0 agent_num: 29 done: False
______________________
id: 42 reward: -0.009878419452887538 service_time: 3396 s_time: 26 penalty: 0 agent_num: 47 done: False
______________________
id: 45 reward: -0.02614795918367347 service_time: 4246 s_time: 41 penalty: 0 agent_num: 28 done: False
______________________
Step:  4960
Pretraining Loss:  tensor(0.0415, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.08603896103896104 service_time: 2942 s_time: 53 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: -0.06197478991596639 service_time: 1542 s_time: 59 penalty: 0 agent_num: 17 done: False
______________________
id: 54 reward: -0.04532967032967033 service_time: 3044 s_time: 33 penalty: 0 agent_num: 13 done: False
______________________
id: 55 reward: -0.002380952380952381 service_time: 2564 s_time: 2 penalty: 0 agent_num: 15 done: False
______________________
id: 51 reward: 0.0008928571428571428 service_time: 2125 s_time: -1 penalty: 0 agent_num: 20 done: False
______________________
id: 48 reward: -0.11904761904761904 service_time: 4504 s_time: 160 penalty: 0 agent_num: 24 done: False
______________________
id: 41 reward: -0.03180803571428571 service_time: 3706 s_time: 57 penalty: 0 agent_num: 32 done: False
______________________
id: 44 reward: -0.009316770186335404 service_time: 2468 s_time: 24 penalty: 0 agent_num: 46 done: False
______________________
id: 40 reward: 0.00046992481203007516 service_time: 2253 s_time: -1 penalty: 0 agent_num: 38 done: False
______________________
id: 45 reward: 0.00701530612244898 service_time: 4235 s_time: -11 penalty: 0 agent_num: 28 done: False
______________________
id: 43 reward: -0.010551948051948052 service_time: 3495 s_time: 26 penalty: 0 agent_num: 44 done: False
______________________
id: 50 reward: -0.008687258687258687 service_time: 3580 s_time: 18 penalty: 0 agent_num: 37 done: False
______________________
id: 46 reward: 0.0004578754578754579 service_time: 3790 s_time: -1 penalty: 0 agent_num: 39 done: False
______________________
id: 53 reward: -0.01539408866995074 service_time: 3326 s_time: 25 penalty: 0 agent_num: 29 done: False
______________________
id: 42 reward: 0.0007598784194528875 service_time: 3394 s_time: -2 penalty: 0 agent_num: 47 done: False
______________________
id: 52 reward: -0.017857142857142856 service_time: 3501 s_time: 32 penalty: 0 agent_num: 32 done: False
______________________
Step:  4976
Pretraining Loss:  tensor(0.0381, device='cuda:0', grad_fn=<MeanBackward0>)
id: 54 reward: -0.14697802197802198 service_time: 3151 s_time: 107 penalty: 0 agent_num: 13 done: False
______________________
id: 47 reward: 0.01050420168067227 service_time: 1532 s_time: -10 penalty: 0 agent_num: 17 done: False
______________________
id: 49 reward: -0.08603896103896104 service_time: 2995 s_time: 53 penalty: 0 agent_num: 11 done: False
______________________
id: 55 reward: -0.02142857142857143 service_time: 2582 s_time: 18 penalty: 0 agent_num: 15 done: False
______________________
id: 51 reward: -0.03214285714285714 service_time: 2161 s_time: 36 penalty: 0 agent_num: 20 done: False
______________________
id: 48 reward: -0.07886904761904762 service_time: 4610 s_time: 106 penalty: 0 agent_num: 24 done: False
______________________
id: 46 reward: 0.0 service_time: 3790 s_time: 0 penalty: 0 agent_num: 39 done: False
______________________
id: 40 reward: -0.011748120300751879 service_time: 2278 s_time: 25 penalty: 0 agent_num: 38 done: False
______________________
id: 41 reward: -0.025669642857142856 service_time: 3752 s_time: 46 penalty: 0 agent_num: 32 done: False
______________________
id: 45 reward: 0.001913265306122449 service_time: 4232 s_time: -3 penalty: 0 agent_num: 28 done: False
______________________
id: 43 reward: -0.018262987012987012 service_time: 3540 s_time: 45 penalty: 0 agent_num: 44 done: False
______________________
id: 42 reward: -0.011018237082066869 service_time: 3423 s_time: 29 penalty: 0 agent_num: 47 done: False
______________________
id: 50 reward: -0.009652509652509652 service_time: 3600 s_time: 20 penalty: 0 agent_num: 37 done: False
______________________
id: 44 reward: -0.011645962732919254 service_time: 2498 s_time: 30 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: -0.042487684729064036 service_time: 3395 s_time: 69 penalty: 0 agent_num: 29 done: False
______________________
id: 52 reward: -0.028459821428571428 service_time: 3552 s_time: 51 penalty: 0 agent_num: 32 done: False
______________________
Step:  4992
Pretraining Loss:  tensor(0.0381, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.056818181818181816 service_time: 3030 s_time: 35 penalty: 0 agent_num: 11 done: False
______________________
id: 55 reward: -0.18214285714285713 service_time: 2735 s_time: 153 penalty: 0 agent_num: 15 done: False
______________________
id: 47 reward: -0.058823529411764705 service_time: 1588 s_time: 56 penalty: 0 agent_num: 17 done: False
______________________
id: 54 reward: -0.09478021978021978 service_time: 3220 s_time: 69 penalty: 0 agent_num: 13 done: False
______________________
id: 51 reward: -0.013392857142857142 service_time: 2176 s_time: 15 penalty: 0 agent_num: 20 done: False
______________________
id: 48 reward: -0.0818452380952381 service_time: 4720 s_time: 110 penalty: 0 agent_num: 24 done: False
______________________
id: 40 reward: 0.0 service_time: 2278 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 46 reward: 0.0 service_time: 3790 s_time: 0 penalty: 0 agent_num: 39 done: False
______________________
id: 50 reward: 0.0014478764478764478 service_time: 3597 s_time: -3 penalty: 0 agent_num: 37 done: False
______________________
id: 42 reward: -0.003799392097264438 service_time: 3433 s_time: 10 penalty: 0 agent_num: 47 done: False
______________________
id: 41 reward: -0.013950892857142858 service_time: 3777 s_time: 25 penalty: 0 agent_num: 32 done: False
______________________
id: 45 reward: 0.0 service_time: 4232 s_time: 0 penalty: 0 agent_num: 28 done: False
______________________
id: 53 reward: -0.02401477832512315 service_time: 3434 s_time: 39 penalty: 0 agent_num: 29 done: False
______________________
id: 43 reward: -0.010146103896103896 service_time: 3565 s_time: 25 penalty: 0 agent_num: 44 done: False
______________________
id: 44 reward: -0.027562111801242236 service_time: 2569 s_time: 71 penalty: 0 agent_num: 46 done: False
______________________
id: 52 reward: -0.012834821428571428 service_time: 3575 s_time: 23 penalty: 0 agent_num: 32 done: False
______________________
Step:  5008
Pretraining Loss:  tensor(0.0393, device='cuda:0', grad_fn=<MeanBackward0>)
id: 54 reward: -0.09340659340659341 service_time: 3288 s_time: 68 penalty: 0 agent_num: 13 done: False
______________________
id: 55 reward: 0.0 service_time: 2735 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 49 reward: -0.07467532467532467 service_time: 3076 s_time: 46 penalty: 0 agent_num: 11 done: False
______________________
id: 51 reward: -0.023214285714285715 service_time: 2202 s_time: 26 penalty: 0 agent_num: 20 done: False
______________________
id: 47 reward: 0.0031512605042016808 service_time: 1585 s_time: -3 penalty: 0 agent_num: 17 done: False
______________________
id: 45 reward: 0.0012755102040816326 service_time: 4230 s_time: -2 penalty: 0 agent_num: 28 done: False
______________________
id: 40 reward: -0.010338345864661654 service_time: 2300 s_time: 22 penalty: 0 agent_num: 38 done: False
______________________
id: 46 reward: 0.0 service_time: 3790 s_time: 0 penalty: 0 agent_num: 39 done: False
______________________
id: 50 reward: -0.010135135135135136 service_time: 3618 s_time: 21 penalty: 0 agent_num: 37 done: False
______________________
id: 48 reward: -0.2261904761904762 service_time: 5024 s_time: 304 penalty: 0 agent_num: 24 done: False
______________________
id: 41 reward: -0.006696428571428571 service_time: 3789 s_time: 12 penalty: 0 agent_num: 32 done: False
______________________
id: 42 reward: 0.0 service_time: 3433 s_time: 0 penalty: 0 agent_num: 47 done: False
______________________
id: 43 reward: -0.01176948051948052 service_time: 3594 s_time: 29 penalty: 0 agent_num: 44 done: False
______________________
id: 44 reward: -0.005434782608695652 service_time: 2583 s_time: 14 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: -0.020935960591133004 service_time: 3468 s_time: 34 penalty: 0 agent_num: 29 done: False
______________________
id: 52 reward: 0.006696428571428571 service_time: 3563 s_time: -12 penalty: 0 agent_num: 32 done: False
______________________
Step:  5024
Pretraining Loss:  tensor(0.0457, device='cuda:0', grad_fn=<MeanBackward0>)
id: 54 reward: -0.11263736263736264 service_time: 3370 s_time: 82 penalty: 0 agent_num: 13 done: False
______________________
id: 49 reward: -0.09253246753246754 service_time: 3133 s_time: 57 penalty: 0 agent_num: 11 done: False
______________________
id: 55 reward: 0.0 service_time: 2735 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 47 reward: -0.0063025210084033615 service_time: 1591 s_time: 6 penalty: 0 agent_num: 17 done: False
______________________
id: 51 reward: 0.008035714285714285 service_time: 2193 s_time: -9 penalty: 0 agent_num: 20 done: False
______________________
id: 48 reward: -0.0818452380952381 service_time: 5134 s_time: 110 penalty: 0 agent_num: 24 done: False
______________________
id: 40 reward: -0.01832706766917293 service_time: 2339 s_time: 39 penalty: 0 agent_num: 38 done: False
______________________
id: 45 reward: 0.0 service_time: 4230 s_time: 0 penalty: 0 agent_num: 28 done: False
______________________
id: 50 reward: -0.018822393822393823 service_time: 3657 s_time: 39 penalty: 0 agent_num: 37 done: False
______________________
id: 41 reward: -0.009486607142857142 service_time: 3806 s_time: 17 penalty: 0 agent_num: 32 done: False
______________________
id: 44 reward: 0.0 service_time: 2583 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 42 reward: -0.014817629179331307 service_time: 3472 s_time: 39 penalty: 0 agent_num: 47 done: False
______________________
id: 53 reward: -0.07266009852216748 service_time: 3586 s_time: 118 penalty: 0 agent_num: 29 done: False
______________________
id: 43 reward: -0.008928571428571428 service_time: 3616 s_time: 22 penalty: 0 agent_num: 44 done: False
______________________
id: 52 reward: -0.04185267857142857 service_time: 3638 s_time: 75 penalty: 0 agent_num: 32 done: False
______________________
id: 46 reward: 20.000457875457876 service_time: 3789 s_time: -1 penalty: 0 agent_num: 39 done: True
______________________
Step:  5040
Pretraining Loss:  tensor(0.0416, device='cuda:0', grad_fn=<MeanBackward0>)
id: 54 reward: -0.08653846153846154 service_time: 3433 s_time: 63 penalty: 0 agent_num: 13 done: False
______________________
id: 49 reward: -0.0633116883116883 service_time: 3172 s_time: 39 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: 0.0 service_time: 1591 s_time: 0 penalty: 0 agent_num: 17 done: False
______________________
id: 51 reward: -0.03660714285714286 service_time: 2234 s_time: 41 penalty: 0 agent_num: 20 done: False
______________________
id: 46 reward: -0.021205357142857144 service_time: 38 s_time: 38 penalty: 0 agent_num: 32 done: False
______________________
id: 55 reward: 0.0 service_time: 2735 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 45 reward: 0.0 service_time: 4230 s_time: 0 penalty: 0 agent_num: 28 done: False
______________________
id: 40 reward: 0.0 service_time: 2339 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 50 reward: -0.012548262548262547 service_time: 3683 s_time: 26 penalty: 0 agent_num: 37 done: False
______________________
id: 44 reward: -0.01203416149068323 service_time: 2614 s_time: 31 penalty: 0 agent_num: 46 done: False
______________________
id: 41 reward: -0.010044642857142858 service_time: 3824 s_time: 18 penalty: 0 agent_num: 32 done: False
______________________
id: 43 reward: -0.017857142857142856 service_time: 3660 s_time: 44 penalty: 0 agent_num: 44 done: False
______________________
id: 48 reward: 0.002232142857142857 service_time: 5131 s_time: -3 penalty: 0 agent_num: 24 done: False
______________________
id: 42 reward: -0.022416413373860182 service_time: 3531 s_time: 59 penalty: 0 agent_num: 47 done: False
______________________
id: 52 reward: 0.0005580357142857143 service_time: 3637 s_time: -1 penalty: 0 agent_num: 32 done: False
______________________
id: 53 reward: 0.01416256157635468 service_time: 3563 s_time: -23 penalty: 0 agent_num: 29 done: False
______________________
Step:  5056
Pretraining Loss:  tensor(0.0384, device='cuda:0', grad_fn=<MeanBackward0>)
id: 54 reward: -0.15521978021978022 service_time: 3546 s_time: 113 penalty: 0 agent_num: 13 done: False
______________________
id: 49 reward: -0.137987012987013 service_time: 3257 s_time: 85 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: 0.01995798319327731 service_time: 1572 s_time: -19 penalty: 0 agent_num: 17 done: False
______________________
id: 55 reward: -0.04285714285714286 service_time: 2771 s_time: 36 penalty: 0 agent_num: 15 done: False
______________________
id: 51 reward: 0.0 service_time: 2234 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 46 reward: -0.021763392857142856 service_time: 77 s_time: 39 penalty: 0 agent_num: 32 done: False
______________________
id: 48 reward: 0.005952380952380952 service_time: 5123 s_time: -8 penalty: 0 agent_num: 24 done: False
______________________
id: 40 reward: 0.0 service_time: 2339 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 50 reward: -0.010135135135135136 service_time: 3704 s_time: 21 penalty: 0 agent_num: 37 done: False
______________________
id: 41 reward: -0.010044642857142858 service_time: 3842 s_time: 18 penalty: 0 agent_num: 32 done: False
______________________
id: 44 reward: 0.0007763975155279503 service_time: 2612 s_time: -2 penalty: 0 agent_num: 46 done: False
______________________
id: 45 reward: 0.0 service_time: 4230 s_time: 0 penalty: 0 agent_num: 28 done: False
______________________
id: 42 reward: -0.0121580547112462 service_time: 3563 s_time: 32 penalty: 0 agent_num: 47 done: False
______________________
id: 43 reward: 0.002029220779220779 service_time: 3655 s_time: -5 penalty: 0 agent_num: 44 done: False
______________________
id: 53 reward: 0.008004926108374385 service_time: 3550 s_time: -13 penalty: 0 agent_num: 29 done: False
______________________
id: 52 reward: -0.024553571428571428 service_time: 3681 s_time: 44 penalty: 0 agent_num: 32 done: False
______________________
Step:  5072
Pretraining Loss:  tensor(0.0484, device='cuda:0', grad_fn=<MeanBackward0>)
id: 47 reward: -0.05777310924369748 service_time: 1627 s_time: 55 penalty: 0 agent_num: 17 done: False
______________________
id: 54 reward: -0.12225274725274725 service_time: 3635 s_time: 89 penalty: 0 agent_num: 13 done: False
______________________
id: 55 reward: -0.05119047619047619 service_time: 2814 s_time: 43 penalty: 0 agent_num: 15 done: False
______________________
id: 51 reward: -0.023214285714285715 service_time: 2260 s_time: 26 penalty: 0 agent_num: 20 done: False
______________________
id: 49 reward: -0.09577922077922078 service_time: 3316 s_time: 59 penalty: 0 agent_num: 11 done: False
______________________
id: 46 reward: 0.0 service_time: 77 s_time: 0 penalty: 0 agent_num: 32 done: False
______________________
id: 48 reward: 0.000744047619047619 service_time: 5122 s_time: -1 penalty: 0 agent_num: 24 done: False
______________________
id: 40 reward: -0.011278195488721804 service_time: 2363 s_time: 24 penalty: 0 agent_num: 38 done: False
______________________
id: 44 reward: -0.01203416149068323 service_time: 2643 s_time: 31 penalty: 0 agent_num: 46 done: False
______________________
id: 43 reward: -0.005681818181818182 service_time: 3669 s_time: 14 penalty: 0 agent_num: 44 done: False
______________________
id: 50 reward: -0.0028957528957528956 service_time: 3710 s_time: 6 penalty: 0 agent_num: 37 done: False
______________________
id: 41 reward: -0.026785714285714284 service_time: 3890 s_time: 48 penalty: 0 agent_num: 32 done: False
______________________
id: 53 reward: -0.046798029556650245 service_time: 3626 s_time: 76 penalty: 0 agent_num: 29 done: False
______________________
id: 42 reward: -0.016717325227963525 service_time: 3607 s_time: 44 penalty: 0 agent_num: 47 done: False
______________________
id: 52 reward: -0.005580357142857143 service_time: 3691 s_time: 10 penalty: 0 agent_num: 32 done: False
______________________
id: 45 reward: 20.0 service_time: 4230 s_time: 0 penalty: 0 agent_num: 28 done: True
______________________
Step:  5088
Pretraining Loss:  tensor(0.0479, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.2077922077922078 service_time: 3444 s_time: 128 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: 0.0 service_time: 1627 s_time: 0 penalty: 0 agent_num: 17 done: False
______________________
id: 54 reward: -0.08928571428571429 service_time: 3700 s_time: 65 penalty: 0 agent_num: 13 done: False
______________________
id: 55 reward: -0.09404761904761905 service_time: 2893 s_time: 79 penalty: 0 agent_num: 15 done: False
______________________
id: 51 reward: -0.024107142857142858 service_time: 2287 s_time: 27 penalty: 0 agent_num: 20 done: False
______________________
id: 45 reward: -0.027439024390243903 service_time: 63 s_time: 63 penalty: 0 agent_num: 41 done: False
______________________
id: 48 reward: 0.0 service_time: 5122 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 46 reward: -0.020647321428571428 service_time: 114 s_time: 37 penalty: 0 agent_num: 32 done: False
______________________
id: 50 reward: -0.016891891891891893 service_time: 3745 s_time: 35 penalty: 0 agent_num: 37 done: False
______________________
id: 40 reward: 0.0 service_time: 2363 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 44 reward: -0.007763975155279503 service_time: 2663 s_time: 20 penalty: 0 agent_num: 46 done: False
______________________
id: 41 reward: -0.01953125 service_time: 3925 s_time: 35 penalty: 0 agent_num: 32 done: False
______________________
id: 43 reward: 0.0 service_time: 3669 s_time: 0 penalty: 0 agent_num: 44 done: False
______________________
id: 53 reward: -0.046182266009852216 service_time: 3701 s_time: 75 penalty: 0 agent_num: 29 done: False
______________________
id: 42 reward: -0.0007598784194528875 service_time: 3609 s_time: 2 penalty: 0 agent_num: 47 done: False
______________________
id: 52 reward: -0.024553571428571428 service_time: 3735 s_time: 44 penalty: 0 agent_num: 32 done: False
______________________
Step:  5104
Pretraining Loss:  tensor(0.0300, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.32954545454545453 service_time: 3647 s_time: 203 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: 0.004201680672268907 service_time: 1623 s_time: -4 penalty: 0 agent_num: 17 done: False
______________________
id: 54 reward: -0.15521978021978022 service_time: 3813 s_time: 113 penalty: 0 agent_num: 13 done: False
______________________
id: 46 reward: -0.010044642857142858 service_time: 132 s_time: 18 penalty: 0 agent_num: 32 done: False
______________________
id: 55 reward: -0.06666666666666667 service_time: 2949 s_time: 56 penalty: 0 agent_num: 15 done: False
______________________
id: 45 reward: -0.007404181184668989 service_time: 80 s_time: 17 penalty: 0 agent_num: 41 done: False
______________________
id: 48 reward: 0.0 service_time: 5122 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 51 reward: -0.008928571428571428 service_time: 2297 s_time: 10 penalty: 0 agent_num: 20 done: False
______________________
id: 40 reward: -0.008928571428571428 service_time: 2382 s_time: 19 penalty: 0 agent_num: 38 done: False
______________________
id: 44 reward: 0.0 service_time: 2663 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 41 reward: -0.010044642857142858 service_time: 3943 s_time: 18 penalty: 0 agent_num: 32 done: False
______________________
id: 50 reward: -0.008687258687258687 service_time: 3763 s_time: 18 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: -0.020320197044334975 service_time: 3734 s_time: 33 penalty: 0 agent_num: 29 done: False
______________________
id: 52 reward: 0.0 service_time: 3735 s_time: 0 penalty: 0 agent_num: 32 done: False
______________________
id: 42 reward: -0.018996960486322188 service_time: 3659 s_time: 50 penalty: 0 agent_num: 47 done: False
______________________
id: 43 reward: 20.00202922077922 service_time: 3664 s_time: -5 penalty: 0 agent_num: 44 done: True
______________________
