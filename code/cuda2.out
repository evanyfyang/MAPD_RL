nohup: ignoring input
=============================================
Start Training: GPU=2, LR=1e-4, gamma=0.99, tau=0.1
Task Number: 500, Process Number: 16
Model Directory: ../models/_20250328_1121_lr_1e-4_gamma_0.99_tau_0.1_concat_0_16_500
=============================================
*** Loading map ***
Map size: 21x35 with 352 endpoints and 0 home stations.
Done! (0 s)
*** PreProcessing map ***
*** Loading map ***
Map size: 21x35 with 352 endpoints and 0 home stations.
Done! (0 s)
*** PreProcessing map ***
Done! (0 s)
*** Loading map ***
Map size: 21x35 with 352 endpoints and 0 home stations.
Done! (0 s)
*** PreProcessing map ***
*** Loading map ***
Map size: 21x35 with 352 endpoints and 0 home stations.
Done! (0 s)
*** PreProcessing map ***
Done! (0 s)
*** Loading map ***
Map size: 21x35 with 352 endpoints and 0 home stations.
Done! (0 s)
*** PreProcessing map ***
*** Loading map ***
Map size: 21x35 with 352 endpoints and 0 home stations.
Done! (0 s)
*** PreProcessing map ***
*** Loading map ***
Map size: 21x35 with 352 endpoints and 0 home stations.
Done! (0 s)
*** PreProcessing map ***
Done! (0 s)
Done! (0 s)
*** Loading map ***
Map size: 21x35 with 352 endpoints and 0 home stations.
Done! (0 s)
*** PreProcessing map ***
Done! (0 s)
Done! (0 s)
*** Loading map ***
Map size: 21x35 with 352 endpoints and 0 home stations.
Done! (0 s)
*** PreProcessing map ***
Done! (0 s)
*** Loading map ***
Map size: 21x35 with 352 endpoints and 0 home stations.
Done! (0 s)
*** PreProcessing map ***
*** Loading map ***
Map size: 21x35 with 352 endpoints and 0 home stations.
Done! (0 s)
*** PreProcessing map ***
Done! (0 s)
Done! (0 s)
*** Loading map ***
*** Loading map ***
*** Loading map ***
Map size: 21x35 with 352 endpoints and 0 home stations.
Map size: 21x35 with 352 endpoints and 0 home stations.
Done! (0 s)
Done! (0 s)
*** PreProcessing map ***
*** PreProcessing map ***
Map size: 21x35 with 352 endpoints and 0 home stations.
Done! (0 s)
*** PreProcessing map ***
*** Loading map ***
Map size: 21x35 with 352 endpoints and 0 home stations.
Done! (0 s)
*** PreProcessing map ***
*** Loading map ***
Map size: 21x35 with 352 endpoints and 0 home stations.
Done! (0 s)
*** PreProcessing map ***
Done! (0 s)
Done! (0 s)
Done! (0 s)
Done! (0 s)
Done! (0 s)
Done! (0 s)
Done! (0 s)
/localhome/yya305/miniconda3/envs/MAPD_RL/lib/python3.11/site-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(f"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}")
id: 48 reward: -0.025510204081632654 service_time: 20 s_time: 20 penalty: 0 agent_num: 14 done: False
______________________
id: 43 reward: -0.027472527472527472 service_time: 20 s_time: 20 penalty: 0 agent_num: 13 done: False
______________________
id: 42 reward: -0.02100840336134454 service_time: 20 s_time: 20 penalty: 0 agent_num: 17 done: False
______________________
id: 40 reward: -0.028769841269841268 service_time: 29 s_time: 29 penalty: 0 agent_num: 18 done: False
______________________
id: 47 reward: -0.02142857142857143 service_time: 24 s_time: 24 penalty: 0 agent_num: 20 done: False
______________________
id: 45 reward: -0.021258503401360544 service_time: 25 s_time: 25 penalty: 0 agent_num: 21 done: False
______________________
id: 51 reward: -0.0205026455026455 service_time: 31 s_time: 31 penalty: 0 agent_num: 27 done: False
______________________
id: 41 reward: -0.013095238095238096 service_time: 22 s_time: 22 penalty: 0 agent_num: 30 done: False
______________________
id: 46 reward: -0.012672811059907835 service_time: 22 s_time: 22 penalty: 0 agent_num: 31 done: False
______________________
id: 44 reward: -0.020089285714285716 service_time: 36 s_time: 36 penalty: 0 agent_num: 32 done: False
______________________
id: 55 reward: -0.009259259259259259 service_time: 14 s_time: 14 penalty: 0 agent_num: 27 done: False
______________________
id: 52 reward: -0.010714285714285714 service_time: 21 s_time: 21 penalty: 0 agent_num: 35 done: False
______________________
id: 53 reward: -0.02023809523809524 service_time: 34 s_time: 34 penalty: 0 agent_num: 30 done: False
______________________
id: 50 reward: -0.027597402597402596 service_time: 34 s_time: 34 penalty: 0 agent_num: 22 done: False
______________________
id: 54 reward: -0.007305194805194805 service_time: 18 s_time: 18 penalty: 0 agent_num: 44 done: False
______________________
id: 49 reward: -0.02131336405529954 service_time: 37 s_time: 37 penalty: 0 agent_num: 31 done: False
______________________
Using cuda device
Step:  0
Pretraining Loss:  tensor(0.0864, device='cuda:0', grad_fn=<MeanBackward0>)
id: 43 reward: -0.04395604395604396 service_time: 52 s_time: 32 penalty: 0 agent_num: 13 done: False
______________________
id: 48 reward: -0.047193877551020405 service_time: 57 s_time: 37 penalty: 0 agent_num: 14 done: False
______________________
id: 42 reward: -0.022058823529411766 service_time: 41 s_time: 21 penalty: 0 agent_num: 17 done: False
______________________
id: 40 reward: -0.023809523809523808 service_time: 53 s_time: 24 penalty: 0 agent_num: 18 done: False
______________________
id: 47 reward: -0.019642857142857142 service_time: 46 s_time: 22 penalty: 0 agent_num: 20 done: False
______________________
id: 45 reward: 0.0 service_time: 25 s_time: 0 penalty: 0 agent_num: 21 done: False
______________________
id: 55 reward: -0.009259259259259259 service_time: 28 s_time: 14 penalty: 0 agent_num: 27 done: False
______________________
id: 50 reward: -0.018668831168831168 service_time: 57 s_time: 23 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: -0.01984126984126984 service_time: 61 s_time: 30 penalty: 0 agent_num: 27 done: False
______________________
id: 46 reward: -0.020737327188940093 service_time: 58 s_time: 36 penalty: 0 agent_num: 31 done: False
______________________
id: 44 reward: -0.015625 service_time: 64 s_time: 28 penalty: 0 agent_num: 32 done: False
______________________
id: 52 reward: -0.014285714285714285 service_time: 49 s_time: 28 penalty: 0 agent_num: 35 done: False
______________________
id: 41 reward: -0.014285714285714285 service_time: 46 s_time: 24 penalty: 0 agent_num: 30 done: False
______________________
id: 53 reward: -0.0125 service_time: 55 s_time: 21 penalty: 0 agent_num: 30 done: False
______________________
id: 49 reward: -0.017857142857142856 service_time: 68 s_time: 31 penalty: 0 agent_num: 31 done: False
______________________
id: 54 reward: 0.0 service_time: 18 s_time: 0 penalty: 0 agent_num: 44 done: False
______________________
Step:  16
Pretraining Loss:  tensor(0.1128, device='cuda:0', grad_fn=<MeanBackward0>)
id: 40 reward: -0.018849206349206348 service_time: 72 s_time: 19 penalty: 0 agent_num: 18 done: False
______________________
id: 43 reward: -0.04807692307692308 service_time: 87 s_time: 35 penalty: 0 agent_num: 13 done: False
______________________
id: 47 reward: -0.015178571428571428 service_time: 63 s_time: 17 penalty: 0 agent_num: 20 done: False
______________________
id: 45 reward: -0.03571428571428571 service_time: 67 s_time: 42 penalty: 0 agent_num: 21 done: False
______________________
id: 42 reward: -0.029411764705882353 service_time: 69 s_time: 28 penalty: 0 agent_num: 17 done: False
______________________
id: 55 reward: -0.012566137566137565 service_time: 47 s_time: 19 penalty: 0 agent_num: 27 done: False
______________________
id: 51 reward: -0.017195767195767195 service_time: 87 s_time: 26 penalty: 0 agent_num: 27 done: False
______________________
id: 50 reward: -0.008928571428571428 service_time: 68 s_time: 11 penalty: 0 agent_num: 22 done: False
______________________
id: 46 reward: -0.010944700460829493 service_time: 77 s_time: 19 penalty: 0 agent_num: 31 done: False
______________________
id: 48 reward: -0.04974489795918367 service_time: 96 s_time: 39 penalty: 0 agent_num: 14 done: False
______________________
id: 44 reward: -0.011160714285714286 service_time: 84 s_time: 20 penalty: 0 agent_num: 32 done: False
______________________
id: 54 reward: -0.013798701298701298 service_time: 52 s_time: 34 penalty: 0 agent_num: 44 done: False
______________________
id: 49 reward: -0.01152073732718894 service_time: 88 s_time: 20 penalty: 0 agent_num: 31 done: False
______________________
id: 53 reward: -0.007738095238095238 service_time: 68 s_time: 13 penalty: 0 agent_num: 30 done: False
______________________
id: 52 reward: -0.02142857142857143 service_time: 91 s_time: 42 penalty: 0 agent_num: 35 done: False
______________________
id: 41 reward: -0.011904761904761904 service_time: 66 s_time: 20 penalty: 0 agent_num: 30 done: False
______________________
Step:  32
Pretraining Loss:  tensor(0.1357, device='cuda:0', grad_fn=<MeanBackward0>)
id: 42 reward: 0.0 service_time: 69 s_time: 0 penalty: 0 agent_num: 17 done: False
______________________
id: 43 reward: 0.0013736263736263737 service_time: 86 s_time: -1 penalty: 0 agent_num: 13 done: False
______________________
id: 40 reward: -0.017857142857142856 service_time: 90 s_time: 18 penalty: 0 agent_num: 18 done: False
______________________
id: 47 reward: -0.00625 service_time: 70 s_time: 7 penalty: 0 agent_num: 20 done: False
______________________
id: 50 reward: -0.016233766233766232 service_time: 88 s_time: 20 penalty: 0 agent_num: 22 done: False
______________________
id: 45 reward: -0.017857142857142856 service_time: 88 s_time: 21 penalty: 0 agent_num: 21 done: False
______________________
id: 51 reward: -0.01984126984126984 service_time: 117 s_time: 30 penalty: 0 agent_num: 27 done: False
______________________
id: 55 reward: -0.0205026455026455 service_time: 78 s_time: 31 penalty: 0 agent_num: 27 done: False
______________________
id: 48 reward: -0.04974489795918367 service_time: 135 s_time: 39 penalty: 0 agent_num: 14 done: False
______________________
id: 53 reward: -0.014285714285714285 service_time: 92 s_time: 24 penalty: 0 agent_num: 30 done: False
______________________
id: 41 reward: -0.01607142857142857 service_time: 93 s_time: 27 penalty: 0 agent_num: 30 done: False
______________________
id: 44 reward: -0.006138392857142857 service_time: 95 s_time: 11 penalty: 0 agent_num: 32 done: False
______________________
id: 49 reward: -0.009216589861751152 service_time: 104 s_time: 16 penalty: 0 agent_num: 31 done: False
______________________
id: 52 reward: -0.008673469387755102 service_time: 108 s_time: 17 penalty: 0 agent_num: 35 done: False
______________________
id: 46 reward: -0.012096774193548387 service_time: 98 s_time: 21 penalty: 0 agent_num: 31 done: False
______________________
id: 54 reward: -0.02150974025974026 service_time: 105 s_time: 53 penalty: 0 agent_num: 44 done: False
______________________
Step:  48
Pretraining Loss:  tensor(0.1560, device='cuda:0', grad_fn=<MeanBackward0>)
id: 43 reward: -0.054945054945054944 service_time: 126 s_time: 40 penalty: 0 agent_num: 13 done: False
______________________
id: 40 reward: -0.017857142857142856 service_time: 108 s_time: 18 penalty: 0 agent_num: 18 done: False
______________________
id: 42 reward: -0.038865546218487396 service_time: 106 s_time: 37 penalty: 0 agent_num: 17 done: False
______________________
id: 48 reward: -0.03826530612244898 service_time: 165 s_time: 30 penalty: 0 agent_num: 14 done: False
______________________
id: 55 reward: -0.010582010582010581 service_time: 94 s_time: 16 penalty: 0 agent_num: 27 done: False
______________________
id: 45 reward: -0.013605442176870748 service_time: 104 s_time: 16 penalty: 0 agent_num: 21 done: False
______________________
id: 51 reward: 0.0 service_time: 117 s_time: 0 penalty: 0 agent_num: 27 done: False
______________________
id: 50 reward: 0.0 service_time: 88 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 44 reward: -0.017299107142857144 service_time: 126 s_time: 31 penalty: 0 agent_num: 32 done: False
______________________
id: 53 reward: -0.01369047619047619 service_time: 115 s_time: 23 penalty: 0 agent_num: 30 done: False
______________________
id: 47 reward: -0.011607142857142858 service_time: 83 s_time: 13 penalty: 0 agent_num: 20 done: False
______________________
id: 46 reward: -0.014400921658986175 service_time: 123 s_time: 25 penalty: 0 agent_num: 31 done: False
______________________
id: 41 reward: -0.020833333333333332 service_time: 128 s_time: 35 penalty: 0 agent_num: 30 done: False
______________________
id: 52 reward: 0.0 service_time: 108 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 49 reward: -0.016129032258064516 service_time: 132 s_time: 28 penalty: 0 agent_num: 31 done: False
______________________
id: 54 reward: -0.014204545454545454 service_time: 140 s_time: 35 penalty: 0 agent_num: 44 done: False
______________________
Step:  64
Pretraining Loss:  tensor(0.1616, device='cuda:0', grad_fn=<MeanBackward0>)
id: 43 reward: -0.028846153846153848 service_time: 147 s_time: 21 penalty: 0 agent_num: 13 done: False
______________________
id: 47 reward: -0.011607142857142858 service_time: 96 s_time: 13 penalty: 0 agent_num: 20 done: False
______________________
id: 45 reward: -0.02295918367346939 service_time: 131 s_time: 27 penalty: 0 agent_num: 21 done: False
______________________
id: 50 reward: -0.033279220779220776 service_time: 129 s_time: 41 penalty: 0 agent_num: 22 done: False
______________________
id: 42 reward: -0.03571428571428571 service_time: 140 s_time: 34 penalty: 0 agent_num: 17 done: False
______________________
id: 48 reward: -0.03571428571428571 service_time: 193 s_time: 28 penalty: 0 agent_num: 14 done: False
______________________
id: 40 reward: -0.044642857142857144 service_time: 153 s_time: 45 penalty: 0 agent_num: 18 done: False
______________________
id: 55 reward: -0.017857142857142856 service_time: 121 s_time: 27 penalty: 0 agent_num: 27 done: False
______________________
id: 51 reward: -0.03373015873015873 service_time: 168 s_time: 51 penalty: 0 agent_num: 27 done: False
______________________
id: 46 reward: -0.013248847926267281 service_time: 146 s_time: 23 penalty: 0 agent_num: 31 done: False
______________________
id: 44 reward: 0.0 service_time: 126 s_time: 0 penalty: 0 agent_num: 32 done: False
______________________
id: 53 reward: -0.01369047619047619 service_time: 138 s_time: 23 penalty: 0 agent_num: 30 done: False
______________________
id: 52 reward: -0.025 service_time: 157 s_time: 49 penalty: 0 agent_num: 35 done: False
______________________
id: 49 reward: -0.014400921658986175 service_time: 157 s_time: 25 penalty: 0 agent_num: 31 done: False
______________________
id: 41 reward: 0.0 service_time: 128 s_time: 0 penalty: 0 agent_num: 30 done: False
______________________
id: 54 reward: 0.0 service_time: 140 s_time: 0 penalty: 0 agent_num: 44 done: False
______________________
Step:  80
Pretraining Loss:  tensor(0.1783, device='cuda:0', grad_fn=<MeanBackward0>)
id: 43 reward: -0.03159340659340659 service_time: 170 s_time: 23 penalty: 0 agent_num: 13 done: False
______________________
id: 48 reward: -0.04336734693877551 service_time: 227 s_time: 34 penalty: 0 agent_num: 14 done: False
______________________
id: 47 reward: 0.0 service_time: 96 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 45 reward: -0.00935374149659864 service_time: 142 s_time: 11 penalty: 0 agent_num: 21 done: False
______________________
id: 40 reward: -0.0248015873015873 service_time: 178 s_time: 25 penalty: 0 agent_num: 18 done: False
______________________
id: 42 reward: -0.029411764705882353 service_time: 168 s_time: 28 penalty: 0 agent_num: 17 done: False
______________________
id: 50 reward: -0.013798701298701298 service_time: 146 s_time: 17 penalty: 0 agent_num: 22 done: False
______________________
id: 46 reward: -0.016129032258064516 service_time: 174 s_time: 28 penalty: 0 agent_num: 31 done: False
______________________
id: 53 reward: -0.010714285714285714 service_time: 156 s_time: 18 penalty: 0 agent_num: 30 done: False
______________________
id: 55 reward: -0.016534391534391533 service_time: 146 s_time: 25 penalty: 0 agent_num: 27 done: False
______________________
id: 51 reward: 0.0 service_time: 168 s_time: 0 penalty: 0 agent_num: 27 done: False
______________________
id: 41 reward: -0.009523809523809525 service_time: 144 s_time: 16 penalty: 0 agent_num: 30 done: False
______________________
id: 44 reward: -0.04296875 service_time: 203 s_time: 77 penalty: 0 agent_num: 32 done: False
______________________
id: 49 reward: -0.019585253456221197 service_time: 191 s_time: 34 penalty: 0 agent_num: 31 done: False
______________________
id: 52 reward: -0.01020408163265306 service_time: 177 s_time: 20 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: -0.018262987012987012 service_time: 185 s_time: 45 penalty: 0 agent_num: 44 done: False
______________________
Step:  96
Pretraining Loss:  tensor(0.1950, device='cuda:0', grad_fn=<MeanBackward0>)
id: 43 reward: -0.06043956043956044 service_time: 214 s_time: 44 penalty: 0 agent_num: 13 done: False
______________________
id: 48 reward: -0.03316326530612245 service_time: 253 s_time: 26 penalty: 0 agent_num: 14 done: False
______________________
id: 47 reward: -0.019642857142857142 service_time: 118 s_time: 22 penalty: 0 agent_num: 20 done: False
______________________
id: 42 reward: -0.018907563025210083 service_time: 186 s_time: 18 penalty: 0 agent_num: 17 done: False
______________________
id: 45 reward: -0.02891156462585034 service_time: 176 s_time: 34 penalty: 0 agent_num: 21 done: False
______________________
id: 40 reward: 0.020833333333333332 service_time: 157 s_time: -21 penalty: 0 agent_num: 18 done: False
______________________
id: 50 reward: -0.040584415584415584 service_time: 196 s_time: 50 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: -0.026455026455026454 service_time: 208 s_time: 40 penalty: 0 agent_num: 27 done: False
______________________
id: 55 reward: -0.016534391534391533 service_time: 171 s_time: 25 penalty: 0 agent_num: 27 done: False
______________________
id: 53 reward: -0.004166666666666667 service_time: 163 s_time: 7 penalty: 0 agent_num: 30 done: False
______________________
id: 46 reward: 0.0 service_time: 174 s_time: 0 penalty: 0 agent_num: 31 done: False
______________________
id: 44 reward: -0.010602678571428572 service_time: 222 s_time: 19 penalty: 0 agent_num: 32 done: False
______________________
id: 41 reward: 0.0 service_time: 144 s_time: 0 penalty: 0 agent_num: 30 done: False
______________________
id: 52 reward: -0.018367346938775512 service_time: 213 s_time: 36 penalty: 0 agent_num: 35 done: False
______________________
id: 49 reward: -0.013248847926267281 service_time: 214 s_time: 23 penalty: 0 agent_num: 31 done: False
______________________
id: 54 reward: -0.014204545454545454 service_time: 220 s_time: 35 penalty: 0 agent_num: 44 done: False
______________________
Step:  112
Pretraining Loss:  tensor(0.2311, device='cuda:0', grad_fn=<MeanBackward0>)
id: 47 reward: 0.0 service_time: 118 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 40 reward: -0.04365079365079365 service_time: 201 s_time: 44 penalty: 0 agent_num: 18 done: False
______________________
id: 42 reward: -0.03676470588235294 service_time: 221 s_time: 35 penalty: 0 agent_num: 17 done: False
______________________
id: 48 reward: -0.030612244897959183 service_time: 277 s_time: 24 penalty: 0 agent_num: 14 done: False
______________________
id: 45 reward: 0.0 service_time: 176 s_time: 0 penalty: 0 agent_num: 21 done: False
______________________
id: 53 reward: -0.016666666666666666 service_time: 191 s_time: 28 penalty: 0 agent_num: 30 done: False
______________________
id: 55 reward: 0.0 service_time: 171 s_time: 0 penalty: 0 agent_num: 27 done: False
______________________
id: 51 reward: -0.0205026455026455 service_time: 239 s_time: 31 penalty: 0 agent_num: 27 done: False
______________________
id: 41 reward: 0.0 service_time: 144 s_time: 0 penalty: 0 agent_num: 30 done: False
______________________
id: 50 reward: -0.02922077922077922 service_time: 232 s_time: 36 penalty: 0 agent_num: 22 done: False
______________________
id: 44 reward: 0.0 service_time: 222 s_time: 0 penalty: 0 agent_num: 32 done: False
______________________
id: 43 reward: -0.01098901098901099 service_time: 222 s_time: 8 penalty: 0 agent_num: 13 done: False
______________________
id: 46 reward: -0.03513824884792627 service_time: 235 s_time: 61 penalty: 0 agent_num: 31 done: False
______________________
id: 49 reward: -0.020161290322580645 service_time: 249 s_time: 35 penalty: 0 agent_num: 31 done: False
______________________
id: 52 reward: 0.0 service_time: 213 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: 0.0 service_time: 220 s_time: 0 penalty: 0 agent_num: 44 done: False
______________________
Step:  128
Pretraining Loss:  tensor(0.2379, device='cuda:0', grad_fn=<MeanBackward0>)
id: 48 reward: 0.003826530612244898 service_time: 274 s_time: -3 penalty: 0 agent_num: 14 done: False
______________________
id: 40 reward: 0.001984126984126984 service_time: 199 s_time: -2 penalty: 0 agent_num: 18 done: False
______________________
id: 43 reward: -0.04395604395604396 service_time: 254 s_time: 32 penalty: 0 agent_num: 13 done: False
______________________
id: 42 reward: 0.0 service_time: 221 s_time: 0 penalty: 0 agent_num: 17 done: False
______________________
id: 45 reward: -0.03231292517006803 service_time: 214 s_time: 38 penalty: 0 agent_num: 21 done: False
______________________
id: 50 reward: -0.015422077922077922 service_time: 251 s_time: 19 penalty: 0 agent_num: 22 done: False
______________________
id: 41 reward: -0.016666666666666666 service_time: 172 s_time: 28 penalty: 0 agent_num: 30 done: False
______________________
id: 53 reward: -0.014285714285714285 service_time: 215 s_time: 24 penalty: 0 agent_num: 30 done: False
______________________
id: 44 reward: -0.005580357142857143 service_time: 232 s_time: 10 penalty: 0 agent_num: 32 done: False
______________________
id: 55 reward: -0.03505291005291005 service_time: 224 s_time: 53 penalty: 0 agent_num: 27 done: False
______________________
id: 49 reward: -0.02476958525345622 service_time: 292 s_time: 43 penalty: 0 agent_num: 31 done: False
______________________
id: 47 reward: -0.025 service_time: 146 s_time: 28 penalty: 0 agent_num: 20 done: False
______________________
id: 46 reward: -0.02534562211981567 service_time: 279 s_time: 44 penalty: 0 agent_num: 31 done: False
______________________
id: 51 reward: -0.023809523809523808 service_time: 275 s_time: 36 penalty: 0 agent_num: 27 done: False
______________________
id: 52 reward: -0.02346938775510204 service_time: 259 s_time: 46 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: -0.014204545454545454 service_time: 255 s_time: 35 penalty: 0 agent_num: 44 done: False
______________________
Step:  144
Pretraining Loss:  tensor(0.2523, device='cuda:0', grad_fn=<MeanBackward0>)
id: 47 reward: -0.022321428571428572 service_time: 171 s_time: 25 penalty: 0 agent_num: 20 done: False
______________________
id: 43 reward: -0.057692307692307696 service_time: 296 s_time: 42 penalty: 0 agent_num: 13 done: False
______________________
id: 48 reward: -0.04846938775510204 service_time: 312 s_time: 38 penalty: 0 agent_num: 14 done: False
______________________
id: 40 reward: -0.017857142857142856 service_time: 217 s_time: 18 penalty: 0 agent_num: 18 done: False
______________________
id: 45 reward: 0.0 service_time: 214 s_time: 0 penalty: 0 agent_num: 21 done: False
______________________
id: 42 reward: -0.06512605042016807 service_time: 283 s_time: 62 penalty: 0 agent_num: 17 done: False
______________________
id: 53 reward: -0.0011904761904761906 service_time: 217 s_time: 2 penalty: 0 agent_num: 30 done: False
______________________
id: 50 reward: -0.017045454545454544 service_time: 272 s_time: 21 penalty: 0 agent_num: 22 done: False
______________________
id: 41 reward: -0.011904761904761904 service_time: 192 s_time: 20 penalty: 0 agent_num: 30 done: False
______________________
id: 55 reward: -0.022486772486772486 service_time: 258 s_time: 34 penalty: 0 agent_num: 27 done: False
______________________
id: 46 reward: 0.0 service_time: 279 s_time: 0 penalty: 0 agent_num: 31 done: False
______________________
id: 44 reward: -0.017857142857142856 service_time: 264 s_time: 32 penalty: 0 agent_num: 32 done: False
______________________
id: 51 reward: -0.021164021164021163 service_time: 307 s_time: 32 penalty: 0 agent_num: 27 done: False
______________________
id: 49 reward: 0.0 service_time: 292 s_time: 0 penalty: 0 agent_num: 31 done: False
______________________
id: 52 reward: -0.010714285714285714 service_time: 280 s_time: 21 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: -0.005681818181818182 service_time: 269 s_time: 14 penalty: 0 agent_num: 44 done: False
______________________
Step:  160
Pretraining Loss:  tensor(0.2604, device='cuda:0', grad_fn=<MeanBackward0>)
id: 40 reward: -0.0248015873015873 service_time: 242 s_time: 25 penalty: 0 agent_num: 18 done: False
______________________
id: 47 reward: -0.005357142857142857 service_time: 177 s_time: 6 penalty: 0 agent_num: 20 done: False
______________________
id: 50 reward: -0.012175324675324676 service_time: 287 s_time: 15 penalty: 0 agent_num: 22 done: False
______________________
id: 48 reward: 0.0 service_time: 312 s_time: 0 penalty: 0 agent_num: 14 done: False
______________________
id: 41 reward: 0.0 service_time: 192 s_time: 0 penalty: 0 agent_num: 30 done: False
______________________
id: 42 reward: -0.028361344537815126 service_time: 310 s_time: 27 penalty: 0 agent_num: 17 done: False
______________________
id: 45 reward: -0.03571428571428571 service_time: 256 s_time: 42 penalty: 0 agent_num: 21 done: False
______________________
id: 55 reward: -0.003968253968253968 service_time: 264 s_time: 6 penalty: 0 agent_num: 27 done: False
______________________
id: 51 reward: -0.006613756613756613 service_time: 317 s_time: 10 penalty: 0 agent_num: 27 done: False
______________________
id: 53 reward: -0.01369047619047619 service_time: 240 s_time: 23 penalty: 0 agent_num: 30 done: False
______________________
id: 52 reward: -0.007142857142857143 service_time: 294 s_time: 14 penalty: 0 agent_num: 35 done: False
______________________
id: 44 reward: -0.016741071428571428 service_time: 294 s_time: 30 penalty: 0 agent_num: 32 done: False
______________________
id: 46 reward: -0.03052995391705069 service_time: 332 s_time: 53 penalty: 0 agent_num: 31 done: False
______________________
id: 49 reward: -0.032834101382488476 service_time: 349 s_time: 57 penalty: 0 agent_num: 31 done: False
______________________
id: 43 reward: 0.01098901098901099 service_time: 288 s_time: -8 penalty: 0 agent_num: 13 done: False
______________________
id: 54 reward: -0.006493506493506494 service_time: 285 s_time: 16 penalty: 0 agent_num: 44 done: False
______________________
Step:  176
Pretraining Loss:  tensor(0.2980, device='cuda:0', grad_fn=<MeanBackward0>)
id: 48 reward: -0.026785714285714284 service_time: 333 s_time: 21 penalty: 0 agent_num: 14 done: False
______________________
id: 47 reward: -0.014285714285714285 service_time: 193 s_time: 16 penalty: 0 agent_num: 20 done: False
______________________
id: 45 reward: -0.027210884353741496 service_time: 288 s_time: 32 penalty: 0 agent_num: 21 done: False
______________________
id: 43 reward: -0.08928571428571429 service_time: 353 s_time: 65 penalty: 0 agent_num: 13 done: False
______________________
id: 42 reward: -0.029411764705882353 service_time: 338 s_time: 28 penalty: 0 agent_num: 17 done: False
______________________
id: 50 reward: -0.008928571428571428 service_time: 298 s_time: 11 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: 0.0013227513227513227 service_time: 315 s_time: -2 penalty: 0 agent_num: 27 done: False
______________________
id: 41 reward: -0.02023809523809524 service_time: 226 s_time: 34 penalty: 0 agent_num: 30 done: False
______________________
id: 53 reward: -0.010714285714285714 service_time: 258 s_time: 18 penalty: 0 agent_num: 30 done: False
______________________
id: 52 reward: -0.013265306122448979 service_time: 320 s_time: 26 penalty: 0 agent_num: 35 done: False
______________________
id: 40 reward: -0.04265873015873016 service_time: 285 s_time: 43 penalty: 0 agent_num: 18 done: False
______________________
id: 55 reward: -0.023809523809523808 service_time: 300 s_time: 36 penalty: 0 agent_num: 27 done: False
______________________
id: 49 reward: -0.007488479262672811 service_time: 362 s_time: 13 penalty: 0 agent_num: 31 done: False
______________________
id: 44 reward: -0.018973214285714284 service_time: 328 s_time: 34 penalty: 0 agent_num: 32 done: False
______________________
id: 54 reward: -0.007305194805194805 service_time: 303 s_time: 18 penalty: 0 agent_num: 44 done: False
______________________
id: 46 reward: -0.017857142857142856 service_time: 363 s_time: 31 penalty: 0 agent_num: 31 done: False
______________________
Step:  192
Pretraining Loss:  tensor(0.2981, device='cuda:0', grad_fn=<MeanBackward0>)
id: 40 reward: 0.0 service_time: 285 s_time: 0 penalty: 0 agent_num: 18 done: False
______________________
id: 45 reward: -0.021258503401360544 service_time: 313 s_time: 25 penalty: 0 agent_num: 21 done: False
______________________
id: 48 reward: 0.0 service_time: 333 s_time: 0 penalty: 0 agent_num: 14 done: False
______________________
id: 42 reward: 0.0 service_time: 338 s_time: 0 penalty: 0 agent_num: 17 done: False
______________________
id: 50 reward: -0.025162337662337664 service_time: 329 s_time: 31 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: 0.0 service_time: 193 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 41 reward: 0.0 service_time: 226 s_time: 0 penalty: 0 agent_num: 30 done: False
______________________
id: 53 reward: -0.019642857142857142 service_time: 291 s_time: 33 penalty: 0 agent_num: 30 done: False
______________________
id: 55 reward: -0.01455026455026455 service_time: 322 s_time: 22 penalty: 0 agent_num: 27 done: False
______________________
id: 44 reward: 0.0 service_time: 328 s_time: 0 penalty: 0 agent_num: 32 done: False
______________________
id: 49 reward: -0.0069124423963133645 service_time: 374 s_time: 12 penalty: 0 agent_num: 31 done: False
______________________
id: 52 reward: -0.010714285714285714 service_time: 341 s_time: 21 penalty: 0 agent_num: 35 done: False
______________________
id: 46 reward: -0.014976958525345621 service_time: 389 s_time: 26 penalty: 0 agent_num: 31 done: False
______________________
id: 54 reward: -0.006493506493506494 service_time: 319 s_time: 16 penalty: 0 agent_num: 44 done: False
______________________
id: 43 reward: -0.059065934065934064 service_time: 396 s_time: 43 penalty: 0 agent_num: 13 done: False
______________________
id: 51 reward: -0.05357142857142857 service_time: 396 s_time: 81 penalty: 0 agent_num: 27 done: False
______________________
Step:  208
Pretraining Loss:  tensor(0.3418, device='cuda:0', grad_fn=<MeanBackward0>)
id: 48 reward: 0.0 service_time: 333 s_time: 0 penalty: 0 agent_num: 14 done: False
______________________
id: 50 reward: -0.024350649350649352 service_time: 359 s_time: 30 penalty: 0 agent_num: 22 done: False
______________________
id: 42 reward: -0.10294117647058823 service_time: 436 s_time: 98 penalty: 0 agent_num: 17 done: False
______________________
id: 45 reward: -0.02465986394557823 service_time: 342 s_time: 29 penalty: 0 agent_num: 21 done: False
______________________
id: 53 reward: -0.016666666666666666 service_time: 319 s_time: 28 penalty: 0 agent_num: 30 done: False
______________________
id: 43 reward: 0.013736263736263736 service_time: 386 s_time: -10 penalty: 0 agent_num: 13 done: False
______________________
id: 51 reward: -0.021825396825396824 service_time: 429 s_time: 33 penalty: 0 agent_num: 27 done: False
______________________
id: 47 reward: -0.027678571428571427 service_time: 224 s_time: 31 penalty: 0 agent_num: 20 done: False
______________________
id: 40 reward: -0.09126984126984126 service_time: 377 s_time: 92 penalty: 0 agent_num: 18 done: False
______________________
id: 52 reward: -0.006122448979591836 service_time: 353 s_time: 12 penalty: 0 agent_num: 35 done: False
______________________
id: 55 reward: 0.0 service_time: 322 s_time: 0 penalty: 0 agent_num: 27 done: False
______________________
id: 49 reward: 0.0 service_time: 374 s_time: 0 penalty: 0 agent_num: 31 done: False
______________________
id: 54 reward: -0.006899350649350649 service_time: 336 s_time: 17 penalty: 0 agent_num: 44 done: False
______________________
id: 41 reward: -0.006547619047619048 service_time: 237 s_time: 11 penalty: 0 agent_num: 30 done: False
______________________
id: 46 reward: -0.009216589861751152 service_time: 405 s_time: 16 penalty: 0 agent_num: 31 done: False
______________________
id: 44 reward: -0.029017857142857144 service_time: 380 s_time: 52 penalty: 0 agent_num: 32 done: False
______________________
Step:  224
Pretraining Loss:  tensor(0.3457, device='cuda:0', grad_fn=<MeanBackward0>)
id: 48 reward: -0.030612244897959183 service_time: 357 s_time: 24 penalty: 0 agent_num: 14 done: False
______________________
id: 40 reward: -0.025793650793650792 service_time: 403 s_time: 26 penalty: 0 agent_num: 18 done: False
______________________
id: 45 reward: -0.025510204081632654 service_time: 372 s_time: 30 penalty: 0 agent_num: 21 done: False
______________________
id: 42 reward: -0.017857142857142856 service_time: 453 s_time: 17 penalty: 0 agent_num: 17 done: False
______________________
id: 41 reward: -0.01130952380952381 service_time: 256 s_time: 19 penalty: 0 agent_num: 30 done: False
______________________
id: 53 reward: -0.01130952380952381 service_time: 338 s_time: 19 penalty: 0 agent_num: 30 done: False
______________________
id: 47 reward: -0.010714285714285714 service_time: 236 s_time: 12 penalty: 0 agent_num: 20 done: False
______________________
id: 50 reward: -0.01948051948051948 service_time: 383 s_time: 24 penalty: 0 agent_num: 22 done: False
______________________
id: 55 reward: -0.00992063492063492 service_time: 337 s_time: 15 penalty: 0 agent_num: 27 done: False
______________________
id: 51 reward: -0.015873015873015872 service_time: 453 s_time: 24 penalty: 0 agent_num: 27 done: False
______________________
id: 43 reward: 0.0 service_time: 386 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 49 reward: -0.01152073732718894 service_time: 394 s_time: 20 penalty: 0 agent_num: 31 done: False
______________________
id: 46 reward: -0.014976958525345621 service_time: 431 s_time: 26 penalty: 0 agent_num: 31 done: False
______________________
id: 52 reward: -0.012755102040816327 service_time: 378 s_time: 25 penalty: 0 agent_num: 35 done: False
______________________
id: 44 reward: -0.020089285714285716 service_time: 416 s_time: 36 penalty: 0 agent_num: 32 done: False
______________________
id: 54 reward: 0.0 service_time: 336 s_time: 0 penalty: 0 agent_num: 44 done: False
______________________
Step:  240
Pretraining Loss:  tensor(0.3853, device='cuda:0', grad_fn=<MeanBackward0>)
id: 48 reward: -0.03571428571428571 service_time: 385 s_time: 28 penalty: 0 agent_num: 14 done: False
______________________
id: 45 reward: -0.017857142857142856 service_time: 393 s_time: 21 penalty: 0 agent_num: 21 done: False
______________________
id: 50 reward: 0.0 service_time: 383 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 43 reward: -0.017857142857142856 service_time: 399 s_time: 13 penalty: 0 agent_num: 13 done: False
______________________
id: 51 reward: -0.01455026455026455 service_time: 475 s_time: 22 penalty: 0 agent_num: 27 done: False
______________________
id: 47 reward: -0.02142857142857143 service_time: 260 s_time: 24 penalty: 0 agent_num: 20 done: False
______________________
id: 40 reward: -0.04265873015873016 service_time: 446 s_time: 43 penalty: 0 agent_num: 18 done: False
______________________
id: 42 reward: -0.051470588235294115 service_time: 502 s_time: 49 penalty: 0 agent_num: 17 done: False
______________________
id: 41 reward: -0.005952380952380952 service_time: 266 s_time: 10 penalty: 0 agent_num: 30 done: False
______________________
id: 55 reward: -0.02976190476190476 service_time: 382 s_time: 45 penalty: 0 agent_num: 27 done: False
______________________
id: 49 reward: -0.022465437788018433 service_time: 433 s_time: 39 penalty: 0 agent_num: 31 done: False
______________________
id: 52 reward: -0.013265306122448979 service_time: 404 s_time: 26 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: -0.008116883116883116 service_time: 356 s_time: 20 penalty: 0 agent_num: 44 done: False
______________________
id: 44 reward: -0.0033482142857142855 service_time: 422 s_time: 6 penalty: 0 agent_num: 32 done: False
______________________
id: 53 reward: -0.023214285714285715 service_time: 377 s_time: 39 penalty: 0 agent_num: 30 done: False
______________________
id: 46 reward: -0.027649769585253458 service_time: 479 s_time: 48 penalty: 0 agent_num: 31 done: False
______________________
Step:  256
Pretraining Loss:  tensor(0.4212, device='cuda:0', grad_fn=<MeanBackward0>)
id: 43 reward: 0.01098901098901099 service_time: 391 s_time: -8 penalty: 0 agent_num: 13 done: False
______________________
id: 42 reward: -0.06512605042016807 service_time: 564 s_time: 62 penalty: 0 agent_num: 17 done: False
______________________
id: 45 reward: 0.0 service_time: 393 s_time: 0 penalty: 0 agent_num: 21 done: False
______________________
id: 41 reward: 0.0 service_time: 266 s_time: 0 penalty: 0 agent_num: 30 done: False
______________________
id: 48 reward: 0.0 service_time: 385 s_time: 0 penalty: 0 agent_num: 14 done: False
______________________
id: 40 reward: -0.028769841269841268 service_time: 475 s_time: 29 penalty: 0 agent_num: 18 done: False
______________________
id: 47 reward: -0.033035714285714286 service_time: 297 s_time: 37 penalty: 0 agent_num: 20 done: False
______________________
id: 53 reward: -0.027976190476190477 service_time: 424 s_time: 47 penalty: 0 agent_num: 30 done: False
______________________
id: 55 reward: -0.022486772486772486 service_time: 416 s_time: 34 penalty: 0 agent_num: 27 done: False
______________________
id: 52 reward: -0.01989795918367347 service_time: 443 s_time: 39 penalty: 0 agent_num: 35 done: False
______________________
id: 44 reward: -0.014508928571428572 service_time: 448 s_time: 26 penalty: 0 agent_num: 32 done: False
______________________
id: 46 reward: 0.0 service_time: 479 s_time: 0 penalty: 0 agent_num: 31 done: False
______________________
id: 51 reward: -0.017195767195767195 service_time: 501 s_time: 26 penalty: 0 agent_num: 27 done: False
______________________
id: 50 reward: -0.0698051948051948 service_time: 469 s_time: 86 penalty: 0 agent_num: 22 done: False
______________________
id: 54 reward: -0.01948051948051948 service_time: 404 s_time: 48 penalty: 0 agent_num: 44 done: False
______________________
id: 49 reward: -0.04205069124423963 service_time: 506 s_time: 73 penalty: 0 agent_num: 31 done: False
______________________
Step:  272
Pretraining Loss:  tensor(0.4465, device='cuda:0', grad_fn=<MeanBackward0>)
id: 48 reward: -0.01913265306122449 service_time: 400 s_time: 15 penalty: 0 agent_num: 14 done: False
______________________
id: 47 reward: -0.01607142857142857 service_time: 315 s_time: 18 penalty: 0 agent_num: 20 done: False
______________________
id: 45 reward: -0.03231292517006803 service_time: 431 s_time: 38 penalty: 0 agent_num: 21 done: False
______________________
id: 43 reward: 0.02197802197802198 service_time: 375 s_time: -16 penalty: 0 agent_num: 13 done: False
______________________
id: 50 reward: -0.02353896103896104 service_time: 498 s_time: 29 penalty: 0 agent_num: 22 done: False
______________________
id: 42 reward: 0.0021008403361344537 service_time: 562 s_time: -2 penalty: 0 agent_num: 17 done: False
______________________
id: 40 reward: 0.01984126984126984 service_time: 455 s_time: -20 penalty: 0 agent_num: 18 done: False
______________________
id: 51 reward: -0.02447089947089947 service_time: 538 s_time: 37 penalty: 0 agent_num: 27 done: False
______________________
id: 55 reward: -0.01455026455026455 service_time: 438 s_time: 22 penalty: 0 agent_num: 27 done: False
______________________
id: 52 reward: -0.012244897959183673 service_time: 467 s_time: 24 penalty: 0 agent_num: 35 done: False
______________________
id: 53 reward: -0.02261904761904762 service_time: 462 s_time: 38 penalty: 0 agent_num: 30 done: False
______________________
id: 44 reward: -0.0033482142857142855 service_time: 454 s_time: 6 penalty: 0 agent_num: 32 done: False
______________________
id: 46 reward: -0.0293778801843318 service_time: 530 s_time: 51 penalty: 0 agent_num: 31 done: False
______________________
id: 41 reward: 0.0 service_time: 266 s_time: 0 penalty: 0 agent_num: 30 done: False
______________________
id: 54 reward: -0.015016233766233766 service_time: 441 s_time: 37 penalty: 0 agent_num: 44 done: False
______________________
id: 49 reward: -0.02131336405529954 service_time: 543 s_time: 37 penalty: 0 agent_num: 31 done: False
______________________
Step:  288
Pretraining Loss:  tensor(0.4617, device='cuda:0', grad_fn=<MeanBackward0>)
id: 48 reward: -0.01403061224489796 service_time: 411 s_time: 11 penalty: 0 agent_num: 14 done: False
______________________
id: 43 reward: 0.0 service_time: 375 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 42 reward: 0.014705882352941176 service_time: 548 s_time: -14 penalty: 0 agent_num: 17 done: False
______________________
id: 47 reward: -0.033928571428571426 service_time: 353 s_time: 38 penalty: 0 agent_num: 20 done: False
______________________
id: 40 reward: -0.031746031746031744 service_time: 487 s_time: 32 penalty: 0 agent_num: 18 done: False
______________________
id: 45 reward: -0.03486394557823129 service_time: 472 s_time: 41 penalty: 0 agent_num: 21 done: False
______________________
id: 41 reward: -0.01130952380952381 service_time: 285 s_time: 19 penalty: 0 agent_num: 30 done: False
______________________
id: 51 reward: -0.017857142857142856 service_time: 565 s_time: 27 penalty: 0 agent_num: 27 done: False
______________________
id: 50 reward: -0.030844155844155844 service_time: 536 s_time: 38 penalty: 0 agent_num: 22 done: False
______________________
id: 55 reward: -0.03306878306878307 service_time: 488 s_time: 50 penalty: 0 agent_num: 27 done: False
______________________
id: 44 reward: 0.0 service_time: 454 s_time: 0 penalty: 0 agent_num: 32 done: False
______________________
id: 53 reward: -0.025 service_time: 504 s_time: 42 penalty: 0 agent_num: 30 done: False
______________________
id: 52 reward: -0.01020408163265306 service_time: 487 s_time: 20 penalty: 0 agent_num: 35 done: False
______________________
id: 46 reward: -0.02476958525345622 service_time: 573 s_time: 43 penalty: 0 agent_num: 31 done: False
______________________
id: 54 reward: -0.015827922077922076 service_time: 480 s_time: 39 penalty: 0 agent_num: 44 done: False
______________________
id: 49 reward: 0.001152073732718894 service_time: 541 s_time: -2 penalty: 0 agent_num: 31 done: False
______________________
Step:  304
Pretraining Loss:  tensor(0.4340, device='cuda:0', grad_fn=<MeanBackward0>)
id: 48 reward: 0.0 service_time: 411 s_time: 0 penalty: 0 agent_num: 14 done: False
______________________
id: 47 reward: -0.015178571428571428 service_time: 370 s_time: 17 penalty: 0 agent_num: 20 done: False
______________________
id: 45 reward: -0.02465986394557823 service_time: 501 s_time: 29 penalty: 0 agent_num: 21 done: False
______________________
id: 50 reward: -0.008928571428571428 service_time: 547 s_time: 11 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: -0.021164021164021163 service_time: 597 s_time: 32 penalty: 0 agent_num: 27 done: False
______________________
id: 52 reward: -0.004591836734693878 service_time: 496 s_time: 9 penalty: 0 agent_num: 35 done: False
______________________
id: 41 reward: -0.0125 service_time: 306 s_time: 21 penalty: 0 agent_num: 30 done: False
______________________
id: 43 reward: -0.0027472527472527475 service_time: 377 s_time: 2 penalty: 0 agent_num: 13 done: False
______________________
id: 42 reward: -0.03361344537815126 service_time: 580 s_time: 32 penalty: 0 agent_num: 17 done: False
______________________
id: 53 reward: -0.01607142857142857 service_time: 531 s_time: 27 penalty: 0 agent_num: 30 done: False
______________________
id: 40 reward: 0.025793650793650792 service_time: 461 s_time: -26 penalty: 0 agent_num: 18 done: False
______________________
id: 44 reward: -0.013950892857142858 service_time: 479 s_time: 25 penalty: 0 agent_num: 32 done: False
______________________
id: 55 reward: -0.01521164021164021 service_time: 511 s_time: 23 penalty: 0 agent_num: 27 done: False
______________________
id: 54 reward: -0.006493506493506494 service_time: 496 s_time: 16 penalty: 0 agent_num: 44 done: False
______________________
id: 46 reward: -0.022465437788018433 service_time: 612 s_time: 39 penalty: 0 agent_num: 31 done: False
______________________
id: 49 reward: -0.026497695852534562 service_time: 587 s_time: 46 penalty: 0 agent_num: 31 done: False
______________________
Step:  320
Pretraining Loss:  tensor(0.4464, device='cuda:0', grad_fn=<MeanBackward0>)
id: 48 reward: -0.036989795918367346 service_time: 440 s_time: 29 penalty: 0 agent_num: 14 done: False
______________________
id: 42 reward: 0.0 service_time: 580 s_time: 0 penalty: 0 agent_num: 17 done: False
______________________
id: 47 reward: 0.0 service_time: 370 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 40 reward: -0.03670634920634921 service_time: 498 s_time: 37 penalty: 0 agent_num: 18 done: False
______________________
id: 43 reward: 0.0 service_time: 377 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 53 reward: -0.013095238095238096 service_time: 553 s_time: 22 penalty: 0 agent_num: 30 done: False
______________________
id: 41 reward: 0.0 service_time: 306 s_time: 0 penalty: 0 agent_num: 30 done: False
______________________
id: 51 reward: -0.011243386243386243 service_time: 614 s_time: 17 penalty: 0 agent_num: 27 done: False
______________________
id: 50 reward: -0.037337662337662336 service_time: 593 s_time: 46 penalty: 0 agent_num: 22 done: False
______________________
id: 44 reward: -0.021763392857142856 service_time: 518 s_time: 39 penalty: 0 agent_num: 32 done: False
______________________
id: 55 reward: -0.009259259259259259 service_time: 525 s_time: 14 penalty: 0 agent_num: 27 done: False
______________________
id: 52 reward: -0.015306122448979591 service_time: 526 s_time: 30 penalty: 0 agent_num: 35 done: False
______________________
id: 45 reward: -0.03826530612244898 service_time: 546 s_time: 45 penalty: 0 agent_num: 21 done: False
______________________
id: 54 reward: -0.019886363636363636 service_time: 545 s_time: 49 penalty: 0 agent_num: 44 done: False
______________________
id: 46 reward: 0.0 service_time: 612 s_time: 0 penalty: 0 agent_num: 31 done: False
______________________
id: 49 reward: 0.000576036866359447 service_time: 586 s_time: -1 penalty: 0 agent_num: 31 done: False
______________________
Step:  336
Pretraining Loss:  tensor(0.4687, device='cuda:0', grad_fn=<MeanBackward0>)
id: 48 reward: 0.0 service_time: 440 s_time: 0 penalty: 0 agent_num: 14 done: False
______________________
id: 47 reward: 0.0 service_time: 370 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 45 reward: -0.011904761904761904 service_time: 560 s_time: 14 penalty: 0 agent_num: 21 done: False
______________________
id: 51 reward: -0.023148148148148147 service_time: 649 s_time: 35 penalty: 0 agent_num: 27 done: False
______________________
id: 41 reward: -0.010714285714285714 service_time: 324 s_time: 18 penalty: 0 agent_num: 30 done: False
______________________
id: 43 reward: 0.0013736263736263737 service_time: 376 s_time: -1 penalty: 0 agent_num: 13 done: False
______________________
id: 44 reward: -0.010044642857142858 service_time: 536 s_time: 18 penalty: 0 agent_num: 32 done: False
______________________
id: 52 reward: -0.027040816326530614 service_time: 579 s_time: 53 penalty: 0 agent_num: 35 done: False
______________________
id: 42 reward: -0.017857142857142856 service_time: 597 s_time: 17 penalty: 0 agent_num: 17 done: False
______________________
id: 40 reward: -0.08432539682539683 service_time: 583 s_time: 85 penalty: 0 agent_num: 18 done: False
______________________
id: 53 reward: -0.0011904761904761906 service_time: 555 s_time: 2 penalty: 0 agent_num: 30 done: False
______________________
id: 54 reward: -0.015016233766233766 service_time: 582 s_time: 37 penalty: 0 agent_num: 44 done: False
______________________
id: 55 reward: -0.027116402116402115 service_time: 566 s_time: 41 penalty: 0 agent_num: 27 done: False
______________________
id: 46 reward: -0.04032258064516129 service_time: 682 s_time: 70 penalty: 0 agent_num: 31 done: False
______________________
id: 50 reward: -0.037337662337662336 service_time: 639 s_time: 46 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: -0.03341013824884793 service_time: 644 s_time: 58 penalty: 0 agent_num: 31 done: False
______________________
Step:  352
Pretraining Loss:  tensor(0.4665, device='cuda:0', grad_fn=<MeanBackward0>)
id: 48 reward: -0.016581632653061226 service_time: 453 s_time: 13 penalty: 0 agent_num: 14 done: False
______________________
id: 43 reward: 0.0 service_time: 376 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 47 reward: -0.039285714285714285 service_time: 414 s_time: 44 penalty: 0 agent_num: 20 done: False
______________________
id: 41 reward: 0.0 service_time: 324 s_time: 0 penalty: 0 agent_num: 30 done: False
______________________
id: 53 reward: -0.020833333333333332 service_time: 590 s_time: 35 penalty: 0 agent_num: 30 done: False
______________________
id: 42 reward: -0.04411764705882353 service_time: 639 s_time: 42 penalty: 0 agent_num: 17 done: False
______________________
id: 44 reward: -0.0078125 service_time: 550 s_time: 14 penalty: 0 agent_num: 32 done: False
______________________
id: 52 reward: -0.019387755102040816 service_time: 617 s_time: 38 penalty: 0 agent_num: 35 done: False
______________________
id: 40 reward: 0.005952380952380952 service_time: 577 s_time: -6 penalty: 0 agent_num: 18 done: False
______________________
id: 55 reward: -0.011243386243386243 service_time: 583 s_time: 17 penalty: 0 agent_num: 27 done: False
______________________
id: 45 reward: -0.03571428571428571 service_time: 602 s_time: 42 penalty: 0 agent_num: 21 done: False
______________________
id: 46 reward: -0.016129032258064516 service_time: 710 s_time: 28 penalty: 0 agent_num: 31 done: False
______________________
id: 54 reward: -0.002435064935064935 service_time: 588 s_time: 6 penalty: 0 agent_num: 44 done: False
______________________
id: 50 reward: 0.007305194805194805 service_time: 630 s_time: -9 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: -0.025793650793650792 service_time: 688 s_time: 39 penalty: 0 agent_num: 27 done: False
______________________
id: 49 reward: -0.017857142857142856 service_time: 675 s_time: 31 penalty: 0 agent_num: 31 done: False
______________________
Step:  368
Pretraining Loss:  tensor(0.4471, device='cuda:0', grad_fn=<MeanBackward0>)
id: 43 reward: -0.05631868131868132 service_time: 417 s_time: 41 penalty: 0 agent_num: 13 done: False
______________________
id: 47 reward: 0.0 service_time: 414 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 48 reward: 0.0 service_time: 453 s_time: 0 penalty: 0 agent_num: 14 done: False
______________________
id: 53 reward: -0.014285714285714285 service_time: 614 s_time: 24 penalty: 0 agent_num: 30 done: False
______________________
id: 52 reward: -0.017346938775510204 service_time: 651 s_time: 34 penalty: 0 agent_num: 35 done: False
______________________
id: 42 reward: 0.005252100840336135 service_time: 634 s_time: -5 penalty: 0 agent_num: 17 done: False
______________________
id: 40 reward: -0.03968253968253968 service_time: 617 s_time: 40 penalty: 0 agent_num: 18 done: False
______________________
id: 45 reward: -0.0391156462585034 service_time: 648 s_time: 46 penalty: 0 agent_num: 21 done: False
______________________
id: 41 reward: -0.009523809523809525 service_time: 340 s_time: 16 penalty: 0 agent_num: 30 done: False
______________________
id: 46 reward: -0.014400921658986175 service_time: 735 s_time: 25 penalty: 0 agent_num: 31 done: False
______________________
id: 49 reward: -0.017857142857142856 service_time: 706 s_time: 31 penalty: 0 agent_num: 31 done: False
______________________
id: 55 reward: -0.021164021164021163 service_time: 615 s_time: 32 penalty: 0 agent_num: 27 done: False
______________________
id: 50 reward: 0.0008116883116883117 service_time: 629 s_time: -1 penalty: 0 agent_num: 22 done: False
______________________
id: 44 reward: -0.020089285714285716 service_time: 586 s_time: 36 penalty: 0 agent_num: 32 done: False
______________________
id: 51 reward: -0.013227513227513227 service_time: 708 s_time: 20 penalty: 0 agent_num: 27 done: False
______________________
id: 54 reward: -0.0036525974025974025 service_time: 597 s_time: 9 penalty: 0 agent_num: 44 done: False
______________________
Step:  384
Pretraining Loss:  tensor(0.4782, device='cuda:0', grad_fn=<MeanBackward0>)
id: 43 reward: 0.0 service_time: 417 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 48 reward: -0.04081632653061224 service_time: 485 s_time: 32 penalty: 0 agent_num: 14 done: False
______________________
id: 47 reward: -0.019642857142857142 service_time: 436 s_time: 22 penalty: 0 agent_num: 20 done: False
______________________
id: 42 reward: 0.004201680672268907 service_time: 630 s_time: -4 penalty: 0 agent_num: 17 done: False
______________________
id: 53 reward: -0.007738095238095238 service_time: 627 s_time: 13 penalty: 0 agent_num: 30 done: False
______________________
id: 55 reward: -0.027116402116402115 service_time: 656 s_time: 41 penalty: 0 agent_num: 27 done: False
______________________
id: 52 reward: -0.013265306122448979 service_time: 677 s_time: 26 penalty: 0 agent_num: 35 done: False
______________________
id: 44 reward: -0.020089285714285716 service_time: 622 s_time: 36 penalty: 0 agent_num: 32 done: False
______________________
id: 41 reward: -0.015476190476190477 service_time: 366 s_time: 26 penalty: 0 agent_num: 30 done: False
______________________
id: 50 reward: -0.06493506493506493 service_time: 709 s_time: 80 penalty: 0 agent_num: 22 done: False
______________________
id: 40 reward: -0.10218253968253968 service_time: 720 s_time: 103 penalty: 0 agent_num: 18 done: False
______________________
id: 46 reward: -0.004032258064516129 service_time: 742 s_time: 7 penalty: 0 agent_num: 31 done: False
______________________
id: 54 reward: -0.012175324675324676 service_time: 627 s_time: 30 penalty: 0 agent_num: 44 done: False
______________________
id: 45 reward: -0.01870748299319728 service_time: 670 s_time: 22 penalty: 0 agent_num: 21 done: False
______________________
id: 51 reward: -0.008597883597883597 service_time: 721 s_time: 13 penalty: 0 agent_num: 27 done: False
______________________
id: 49 reward: 0.0 service_time: 706 s_time: 0 penalty: 0 agent_num: 31 done: False
______________________
Step:  400
Pretraining Loss:  tensor(0.5004, device='cuda:0', grad_fn=<MeanBackward0>)
id: 48 reward: 0.0 service_time: 485 s_time: 0 penalty: 0 agent_num: 14 done: False
______________________
id: 43 reward: 0.0 service_time: 417 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 47 reward: 0.0 service_time: 436 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 41 reward: -0.007142857142857143 service_time: 378 s_time: 12 penalty: 0 agent_num: 30 done: False
______________________
id: 45 reward: -0.021258503401360544 service_time: 695 s_time: 25 penalty: 0 agent_num: 21 done: False
______________________
id: 53 reward: -0.008333333333333333 service_time: 641 s_time: 14 penalty: 0 agent_num: 30 done: False
______________________
id: 52 reward: -0.009183673469387756 service_time: 695 s_time: 18 penalty: 0 agent_num: 35 done: False
______________________
id: 55 reward: -0.01917989417989418 service_time: 685 s_time: 29 penalty: 0 agent_num: 27 done: False
______________________
id: 44 reward: -0.014508928571428572 service_time: 648 s_time: 26 penalty: 0 agent_num: 32 done: False
______________________
id: 40 reward: -0.027777777777777776 service_time: 748 s_time: 28 penalty: 0 agent_num: 18 done: False
______________________
id: 42 reward: 0.0 service_time: 630 s_time: 0 penalty: 0 agent_num: 17 done: False
______________________
id: 50 reward: 0.011363636363636364 service_time: 695 s_time: -14 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: -0.027777777777777776 service_time: 763 s_time: 42 penalty: 0 agent_num: 27 done: False
______________________
id: 46 reward: -0.005184331797235023 service_time: 751 s_time: 9 penalty: 0 agent_num: 31 done: False
______________________
id: 49 reward: -0.05069124423963134 service_time: 794 s_time: 88 penalty: 0 agent_num: 31 done: False
______________________
id: 54 reward: 0.0008116883116883117 service_time: 625 s_time: -2 penalty: 0 agent_num: 44 done: False
______________________
Step:  416
Pretraining Loss:  tensor(0.4742, device='cuda:0', grad_fn=<MeanBackward0>)
id: 43 reward: 0.020604395604395604 service_time: 402 s_time: -15 penalty: 0 agent_num: 13 done: False
______________________
id: 48 reward: -0.03571428571428571 service_time: 513 s_time: 28 penalty: 0 agent_num: 14 done: False
______________________
id: 47 reward: -0.02142857142857143 service_time: 460 s_time: 24 penalty: 0 agent_num: 20 done: False
______________________
id: 41 reward: 0.0 service_time: 378 s_time: 0 penalty: 0 agent_num: 30 done: False
______________________
id: 50 reward: -0.03977272727272727 service_time: 744 s_time: 49 penalty: 0 agent_num: 22 done: False
______________________
id: 42 reward: 0.008403361344537815 service_time: 622 s_time: -8 penalty: 0 agent_num: 17 done: False
______________________
id: 53 reward: -0.011904761904761904 service_time: 661 s_time: 20 penalty: 0 agent_num: 30 done: False
______________________
id: 40 reward: 0.030753968253968252 service_time: 717 s_time: -31 penalty: 0 agent_num: 18 done: False
______________________
id: 55 reward: -0.011904761904761904 service_time: 703 s_time: 18 penalty: 0 agent_num: 27 done: False
______________________
id: 52 reward: -0.01173469387755102 service_time: 718 s_time: 23 penalty: 0 agent_num: 35 done: False
______________________
id: 44 reward: -0.014508928571428572 service_time: 674 s_time: 26 penalty: 0 agent_num: 32 done: False
______________________
id: 46 reward: -0.0293778801843318 service_time: 802 s_time: 51 penalty: 0 agent_num: 31 done: False
______________________
id: 51 reward: 0.004629629629629629 service_time: 756 s_time: -7 penalty: 0 agent_num: 27 done: False
______________________
id: 54 reward: -0.02150974025974026 service_time: 678 s_time: 53 penalty: 0 agent_num: 44 done: False
______________________
id: 45 reward: -0.039965986394557826 service_time: 742 s_time: 47 penalty: 0 agent_num: 21 done: False
______________________
id: 49 reward: -0.012096774193548387 service_time: 815 s_time: 21 penalty: 0 agent_num: 31 done: False
______________________
Step:  432
Pretraining Loss:  tensor(0.4711, device='cuda:0', grad_fn=<MeanBackward0>)
id: 48 reward: 0.002551020408163265 service_time: 511 s_time: -2 penalty: 0 agent_num: 14 done: False
______________________
id: 43 reward: -0.050824175824175824 service_time: 439 s_time: 37 penalty: 0 agent_num: 13 done: False
______________________
id: 41 reward: -0.01369047619047619 service_time: 401 s_time: 23 penalty: 0 agent_num: 30 done: False
______________________
id: 47 reward: 0.0 service_time: 460 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 42 reward: 0.017857142857142856 service_time: 605 s_time: -17 penalty: 0 agent_num: 17 done: False
______________________
id: 50 reward: -0.037337662337662336 service_time: 790 s_time: 46 penalty: 0 agent_num: 22 done: False
______________________
id: 55 reward: -0.006613756613756613 service_time: 713 s_time: 10 penalty: 0 agent_num: 27 done: False
______________________
id: 44 reward: 0.0 service_time: 674 s_time: 0 penalty: 0 agent_num: 32 done: False
______________________
id: 52 reward: -0.004081632653061225 service_time: 726 s_time: 8 penalty: 0 agent_num: 35 done: False
______________________
id: 51 reward: -0.028439153439153438 service_time: 799 s_time: 43 penalty: 0 agent_num: 27 done: False
______________________
id: 45 reward: -0.02465986394557823 service_time: 771 s_time: 29 penalty: 0 agent_num: 21 done: False
______________________
id: 53 reward: -0.007738095238095238 service_time: 674 s_time: 13 penalty: 0 agent_num: 30 done: False
______________________
id: 40 reward: 0.023809523809523808 service_time: 693 s_time: -24 penalty: 0 agent_num: 18 done: False
______________________
id: 49 reward: -0.019585253456221197 service_time: 849 s_time: 34 penalty: 0 agent_num: 31 done: False
______________________
id: 46 reward: -0.009216589861751152 service_time: 818 s_time: 16 penalty: 0 agent_num: 31 done: False
______________________
id: 54 reward: -0.006087662337662338 service_time: 693 s_time: 15 penalty: 0 agent_num: 44 done: False
______________________
Step:  448
Pretraining Loss:  tensor(0.4877, device='cuda:0', grad_fn=<MeanBackward0>)
id: 43 reward: 0.0 service_time: 439 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 48 reward: -0.02423469387755102 service_time: 530 s_time: 19 penalty: 0 agent_num: 14 done: False
______________________
id: 40 reward: -0.001984126984126984 service_time: 695 s_time: 2 penalty: 0 agent_num: 18 done: False
______________________
id: 47 reward: -0.039285714285714285 service_time: 504 s_time: 44 penalty: 0 agent_num: 20 done: False
______________________
id: 42 reward: 0.011554621848739496 service_time: 594 s_time: -11 penalty: 0 agent_num: 17 done: False
______________________
id: 50 reward: -0.01948051948051948 service_time: 814 s_time: 24 penalty: 0 agent_num: 22 done: False
______________________
id: 53 reward: -0.01488095238095238 service_time: 699 s_time: 25 penalty: 0 agent_num: 30 done: False
______________________
id: 52 reward: 0.0 service_time: 726 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 49 reward: -0.02476958525345622 service_time: 892 s_time: 43 penalty: 0 agent_num: 31 done: False
______________________
id: 41 reward: 0.0 service_time: 401 s_time: 0 penalty: 0 agent_num: 30 done: False
______________________
id: 44 reward: -0.020647321428571428 service_time: 711 s_time: 37 penalty: 0 agent_num: 32 done: False
______________________
id: 51 reward: -0.006613756613756613 service_time: 809 s_time: 10 penalty: 0 agent_num: 27 done: False
______________________
id: 54 reward: 0.0 service_time: 693 s_time: 0 penalty: 0 agent_num: 44 done: False
______________________
id: 45 reward: -0.03486394557823129 service_time: 812 s_time: 41 penalty: 0 agent_num: 21 done: False
______________________
id: 46 reward: 0.010368663594470046 service_time: 800 s_time: -18 penalty: 0 agent_num: 31 done: False
______________________
id: 55 reward: -0.03505291005291005 service_time: 766 s_time: 53 penalty: 0 agent_num: 27 done: False
______________________
Step:  464
Pretraining Loss:  tensor(0.4995, device='cuda:0', grad_fn=<MeanBackward0>)
id: 43 reward: 0.0 service_time: 439 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 48 reward: -0.03571428571428571 service_time: 558 s_time: 28 penalty: 0 agent_num: 14 done: False
______________________
id: 40 reward: 0.01488095238095238 service_time: 680 s_time: -15 penalty: 0 agent_num: 18 done: False
______________________
id: 47 reward: 0.0026785714285714286 service_time: 501 s_time: -3 penalty: 0 agent_num: 20 done: False
______________________
id: 41 reward: -0.0125 service_time: 422 s_time: 21 penalty: 0 agent_num: 30 done: False
______________________
id: 42 reward: -0.06722689075630252 service_time: 658 s_time: 64 penalty: 0 agent_num: 17 done: False
______________________
id: 52 reward: -0.023979591836734693 service_time: 773 s_time: 47 penalty: 0 agent_num: 35 done: False
______________________
id: 44 reward: -0.013950892857142858 service_time: 736 s_time: 25 penalty: 0 agent_num: 32 done: False
______________________
id: 51 reward: -0.022486772486772486 service_time: 843 s_time: 34 penalty: 0 agent_num: 27 done: False
______________________
id: 45 reward: -0.0195578231292517 service_time: 835 s_time: 23 penalty: 0 agent_num: 21 done: False
______________________
id: 55 reward: -0.02976190476190476 service_time: 811 s_time: 45 penalty: 0 agent_num: 27 done: False
______________________
id: 53 reward: -0.01904761904761905 service_time: 731 s_time: 32 penalty: 0 agent_num: 30 done: False
______________________
id: 50 reward: -0.05113636363636364 service_time: 877 s_time: 63 penalty: 0 agent_num: 22 done: False
______________________
id: 46 reward: -0.03110599078341014 service_time: 854 s_time: 54 penalty: 0 agent_num: 31 done: False
______________________
id: 49 reward: -0.007488479262672811 service_time: 905 s_time: 13 penalty: 0 agent_num: 31 done: False
______________________
id: 54 reward: -0.020292207792207792 service_time: 743 s_time: 50 penalty: 0 agent_num: 44 done: False
______________________
Step:  480
Pretraining Loss:  tensor(0.4895, device='cuda:0', grad_fn=<MeanBackward0>)
id: 48 reward: -0.0012755102040816326 service_time: 559 s_time: 1 penalty: 0 agent_num: 14 done: False
______________________
id: 40 reward: 0.0 service_time: 680 s_time: 0 penalty: 0 agent_num: 18 done: False
______________________
id: 43 reward: -0.03159340659340659 service_time: 462 s_time: 23 penalty: 0 agent_num: 13 done: False
______________________
id: 47 reward: -0.039285714285714285 service_time: 545 s_time: 44 penalty: 0 agent_num: 20 done: False
______________________
id: 42 reward: 0.0 service_time: 658 s_time: 0 penalty: 0 agent_num: 17 done: False
______________________
id: 50 reward: 0.0 service_time: 877 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 52 reward: -0.02040816326530612 service_time: 813 s_time: 40 penalty: 0 agent_num: 35 done: False
______________________
id: 44 reward: -0.010044642857142858 service_time: 754 s_time: 18 penalty: 0 agent_num: 32 done: False
______________________
id: 53 reward: -0.01607142857142857 service_time: 758 s_time: 27 penalty: 0 agent_num: 30 done: False
______________________
id: 41 reward: 0.0 service_time: 422 s_time: 0 penalty: 0 agent_num: 30 done: False
______________________
id: 46 reward: -0.01152073732718894 service_time: 874 s_time: 20 penalty: 0 agent_num: 31 done: False
______________________
id: 45 reward: 0.017006802721088437 service_time: 815 s_time: -20 penalty: 0 agent_num: 21 done: False
______________________
id: 51 reward: -0.008597883597883597 service_time: 856 s_time: 13 penalty: 0 agent_num: 27 done: False
______________________
id: 54 reward: 0.0008116883116883117 service_time: 741 s_time: -2 penalty: 0 agent_num: 44 done: False
______________________
id: 49 reward: 0.001152073732718894 service_time: 903 s_time: -2 penalty: 0 agent_num: 31 done: False
______________________
id: 55 reward: -0.025793650793650792 service_time: 850 s_time: 39 penalty: 0 agent_num: 27 done: False
______________________
Step:  496
Pretraining Loss:  tensor(0.4794, device='cuda:0', grad_fn=<MeanBackward0>)
id: 43 reward: -0.017857142857142856 service_time: 475 s_time: 13 penalty: 0 agent_num: 13 done: False
______________________
id: 48 reward: -0.044642857142857144 service_time: 594 s_time: 35 penalty: 0 agent_num: 14 done: False
______________________
id: 40 reward: -0.028769841269841268 service_time: 709 s_time: 29 penalty: 0 agent_num: 18 done: False
______________________
id: 47 reward: -0.020535714285714286 service_time: 568 s_time: 23 penalty: 0 agent_num: 20 done: False
______________________
id: 41 reward: -0.002976190476190476 service_time: 427 s_time: 5 penalty: 0 agent_num: 30 done: False
______________________
id: 42 reward: 0.015756302521008403 service_time: 643 s_time: -15 penalty: 0 agent_num: 17 done: False
______________________
id: 51 reward: -0.009259259259259259 service_time: 870 s_time: 14 penalty: 0 agent_num: 27 done: False
______________________
id: 53 reward: -0.016666666666666666 service_time: 786 s_time: 28 penalty: 0 agent_num: 30 done: False
______________________
id: 52 reward: -0.005612244897959183 service_time: 824 s_time: 11 penalty: 0 agent_num: 35 done: False
______________________
id: 45 reward: -0.04591836734693878 service_time: 869 s_time: 54 penalty: 0 agent_num: 21 done: False
______________________
id: 44 reward: -0.010602678571428572 service_time: 773 s_time: 19 penalty: 0 agent_num: 32 done: False
______________________
id: 50 reward: 0.024350649350649352 service_time: 847 s_time: -30 penalty: 0 agent_num: 22 done: False
______________________
id: 46 reward: 0.0 service_time: 874 s_time: 0 penalty: 0 agent_num: 31 done: False
______________________
id: 55 reward: -0.015873015873015872 service_time: 874 s_time: 24 penalty: 0 agent_num: 27 done: False
______________________
id: 54 reward: -0.013392857142857142 service_time: 774 s_time: 33 penalty: 0 agent_num: 44 done: False
______________________
id: 49 reward: -0.021889400921658985 service_time: 941 s_time: 38 penalty: 0 agent_num: 31 done: False
______________________
Step:  512
Pretraining Loss:  tensor(0.4886, device='cuda:0', grad_fn=<MeanBackward0>)
id: 43 reward: 0.0027472527472527475 service_time: 473 s_time: -2 penalty: 0 agent_num: 13 done: False
______________________
id: 42 reward: -0.04201680672268908 service_time: 683 s_time: 40 penalty: 0 agent_num: 17 done: False
______________________
id: 47 reward: 0.0 service_time: 568 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 40 reward: 0.010912698412698412 service_time: 698 s_time: -11 penalty: 0 agent_num: 18 done: False
______________________
id: 50 reward: -0.030032467532467532 service_time: 884 s_time: 37 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: -0.009259259259259259 service_time: 884 s_time: 14 penalty: 0 agent_num: 27 done: False
______________________
id: 52 reward: -0.008673469387755102 service_time: 841 s_time: 17 penalty: 0 agent_num: 35 done: False
______________________
id: 41 reward: -0.02142857142857143 service_time: 463 s_time: 36 penalty: 0 agent_num: 30 done: False
______________________
id: 53 reward: -0.007738095238095238 service_time: 799 s_time: 13 penalty: 0 agent_num: 30 done: False
______________________
id: 48 reward: -0.05994897959183673 service_time: 641 s_time: 47 penalty: 0 agent_num: 14 done: False
______________________
id: 46 reward: -0.01555299539170507 service_time: 901 s_time: 27 penalty: 0 agent_num: 31 done: False
______________________
id: 45 reward: -0.007653061224489796 service_time: 878 s_time: 9 penalty: 0 agent_num: 21 done: False
______________________
id: 44 reward: -0.021205357142857144 service_time: 811 s_time: 38 penalty: 0 agent_num: 32 done: False
______________________
id: 49 reward: -0.018433179723502304 service_time: 973 s_time: 32 penalty: 0 agent_num: 31 done: False
______________________
id: 54 reward: -0.015422077922077922 service_time: 812 s_time: 38 penalty: 0 agent_num: 44 done: False
______________________
id: 55 reward: -0.041005291005291 service_time: 936 s_time: 62 penalty: 0 agent_num: 27 done: False
______________________
Step:  528
Pretraining Loss:  tensor(0.5090, device='cuda:0', grad_fn=<MeanBackward0>)
id: 43 reward: -0.07005494505494506 service_time: 524 s_time: 51 penalty: 0 agent_num: 13 done: False
______________________
id: 40 reward: -0.05555555555555555 service_time: 754 s_time: 56 penalty: 0 agent_num: 18 done: False
______________________
id: 42 reward: -0.03466386554621849 service_time: 716 s_time: 33 penalty: 0 agent_num: 17 done: False
______________________
id: 41 reward: 0.0 service_time: 463 s_time: 0 penalty: 0 agent_num: 30 done: False
______________________
id: 47 reward: 0.0 service_time: 568 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 44 reward: -0.018415178571428572 service_time: 844 s_time: 33 penalty: 0 agent_num: 32 done: False
______________________
id: 49 reward: -0.02131336405529954 service_time: 1010 s_time: 37 penalty: 0 agent_num: 31 done: False
______________________
id: 50 reward: -0.026785714285714284 service_time: 917 s_time: 33 penalty: 0 agent_num: 22 done: False
______________________
id: 55 reward: -0.004629629629629629 service_time: 943 s_time: 7 penalty: 0 agent_num: 27 done: False
______________________
id: 51 reward: -0.03505291005291005 service_time: 937 s_time: 53 penalty: 0 agent_num: 27 done: False
______________________
id: 53 reward: -0.014285714285714285 service_time: 823 s_time: 24 penalty: 0 agent_num: 30 done: False
______________________
id: 46 reward: 0.0 service_time: 901 s_time: 0 penalty: 0 agent_num: 31 done: False
______________________
id: 52 reward: -0.012755102040816327 service_time: 866 s_time: 25 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: 0.003826530612244898 service_time: 638 s_time: -3 penalty: 0 agent_num: 14 done: False
______________________
id: 54 reward: -0.020292207792207792 service_time: 862 s_time: 50 penalty: 0 agent_num: 44 done: False
______________________
id: 45 reward: 0.006802721088435374 service_time: 870 s_time: -8 penalty: 0 agent_num: 21 done: False
______________________
Step:  544
Pretraining Loss:  tensor(0.5348, device='cuda:0', grad_fn=<MeanBackward0>)
id: 43 reward: 0.0 service_time: 524 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 42 reward: -0.03046218487394958 service_time: 745 s_time: 29 penalty: 0 agent_num: 17 done: False
______________________
id: 40 reward: 0.011904761904761904 service_time: 742 s_time: -12 penalty: 0 agent_num: 18 done: False
______________________
id: 50 reward: 0.0016233766233766235 service_time: 915 s_time: -2 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: -0.018518518518518517 service_time: 965 s_time: 28 penalty: 0 agent_num: 27 done: False
______________________
id: 46 reward: -0.04723502304147465 service_time: 983 s_time: 82 penalty: 0 agent_num: 31 done: False
______________________
id: 48 reward: -0.03826530612244898 service_time: 668 s_time: 30 penalty: 0 agent_num: 14 done: False
______________________
id: 47 reward: -0.005357142857142857 service_time: 574 s_time: 6 penalty: 0 agent_num: 20 done: False
______________________
id: 52 reward: -0.02040816326530612 service_time: 906 s_time: 40 penalty: 0 agent_num: 35 done: False
______________________
id: 41 reward: -0.006547619047619048 service_time: 474 s_time: 11 penalty: 0 agent_num: 30 done: False
______________________
id: 54 reward: -0.017857142857142856 service_time: 906 s_time: 44 penalty: 0 agent_num: 44 done: False
______________________
id: 45 reward: -0.01020408163265306 service_time: 882 s_time: 12 penalty: 0 agent_num: 21 done: False
______________________
id: 53 reward: -0.02261904761904762 service_time: 861 s_time: 38 penalty: 0 agent_num: 30 done: False
______________________
id: 49 reward: -0.01555299539170507 service_time: 1037 s_time: 27 penalty: 0 agent_num: 31 done: False
______________________
id: 44 reward: -0.020089285714285716 service_time: 880 s_time: 36 penalty: 0 agent_num: 32 done: False
______________________
id: 55 reward: -0.02976190476190476 service_time: 988 s_time: 45 penalty: 0 agent_num: 27 done: False
______________________
Step:  560
Pretraining Loss:  tensor(0.4569, device='cuda:0', grad_fn=<MeanBackward0>)
id: 43 reward: 0.013736263736263736 service_time: 514 s_time: -10 penalty: 0 agent_num: 13 done: False
______________________
id: 47 reward: -0.033928571428571426 service_time: 612 s_time: 38 penalty: 0 agent_num: 20 done: False
______________________
id: 40 reward: 0.011904761904761904 service_time: 730 s_time: -12 penalty: 0 agent_num: 18 done: False
______________________
id: 48 reward: 0.0012755102040816326 service_time: 667 s_time: -1 penalty: 0 agent_num: 14 done: False
______________________
id: 42 reward: -0.03676470588235294 service_time: 780 s_time: 35 penalty: 0 agent_num: 17 done: False
______________________
id: 50 reward: 0.025162337662337664 service_time: 884 s_time: -31 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: -0.007936507936507936 service_time: 977 s_time: 12 penalty: 0 agent_num: 27 done: False
______________________
id: 44 reward: -0.012834821428571428 service_time: 903 s_time: 23 penalty: 0 agent_num: 32 done: False
______________________
id: 45 reward: 0.030612244897959183 service_time: 846 s_time: -36 penalty: 0 agent_num: 21 done: False
______________________
id: 52 reward: 0.0010204081632653062 service_time: 904 s_time: -2 penalty: 0 agent_num: 35 done: False
______________________
id: 41 reward: -0.017261904761904763 service_time: 503 s_time: 29 penalty: 0 agent_num: 30 done: False
______________________
id: 55 reward: -0.017857142857142856 service_time: 1015 s_time: 27 penalty: 0 agent_num: 27 done: False
______________________
id: 49 reward: -0.024193548387096774 service_time: 1079 s_time: 42 penalty: 0 agent_num: 31 done: False
______________________
id: 46 reward: -0.016705069124423964 service_time: 1012 s_time: 29 penalty: 0 agent_num: 31 done: False
______________________
id: 54 reward: -0.019886363636363636 service_time: 955 s_time: 49 penalty: 0 agent_num: 44 done: False
______________________
id: 53 reward: -0.010714285714285714 service_time: 879 s_time: 18 penalty: 0 agent_num: 30 done: False
______________________
Step:  576
Pretraining Loss:  tensor(0.4831, device='cuda:0', grad_fn=<MeanBackward0>)
id: 43 reward: -0.050824175824175824 service_time: 551 s_time: 37 penalty: 0 agent_num: 13 done: False
______________________
id: 48 reward: -0.06887755102040816 service_time: 721 s_time: 54 penalty: 0 agent_num: 14 done: False
______________________
id: 40 reward: 0.0 service_time: 730 s_time: 0 penalty: 0 agent_num: 18 done: False
______________________
id: 47 reward: 0.0 service_time: 612 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 42 reward: 0.0 service_time: 780 s_time: 0 penalty: 0 agent_num: 17 done: False
______________________
id: 41 reward: -0.008333333333333333 service_time: 517 s_time: 14 penalty: 0 agent_num: 30 done: False
______________________
id: 51 reward: -0.027777777777777776 service_time: 1019 s_time: 42 penalty: 0 agent_num: 27 done: False
______________________
id: 46 reward: -0.02534562211981567 service_time: 1056 s_time: 44 penalty: 0 agent_num: 31 done: False
______________________
id: 52 reward: -0.039285714285714285 service_time: 981 s_time: 77 penalty: 0 agent_num: 35 done: False
______________________
id: 50 reward: -0.05194805194805195 service_time: 948 s_time: 64 penalty: 0 agent_num: 22 done: False
______________________
id: 45 reward: 0.012755102040816327 service_time: 831 s_time: -15 penalty: 0 agent_num: 21 done: False
______________________
id: 53 reward: -0.002976190476190476 service_time: 884 s_time: 5 penalty: 0 agent_num: 30 done: False
______________________
id: 49 reward: -0.02476958525345622 service_time: 1122 s_time: 43 penalty: 0 agent_num: 31 done: False
______________________
id: 44 reward: -0.009486607142857142 service_time: 920 s_time: 17 penalty: 0 agent_num: 32 done: False
______________________
id: 54 reward: 0.0 service_time: 955 s_time: 0 penalty: 0 agent_num: 44 done: False
______________________
id: 55 reward: 0.0006613756613756613 service_time: 1014 s_time: -1 penalty: 0 agent_num: 27 done: False
______________________
Step:  592
Pretraining Loss:  tensor(0.4719, device='cuda:0', grad_fn=<MeanBackward0>)
id: 43 reward: -0.042582417582417584 service_time: 582 s_time: 31 penalty: 0 agent_num: 13 done: False
______________________
id: 40 reward: 0.0 service_time: 730 s_time: 0 penalty: 0 agent_num: 18 done: False
______________________
id: 42 reward: 0.018907563025210083 service_time: 762 s_time: -18 penalty: 0 agent_num: 17 done: False
______________________
id: 47 reward: -0.016964285714285713 service_time: 631 s_time: 19 penalty: 0 agent_num: 20 done: False
______________________
id: 41 reward: 0.0 service_time: 517 s_time: 0 penalty: 0 agent_num: 30 done: False
______________________
id: 51 reward: 0.0 service_time: 1019 s_time: 0 penalty: 0 agent_num: 27 done: False
______________________
id: 48 reward: -0.04336734693877551 service_time: 755 s_time: 34 penalty: 0 agent_num: 14 done: False
______________________
id: 50 reward: 0.004058441558441558 service_time: 943 s_time: -5 penalty: 0 agent_num: 22 done: False
______________________
id: 44 reward: -0.01171875 service_time: 941 s_time: 21 penalty: 0 agent_num: 32 done: False
______________________
id: 49 reward: -0.008064516129032258 service_time: 1136 s_time: 14 penalty: 0 agent_num: 31 done: False
______________________
id: 46 reward: -0.026497695852534562 service_time: 1102 s_time: 46 penalty: 0 agent_num: 31 done: False
______________________
id: 55 reward: -0.05423280423280423 service_time: 1096 s_time: 82 penalty: 0 agent_num: 27 done: False
______________________
id: 45 reward: -0.04336734693877551 service_time: 882 s_time: 51 penalty: 0 agent_num: 21 done: False
______________________
id: 53 reward: -0.006547619047619048 service_time: 895 s_time: 11 penalty: 0 agent_num: 30 done: False
______________________
id: 54 reward: -0.024350649350649352 service_time: 1015 s_time: 60 penalty: 0 agent_num: 44 done: False
______________________
id: 52 reward: -0.015306122448979591 service_time: 1011 s_time: 30 penalty: 0 agent_num: 35 done: False
______________________
Step:  608
Pretraining Loss:  tensor(0.4490, device='cuda:0', grad_fn=<MeanBackward0>)
id: 42 reward: 0.0021008403361344537 service_time: 760 s_time: -2 penalty: 0 agent_num: 17 done: False
______________________
id: 43 reward: 0.0 service_time: 582 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 47 reward: 0.0 service_time: 631 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 48 reward: -0.05994897959183673 service_time: 802 s_time: 47 penalty: 0 agent_num: 14 done: False
______________________
id: 40 reward: -0.08134920634920635 service_time: 812 s_time: 82 penalty: 0 agent_num: 18 done: False
______________________
id: 50 reward: -0.004058441558441558 service_time: 948 s_time: 5 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: -0.012566137566137565 service_time: 1038 s_time: 19 penalty: 0 agent_num: 27 done: False
______________________
id: 45 reward: 0.00510204081632653 service_time: 876 s_time: -6 penalty: 0 agent_num: 21 done: False
______________________
id: 52 reward: -0.011224489795918367 service_time: 1033 s_time: 22 penalty: 0 agent_num: 35 done: False
______________________
id: 41 reward: -0.02142857142857143 service_time: 553 s_time: 36 penalty: 0 agent_num: 30 done: False
______________________
id: 53 reward: -0.006547619047619048 service_time: 906 s_time: 11 penalty: 0 agent_num: 30 done: False
______________________
id: 44 reward: -0.006696428571428571 service_time: 953 s_time: 12 penalty: 0 agent_num: 32 done: False
______________________
id: 46 reward: -0.020161290322580645 service_time: 1137 s_time: 35 penalty: 0 agent_num: 31 done: False
______________________
id: 49 reward: -0.010368663594470046 service_time: 1154 s_time: 18 penalty: 0 agent_num: 31 done: False
______________________
id: 54 reward: -0.013392857142857142 service_time: 1048 s_time: 33 penalty: 0 agent_num: 44 done: False
______________________
id: 55 reward: -0.022486772486772486 service_time: 1130 s_time: 34 penalty: 0 agent_num: 27 done: False
______________________
Step:  624
Pretraining Loss:  tensor(0.4677, device='cuda:0', grad_fn=<MeanBackward0>)
id: 43 reward: 0.0 service_time: 582 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 40 reward: 0.0 service_time: 812 s_time: 0 penalty: 0 agent_num: 18 done: False
______________________
id: 42 reward: -0.03571428571428571 service_time: 794 s_time: 34 penalty: 0 agent_num: 17 done: False
______________________
id: 47 reward: -0.030357142857142857 service_time: 665 s_time: 34 penalty: 0 agent_num: 20 done: False
______________________
id: 48 reward: -0.08418367346938775 service_time: 868 s_time: 66 penalty: 0 agent_num: 14 done: False
______________________
id: 50 reward: -0.021915584415584416 service_time: 975 s_time: 27 penalty: 0 agent_num: 22 done: False
______________________
id: 53 reward: -0.009523809523809525 service_time: 922 s_time: 16 penalty: 0 agent_num: 30 done: False
______________________
id: 44 reward: -0.0016741071428571428 service_time: 956 s_time: 3 penalty: 0 agent_num: 32 done: False
______________________
id: 55 reward: -0.01521164021164021 service_time: 1153 s_time: 23 penalty: 0 agent_num: 27 done: False
______________________
id: 45 reward: 0.0 service_time: 876 s_time: 0 penalty: 0 agent_num: 21 done: False
______________________
id: 49 reward: 0.0 service_time: 1154 s_time: 0 penalty: 0 agent_num: 31 done: False
______________________
id: 52 reward: -0.02040816326530612 service_time: 1073 s_time: 40 penalty: 0 agent_num: 35 done: False
______________________
id: 51 reward: -0.047619047619047616 service_time: 1110 s_time: 72 penalty: 0 agent_num: 27 done: False
______________________
id: 41 reward: -0.008928571428571428 service_time: 568 s_time: 15 penalty: 0 agent_num: 30 done: False
______________________
id: 46 reward: 0.0 service_time: 1137 s_time: 0 penalty: 0 agent_num: 31 done: False
______________________
id: 54 reward: 0.0 service_time: 1048 s_time: 0 penalty: 0 agent_num: 44 done: False
______________________
Step:  640
Pretraining Loss:  tensor(0.4817, device='cuda:0', grad_fn=<MeanBackward0>)
id: 43 reward: -0.03571428571428571 service_time: 608 s_time: 26 penalty: 0 agent_num: 13 done: False
______________________
id: 40 reward: -0.030753968253968252 service_time: 843 s_time: 31 penalty: 0 agent_num: 18 done: False
______________________
id: 42 reward: 0.01365546218487395 service_time: 781 s_time: -13 penalty: 0 agent_num: 17 done: False
______________________
id: 50 reward: 0.0 service_time: 975 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: 0.0 service_time: 665 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 41 reward: -0.009523809523809525 service_time: 584 s_time: 16 penalty: 0 agent_num: 30 done: False
______________________
id: 45 reward: 0.0 service_time: 876 s_time: 0 penalty: 0 agent_num: 21 done: False
______________________
id: 53 reward: -0.01130952380952381 service_time: 941 s_time: 19 penalty: 0 agent_num: 30 done: False
______________________
id: 48 reward: 0.0 service_time: 868 s_time: 0 penalty: 0 agent_num: 14 done: False
______________________
id: 44 reward: 0.0 service_time: 956 s_time: 0 penalty: 0 agent_num: 32 done: False
______________________
id: 52 reward: 0.00816326530612245 service_time: 1057 s_time: -16 penalty: 0 agent_num: 35 done: False
______________________
id: 51 reward: -0.011904761904761904 service_time: 1128 s_time: 18 penalty: 0 agent_num: 27 done: False
______________________
id: 54 reward: -0.029626623376623376 service_time: 1121 s_time: 73 penalty: 0 agent_num: 44 done: False
______________________
id: 49 reward: -0.009792626728110598 service_time: 1171 s_time: 17 penalty: 0 agent_num: 31 done: False
______________________
id: 46 reward: -0.03110599078341014 service_time: 1191 s_time: 54 penalty: 0 agent_num: 31 done: False
______________________
id: 55 reward: -0.011243386243386243 service_time: 1170 s_time: 17 penalty: 0 agent_num: 27 done: False
______________________
Step:  656
Pretraining Loss:  tensor(0.4746, device='cuda:0', grad_fn=<MeanBackward0>)
id: 43 reward: 0.0 service_time: 608 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 42 reward: -0.03991596638655462 service_time: 819 s_time: 38 penalty: 0 agent_num: 17 done: False
______________________
id: 40 reward: -0.04662698412698413 service_time: 890 s_time: 47 penalty: 0 agent_num: 18 done: False
______________________
id: 48 reward: -0.047193877551020405 service_time: 905 s_time: 37 penalty: 0 agent_num: 14 done: False
______________________
id: 47 reward: -0.023214285714285715 service_time: 691 s_time: 26 penalty: 0 agent_num: 20 done: False
______________________
id: 41 reward: -0.016666666666666666 service_time: 612 s_time: 28 penalty: 0 agent_num: 30 done: False
______________________
id: 50 reward: 0.005681818181818182 service_time: 968 s_time: -7 penalty: 0 agent_num: 22 done: False
______________________
id: 44 reward: -0.030691964285714284 service_time: 1011 s_time: 55 penalty: 0 agent_num: 32 done: False
______________________
id: 52 reward: -0.010714285714285714 service_time: 1078 s_time: 21 penalty: 0 agent_num: 35 done: False
______________________
id: 45 reward: 0.01445578231292517 service_time: 859 s_time: -17 penalty: 0 agent_num: 21 done: False
______________________
id: 55 reward: -0.03373015873015873 service_time: 1221 s_time: 51 penalty: 0 agent_num: 27 done: False
______________________
id: 53 reward: -0.01130952380952381 service_time: 960 s_time: 19 penalty: 0 agent_num: 30 done: False
______________________
id: 51 reward: -0.013888888888888888 service_time: 1149 s_time: 21 penalty: 0 agent_num: 27 done: False
______________________
id: 54 reward: 0.0008116883116883117 service_time: 1119 s_time: -2 penalty: 0 agent_num: 44 done: False
______________________
id: 49 reward: -0.04665898617511521 service_time: 1252 s_time: 81 penalty: 0 agent_num: 31 done: False
______________________
id: 46 reward: -0.014976958525345621 service_time: 1217 s_time: 26 penalty: 0 agent_num: 31 done: False
______________________
Step:  672
Pretraining Loss:  tensor(0.4747, device='cuda:0', grad_fn=<MeanBackward0>)
id: 43 reward: 0.0 service_time: 608 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 40 reward: 0.0 service_time: 890 s_time: 0 penalty: 0 agent_num: 18 done: False
______________________
id: 47 reward: -0.01607142857142857 service_time: 709 s_time: 18 penalty: 0 agent_num: 20 done: False
______________________
id: 42 reward: 0.0 service_time: 819 s_time: 0 penalty: 0 agent_num: 17 done: False
______________________
id: 50 reward: 0.0 service_time: 968 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 45 reward: -0.10119047619047619 service_time: 978 s_time: 119 penalty: 0 agent_num: 21 done: False
______________________
id: 53 reward: -0.019642857142857142 service_time: 993 s_time: 33 penalty: 0 agent_num: 30 done: False
______________________
id: 51 reward: -0.017195767195767195 service_time: 1175 s_time: 26 penalty: 0 agent_num: 27 done: False
______________________
id: 44 reward: -0.025669642857142856 service_time: 1057 s_time: 46 penalty: 0 agent_num: 32 done: False
______________________
id: 48 reward: -0.039540816326530615 service_time: 936 s_time: 31 penalty: 0 agent_num: 14 done: False
______________________
id: 46 reward: -0.009792626728110598 service_time: 1234 s_time: 17 penalty: 0 agent_num: 31 done: False
______________________
id: 41 reward: 0.0 service_time: 612 s_time: 0 penalty: 0 agent_num: 30 done: False
______________________
id: 54 reward: -0.018262987012987012 service_time: 1164 s_time: 45 penalty: 0 agent_num: 44 done: False
______________________
id: 49 reward: -0.0069124423963133645 service_time: 1264 s_time: 12 penalty: 0 agent_num: 31 done: False
______________________
id: 52 reward: -0.0326530612244898 service_time: 1142 s_time: 64 penalty: 0 agent_num: 35 done: False
______________________
id: 55 reward: -0.025793650793650792 service_time: 1260 s_time: 39 penalty: 0 agent_num: 27 done: False
______________________
Step:  688
Pretraining Loss:  tensor(0.4633, device='cuda:0', grad_fn=<MeanBackward0>)
id: 43 reward: 0.0 service_time: 608 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 40 reward: 0.0 service_time: 890 s_time: 0 penalty: 0 agent_num: 18 done: False
______________________
id: 47 reward: 0.0 service_time: 709 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 48 reward: 0.0 service_time: 936 s_time: 0 penalty: 0 agent_num: 14 done: False
______________________
id: 50 reward: -0.0836038961038961 service_time: 1071 s_time: 103 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: -0.010944700460829493 service_time: 1283 s_time: 19 penalty: 0 agent_num: 31 done: False
______________________
id: 51 reward: 0.0013227513227513227 service_time: 1173 s_time: -2 penalty: 0 agent_num: 27 done: False
______________________
id: 45 reward: -0.016156462585034014 service_time: 997 s_time: 19 penalty: 0 agent_num: 21 done: False
______________________
id: 41 reward: -0.013095238095238096 service_time: 634 s_time: 22 penalty: 0 agent_num: 30 done: False
______________________
id: 42 reward: -0.08823529411764706 service_time: 903 s_time: 84 penalty: 0 agent_num: 17 done: False
______________________
id: 46 reward: -0.020737327188940093 service_time: 1270 s_time: 36 penalty: 0 agent_num: 31 done: False
______________________
id: 44 reward: -0.013950892857142858 service_time: 1082 s_time: 25 penalty: 0 agent_num: 32 done: False
______________________
id: 55 reward: 0.0 service_time: 1260 s_time: 0 penalty: 0 agent_num: 27 done: False
______________________
id: 53 reward: -0.02619047619047619 service_time: 1037 s_time: 44 penalty: 0 agent_num: 30 done: False
______________________
id: 52 reward: -0.02040816326530612 service_time: 1182 s_time: 40 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: 0.0 service_time: 1164 s_time: 0 penalty: 0 agent_num: 44 done: False
______________________
Step:  704
Pretraining Loss:  tensor(0.4460, device='cuda:0', grad_fn=<MeanBackward0>)
id: 43 reward: 0.0 service_time: 608 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 40 reward: -0.025793650793650792 service_time: 916 s_time: 26 penalty: 0 agent_num: 18 done: False
______________________
id: 47 reward: 0.0 service_time: 709 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 50 reward: -0.002435064935064935 service_time: 1074 s_time: 3 penalty: 0 agent_num: 22 done: False
______________________
id: 42 reward: 0.0021008403361344537 service_time: 901 s_time: -2 penalty: 0 agent_num: 17 done: False
______________________
id: 41 reward: -0.013095238095238096 service_time: 656 s_time: 22 penalty: 0 agent_num: 30 done: False
______________________
id: 44 reward: 0.0 service_time: 1082 s_time: 0 penalty: 0 agent_num: 32 done: False
______________________
id: 51 reward: -0.031084656084656083 service_time: 1220 s_time: 47 penalty: 0 agent_num: 27 done: False
______________________
id: 45 reward: 0.045068027210884355 service_time: 944 s_time: -53 penalty: 0 agent_num: 21 done: False
______________________
id: 49 reward: -0.013824884792626729 service_time: 1307 s_time: 24 penalty: 0 agent_num: 31 done: False
______________________
id: 46 reward: -0.019009216589861752 service_time: 1303 s_time: 33 penalty: 0 agent_num: 31 done: False
______________________
id: 53 reward: -0.023809523809523808 service_time: 1077 s_time: 40 penalty: 0 agent_num: 30 done: False
______________________
id: 54 reward: -0.012581168831168832 service_time: 1195 s_time: 31 penalty: 0 agent_num: 44 done: False
______________________
id: 48 reward: -0.025510204081632654 service_time: 956 s_time: 20 penalty: 0 agent_num: 14 done: False
______________________
id: 52 reward: -0.0163265306122449 service_time: 1214 s_time: 32 penalty: 0 agent_num: 35 done: False
______________________
id: 55 reward: -0.01984126984126984 service_time: 1290 s_time: 30 penalty: 0 agent_num: 27 done: False
______________________
Step:  720
Pretraining Loss:  tensor(0.4835, device='cuda:0', grad_fn=<MeanBackward0>)
id: 43 reward: -0.03296703296703297 service_time: 632 s_time: 24 penalty: 0 agent_num: 13 done: False
______________________
id: 48 reward: -0.02806122448979592 service_time: 978 s_time: 22 penalty: 0 agent_num: 14 done: False
______________________
id: 40 reward: 0.034722222222222224 service_time: 881 s_time: -35 penalty: 0 agent_num: 18 done: False
______________________
id: 42 reward: 0.0 service_time: 901 s_time: 0 penalty: 0 agent_num: 17 done: False
______________________
id: 45 reward: -0.1284013605442177 service_time: 1095 s_time: 151 penalty: 0 agent_num: 21 done: False
______________________
id: 50 reward: -0.05519480519480519 service_time: 1142 s_time: 68 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: -0.026785714285714284 service_time: 739 s_time: 30 penalty: 0 agent_num: 20 done: False
______________________
id: 53 reward: -0.013095238095238096 service_time: 1099 s_time: 22 penalty: 0 agent_num: 30 done: False
______________________
id: 52 reward: -0.007142857142857143 service_time: 1228 s_time: 14 penalty: 0 agent_num: 35 done: False
______________________
id: 49 reward: -0.022465437788018433 service_time: 1346 s_time: 39 penalty: 0 agent_num: 31 done: False
______________________
id: 55 reward: -0.06944444444444445 service_time: 1395 s_time: 105 penalty: 0 agent_num: 27 done: False
______________________
id: 44 reward: -0.03236607142857143 service_time: 1140 s_time: 58 penalty: 0 agent_num: 32 done: False
______________________
id: 41 reward: 0.0 service_time: 656 s_time: 0 penalty: 0 agent_num: 30 done: False
______________________
id: 46 reward: -0.012096774193548387 service_time: 1324 s_time: 21 penalty: 0 agent_num: 31 done: False
______________________
id: 51 reward: -0.023809523809523808 service_time: 1256 s_time: 36 penalty: 0 agent_num: 27 done: False
______________________
id: 54 reward: -0.01461038961038961 service_time: 1231 s_time: 36 penalty: 0 agent_num: 44 done: False
______________________
Step:  736
Pretraining Loss:  tensor(0.4576, device='cuda:0', grad_fn=<MeanBackward0>)
id: 43 reward: -0.08928571428571429 service_time: 697 s_time: 65 penalty: 0 agent_num: 13 done: False
______________________
id: 40 reward: -0.026785714285714284 service_time: 908 s_time: 27 penalty: 0 agent_num: 18 done: False
______________________
id: 48 reward: 0.01020408163265306 service_time: 970 s_time: -8 penalty: 0 agent_num: 14 done: False
______________________
id: 42 reward: -0.058823529411764705 service_time: 957 s_time: 56 penalty: 0 agent_num: 17 done: False
______________________
id: 47 reward: -0.030357142857142857 service_time: 773 s_time: 34 penalty: 0 agent_num: 20 done: False
______________________
id: 50 reward: 0.004058441558441558 service_time: 1137 s_time: -5 penalty: 0 agent_num: 22 done: False
______________________
id: 53 reward: 0.0 service_time: 1099 s_time: 0 penalty: 0 agent_num: 30 done: False
______________________
id: 41 reward: -0.020833333333333332 service_time: 691 s_time: 35 penalty: 0 agent_num: 30 done: False
______________________
id: 45 reward: 0.017006802721088437 service_time: 1075 s_time: -20 penalty: 0 agent_num: 21 done: False
______________________
id: 44 reward: 0.0005580357142857143 service_time: 1139 s_time: -1 penalty: 0 agent_num: 32 done: False
______________________
id: 46 reward: 0.0 service_time: 1324 s_time: 0 penalty: 0 agent_num: 31 done: False
______________________
id: 51 reward: -0.02513227513227513 service_time: 1294 s_time: 38 penalty: 0 agent_num: 27 done: False
______________________
id: 49 reward: -0.013824884792626729 service_time: 1370 s_time: 24 penalty: 0 agent_num: 31 done: False
______________________
id: 52 reward: -0.011224489795918367 service_time: 1250 s_time: 22 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: 0.0 service_time: 1231 s_time: 0 penalty: 0 agent_num: 44 done: False
______________________
id: 55 reward: 0.027116402116402115 service_time: 1354 s_time: -41 penalty: 0 agent_num: 27 done: False
______________________
Step:  752
Pretraining Loss:  tensor(0.5086, device='cuda:0', grad_fn=<MeanBackward0>)
id: 40 reward: -0.023809523809523808 service_time: 932 s_time: 24 penalty: 0 agent_num: 18 done: False
______________________
id: 47 reward: -0.008035714285714285 service_time: 782 s_time: 9 penalty: 0 agent_num: 20 done: False
______________________
id: 48 reward: 0.011479591836734694 service_time: 961 s_time: -9 penalty: 0 agent_num: 14 done: False
______________________
id: 42 reward: 0.0 service_time: 957 s_time: 0 penalty: 0 agent_num: 17 done: False
______________________
id: 43 reward: -0.1401098901098901 service_time: 799 s_time: 102 penalty: 0 agent_num: 13 done: False
______________________
id: 45 reward: 0.0 service_time: 1075 s_time: 0 penalty: 0 agent_num: 21 done: False
______________________
id: 49 reward: -0.012672811059907835 service_time: 1392 s_time: 22 penalty: 0 agent_num: 31 done: False
______________________
id: 50 reward: -0.045454545454545456 service_time: 1193 s_time: 56 penalty: 0 agent_num: 22 done: False
______________________
id: 53 reward: -0.018452380952380953 service_time: 1130 s_time: 31 penalty: 0 agent_num: 30 done: False
______________________
id: 41 reward: -0.017857142857142856 service_time: 721 s_time: 30 penalty: 0 agent_num: 30 done: False
______________________
id: 52 reward: -0.01479591836734694 service_time: 1279 s_time: 29 penalty: 0 agent_num: 35 done: False
______________________
id: 44 reward: -0.03180803571428571 service_time: 1196 s_time: 57 penalty: 0 agent_num: 32 done: False
______________________
id: 51 reward: -0.009259259259259259 service_time: 1308 s_time: 14 penalty: 0 agent_num: 27 done: False
______________________
id: 55 reward: -0.03306878306878307 service_time: 1404 s_time: 50 penalty: 0 agent_num: 27 done: False
______________________
id: 46 reward: -0.023617511520737326 service_time: 1365 s_time: 41 penalty: 0 agent_num: 31 done: False
______________________
id: 54 reward: -0.03571428571428571 service_time: 1319 s_time: 88 penalty: 0 agent_num: 44 done: False
______________________
Step:  768
Pretraining Loss:  tensor(0.5820, device='cuda:0', grad_fn=<MeanBackward0>)
id: 48 reward: -0.03443877551020408 service_time: 988 s_time: 27 penalty: 0 agent_num: 14 done: False
______________________
id: 40 reward: 0.001984126984126984 service_time: 930 s_time: -2 penalty: 0 agent_num: 18 done: False
______________________
id: 43 reward: -0.14835164835164835 service_time: 907 s_time: 108 penalty: 0 agent_num: 13 done: False
______________________
id: 42 reward: 0.0021008403361344537 service_time: 955 s_time: -2 penalty: 0 agent_num: 17 done: False
______________________
id: 47 reward: 0.0 service_time: 782 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 50 reward: 0.022727272727272728 service_time: 1165 s_time: -28 penalty: 0 agent_num: 22 done: False
______________________
id: 45 reward: -0.02465986394557823 service_time: 1104 s_time: 29 penalty: 0 agent_num: 21 done: False
______________________
id: 53 reward: -0.005357142857142857 service_time: 1139 s_time: 9 penalty: 0 agent_num: 30 done: False
______________________
id: 41 reward: 0.0 service_time: 721 s_time: 0 penalty: 0 agent_num: 30 done: False
______________________
id: 44 reward: -0.01953125 service_time: 1231 s_time: 35 penalty: 0 agent_num: 32 done: False
______________________
id: 49 reward: -0.02131336405529954 service_time: 1429 s_time: 37 penalty: 0 agent_num: 31 done: False
______________________
id: 52 reward: -0.02193877551020408 service_time: 1322 s_time: 43 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: -0.018668831168831168 service_time: 1365 s_time: 46 penalty: 0 agent_num: 44 done: False
______________________
id: 51 reward: -0.013227513227513227 service_time: 1328 s_time: 20 penalty: 0 agent_num: 27 done: False
______________________
id: 55 reward: 0.018518518518518517 service_time: 1376 s_time: -28 penalty: 0 agent_num: 27 done: False
______________________
id: 46 reward: -0.02880184331797235 service_time: 1415 s_time: 50 penalty: 0 agent_num: 31 done: False
______________________
Step:  784
Pretraining Loss:  tensor(0.5672, device='cuda:0', grad_fn=<MeanBackward0>)
id: 40 reward: -0.044642857142857144 service_time: 975 s_time: 45 penalty: 0 agent_num: 18 done: False
______________________
id: 48 reward: -0.021683673469387755 service_time: 1005 s_time: 17 penalty: 0 agent_num: 14 done: False
______________________
id: 42 reward: 0.0 service_time: 955 s_time: 0 penalty: 0 agent_num: 17 done: False
______________________
id: 43 reward: 0.0 service_time: 907 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 50 reward: 0.0 service_time: 1165 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: 0.0 service_time: 782 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 45 reward: 0.0 service_time: 1104 s_time: 0 penalty: 0 agent_num: 21 done: False
______________________
id: 53 reward: -0.0005952380952380953 service_time: 1140 s_time: 1 penalty: 0 agent_num: 30 done: False
______________________
id: 49 reward: 0.0 service_time: 1429 s_time: 0 penalty: 0 agent_num: 31 done: False
______________________
id: 41 reward: -0.006547619047619048 service_time: 732 s_time: 11 penalty: 0 agent_num: 30 done: False
______________________
id: 51 reward: 0.0 service_time: 1328 s_time: 0 penalty: 0 agent_num: 27 done: False
______________________
id: 52 reward: 0.0 service_time: 1322 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 44 reward: 0.00390625 service_time: 1224 s_time: -7 penalty: 0 agent_num: 32 done: False
______________________
id: 55 reward: 0.0 service_time: 1376 s_time: 0 penalty: 0 agent_num: 27 done: False
______________________
id: 46 reward: 0.000576036866359447 service_time: 1414 s_time: -1 penalty: 0 agent_num: 31 done: False
______________________
id: 54 reward: 0.0008116883116883117 service_time: 1363 s_time: -2 penalty: 0 agent_num: 44 done: False
______________________
Step:  800
Pretraining Loss:  tensor(0.5777, device='cuda:0', grad_fn=<MeanBackward0>)
id: 48 reward: 0.0012755102040816326 service_time: 1004 s_time: -1 penalty: 0 agent_num: 14 done: False
______________________
id: 42 reward: -0.06407563025210083 service_time: 1016 s_time: 61 penalty: 0 agent_num: 17 done: False
______________________
id: 43 reward: -0.06043956043956044 service_time: 951 s_time: 44 penalty: 0 agent_num: 13 done: False
______________________
id: 45 reward: -0.04931972789115646 service_time: 1162 s_time: 58 penalty: 0 agent_num: 21 done: False
______________________
id: 40 reward: -0.09722222222222222 service_time: 1073 s_time: 98 penalty: 0 agent_num: 18 done: False
______________________
id: 53 reward: 0.0017857142857142857 service_time: 1137 s_time: -3 penalty: 0 agent_num: 30 done: False
______________________
id: 41 reward: 0.0 service_time: 732 s_time: 0 penalty: 0 agent_num: 30 done: False
______________________
id: 50 reward: -0.041396103896103896 service_time: 1216 s_time: 51 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: -0.025892857142857145 service_time: 811 s_time: 29 penalty: 0 agent_num: 20 done: False
______________________
id: 46 reward: 0.005184331797235023 service_time: 1405 s_time: -9 penalty: 0 agent_num: 31 done: False
______________________
id: 49 reward: 0.0 service_time: 1429 s_time: 0 penalty: 0 agent_num: 31 done: False
______________________
id: 52 reward: 0.0020408163265306124 service_time: 1318 s_time: -4 penalty: 0 agent_num: 35 done: False
______________________
id: 44 reward: 0.0 service_time: 1224 s_time: 0 penalty: 0 agent_num: 32 done: False
______________________
id: 51 reward: -0.0006613756613756613 service_time: 1329 s_time: 1 penalty: 0 agent_num: 27 done: False
______________________
id: 54 reward: 0.0008116883116883117 service_time: 1361 s_time: -2 penalty: 0 agent_num: 44 done: False
______________________
id: 55 reward: -0.047619047619047616 service_time: 1448 s_time: 72 penalty: 0 agent_num: 27 done: False
______________________
Step:  816
Pretraining Loss:  tensor(0.5901, device='cuda:0', grad_fn=<MeanBackward0>)
id: 40 reward: -0.051587301587301584 service_time: 1125 s_time: 52 penalty: 0 agent_num: 18 done: False
______________________
id: 47 reward: -0.019642857142857142 service_time: 833 s_time: 22 penalty: 0 agent_num: 20 done: False
______________________
id: 45 reward: -0.03741496598639456 service_time: 1206 s_time: 44 penalty: 0 agent_num: 21 done: False
______________________
id: 42 reward: -0.032563025210084036 service_time: 1047 s_time: 31 penalty: 0 agent_num: 17 done: False
______________________
id: 48 reward: -0.06377551020408163 service_time: 1054 s_time: 50 penalty: 0 agent_num: 14 done: False
______________________
id: 43 reward: -0.0521978021978022 service_time: 989 s_time: 38 penalty: 0 agent_num: 13 done: False
______________________
id: 50 reward: -0.027597402597402596 service_time: 1250 s_time: 34 penalty: 0 agent_num: 22 done: False
______________________
id: 41 reward: 0.0 service_time: 732 s_time: 0 penalty: 0 agent_num: 30 done: False
______________________
id: 44 reward: 0.0005580357142857143 service_time: 1223 s_time: -1 penalty: 0 agent_num: 32 done: False
______________________
id: 55 reward: -0.0026455026455026454 service_time: 1452 s_time: 4 penalty: 0 agent_num: 27 done: False
______________________
id: 52 reward: 0.003061224489795918 service_time: 1312 s_time: -6 penalty: 0 agent_num: 35 done: False
______________________
id: 49 reward: 0.006336405529953917 service_time: 1418 s_time: -11 penalty: 0 agent_num: 31 done: False
______________________
id: 51 reward: 0.003968253968253968 service_time: 1323 s_time: -6 penalty: 0 agent_num: 27 done: False
______________________
id: 46 reward: 0.006336405529953917 service_time: 1394 s_time: -11 penalty: 0 agent_num: 31 done: False
______________________
id: 54 reward: 0.0 service_time: 1361 s_time: 0 penalty: 0 agent_num: 44 done: False
______________________
id: 53 reward: 20.00357142857143 service_time: 1131 s_time: -6 penalty: 0 agent_num: 30 done: True
______________________
Step:  832
Pretraining Loss:  tensor(0.5661, device='cuda:0', grad_fn=<MeanBackward0>)
id: 43 reward: -0.09065934065934066 service_time: 1055 s_time: 66 penalty: 0 agent_num: 13 done: False
______________________
id: 48 reward: 0.01020408163265306 service_time: 1046 s_time: -8 penalty: 0 agent_num: 14 done: False
______________________
id: 47 reward: -0.020535714285714286 service_time: 856 s_time: 23 penalty: 0 agent_num: 20 done: False
______________________
id: 42 reward: -0.11974789915966387 service_time: 1161 s_time: 114 penalty: 0 agent_num: 17 done: False
______________________
id: 45 reward: -0.11819727891156463 service_time: 1345 s_time: 139 penalty: 0 agent_num: 21 done: False
______________________
id: 50 reward: -0.033279220779220776 service_time: 1291 s_time: 41 penalty: 0 agent_num: 22 done: False
______________________
id: 40 reward: -0.05357142857142857 service_time: 1179 s_time: 54 penalty: 0 agent_num: 18 done: False
______________________
id: 41 reward: 0.0 service_time: 732 s_time: 0 penalty: 0 agent_num: 30 done: False
______________________
id: 53 reward: -0.009839650145772596 service_time: 27 s_time: 27 penalty: 0 agent_num: 49 done: False
______________________
id: 46 reward: 0.0 service_time: 1394 s_time: 0 penalty: 0 agent_num: 31 done: False
______________________
id: 52 reward: 0.0 service_time: 1312 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 49 reward: 0.000576036866359447 service_time: 1417 s_time: -1 penalty: 0 agent_num: 31 done: False
______________________
id: 44 reward: 0.0 service_time: 1223 s_time: 0 penalty: 0 agent_num: 32 done: False
______________________
id: 54 reward: 0.0016233766233766235 service_time: 1357 s_time: -4 penalty: 0 agent_num: 44 done: False
______________________
id: 55 reward: 0.005291005291005291 service_time: 1444 s_time: -8 penalty: 0 agent_num: 27 done: False
______________________
id: 51 reward: 20.00330687830688 service_time: 1318 s_time: -5 penalty: 0 agent_num: 27 done: True
______________________
Step:  848
Pretraining Loss:  tensor(0.2706, device='cuda:0', grad_fn=<MeanBackward0>)
id: 48 reward: -0.02295918367346939 service_time: 1064 s_time: 18 penalty: 0 agent_num: 14 done: False
______________________
id: 42 reward: -0.04096638655462185 service_time: 1200 s_time: 39 penalty: 0 agent_num: 17 done: False
______________________
id: 40 reward: -0.0496031746031746 service_time: 1229 s_time: 50 penalty: 0 agent_num: 18 done: False
______________________
id: 43 reward: -0.125 service_time: 1146 s_time: 91 penalty: 0 agent_num: 13 done: False
______________________
id: 51 reward: -0.010808270676691729 service_time: 23 s_time: 23 penalty: 0 agent_num: 38 done: False
______________________
id: 50 reward: -0.03571428571428571 service_time: 1335 s_time: 44 penalty: 0 agent_num: 22 done: False
______________________
id: 45 reward: -0.08078231292517007 service_time: 1440 s_time: 95 penalty: 0 agent_num: 21 done: False
______________________
id: 47 reward: -0.008035714285714285 service_time: 865 s_time: 9 penalty: 0 agent_num: 20 done: False
______________________
id: 52 reward: 0.0 service_time: 1312 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 49 reward: 0.0 service_time: 1417 s_time: 0 penalty: 0 agent_num: 31 done: False
______________________
id: 46 reward: 0.000576036866359447 service_time: 1393 s_time: -1 penalty: 0 agent_num: 31 done: False
______________________
id: 53 reward: -0.01239067055393586 service_time: 61 s_time: 34 penalty: 0 agent_num: 49 done: False
______________________
id: 44 reward: 0.0 service_time: 1223 s_time: 0 penalty: 0 agent_num: 32 done: False
______________________
id: 41 reward: -0.024404761904761905 service_time: 773 s_time: 41 penalty: 0 agent_num: 30 done: False
______________________
id: 55 reward: 0.0 service_time: 1444 s_time: 0 penalty: 0 agent_num: 27 done: False
______________________
id: 54 reward: 0.0 service_time: 1357 s_time: 0 penalty: 0 agent_num: 44 done: False
______________________
Step:  864
Pretraining Loss:  tensor(0.2423, device='cuda:0', grad_fn=<MeanBackward0>)
id: 43 reward: -0.19230769230769232 service_time: 1286 s_time: 140 penalty: 0 agent_num: 13 done: False
______________________
id: 42 reward: -0.17331932773109243 service_time: 1365 s_time: 165 penalty: 0 agent_num: 17 done: False
______________________
id: 48 reward: 0.0 service_time: 1064 s_time: 0 penalty: 0 agent_num: 14 done: False
______________________
id: 40 reward: -0.060515873015873016 service_time: 1290 s_time: 61 penalty: 0 agent_num: 18 done: False
______________________
id: 51 reward: -0.01362781954887218 service_time: 52 s_time: 29 penalty: 0 agent_num: 38 done: False
______________________
id: 47 reward: -0.022321428571428572 service_time: 890 s_time: 25 penalty: 0 agent_num: 20 done: False
______________________
id: 45 reward: -0.06547619047619048 service_time: 1517 s_time: 77 penalty: 0 agent_num: 21 done: False
______________________
id: 46 reward: -0.001152073732718894 service_time: 1395 s_time: 2 penalty: 0 agent_num: 31 done: False
______________________
id: 50 reward: -0.07142857142857142 service_time: 1423 s_time: 88 penalty: 0 agent_num: 22 done: False
______________________
id: 52 reward: 0.0010204081632653062 service_time: 1310 s_time: -2 penalty: 0 agent_num: 35 done: False
______________________
id: 49 reward: 0.0 service_time: 1417 s_time: 0 penalty: 0 agent_num: 31 done: False
______________________
id: 41 reward: 0.0 service_time: 773 s_time: 0 penalty: 0 agent_num: 30 done: False
______________________
id: 53 reward: -0.0047376093294460644 service_time: 74 s_time: 13 penalty: 0 agent_num: 49 done: False
______________________
id: 55 reward: 0.0013227513227513227 service_time: 1442 s_time: -2 penalty: 0 agent_num: 27 done: False
______________________
id: 44 reward: 20.002232142857142 service_time: 1219 s_time: -4 penalty: 0 agent_num: 32 done: True
______________________
id: 54 reward: 20.001623376623378 service_time: 1353 s_time: -4 penalty: 0 agent_num: 44 done: True
______________________
Step:  880
Pretraining Loss:  tensor(0.2413, device='cuda:0', grad_fn=<MeanBackward0>)
id: 43 reward: -0.08241758241758242 service_time: 1346 s_time: 60 penalty: 0 agent_num: 13 done: False
______________________
id: 48 reward: 0.006377551020408163 service_time: 1059 s_time: -5 penalty: 0 agent_num: 14 done: False
______________________
id: 44 reward: -0.012096774193548387 service_time: 21 s_time: 21 penalty: 0 agent_num: 31 done: False
______________________
id: 40 reward: -0.07142857142857142 service_time: 1362 s_time: 72 penalty: 0 agent_num: 18 done: False
______________________
id: 47 reward: 0.0 service_time: 890 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 51 reward: -0.004699248120300752 service_time: 62 s_time: 10 penalty: 0 agent_num: 38 done: False
______________________
id: 54 reward: -0.002976190476190476 service_time: 7 s_time: 7 penalty: 0 agent_num: 42 done: False
______________________
id: 50 reward: -0.041396103896103896 service_time: 1474 s_time: 51 penalty: 0 agent_num: 22 done: False
______________________
id: 52 reward: 0.0010204081632653062 service_time: 1308 s_time: -2 penalty: 0 agent_num: 35 done: False
______________________
id: 45 reward: 0.01445578231292517 service_time: 1500 s_time: -17 penalty: 0 agent_num: 21 done: False
______________________
id: 49 reward: 0.0 service_time: 1417 s_time: 0 penalty: 0 agent_num: 31 done: False
______________________
id: 53 reward: -0.002551020408163265 service_time: 81 s_time: 7 penalty: 0 agent_num: 49 done: False
______________________
id: 41 reward: -0.008928571428571428 service_time: 788 s_time: 15 penalty: 0 agent_num: 30 done: False
______________________
id: 42 reward: -0.05672268907563025 service_time: 1419 s_time: 54 penalty: 0 agent_num: 17 done: False
______________________
id: 46 reward: 20.0 service_time: 1395 s_time: 0 penalty: 0 agent_num: 31 done: True
______________________
id: 55 reward: 20.00132275132275 service_time: 1440 s_time: -2 penalty: 0 agent_num: 27 done: True
______________________
Step:  896
Pretraining Loss:  tensor(0.2269, device='cuda:0', grad_fn=<MeanBackward0>)
id: 55 reward: -0.028409090909090908 service_time: 35 s_time: 35 penalty: 0 agent_num: 22 done: False
______________________
id: 44 reward: -0.00576036866359447 service_time: 31 s_time: 10 penalty: 0 agent_num: 31 done: False
______________________
id: 42 reward: -0.12605042016806722 service_time: 1539 s_time: 120 penalty: 0 agent_num: 17 done: False
______________________
id: 46 reward: -0.01406926406926407 service_time: 26 s_time: 26 penalty: 0 agent_num: 33 done: False
______________________
id: 48 reward: -0.036989795918367346 service_time: 1088 s_time: 29 penalty: 0 agent_num: 14 done: False
______________________
id: 51 reward: -0.007048872180451127 service_time: 77 s_time: 15 penalty: 0 agent_num: 38 done: False
______________________
id: 47 reward: -0.03214285714285714 service_time: 926 s_time: 36 penalty: 0 agent_num: 20 done: False
______________________
id: 54 reward: -0.012329931972789115 service_time: 36 s_time: 29 penalty: 0 agent_num: 42 done: False
______________________
id: 40 reward: -0.16765873015873015 service_time: 1531 s_time: 169 penalty: 0 agent_num: 18 done: False
______________________
id: 45 reward: 0.0017006802721088435 service_time: 1498 s_time: -2 penalty: 0 agent_num: 21 done: False
______________________
id: 43 reward: -0.08104395604395605 service_time: 1405 s_time: 59 penalty: 0 agent_num: 13 done: False
______________________
id: 53 reward: -0.011661807580174927 service_time: 113 s_time: 32 penalty: 0 agent_num: 49 done: False
______________________
id: 41 reward: 0.0011904761904761906 service_time: 786 s_time: -2 penalty: 0 agent_num: 30 done: False
______________________
id: 49 reward: 0.0 service_time: 1417 s_time: 0 penalty: 0 agent_num: 31 done: False
______________________
id: 50 reward: 0.0008116883116883117 service_time: 1473 s_time: -1 penalty: 0 agent_num: 22 done: False
______________________
id: 52 reward: 20.0 service_time: 1308 s_time: 0 penalty: 0 agent_num: 35 done: True
______________________
Step:  912
Pretraining Loss:  tensor(0.2172, device='cuda:0', grad_fn=<MeanBackward0>)
id: 55 reward: -0.012987012987012988 service_time: 51 s_time: 16 penalty: 0 agent_num: 22 done: False
______________________
id: 48 reward: 0.007653061224489796 service_time: 1082 s_time: -6 penalty: 0 agent_num: 14 done: False
______________________
id: 44 reward: -0.007488479262672811 service_time: 44 s_time: 13 penalty: 0 agent_num: 31 done: False
______________________
id: 52 reward: -0.009424603174603174 service_time: 19 s_time: 19 penalty: 0 agent_num: 36 done: False
______________________
id: 46 reward: -0.012445887445887446 service_time: 49 s_time: 23 penalty: 0 agent_num: 33 done: False
______________________
id: 45 reward: 0.0 service_time: 1498 s_time: 0 penalty: 0 agent_num: 21 done: False
______________________
id: 47 reward: 0.0 service_time: 926 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 50 reward: 0.0 service_time: 1473 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: -0.019736842105263157 service_time: 119 s_time: 42 penalty: 0 agent_num: 38 done: False
______________________
id: 54 reward: 0.0 service_time: 36 s_time: 0 penalty: 0 agent_num: 42 done: False
______________________
id: 42 reward: -0.06302521008403361 service_time: 1599 s_time: 60 penalty: 0 agent_num: 17 done: False
______________________
id: 43 reward: -0.1346153846153846 service_time: 1503 s_time: 98 penalty: 0 agent_num: 13 done: False
______________________
id: 40 reward: -0.0763888888888889 service_time: 1608 s_time: 77 penalty: 0 agent_num: 18 done: False
______________________
id: 41 reward: -0.010714285714285714 service_time: 804 s_time: 18 penalty: 0 agent_num: 30 done: False
______________________
id: 53 reward: -0.01020408163265306 service_time: 141 s_time: 28 penalty: 0 agent_num: 49 done: False
______________________
id: 49 reward: 20.00057603686636 service_time: 1416 s_time: -1 penalty: 0 agent_num: 31 done: True
______________________
Step:  928
Pretraining Loss:  tensor(0.2408, device='cuda:0', grad_fn=<MeanBackward0>)
id: 48 reward: -0.03571428571428571 service_time: 1110 s_time: 28 penalty: 0 agent_num: 14 done: False
______________________
id: 52 reward: 0.0 service_time: 19 s_time: 0 penalty: 0 agent_num: 36 done: False
______________________
id: 46 reward: -0.013528138528138528 service_time: 74 s_time: 25 penalty: 0 agent_num: 33 done: False
______________________
id: 49 reward: -0.013513513513513514 service_time: 28 s_time: 28 penalty: 0 agent_num: 37 done: False
______________________
id: 44 reward: -0.013824884792626729 service_time: 68 s_time: 24 penalty: 0 agent_num: 31 done: False
______________________
id: 47 reward: 0.0 service_time: 926 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 55 reward: -0.0349025974025974 service_time: 94 s_time: 43 penalty: 0 agent_num: 22 done: False
______________________
id: 45 reward: 0.0 service_time: 1498 s_time: 0 penalty: 0 agent_num: 21 done: False
______________________
id: 51 reward: 0.0 service_time: 119 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 40 reward: -0.0744047619047619 service_time: 1683 s_time: 75 penalty: 0 agent_num: 18 done: False
______________________
id: 54 reward: -0.01488095238095238 service_time: 71 s_time: 35 penalty: 0 agent_num: 42 done: False
______________________
id: 41 reward: -0.011904761904761904 service_time: 824 s_time: 20 penalty: 0 agent_num: 30 done: False
______________________
id: 50 reward: 0.0 service_time: 1473 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 43 reward: -0.13873626373626374 service_time: 1604 s_time: 101 penalty: 0 agent_num: 13 done: False
______________________
id: 42 reward: -0.09978991596638656 service_time: 1694 s_time: 95 penalty: 0 agent_num: 17 done: False
______________________
id: 53 reward: -0.0036443148688046646 service_time: 151 s_time: 10 penalty: 0 agent_num: 49 done: False
______________________
Step:  944
Pretraining Loss:  tensor(0.2008, device='cuda:0', grad_fn=<MeanBackward0>)
id: 48 reward: 0.0 service_time: 1110 s_time: 0 penalty: 0 agent_num: 14 done: False
______________________
id: 44 reward: -0.009216589861751152 service_time: 84 s_time: 16 penalty: 0 agent_num: 31 done: False
______________________
id: 45 reward: 0.0 service_time: 1498 s_time: 0 penalty: 0 agent_num: 21 done: False
______________________
id: 49 reward: 0.0 service_time: 28 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 46 reward: 0.0 service_time: 74 s_time: 0 penalty: 0 agent_num: 33 done: False
______________________
id: 52 reward: -0.01636904761904762 service_time: 52 s_time: 33 penalty: 0 agent_num: 36 done: False
______________________
id: 47 reward: -0.01875 service_time: 947 s_time: 21 penalty: 0 agent_num: 20 done: False
______________________
id: 50 reward: 0.004058441558441558 service_time: 1468 s_time: -5 penalty: 0 agent_num: 22 done: False
______________________
id: 55 reward: 0.0 service_time: 94 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 40 reward: 0.003968253968253968 service_time: 1679 s_time: -4 penalty: 0 agent_num: 18 done: False
______________________
id: 54 reward: -0.008928571428571428 service_time: 92 s_time: 21 penalty: 0 agent_num: 42 done: False
______________________
id: 41 reward: -0.013095238095238096 service_time: 846 s_time: 22 penalty: 0 agent_num: 30 done: False
______________________
id: 43 reward: -0.22664835164835165 service_time: 1769 s_time: 165 penalty: 0 agent_num: 13 done: False
______________________
id: 53 reward: 0.002186588921282799 service_time: 145 s_time: -6 penalty: 0 agent_num: 49 done: False
______________________
id: 51 reward: -0.008458646616541353 service_time: 137 s_time: 18 penalty: 0 agent_num: 38 done: False
______________________
id: 42 reward: -0.10819327731092437 service_time: 1797 s_time: 103 penalty: 0 agent_num: 17 done: False
______________________
Step:  960
Pretraining Loss:  tensor(0.1839, device='cuda:0', grad_fn=<MeanBackward0>)
id: 48 reward: -0.01913265306122449 service_time: 1125 s_time: 15 penalty: 0 agent_num: 14 done: False
______________________
id: 43 reward: -0.13736263736263737 service_time: 1869 s_time: 100 penalty: 0 agent_num: 13 done: False
______________________
id: 45 reward: 0.0 service_time: 1498 s_time: 0 penalty: 0 agent_num: 21 done: False
______________________
id: 46 reward: -0.016774891774891776 service_time: 105 s_time: 31 penalty: 0 agent_num: 33 done: False
______________________
id: 40 reward: 0.0 service_time: 1679 s_time: 0 penalty: 0 agent_num: 18 done: False
______________________
id: 44 reward: 0.0 service_time: 84 s_time: 0 penalty: 0 agent_num: 31 done: False
______________________
id: 49 reward: -0.012548262548262547 service_time: 54 s_time: 26 penalty: 0 agent_num: 37 done: False
______________________
id: 52 reward: -0.022321428571428572 service_time: 97 s_time: 45 penalty: 0 agent_num: 36 done: False
______________________
id: 47 reward: 0.0 service_time: 947 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 53 reward: -0.007653061224489796 service_time: 166 s_time: 21 penalty: 0 agent_num: 49 done: False
______________________
id: 41 reward: -0.01488095238095238 service_time: 871 s_time: 25 penalty: 0 agent_num: 30 done: False
______________________
id: 42 reward: -0.08718487394957983 service_time: 1880 s_time: 83 penalty: 0 agent_num: 17 done: False
______________________
id: 50 reward: 0.0 service_time: 1468 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: -0.006109022556390977 service_time: 150 s_time: 13 penalty: 0 agent_num: 38 done: False
______________________
id: 55 reward: -0.05113636363636364 service_time: 157 s_time: 63 penalty: 0 agent_num: 22 done: False
______________________
id: 54 reward: -0.006802721088435374 service_time: 108 s_time: 16 penalty: 0 agent_num: 42 done: False
______________________
Step:  976
Pretraining Loss:  tensor(0.2047, device='cuda:0', grad_fn=<MeanBackward0>)
id: 43 reward: -0.10164835164835165 service_time: 1943 s_time: 74 penalty: 0 agent_num: 13 done: False
______________________
id: 48 reward: -0.036989795918367346 service_time: 1154 s_time: 29 penalty: 0 agent_num: 14 done: False
______________________
id: 40 reward: 0.0 service_time: 1679 s_time: 0 penalty: 0 agent_num: 18 done: False
______________________
id: 46 reward: -0.010822510822510822 service_time: 125 s_time: 20 penalty: 0 agent_num: 33 done: False
______________________
id: 49 reward: -0.010135135135135136 service_time: 75 s_time: 21 penalty: 0 agent_num: 37 done: False
______________________
id: 41 reward: 0.0 service_time: 871 s_time: 0 penalty: 0 agent_num: 30 done: False
______________________
id: 47 reward: -0.008928571428571428 service_time: 957 s_time: 10 penalty: 0 agent_num: 20 done: False
______________________
id: 51 reward: -0.017857142857142856 service_time: 188 s_time: 38 penalty: 0 agent_num: 38 done: False
______________________
id: 53 reward: -0.015306122448979591 service_time: 208 s_time: 42 penalty: 0 agent_num: 49 done: False
______________________
id: 55 reward: -0.005681818181818182 service_time: 164 s_time: 7 penalty: 0 agent_num: 22 done: False
______________________
id: 52 reward: -0.007936507936507936 service_time: 113 s_time: 16 penalty: 0 agent_num: 36 done: False
______________________
id: 54 reward: -0.015731292517006803 service_time: 145 s_time: 37 penalty: 0 agent_num: 42 done: False
______________________
id: 42 reward: -0.10819327731092437 service_time: 1983 s_time: 103 penalty: 0 agent_num: 17 done: False
______________________
id: 45 reward: 20.002551020408163 service_time: 1495 s_time: -3 penalty: 0 agent_num: 21 done: True
______________________
id: 50 reward: 20.0 service_time: 1468 s_time: 0 penalty: 0 agent_num: 22 done: True
______________________
id: 44 reward: -0.04262672811059908 service_time: 158 s_time: 74 penalty: 0 agent_num: 31 done: False
______________________
Step:  992
Pretraining Loss:  tensor(0.2294, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: -0.00935374149659864 service_time: 11 s_time: 11 penalty: 0 agent_num: 21 done: False
______________________
id: 50 reward: -0.004310344827586207 service_time: 7 s_time: 7 penalty: 0 agent_num: 29 done: False
______________________
id: 40 reward: 0.0 service_time: 1679 s_time: 0 penalty: 0 agent_num: 18 done: False
______________________
id: 43 reward: -0.3516483516483517 service_time: 2199 s_time: 256 penalty: 0 agent_num: 13 done: False
______________________
id: 46 reward: 0.0 service_time: 125 s_time: 0 penalty: 0 agent_num: 33 done: False
______________________
id: 49 reward: -0.006756756756756757 service_time: 89 s_time: 14 penalty: 0 agent_num: 37 done: False
______________________
id: 47 reward: -0.008928571428571428 service_time: 967 s_time: 10 penalty: 0 agent_num: 20 done: False
______________________
id: 48 reward: -0.042091836734693876 service_time: 1187 s_time: 33 penalty: 0 agent_num: 14 done: False
______________________
id: 52 reward: -0.011904761904761904 service_time: 137 s_time: 24 penalty: 0 agent_num: 36 done: False
______________________
id: 42 reward: -0.08298319327731092 service_time: 2062 s_time: 79 penalty: 0 agent_num: 17 done: False
______________________
id: 51 reward: 0.0009398496240601503 service_time: 186 s_time: -2 penalty: 0 agent_num: 38 done: False
______________________
id: 41 reward: -0.01369047619047619 service_time: 894 s_time: 23 penalty: 0 agent_num: 30 done: False
______________________
id: 55 reward: -0.015422077922077922 service_time: 183 s_time: 19 penalty: 0 agent_num: 22 done: False
______________________
id: 53 reward: -0.008746355685131196 service_time: 232 s_time: 24 penalty: 0 agent_num: 49 done: False
______________________
id: 54 reward: -0.017857142857142856 service_time: 187 s_time: 42 penalty: 0 agent_num: 42 done: False
______________________
id: 44 reward: -0.02131336405529954 service_time: 195 s_time: 37 penalty: 0 agent_num: 31 done: False
______________________
Step:  1008
Pretraining Loss:  tensor(0.2304, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: -0.027210884353741496 service_time: 43 s_time: 32 penalty: 0 agent_num: 21 done: False
______________________
id: 43 reward: 0.0027472527472527475 service_time: 2197 s_time: -2 penalty: 0 agent_num: 13 done: False
______________________
id: 50 reward: -0.01416256157635468 service_time: 30 s_time: 23 penalty: 0 agent_num: 29 done: False
______________________
id: 46 reward: -0.013528138528138528 service_time: 150 s_time: 25 penalty: 0 agent_num: 33 done: False
______________________
id: 49 reward: -0.027992277992277992 service_time: 147 s_time: 58 penalty: 0 agent_num: 37 done: False
______________________
id: 48 reward: 0.0 service_time: 1187 s_time: 0 penalty: 0 agent_num: 14 done: False
______________________
id: 55 reward: -0.016233766233766232 service_time: 203 s_time: 20 penalty: 0 agent_num: 22 done: False
______________________
id: 52 reward: -0.020337301587301588 service_time: 178 s_time: 41 penalty: 0 agent_num: 36 done: False
______________________
id: 41 reward: -0.01369047619047619 service_time: 917 s_time: 23 penalty: 0 agent_num: 30 done: False
______________________
id: 44 reward: -0.0034562211981566822 service_time: 201 s_time: 6 penalty: 0 agent_num: 31 done: False
______________________
id: 51 reward: -0.009868421052631578 service_time: 207 s_time: 21 penalty: 0 agent_num: 38 done: False
______________________
id: 53 reward: 0.0 service_time: 232 s_time: 0 penalty: 0 agent_num: 49 done: False
______________________
id: 54 reward: -0.011054421768707483 service_time: 213 s_time: 26 penalty: 0 agent_num: 42 done: False
______________________
id: 47 reward: -0.04375 service_time: 1016 s_time: 49 penalty: 0 agent_num: 20 done: False
______________________
id: 42 reward: 0.0 service_time: 2062 s_time: 0 penalty: 0 agent_num: 17 done: False
______________________
id: 40 reward: 20.006944444444443 service_time: 1672 s_time: -7 penalty: 0 agent_num: 18 done: True
______________________
Step:  1024
Pretraining Loss:  tensor(0.2227, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: -0.017006802721088437 service_time: 63 s_time: 20 penalty: 0 agent_num: 21 done: False
______________________
id: 50 reward: -0.0049261083743842365 service_time: 38 s_time: 8 penalty: 0 agent_num: 29 done: False
______________________
id: 40 reward: -0.014423076923076924 service_time: 21 s_time: 21 penalty: 0 agent_num: 26 done: False
______________________
id: 48 reward: -0.05739795918367347 service_time: 1232 s_time: 45 penalty: 0 agent_num: 14 done: False
______________________
id: 42 reward: 0.0 service_time: 2062 s_time: 0 penalty: 0 agent_num: 17 done: False
______________________
id: 43 reward: 0.017857142857142856 service_time: 2184 s_time: -13 penalty: 0 agent_num: 13 done: False
______________________
id: 52 reward: -0.006944444444444444 service_time: 192 s_time: 14 penalty: 0 agent_num: 36 done: False
______________________
id: 46 reward: -0.013528138528138528 service_time: 175 s_time: 25 penalty: 0 agent_num: 33 done: False
______________________
id: 55 reward: -0.026785714285714284 service_time: 236 s_time: 33 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: -0.006756756756756757 service_time: 161 s_time: 14 penalty: 0 agent_num: 37 done: False
______________________
id: 51 reward: -0.015037593984962405 service_time: 239 s_time: 32 penalty: 0 agent_num: 38 done: False
______________________
id: 54 reward: -0.00467687074829932 service_time: 224 s_time: 11 penalty: 0 agent_num: 42 done: False
______________________
id: 41 reward: 0.0 service_time: 917 s_time: 0 penalty: 0 agent_num: 30 done: False
______________________
id: 44 reward: -0.019585253456221197 service_time: 235 s_time: 34 penalty: 0 agent_num: 31 done: False
______________________
id: 53 reward: -0.019314868804664723 service_time: 285 s_time: 53 penalty: 0 agent_num: 49 done: False
______________________
id: 47 reward: -0.00625 service_time: 1023 s_time: 7 penalty: 0 agent_num: 20 done: False
______________________
Step:  1040
Pretraining Loss:  tensor(0.2008, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: -0.031462585034013606 service_time: 100 s_time: 37 penalty: 0 agent_num: 21 done: False
______________________
id: 40 reward: -0.028846153846153848 service_time: 63 s_time: 42 penalty: 0 agent_num: 26 done: False
______________________
id: 43 reward: 0.0 service_time: 2184 s_time: 0 penalty: 0 agent_num: 13 done: False
______________________
id: 48 reward: -0.030612244897959183 service_time: 1256 s_time: 24 penalty: 0 agent_num: 14 done: False
______________________
id: 50 reward: -0.01539408866995074 service_time: 63 s_time: 25 penalty: 0 agent_num: 29 done: False
______________________
id: 46 reward: -0.010822510822510822 service_time: 195 s_time: 20 penalty: 0 agent_num: 33 done: False
______________________
id: 41 reward: -0.009523809523809525 service_time: 933 s_time: 16 penalty: 0 agent_num: 30 done: False
______________________
id: 49 reward: -0.01447876447876448 service_time: 191 s_time: 30 penalty: 0 agent_num: 37 done: False
______________________
id: 55 reward: -0.025974025974025976 service_time: 268 s_time: 32 penalty: 0 agent_num: 22 done: False
______________________
id: 44 reward: -0.009792626728110598 service_time: 252 s_time: 17 penalty: 0 agent_num: 31 done: False
______________________
id: 51 reward: -0.017857142857142856 service_time: 277 s_time: 38 penalty: 0 agent_num: 38 done: False
______________________
id: 47 reward: -0.01875 service_time: 1044 s_time: 21 penalty: 0 agent_num: 20 done: False
______________________
id: 42 reward: 0.0 service_time: 2062 s_time: 0 penalty: 0 agent_num: 17 done: False
______________________
id: 52 reward: -0.017361111111111112 service_time: 227 s_time: 35 penalty: 0 agent_num: 36 done: False
______________________
id: 53 reward: 0.0 service_time: 285 s_time: 0 penalty: 0 agent_num: 49 done: False
______________________
id: 54 reward: -0.003826530612244898 service_time: 233 s_time: 9 penalty: 0 agent_num: 42 done: False
______________________
Step:  1056
Pretraining Loss:  tensor(0.2556, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: -0.031462585034013606 service_time: 137 s_time: 37 penalty: 0 agent_num: 21 done: False
______________________
id: 43 reward: 0.0013736263736263737 service_time: 2183 s_time: -1 penalty: 0 agent_num: 13 done: False
______________________
id: 40 reward: 0.0 service_time: 63 s_time: 0 penalty: 0 agent_num: 26 done: False
______________________
id: 50 reward: -0.007389162561576354 service_time: 75 s_time: 12 penalty: 0 agent_num: 29 done: False
______________________
id: 48 reward: 0.007653061224489796 service_time: 1250 s_time: -6 penalty: 0 agent_num: 14 done: False
______________________
id: 46 reward: -0.010281385281385282 service_time: 214 s_time: 19 penalty: 0 agent_num: 33 done: False
______________________
id: 52 reward: -0.005952380952380952 service_time: 239 s_time: 12 penalty: 0 agent_num: 36 done: False
______________________
id: 49 reward: -0.009652509652509652 service_time: 211 s_time: 20 penalty: 0 agent_num: 37 done: False
______________________
id: 55 reward: -0.02353896103896104 service_time: 297 s_time: 29 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: 0.0 service_time: 1044 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 41 reward: 0.0 service_time: 933 s_time: 0 penalty: 0 agent_num: 30 done: False
______________________
id: 44 reward: 0.0 service_time: 252 s_time: 0 penalty: 0 agent_num: 31 done: False
______________________
id: 51 reward: 0.0 service_time: 277 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 53 reward: -0.008017492711370262 service_time: 307 s_time: 22 penalty: 0 agent_num: 49 done: False
______________________
id: 54 reward: -0.006377551020408163 service_time: 248 s_time: 15 penalty: 0 agent_num: 42 done: False
______________________
id: 42 reward: 20.0 service_time: 2062 s_time: 0 penalty: 0 agent_num: 17 done: True
______________________
Step:  1072
Pretraining Loss:  tensor(0.2505, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: -0.02040816326530612 service_time: 161 s_time: 24 penalty: 0 agent_num: 21 done: False
______________________
id: 40 reward: -0.032280219780219783 service_time: 110 s_time: 47 penalty: 0 agent_num: 26 done: False
______________________
id: 48 reward: 0.0 service_time: 1250 s_time: 0 penalty: 0 agent_num: 14 done: False
______________________
id: 50 reward: -0.01539408866995074 service_time: 100 s_time: 25 penalty: 0 agent_num: 29 done: False
______________________
id: 46 reward: -0.012445887445887446 service_time: 237 s_time: 23 penalty: 0 agent_num: 33 done: False
______________________
id: 42 reward: -0.014194139194139194 service_time: 31 s_time: 31 penalty: 0 agent_num: 39 done: False
______________________
id: 47 reward: -0.0125 service_time: 1058 s_time: 14 penalty: 0 agent_num: 20 done: False
______________________
id: 49 reward: -0.008687258687258687 service_time: 229 s_time: 18 penalty: 0 agent_num: 37 done: False
______________________
id: 54 reward: -0.00977891156462585 service_time: 271 s_time: 23 penalty: 0 agent_num: 42 done: False
______________________
id: 51 reward: -0.007518796992481203 service_time: 293 s_time: 16 penalty: 0 agent_num: 38 done: False
______________________
id: 44 reward: -0.026497695852534562 service_time: 298 s_time: 46 penalty: 0 agent_num: 31 done: False
______________________
id: 41 reward: -0.013095238095238096 service_time: 955 s_time: 22 penalty: 0 agent_num: 30 done: False
______________________
id: 55 reward: -0.017045454545454544 service_time: 318 s_time: 21 penalty: 0 agent_num: 22 done: False
______________________
id: 53 reward: 0.0 service_time: 307 s_time: 0 penalty: 0 agent_num: 49 done: False
______________________
id: 43 reward: 20.0 service_time: 2183 s_time: 0 penalty: 0 agent_num: 13 done: True
______________________
id: 52 reward: -0.014384920634920634 service_time: 268 s_time: 29 penalty: 0 agent_num: 36 done: False
______________________
Step:  1088
Pretraining Loss:  tensor(0.2142, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: 0.0 service_time: 161 s_time: 0 penalty: 0 agent_num: 21 done: False
______________________
id: 40 reward: -0.012362637362637362 service_time: 128 s_time: 18 penalty: 0 agent_num: 26 done: False
______________________
id: 48 reward: -0.01020408163265306 service_time: 1258 s_time: 8 penalty: 0 agent_num: 14 done: False
______________________
id: 50 reward: -0.017241379310344827 service_time: 128 s_time: 28 penalty: 0 agent_num: 29 done: False
______________________
id: 46 reward: 0.0 service_time: 237 s_time: 0 penalty: 0 agent_num: 33 done: False
______________________
id: 49 reward: -0.00723938223938224 service_time: 244 s_time: 15 penalty: 0 agent_num: 37 done: False
______________________
id: 42 reward: -0.007326007326007326 service_time: 47 s_time: 16 penalty: 0 agent_num: 39 done: False
______________________
id: 47 reward: 0.0 service_time: 1058 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 43 reward: -0.003061224489795918 service_time: 6 s_time: 6 penalty: 0 agent_num: 35 done: False
______________________
id: 44 reward: -0.007488479262672811 service_time: 311 s_time: 13 penalty: 0 agent_num: 31 done: False
______________________
id: 55 reward: -0.020292207792207792 service_time: 343 s_time: 25 penalty: 0 agent_num: 22 done: False
______________________
id: 54 reward: -0.017006802721088437 service_time: 311 s_time: 40 penalty: 0 agent_num: 42 done: False
______________________
id: 51 reward: 0.002349624060150376 service_time: 288 s_time: -5 penalty: 0 agent_num: 38 done: False
______________________
id: 53 reward: -0.02587463556851312 service_time: 378 s_time: 71 penalty: 0 agent_num: 49 done: False
______________________
id: 52 reward: -0.013888888888888888 service_time: 296 s_time: 28 penalty: 0 agent_num: 36 done: False
______________________
id: 41 reward: -0.007142857142857143 service_time: 967 s_time: 12 penalty: 0 agent_num: 30 done: False
______________________
Step:  1104
Pretraining Loss:  tensor(0.1619, device='cuda:0', grad_fn=<MeanBackward0>)
id: 48 reward: -0.03826530612244898 service_time: 1288 s_time: 30 penalty: 0 agent_num: 14 done: False
______________________
id: 40 reward: 0.0 service_time: 128 s_time: 0 penalty: 0 agent_num: 26 done: False
______________________
id: 50 reward: -0.01847290640394089 service_time: 158 s_time: 30 penalty: 0 agent_num: 29 done: False
______________________
id: 43 reward: -0.025510204081632654 service_time: 56 s_time: 50 penalty: 0 agent_num: 35 done: False
______________________
id: 46 reward: -0.026515151515151516 service_time: 286 s_time: 49 penalty: 0 agent_num: 33 done: False
______________________
id: 42 reward: -0.007326007326007326 service_time: 63 s_time: 16 penalty: 0 agent_num: 39 done: False
______________________
id: 49 reward: -0.016409266409266408 service_time: 278 s_time: 34 penalty: 0 agent_num: 37 done: False
______________________
id: 47 reward: -0.020535714285714286 service_time: 1081 s_time: 23 penalty: 0 agent_num: 20 done: False
______________________
id: 45 reward: -0.07482993197278912 service_time: 249 s_time: 88 penalty: 0 agent_num: 21 done: False
______________________
id: 41 reward: -0.01904761904761905 service_time: 999 s_time: 32 penalty: 0 agent_num: 30 done: False
______________________
id: 55 reward: 0.0 service_time: 343 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 44 reward: -0.016705069124423964 service_time: 340 s_time: 29 penalty: 0 agent_num: 31 done: False
______________________
id: 51 reward: -0.010808270676691729 service_time: 311 s_time: 23 penalty: 0 agent_num: 38 done: False
______________________
id: 54 reward: 0.0 service_time: 311 s_time: 0 penalty: 0 agent_num: 42 done: False
______________________
id: 53 reward: 0.0 service_time: 378 s_time: 0 penalty: 0 agent_num: 49 done: False
______________________
id: 52 reward: -0.013392857142857142 service_time: 323 s_time: 27 penalty: 0 agent_num: 36 done: False
______________________
Step:  1120
Pretraining Loss:  tensor(0.1937, device='cuda:0', grad_fn=<MeanBackward0>)
id: 48 reward: 0.0 service_time: 1288 s_time: 0 penalty: 0 agent_num: 14 done: False
______________________
id: 45 reward: 0.017006802721088437 service_time: 229 s_time: -20 penalty: 0 agent_num: 21 done: False
______________________
id: 50 reward: -0.01600985221674877 service_time: 184 s_time: 26 penalty: 0 agent_num: 29 done: False
______________________
id: 43 reward: -0.01479591836734694 service_time: 85 s_time: 29 penalty: 0 agent_num: 35 done: False
______________________
id: 40 reward: -0.04807692307692308 service_time: 198 s_time: 70 penalty: 0 agent_num: 26 done: False
______________________
id: 47 reward: -0.01875 service_time: 1102 s_time: 21 penalty: 0 agent_num: 20 done: False
______________________
id: 46 reward: 0.0 service_time: 286 s_time: 0 penalty: 0 agent_num: 33 done: False
______________________
id: 55 reward: -0.05844155844155844 service_time: 415 s_time: 72 penalty: 0 agent_num: 22 done: False
______________________
id: 44 reward: -0.009216589861751152 service_time: 356 s_time: 16 penalty: 0 agent_num: 31 done: False
______________________
id: 52 reward: 0.0 service_time: 323 s_time: 0 penalty: 0 agent_num: 36 done: False
______________________
id: 41 reward: 0.0 service_time: 999 s_time: 0 penalty: 0 agent_num: 30 done: False
______________________
id: 54 reward: 0.0 service_time: 311 s_time: 0 penalty: 0 agent_num: 42 done: False
______________________
id: 42 reward: -0.009615384615384616 service_time: 84 s_time: 21 penalty: 0 agent_num: 39 done: False
______________________
id: 51 reward: 0.0009398496240601503 service_time: 309 s_time: -2 penalty: 0 agent_num: 38 done: False
______________________
id: 49 reward: -0.0111003861003861 service_time: 301 s_time: 23 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: -0.021137026239067054 service_time: 436 s_time: 58 penalty: 0 agent_num: 49 done: False
______________________
Step:  1136
Pretraining Loss:  tensor(0.1919, device='cuda:0', grad_fn=<MeanBackward0>)
id: 48 reward: -0.042091836734693876 service_time: 1321 s_time: 33 penalty: 0 agent_num: 14 done: False
______________________
id: 50 reward: -0.014778325123152709 service_time: 208 s_time: 24 penalty: 0 agent_num: 29 done: False
______________________
id: 43 reward: 0.0 service_time: 85 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 47 reward: 0.0 service_time: 1102 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 40 reward: -0.008928571428571428 service_time: 211 s_time: 13 penalty: 0 agent_num: 26 done: False
______________________
id: 45 reward: -0.0195578231292517 service_time: 252 s_time: 23 penalty: 0 agent_num: 21 done: False
______________________
id: 46 reward: -0.03192640692640693 service_time: 345 s_time: 59 penalty: 0 agent_num: 33 done: False
______________________
id: 51 reward: 0.0 service_time: 309 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 41 reward: 0.0 service_time: 999 s_time: 0 penalty: 0 agent_num: 30 done: False
______________________
id: 55 reward: -0.037337662337662336 service_time: 461 s_time: 46 penalty: 0 agent_num: 22 done: False
______________________
id: 42 reward: -0.013736263736263736 service_time: 114 s_time: 30 penalty: 0 agent_num: 39 done: False
______________________
id: 49 reward: -0.012065637065637066 service_time: 326 s_time: 25 penalty: 0 agent_num: 37 done: False
______________________
id: 44 reward: -0.009216589861751152 service_time: 372 s_time: 16 penalty: 0 agent_num: 31 done: False
______________________
id: 52 reward: -0.025793650793650792 service_time: 375 s_time: 52 penalty: 0 agent_num: 36 done: False
______________________
id: 53 reward: -0.008746355685131196 service_time: 460 s_time: 24 penalty: 0 agent_num: 49 done: False
______________________
id: 54 reward: -0.004251700680272109 service_time: 321 s_time: 10 penalty: 0 agent_num: 42 done: False
______________________
Step:  1152
Pretraining Loss:  tensor(0.1991, device='cuda:0', grad_fn=<MeanBackward0>)
id: 48 reward: -0.017857142857142856 service_time: 1335 s_time: 14 penalty: 0 agent_num: 14 done: False
______________________
id: 40 reward: -0.009615384615384616 service_time: 225 s_time: 14 penalty: 0 agent_num: 26 done: False
______________________
id: 45 reward: -0.013605442176870748 service_time: 268 s_time: 16 penalty: 0 agent_num: 21 done: False
______________________
id: 47 reward: -0.017857142857142856 service_time: 1122 s_time: 20 penalty: 0 agent_num: 20 done: False
______________________
id: 43 reward: -0.02857142857142857 service_time: 141 s_time: 56 penalty: 0 agent_num: 35 done: False
______________________
id: 50 reward: -0.024630541871921183 service_time: 248 s_time: 40 penalty: 0 agent_num: 29 done: False
______________________
id: 42 reward: -0.007326007326007326 service_time: 130 s_time: 16 penalty: 0 agent_num: 39 done: False
______________________
id: 44 reward: -0.022465437788018433 service_time: 411 s_time: 39 penalty: 0 agent_num: 31 done: False
______________________
id: 49 reward: 0.0 service_time: 326 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 46 reward: -0.01406926406926407 service_time: 371 s_time: 26 penalty: 0 agent_num: 33 done: False
______________________
id: 52 reward: -0.011904761904761904 service_time: 399 s_time: 24 penalty: 0 agent_num: 36 done: False
______________________
id: 41 reward: -0.02142857142857143 service_time: 1035 s_time: 36 penalty: 0 agent_num: 30 done: False
______________________
id: 51 reward: -0.010808270676691729 service_time: 332 s_time: 23 penalty: 0 agent_num: 38 done: False
______________________
id: 55 reward: 0.0 service_time: 461 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 53 reward: 0.0 service_time: 460 s_time: 0 penalty: 0 agent_num: 49 done: False
______________________
id: 54 reward: -0.00977891156462585 service_time: 344 s_time: 23 penalty: 0 agent_num: 42 done: False
______________________
Step:  1168
Pretraining Loss:  tensor(0.1925, device='cuda:0', grad_fn=<MeanBackward0>)
id: 48 reward: 0.0 service_time: 1335 s_time: 0 penalty: 0 agent_num: 14 done: False
______________________
id: 47 reward: 0.0 service_time: 1122 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 55 reward: -0.04788961038961039 service_time: 520 s_time: 59 penalty: 0 agent_num: 22 done: False
______________________
id: 40 reward: -0.019230769230769232 service_time: 253 s_time: 28 penalty: 0 agent_num: 26 done: False
______________________
id: 45 reward: -0.027210884353741496 service_time: 300 s_time: 32 penalty: 0 agent_num: 21 done: False
______________________
id: 43 reward: 0.002551020408163265 service_time: 136 s_time: -5 penalty: 0 agent_num: 35 done: False
______________________
id: 50 reward: -0.02894088669950739 service_time: 295 s_time: 47 penalty: 0 agent_num: 29 done: False
______________________
id: 49 reward: -0.022683397683397683 service_time: 373 s_time: 47 penalty: 0 agent_num: 37 done: False
______________________
id: 46 reward: -0.015151515151515152 service_time: 399 s_time: 28 penalty: 0 agent_num: 33 done: False
______________________
id: 42 reward: -0.009157509157509158 service_time: 150 s_time: 20 penalty: 0 agent_num: 39 done: False
______________________
id: 51 reward: -0.011278195488721804 service_time: 356 s_time: 24 penalty: 0 agent_num: 38 done: False
______________________
id: 41 reward: 0.0 service_time: 1035 s_time: 0 penalty: 0 agent_num: 30 done: False
______________________
id: 52 reward: -0.012896825396825396 service_time: 425 s_time: 26 penalty: 0 agent_num: 36 done: False
______________________
id: 44 reward: -0.018433179723502304 service_time: 443 s_time: 32 penalty: 0 agent_num: 31 done: False
______________________
id: 53 reward: -0.022230320699708456 service_time: 521 s_time: 61 penalty: 0 agent_num: 49 done: False
______________________
id: 54 reward: -0.011479591836734694 service_time: 371 s_time: 27 penalty: 0 agent_num: 42 done: False
______________________
Step:  1184
Pretraining Loss:  tensor(0.2135, device='cuda:0', grad_fn=<MeanBackward0>)
id: 48 reward: -0.029336734693877552 service_time: 1358 s_time: 23 penalty: 0 agent_num: 14 done: False
______________________
id: 47 reward: -0.022321428571428572 service_time: 1147 s_time: 25 penalty: 0 agent_num: 20 done: False
______________________
id: 40 reward: -0.016483516483516484 service_time: 277 s_time: 24 penalty: 0 agent_num: 26 done: False
______________________
id: 50 reward: -0.013546798029556651 service_time: 317 s_time: 22 penalty: 0 agent_num: 29 done: False
______________________
id: 46 reward: -0.007034632034632035 service_time: 412 s_time: 13 penalty: 0 agent_num: 33 done: False
______________________
id: 42 reward: -0.012362637362637362 service_time: 177 s_time: 27 penalty: 0 agent_num: 39 done: False
______________________
id: 45 reward: -0.025510204081632654 service_time: 330 s_time: 30 penalty: 0 agent_num: 21 done: False
______________________
id: 51 reward: -0.004699248120300752 service_time: 366 s_time: 10 penalty: 0 agent_num: 38 done: False
______________________
id: 41 reward: -0.01369047619047619 service_time: 1058 s_time: 23 penalty: 0 agent_num: 30 done: False
______________________
id: 49 reward: -0.013996138996138996 service_time: 402 s_time: 29 penalty: 0 agent_num: 37 done: False
______________________
id: 43 reward: -0.025 service_time: 185 s_time: 49 penalty: 0 agent_num: 35 done: False
______________________
id: 44 reward: -0.016705069124423964 service_time: 472 s_time: 29 penalty: 0 agent_num: 31 done: False
______________________
id: 54 reward: -0.007227891156462585 service_time: 388 s_time: 17 penalty: 0 agent_num: 42 done: False
______________________
id: 52 reward: -0.00496031746031746 service_time: 435 s_time: 10 penalty: 0 agent_num: 36 done: False
______________________
id: 55 reward: -0.01461038961038961 service_time: 538 s_time: 18 penalty: 0 agent_num: 22 done: False
______________________
id: 53 reward: -0.008017492711370262 service_time: 543 s_time: 22 penalty: 0 agent_num: 49 done: False
______________________
Step:  1200
Pretraining Loss:  tensor(0.2041, device='cuda:0', grad_fn=<MeanBackward0>)
id: 40 reward: -0.01098901098901099 service_time: 293 s_time: 16 penalty: 0 agent_num: 26 done: False
______________________
id: 43 reward: -0.007142857142857143 service_time: 199 s_time: 14 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.01913265306122449 service_time: 1373 s_time: 15 penalty: 0 agent_num: 14 done: False
______________________
id: 51 reward: 0.0 service_time: 366 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 45 reward: -0.03316326530612245 service_time: 369 s_time: 39 penalty: 0 agent_num: 21 done: False
______________________
id: 50 reward: -0.01600985221674877 service_time: 343 s_time: 26 penalty: 0 agent_num: 29 done: False
______________________
id: 54 reward: -0.011054421768707483 service_time: 414 s_time: 26 penalty: 0 agent_num: 42 done: False
______________________
id: 42 reward: -0.012362637362637362 service_time: 204 s_time: 27 penalty: 0 agent_num: 39 done: False
______________________
id: 44 reward: 0.0 service_time: 472 s_time: 0 penalty: 0 agent_num: 31 done: False
______________________
id: 46 reward: -0.010281385281385282 service_time: 431 s_time: 19 penalty: 0 agent_num: 33 done: False
______________________
id: 41 reward: 0.0 service_time: 1058 s_time: 0 penalty: 0 agent_num: 30 done: False
______________________
id: 55 reward: -0.03409090909090909 service_time: 580 s_time: 42 penalty: 0 agent_num: 22 done: False
______________________
id: 52 reward: -0.02132936507936508 service_time: 478 s_time: 43 penalty: 0 agent_num: 36 done: False
______________________
id: 49 reward: -0.03426640926640927 service_time: 473 s_time: 71 penalty: 0 agent_num: 37 done: False
______________________
id: 47 reward: 20.0 service_time: 1147 s_time: 0 penalty: 0 agent_num: 20 done: True
______________________
id: 53 reward: 0.0 service_time: 543 s_time: 0 penalty: 0 agent_num: 49 done: False
______________________
Step:  1216
Pretraining Loss:  tensor(0.2356, device='cuda:0', grad_fn=<MeanBackward0>)
id: 47 reward: -0.011645962732919254 service_time: 15 s_time: 15 penalty: 0 agent_num: 23 done: False
______________________
id: 40 reward: -0.012362637362637362 service_time: 311 s_time: 18 penalty: 0 agent_num: 26 done: False
______________________
id: 50 reward: -0.023399014778325122 service_time: 381 s_time: 38 penalty: 0 agent_num: 29 done: False
______________________
id: 45 reward: -0.03826530612244898 service_time: 414 s_time: 45 penalty: 0 agent_num: 21 done: False
______________________
id: 49 reward: 0.011583011583011582 service_time: 449 s_time: -24 penalty: 0 agent_num: 37 done: False
______________________
id: 54 reward: -0.012755102040816327 service_time: 444 s_time: 30 penalty: 0 agent_num: 42 done: False
______________________
id: 51 reward: 0.0 service_time: 366 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 44 reward: -0.03110599078341014 service_time: 526 s_time: 54 penalty: 0 agent_num: 31 done: False
______________________
id: 42 reward: -0.01510989010989011 service_time: 237 s_time: 33 penalty: 0 agent_num: 39 done: False
______________________
id: 46 reward: -0.016233766233766232 service_time: 461 s_time: 30 penalty: 0 agent_num: 33 done: False
______________________
id: 43 reward: -0.00816326530612245 service_time: 215 s_time: 16 penalty: 0 agent_num: 35 done: False
______________________
id: 52 reward: -0.008928571428571428 service_time: 496 s_time: 18 penalty: 0 agent_num: 36 done: False
______________________
id: 48 reward: 19.982142857142858 service_time: 1387 s_time: 14 penalty: 0 agent_num: 14 done: True
______________________
id: 41 reward: -0.025 service_time: 1100 s_time: 42 penalty: 0 agent_num: 30 done: False
______________________
id: 55 reward: -0.0349025974025974 service_time: 623 s_time: 43 penalty: 0 agent_num: 22 done: False
______________________
id: 53 reward: -0.01967930029154519 service_time: 597 s_time: 54 penalty: 0 agent_num: 49 done: False
______________________
Step:  1232
Pretraining Loss:  tensor(0.2330, device='cuda:0', grad_fn=<MeanBackward0>)
id: 47 reward: -0.021739130434782608 service_time: 43 s_time: 28 penalty: 0 agent_num: 23 done: False
______________________
id: 40 reward: -0.01304945054945055 service_time: 330 s_time: 19 penalty: 0 agent_num: 26 done: False
______________________
id: 48 reward: -0.0049833887043189366 service_time: 12 s_time: 12 penalty: 0 agent_num: 43 done: False
______________________
id: 45 reward: 0.0 service_time: 414 s_time: 0 penalty: 0 agent_num: 21 done: False
______________________
id: 50 reward: -0.011699507389162561 service_time: 400 s_time: 19 penalty: 0 agent_num: 29 done: False
______________________
id: 43 reward: 0.0005102040816326531 service_time: 214 s_time: -1 penalty: 0 agent_num: 35 done: False
______________________
id: 44 reward: -0.009792626728110598 service_time: 543 s_time: 17 penalty: 0 agent_num: 31 done: False
______________________
id: 51 reward: -0.010808270676691729 service_time: 389 s_time: 23 penalty: 0 agent_num: 38 done: False
______________________
id: 49 reward: -0.012548262548262547 service_time: 475 s_time: 26 penalty: 0 agent_num: 37 done: False
______________________
id: 54 reward: 0.0 service_time: 444 s_time: 0 penalty: 0 agent_num: 42 done: False
______________________
id: 42 reward: 0.0 service_time: 237 s_time: 0 penalty: 0 agent_num: 39 done: False
______________________
id: 46 reward: 0.0010822510822510823 service_time: 459 s_time: -2 penalty: 0 agent_num: 33 done: False
______________________
id: 55 reward: -0.015422077922077922 service_time: 642 s_time: 19 penalty: 0 agent_num: 22 done: False
______________________
id: 52 reward: -0.01240079365079365 service_time: 521 s_time: 25 penalty: 0 agent_num: 36 done: False
______________________
id: 53 reward: 0.0 service_time: 597 s_time: 0 penalty: 0 agent_num: 49 done: False
______________________
id: 41 reward: 19.985714285714284 service_time: 1124 s_time: 24 penalty: 0 agent_num: 30 done: True
______________________
Step:  1248
Pretraining Loss:  tensor(0.1818, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.04404761904761905 service_time: 37 s_time: 37 penalty: 0 agent_num: 15 done: False
______________________
id: 47 reward: -0.015527950310559006 service_time: 63 s_time: 20 penalty: 0 agent_num: 23 done: False
______________________
id: 45 reward: -0.055272108843537414 service_time: 479 s_time: 65 penalty: 0 agent_num: 21 done: False
______________________
id: 48 reward: 0.0 service_time: 12 s_time: 0 penalty: 0 agent_num: 43 done: False
______________________
id: 40 reward: -0.008928571428571428 service_time: 343 s_time: 13 penalty: 0 agent_num: 26 done: False
______________________
id: 50 reward: -0.021551724137931036 service_time: 435 s_time: 35 penalty: 0 agent_num: 29 done: False
______________________
id: 44 reward: 0.0 service_time: 543 s_time: 0 penalty: 0 agent_num: 31 done: False
______________________
id: 43 reward: -0.01479591836734694 service_time: 243 s_time: 29 penalty: 0 agent_num: 35 done: False
______________________
id: 42 reward: -0.003663003663003663 service_time: 245 s_time: 8 penalty: 0 agent_num: 39 done: False
______________________
id: 51 reward: -0.0037593984962406013 service_time: 397 s_time: 8 penalty: 0 agent_num: 38 done: False
______________________
id: 54 reward: -0.00935374149659864 service_time: 466 s_time: 22 penalty: 0 agent_num: 42 done: False
______________________
id: 46 reward: -0.02867965367965368 service_time: 512 s_time: 53 penalty: 0 agent_num: 33 done: False
______________________
id: 55 reward: -0.04383116883116883 service_time: 696 s_time: 54 penalty: 0 agent_num: 22 done: False
______________________
id: 52 reward: -0.017361111111111112 service_time: 556 s_time: 35 penalty: 0 agent_num: 36 done: False
______________________
id: 49 reward: -0.02027027027027027 service_time: 517 s_time: 42 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: -0.018950437317784258 service_time: 649 s_time: 52 penalty: 0 agent_num: 49 done: False
______________________
Step:  1264
Pretraining Loss:  tensor(0.1894, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: 0.0 service_time: 37 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 47 reward: -0.007763975155279503 service_time: 73 s_time: 10 penalty: 0 agent_num: 23 done: False
______________________
id: 48 reward: -0.009551495016611296 service_time: 35 s_time: 23 penalty: 0 agent_num: 43 done: False
______________________
id: 45 reward: -0.02891156462585034 service_time: 513 s_time: 34 penalty: 0 agent_num: 21 done: False
______________________
id: 40 reward: -0.020604395604395604 service_time: 373 s_time: 30 penalty: 0 agent_num: 26 done: False
______________________
id: 51 reward: -0.010338345864661654 service_time: 419 s_time: 22 penalty: 0 agent_num: 38 done: False
______________________
id: 42 reward: -0.022893772893772892 service_time: 295 s_time: 50 penalty: 0 agent_num: 39 done: False
______________________
id: 44 reward: -0.036290322580645164 service_time: 606 s_time: 63 penalty: 0 agent_num: 31 done: False
______________________
id: 50 reward: -0.014778325123152709 service_time: 459 s_time: 24 penalty: 0 agent_num: 29 done: False
______________________
id: 46 reward: -0.040584415584415584 service_time: 587 s_time: 75 penalty: 0 agent_num: 33 done: False
______________________
id: 54 reward: 0.0008503401360544217 service_time: 464 s_time: -2 penalty: 0 agent_num: 42 done: False
______________________
id: 52 reward: -0.012896825396825396 service_time: 582 s_time: 26 penalty: 0 agent_num: 36 done: False
______________________
id: 49 reward: -0.012548262548262547 service_time: 543 s_time: 26 penalty: 0 agent_num: 37 done: False
______________________
id: 43 reward: -0.026530612244897958 service_time: 295 s_time: 52 penalty: 0 agent_num: 35 done: False
______________________
id: 55 reward: -0.0349025974025974 service_time: 739 s_time: 43 penalty: 0 agent_num: 22 done: False
______________________
id: 53 reward: -0.0036443148688046646 service_time: 659 s_time: 10 penalty: 0 agent_num: 49 done: False
______________________
Step:  1280
Pretraining Loss:  tensor(0.2008, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.016666666666666666 service_time: 51 s_time: 14 penalty: 0 agent_num: 15 done: False
______________________
id: 47 reward: -0.023291925465838508 service_time: 103 s_time: 30 penalty: 0 agent_num: 23 done: False
______________________
id: 40 reward: 0.0 service_time: 373 s_time: 0 penalty: 0 agent_num: 26 done: False
______________________
id: 45 reward: -0.02891156462585034 service_time: 547 s_time: 34 penalty: 0 agent_num: 21 done: False
______________________
id: 50 reward: -0.017241379310344827 service_time: 487 s_time: 28 penalty: 0 agent_num: 29 done: False
______________________
id: 48 reward: -0.0170265780730897 service_time: 76 s_time: 41 penalty: 0 agent_num: 43 done: False
______________________
id: 51 reward: 0.0 service_time: 419 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 44 reward: -0.013824884792626729 service_time: 630 s_time: 24 penalty: 0 agent_num: 31 done: False
______________________
id: 54 reward: 0.0 service_time: 464 s_time: 0 penalty: 0 agent_num: 42 done: False
______________________
id: 42 reward: -0.010073260073260074 service_time: 317 s_time: 22 penalty: 0 agent_num: 39 done: False
______________________
id: 52 reward: -0.000496031746031746 service_time: 583 s_time: 1 penalty: 0 agent_num: 36 done: False
______________________
id: 55 reward: -0.003246753246753247 service_time: 743 s_time: 4 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: -0.007722007722007722 service_time: 559 s_time: 16 penalty: 0 agent_num: 37 done: False
______________________
id: 43 reward: -0.012244897959183673 service_time: 319 s_time: 24 penalty: 0 agent_num: 35 done: False
______________________
id: 46 reward: -0.016774891774891776 service_time: 618 s_time: 31 penalty: 0 agent_num: 33 done: False
______________________
id: 53 reward: 0.0 service_time: 659 s_time: 0 penalty: 0 agent_num: 49 done: False
______________________
Step:  1296
Pretraining Loss:  tensor(0.1976, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.017857142857142856 service_time: 66 s_time: 15 penalty: 0 agent_num: 15 done: False
______________________
id: 47 reward: -0.010869565217391304 service_time: 117 s_time: 14 penalty: 0 agent_num: 23 done: False
______________________
id: 48 reward: -0.011627906976744186 service_time: 104 s_time: 28 penalty: 0 agent_num: 43 done: False
______________________
id: 50 reward: -0.01539408866995074 service_time: 512 s_time: 25 penalty: 0 agent_num: 29 done: False
______________________
id: 44 reward: -0.017857142857142856 service_time: 661 s_time: 31 penalty: 0 agent_num: 31 done: False
______________________
id: 51 reward: -0.008928571428571428 service_time: 438 s_time: 19 penalty: 0 agent_num: 38 done: False
______________________
id: 40 reward: -0.05563186813186813 service_time: 454 s_time: 81 penalty: 0 agent_num: 26 done: False
______________________
id: 55 reward: 0.010551948051948052 service_time: 730 s_time: -13 penalty: 0 agent_num: 22 done: False
______________________
id: 52 reward: -0.023313492063492064 service_time: 630 s_time: 47 penalty: 0 agent_num: 36 done: False
______________________
id: 54 reward: -0.010629251700680272 service_time: 489 s_time: 25 penalty: 0 agent_num: 42 done: False
______________________
id: 46 reward: -0.0091991341991342 service_time: 635 s_time: 17 penalty: 0 agent_num: 33 done: False
______________________
id: 42 reward: -0.010073260073260074 service_time: 339 s_time: 22 penalty: 0 agent_num: 39 done: False
______________________
id: 45 reward: -0.02976190476190476 service_time: 582 s_time: 35 penalty: 0 agent_num: 21 done: False
______________________
id: 49 reward: -0.016409266409266408 service_time: 593 s_time: 34 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: -0.00619533527696793 service_time: 676 s_time: 17 penalty: 0 agent_num: 49 done: False
______________________
id: 43 reward: -0.02193877551020408 service_time: 362 s_time: 43 penalty: 0 agent_num: 35 done: False
______________________
Step:  1312
Pretraining Loss:  tensor(0.2313, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.03571428571428571 service_time: 96 s_time: 30 penalty: 0 agent_num: 15 done: False
______________________
id: 47 reward: -0.02562111801242236 service_time: 150 s_time: 33 penalty: 0 agent_num: 23 done: False
______________________
id: 50 reward: 0.0012315270935960591 service_time: 510 s_time: -2 penalty: 0 agent_num: 29 done: False
______________________
id: 51 reward: -0.005169172932330827 service_time: 449 s_time: 11 penalty: 0 agent_num: 38 done: False
______________________
id: 48 reward: 0.0 service_time: 104 s_time: 0 penalty: 0 agent_num: 43 done: False
______________________
id: 42 reward: -0.0009157509157509158 service_time: 341 s_time: 2 penalty: 0 agent_num: 39 done: False
______________________
id: 52 reward: -0.018353174603174604 service_time: 667 s_time: 37 penalty: 0 agent_num: 36 done: False
______________________
id: 44 reward: -0.01728110599078341 service_time: 691 s_time: 30 penalty: 0 agent_num: 31 done: False
______________________
id: 54 reward: 0.0 service_time: 489 s_time: 0 penalty: 0 agent_num: 42 done: False
______________________
id: 49 reward: -0.019787644787644786 service_time: 634 s_time: 41 penalty: 0 agent_num: 37 done: False
______________________
id: 40 reward: -0.010302197802197802 service_time: 469 s_time: 15 penalty: 0 agent_num: 26 done: False
______________________
id: 46 reward: 0.004329004329004329 service_time: 627 s_time: -8 penalty: 0 agent_num: 33 done: False
______________________
id: 43 reward: -0.006122448979591836 service_time: 374 s_time: 12 penalty: 0 agent_num: 35 done: False
______________________
id: 53 reward: -0.014941690962099125 service_time: 717 s_time: 41 penalty: 0 agent_num: 49 done: False
______________________
id: 55 reward: -0.09902597402597403 service_time: 852 s_time: 122 penalty: 0 agent_num: 22 done: False
______________________
id: 45 reward: -0.025510204081632654 service_time: 612 s_time: 30 penalty: 0 agent_num: 21 done: False
______________________
Step:  1328
Pretraining Loss:  tensor(0.2436, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: 0.0 service_time: 96 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 45 reward: -0.017857142857142856 service_time: 633 s_time: 21 penalty: 0 agent_num: 21 done: False
______________________
id: 40 reward: -0.021291208791208792 service_time: 500 s_time: 31 penalty: 0 agent_num: 26 done: False
______________________
id: 51 reward: -0.007048872180451127 service_time: 464 s_time: 15 penalty: 0 agent_num: 38 done: False
______________________
id: 47 reward: -0.02251552795031056 service_time: 179 s_time: 29 penalty: 0 agent_num: 23 done: False
______________________
id: 48 reward: -0.014950166112956811 service_time: 140 s_time: 36 penalty: 0 agent_num: 43 done: False
______________________
id: 44 reward: -0.020161290322580645 service_time: 726 s_time: 35 penalty: 0 agent_num: 31 done: False
______________________
id: 42 reward: -0.008241758241758242 service_time: 359 s_time: 18 penalty: 0 agent_num: 39 done: False
______________________
id: 46 reward: -0.012445887445887446 service_time: 650 s_time: 23 penalty: 0 agent_num: 33 done: False
______________________
id: 52 reward: -0.005952380952380952 service_time: 679 s_time: 12 penalty: 0 agent_num: 36 done: False
______________________
id: 50 reward: -0.042487684729064036 service_time: 579 s_time: 69 penalty: 0 agent_num: 29 done: False
______________________
id: 53 reward: 0.0 service_time: 717 s_time: 0 penalty: 0 agent_num: 49 done: False
______________________
id: 54 reward: -0.015731292517006803 service_time: 526 s_time: 37 penalty: 0 agent_num: 42 done: False
______________________
id: 55 reward: 0.006493506493506494 service_time: 844 s_time: -8 penalty: 0 agent_num: 22 done: False
______________________
id: 43 reward: -0.018367346938775512 service_time: 410 s_time: 36 penalty: 0 agent_num: 35 done: False
______________________
id: 49 reward: -0.016891891891891893 service_time: 669 s_time: 35 penalty: 0 agent_num: 37 done: False
______________________
Step:  1344
Pretraining Loss:  tensor(0.2543, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.0380952380952381 service_time: 128 s_time: 32 penalty: 0 agent_num: 15 done: False
______________________
id: 47 reward: -0.017080745341614908 service_time: 201 s_time: 22 penalty: 0 agent_num: 23 done: False
______________________
id: 51 reward: 0.0 service_time: 464 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 42 reward: -0.009615384615384616 service_time: 380 s_time: 21 penalty: 0 agent_num: 39 done: False
______________________
id: 46 reward: -0.022186147186147188 service_time: 691 s_time: 41 penalty: 0 agent_num: 33 done: False
______________________
id: 52 reward: 0.001984126984126984 service_time: 675 s_time: -4 penalty: 0 agent_num: 36 done: False
______________________
id: 48 reward: -0.010382059800664452 service_time: 165 s_time: 25 penalty: 0 agent_num: 43 done: False
______________________
id: 54 reward: 0.0 service_time: 526 s_time: 0 penalty: 0 agent_num: 42 done: False
______________________
id: 40 reward: -0.01098901098901099 service_time: 516 s_time: 16 penalty: 0 agent_num: 26 done: False
______________________
id: 44 reward: -0.013824884792626729 service_time: 750 s_time: 24 penalty: 0 agent_num: 31 done: False
______________________
id: 55 reward: -0.05113636363636364 service_time: 907 s_time: 63 penalty: 0 agent_num: 22 done: False
______________________
id: 50 reward: -0.017241379310344827 service_time: 607 s_time: 28 penalty: 0 agent_num: 29 done: False
______________________
id: 43 reward: -0.008673469387755102 service_time: 427 s_time: 17 penalty: 0 agent_num: 35 done: False
______________________
id: 53 reward: -0.006559766763848397 service_time: 735 s_time: 18 penalty: 0 agent_num: 49 done: False
______________________
id: 49 reward: -0.0019305019305019305 service_time: 673 s_time: 4 penalty: 0 agent_num: 37 done: False
______________________
id: 45 reward: -0.017006802721088437 service_time: 653 s_time: 20 penalty: 0 agent_num: 21 done: False
______________________
Step:  1360
Pretraining Loss:  tensor(0.2787, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.015476190476190477 service_time: 141 s_time: 13 penalty: 0 agent_num: 15 done: False
______________________
id: 40 reward: -0.019917582417582416 service_time: 545 s_time: 29 penalty: 0 agent_num: 26 done: False
______________________
id: 45 reward: -0.027210884353741496 service_time: 685 s_time: 32 penalty: 0 agent_num: 21 done: False
______________________
id: 47 reward: -0.024844720496894408 service_time: 233 s_time: 32 penalty: 0 agent_num: 23 done: False
______________________
id: 51 reward: 0.0 service_time: 464 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 42 reward: -0.006868131868131868 service_time: 395 s_time: 15 penalty: 0 agent_num: 39 done: False
______________________
id: 44 reward: -0.02131336405529954 service_time: 787 s_time: 37 penalty: 0 agent_num: 31 done: False
______________________
id: 52 reward: -0.010912698412698412 service_time: 697 s_time: 22 penalty: 0 agent_num: 36 done: False
______________________
id: 50 reward: -0.024630541871921183 service_time: 647 s_time: 40 penalty: 0 agent_num: 29 done: False
______________________
id: 46 reward: -0.011363636363636364 service_time: 712 s_time: 21 penalty: 0 agent_num: 33 done: False
______________________
id: 48 reward: 0.0 service_time: 165 s_time: 0 penalty: 0 agent_num: 43 done: False
______________________
id: 54 reward: -0.00510204081632653 service_time: 538 s_time: 12 penalty: 0 agent_num: 42 done: False
______________________
id: 43 reward: -0.010714285714285714 service_time: 448 s_time: 21 penalty: 0 agent_num: 35 done: False
______________________
id: 55 reward: 0.024350649350649352 service_time: 877 s_time: -30 penalty: 0 agent_num: 22 done: False
______________________
id: 53 reward: -0.018221574344023325 service_time: 785 s_time: 50 penalty: 0 agent_num: 49 done: False
______________________
id: 49 reward: -0.00916988416988417 service_time: 692 s_time: 19 penalty: 0 agent_num: 37 done: False
______________________
Step:  1376
Pretraining Loss:  tensor(0.2451, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.014285714285714285 service_time: 153 s_time: 12 penalty: 0 agent_num: 15 done: False
______________________
id: 40 reward: -0.02815934065934066 service_time: 586 s_time: 41 penalty: 0 agent_num: 26 done: False
______________________
id: 47 reward: 0.0038819875776397515 service_time: 228 s_time: -5 penalty: 0 agent_num: 23 done: False
______________________
id: 51 reward: -0.006109022556390977 service_time: 477 s_time: 13 penalty: 0 agent_num: 38 done: False
______________________
id: 42 reward: 0.0 service_time: 395 s_time: 0 penalty: 0 agent_num: 39 done: False
______________________
id: 52 reward: -0.009424603174603174 service_time: 716 s_time: 19 penalty: 0 agent_num: 36 done: False
______________________
id: 46 reward: -0.006493506493506494 service_time: 724 s_time: 12 penalty: 0 agent_num: 33 done: False
______________________
id: 54 reward: -0.008078231292517007 service_time: 557 s_time: 19 penalty: 0 agent_num: 42 done: False
______________________
id: 44 reward: 0.0 service_time: 787 s_time: 0 penalty: 0 agent_num: 31 done: False
______________________
id: 48 reward: -0.012043189368770765 service_time: 194 s_time: 29 penalty: 0 agent_num: 43 done: False
______________________
id: 49 reward: -0.015444015444015444 service_time: 724 s_time: 32 penalty: 0 agent_num: 37 done: False
______________________
id: 43 reward: 0.0 service_time: 448 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 53 reward: -0.008746355685131196 service_time: 809 s_time: 24 penalty: 0 agent_num: 49 done: False
______________________
id: 55 reward: 0.030844155844155844 service_time: 839 s_time: -38 penalty: 0 agent_num: 22 done: False
______________________
id: 50 reward: -0.017241379310344827 service_time: 675 s_time: 28 penalty: 0 agent_num: 29 done: False
______________________
id: 45 reward: -0.04251700680272109 service_time: 735 s_time: 50 penalty: 0 agent_num: 21 done: False
______________________
Step:  1392
Pretraining Loss:  tensor(0.2708, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.01904761904761905 service_time: 169 s_time: 16 penalty: 0 agent_num: 15 done: False
______________________
id: 51 reward: -0.010808270676691729 service_time: 500 s_time: 23 penalty: 0 agent_num: 38 done: False
______________________
id: 47 reward: -0.013198757763975156 service_time: 245 s_time: 17 penalty: 0 agent_num: 23 done: False
______________________
id: 40 reward: -0.019230769230769232 service_time: 614 s_time: 28 penalty: 0 agent_num: 26 done: False
______________________
id: 46 reward: 0.0 service_time: 724 s_time: 0 penalty: 0 agent_num: 33 done: False
______________________
id: 42 reward: -0.007326007326007326 service_time: 411 s_time: 16 penalty: 0 agent_num: 39 done: False
______________________
id: 45 reward: 0.031462585034013606 service_time: 698 s_time: -37 penalty: 0 agent_num: 21 done: False
______________________
id: 44 reward: -0.03744239631336405 service_time: 852 s_time: 65 penalty: 0 agent_num: 31 done: False
______________________
id: 50 reward: -0.01539408866995074 service_time: 700 s_time: 25 penalty: 0 agent_num: 29 done: False
______________________
id: 52 reward: -0.01984126984126984 service_time: 756 s_time: 40 penalty: 0 agent_num: 36 done: False
______________________
id: 43 reward: -0.039285714285714285 service_time: 525 s_time: 77 penalty: 0 agent_num: 35 done: False
______________________
id: 53 reward: -0.008746355685131196 service_time: 833 s_time: 24 penalty: 0 agent_num: 49 done: False
______________________
id: 49 reward: -0.005308880308880309 service_time: 735 s_time: 11 penalty: 0 agent_num: 37 done: False
______________________
id: 54 reward: 0.0 service_time: 557 s_time: 0 penalty: 0 agent_num: 42 done: False
______________________
id: 55 reward: 0.0 service_time: 839 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 48 reward: -0.03945182724252492 service_time: 289 s_time: 95 penalty: 0 agent_num: 43 done: False
______________________
Step:  1408
Pretraining Loss:  tensor(0.2826, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.03214285714285714 service_time: 196 s_time: 27 penalty: 0 agent_num: 15 done: False
______________________
id: 47 reward: 0.0 service_time: 245 s_time: 0 penalty: 0 agent_num: 23 done: False
______________________
id: 51 reward: 0.0 service_time: 500 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 42 reward: -0.018315018315018316 service_time: 451 s_time: 40 penalty: 0 agent_num: 39 done: False
______________________
id: 45 reward: 0.03826530612244898 service_time: 653 s_time: -45 penalty: 0 agent_num: 21 done: False
______________________
id: 55 reward: -0.021915584415584416 service_time: 866 s_time: 27 penalty: 0 agent_num: 22 done: False
______________________
id: 40 reward: -0.026785714285714284 service_time: 653 s_time: 39 penalty: 0 agent_num: 26 done: False
______________________
id: 46 reward: -0.032467532467532464 service_time: 784 s_time: 60 penalty: 0 agent_num: 33 done: False
______________________
id: 44 reward: 0.001152073732718894 service_time: 850 s_time: -2 penalty: 0 agent_num: 31 done: False
______________________
id: 52 reward: -0.01984126984126984 service_time: 796 s_time: 40 penalty: 0 agent_num: 36 done: False
______________________
id: 50 reward: 0.004310344827586207 service_time: 693 s_time: -7 penalty: 0 agent_num: 29 done: False
______________________
id: 53 reward: 0.0014577259475218659 service_time: 829 s_time: -4 penalty: 0 agent_num: 49 done: False
______________________
id: 49 reward: -0.0111003861003861 service_time: 758 s_time: 23 penalty: 0 agent_num: 37 done: False
______________________
id: 54 reward: -0.002551020408163265 service_time: 563 s_time: 6 penalty: 0 agent_num: 42 done: False
______________________
id: 43 reward: -0.02295918367346939 service_time: 570 s_time: 45 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: 0.0070598006644518275 service_time: 272 s_time: -17 penalty: 0 agent_num: 43 done: False
______________________
Step:  1424
Pretraining Loss:  tensor(0.2856, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: 0.0 service_time: 196 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 47 reward: -0.036490683229813664 service_time: 292 s_time: 47 penalty: 0 agent_num: 23 done: False
______________________
id: 51 reward: -0.008928571428571428 service_time: 519 s_time: 19 penalty: 0 agent_num: 38 done: False
______________________
id: 45 reward: -0.01870748299319728 service_time: 675 s_time: 22 penalty: 0 agent_num: 21 done: False
______________________
id: 55 reward: 0.008928571428571428 service_time: 855 s_time: -11 penalty: 0 agent_num: 22 done: False
______________________
id: 54 reward: -0.005952380952380952 service_time: 577 s_time: 14 penalty: 0 agent_num: 42 done: False
______________________
id: 46 reward: -0.015151515151515152 service_time: 812 s_time: 28 penalty: 0 agent_num: 33 done: False
______________________
id: 44 reward: -0.03917050691244239 service_time: 918 s_time: 68 penalty: 0 agent_num: 31 done: False
______________________
id: 48 reward: -0.0020764119601328905 service_time: 277 s_time: 5 penalty: 0 agent_num: 43 done: False
______________________
id: 52 reward: -0.006448412698412698 service_time: 809 s_time: 13 penalty: 0 agent_num: 36 done: False
______________________
id: 53 reward: -0.01567055393586006 service_time: 872 s_time: 43 penalty: 0 agent_num: 49 done: False
______________________
id: 50 reward: -0.04864532019704434 service_time: 772 s_time: 79 penalty: 0 agent_num: 29 done: False
______________________
id: 42 reward: -0.035256410256410256 service_time: 528 s_time: 77 penalty: 0 agent_num: 39 done: False
______________________
id: 49 reward: -0.007722007722007722 service_time: 774 s_time: 16 penalty: 0 agent_num: 37 done: False
______________________
id: 40 reward: -0.0027472527472527475 service_time: 657 s_time: 4 penalty: 0 agent_num: 26 done: False
______________________
id: 43 reward: -0.01020408163265306 service_time: 590 s_time: 20 penalty: 0 agent_num: 35 done: False
______________________
Step:  1440
Pretraining Loss:  tensor(0.2727, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.016666666666666666 service_time: 210 s_time: 14 penalty: 0 agent_num: 15 done: False
______________________
id: 47 reward: -0.02096273291925466 service_time: 319 s_time: 27 penalty: 0 agent_num: 23 done: False
______________________
id: 40 reward: -0.03708791208791209 service_time: 711 s_time: 54 penalty: 0 agent_num: 26 done: False
______________________
id: 55 reward: 0.004058441558441558 service_time: 850 s_time: -5 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: 0.0009398496240601503 service_time: 517 s_time: -2 penalty: 0 agent_num: 38 done: False
______________________
id: 54 reward: 0.0 service_time: 577 s_time: 0 penalty: 0 agent_num: 42 done: False
______________________
id: 46 reward: -0.016774891774891776 service_time: 843 s_time: 31 penalty: 0 agent_num: 33 done: False
______________________
id: 45 reward: -0.0391156462585034 service_time: 721 s_time: 46 penalty: 0 agent_num: 21 done: False
______________________
id: 48 reward: 0.0 service_time: 277 s_time: 0 penalty: 0 agent_num: 43 done: False
______________________
id: 50 reward: 0.004310344827586207 service_time: 765 s_time: -7 penalty: 0 agent_num: 29 done: False
______________________
id: 53 reward: -0.009839650145772596 service_time: 899 s_time: 27 penalty: 0 agent_num: 49 done: False
______________________
id: 49 reward: -0.0111003861003861 service_time: 797 s_time: 23 penalty: 0 agent_num: 37 done: False
______________________
id: 52 reward: -0.007936507936507936 service_time: 825 s_time: 16 penalty: 0 agent_num: 36 done: False
______________________
id: 42 reward: 0.0004578754578754579 service_time: 527 s_time: -1 penalty: 0 agent_num: 39 done: False
______________________
id: 44 reward: -0.012672811059907835 service_time: 940 s_time: 22 penalty: 0 agent_num: 31 done: False
______________________
id: 43 reward: -0.012755102040816327 service_time: 615 s_time: 25 penalty: 0 agent_num: 35 done: False
______________________
Step:  1456
Pretraining Loss:  tensor(0.2495, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.02142857142857143 service_time: 228 s_time: 18 penalty: 0 agent_num: 15 done: False
______________________
id: 51 reward: 0.0 service_time: 517 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 55 reward: 0.0 service_time: 850 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: -0.03804347826086957 service_time: 368 s_time: 49 penalty: 0 agent_num: 23 done: False
______________________
id: 48 reward: -0.024916943521594685 service_time: 337 s_time: 60 penalty: 0 agent_num: 43 done: False
______________________
id: 50 reward: -0.01539408866995074 service_time: 790 s_time: 25 penalty: 0 agent_num: 29 done: False
______________________
id: 46 reward: 0.0 service_time: 843 s_time: 0 penalty: 0 agent_num: 33 done: False
______________________
id: 44 reward: 0.001152073732718894 service_time: 938 s_time: -2 penalty: 0 agent_num: 31 done: False
______________________
id: 54 reward: -0.003401360544217687 service_time: 585 s_time: 8 penalty: 0 agent_num: 42 done: False
______________________
id: 53 reward: -0.007288629737609329 service_time: 919 s_time: 20 penalty: 0 agent_num: 49 done: False
______________________
id: 42 reward: -0.025183150183150184 service_time: 582 s_time: 55 penalty: 0 agent_num: 39 done: False
______________________
id: 49 reward: -0.015926640926640926 service_time: 830 s_time: 33 penalty: 0 agent_num: 37 done: False
______________________
id: 40 reward: -0.0006868131868131869 service_time: 712 s_time: 1 penalty: 0 agent_num: 26 done: False
______________________
id: 43 reward: 0.0010204081632653062 service_time: 613 s_time: -2 penalty: 0 agent_num: 35 done: False
______________________
id: 45 reward: -0.0391156462585034 service_time: 767 s_time: 46 penalty: 0 agent_num: 21 done: False
______________________
id: 52 reward: -0.025793650793650792 service_time: 877 s_time: 52 penalty: 0 agent_num: 36 done: False
______________________
Step:  1472
Pretraining Loss:  tensor(0.2835, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: 0.0 service_time: 228 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 51 reward: -0.007048872180451127 service_time: 532 s_time: 15 penalty: 0 agent_num: 38 done: False
______________________
id: 47 reward: -0.029503105590062112 service_time: 406 s_time: 38 penalty: 0 agent_num: 23 done: False
______________________
id: 55 reward: 0.0 service_time: 850 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 40 reward: -0.030906593406593408 service_time: 757 s_time: 45 penalty: 0 agent_num: 26 done: False
______________________
id: 54 reward: 0.0 service_time: 585 s_time: 0 penalty: 0 agent_num: 42 done: False
______________________
id: 45 reward: 0.005952380952380952 service_time: 760 s_time: -7 penalty: 0 agent_num: 21 done: False
______________________
id: 49 reward: 0.00048262548262548264 service_time: 829 s_time: -1 penalty: 0 agent_num: 37 done: False
______________________
id: 46 reward: -0.031385281385281384 service_time: 901 s_time: 58 penalty: 0 agent_num: 33 done: False
______________________
id: 44 reward: -0.02707373271889401 service_time: 985 s_time: 47 penalty: 0 agent_num: 31 done: False
______________________
id: 42 reward: -0.005036630036630037 service_time: 593 s_time: 11 penalty: 0 agent_num: 39 done: False
______________________
id: 50 reward: -0.04864532019704434 service_time: 869 s_time: 79 penalty: 0 agent_num: 29 done: False
______________________
id: 43 reward: -0.029081632653061223 service_time: 670 s_time: 57 penalty: 0 agent_num: 35 done: False
______________________
id: 53 reward: -0.007288629737609329 service_time: 939 s_time: 20 penalty: 0 agent_num: 49 done: False
______________________
id: 48 reward: -0.025332225913621262 service_time: 398 s_time: 61 penalty: 0 agent_num: 43 done: False
______________________
id: 52 reward: -0.0248015873015873 service_time: 927 s_time: 50 penalty: 0 agent_num: 36 done: False
______________________
Step:  1488
Pretraining Loss:  tensor(0.2749, device='cuda:0', grad_fn=<MeanBackward0>)
id: 47 reward: -0.017080745341614908 service_time: 428 s_time: 22 penalty: 0 agent_num: 23 done: False
______________________
id: 41 reward: -0.02857142857142857 service_time: 252 s_time: 24 penalty: 0 agent_num: 15 done: False
______________________
id: 51 reward: -0.01456766917293233 service_time: 563 s_time: 31 penalty: 0 agent_num: 38 done: False
______________________
id: 50 reward: -0.01600985221674877 service_time: 895 s_time: 26 penalty: 0 agent_num: 29 done: False
______________________
id: 54 reward: 0.0 service_time: 585 s_time: 0 penalty: 0 agent_num: 42 done: False
______________________
id: 55 reward: -0.03165584415584415 service_time: 889 s_time: 39 penalty: 0 agent_num: 22 done: False
______________________
id: 44 reward: -0.04723502304147465 service_time: 1067 s_time: 82 penalty: 0 agent_num: 31 done: False
______________________
id: 48 reward: 0.005398671096345515 service_time: 385 s_time: -13 penalty: 0 agent_num: 43 done: False
______________________
id: 46 reward: -0.01461038961038961 service_time: 928 s_time: 27 penalty: 0 agent_num: 33 done: False
______________________
id: 45 reward: 0.0 service_time: 760 s_time: 0 penalty: 0 agent_num: 21 done: False
______________________
id: 49 reward: -0.024613899613899613 service_time: 880 s_time: 51 penalty: 0 agent_num: 37 done: False
______________________
id: 43 reward: -0.010714285714285714 service_time: 691 s_time: 21 penalty: 0 agent_num: 35 done: False
______________________
id: 40 reward: -0.008928571428571428 service_time: 770 s_time: 13 penalty: 0 agent_num: 26 done: False
______________________
id: 53 reward: -0.008381924198250729 service_time: 962 s_time: 23 penalty: 0 agent_num: 49 done: False
______________________
id: 42 reward: -0.009615384615384616 service_time: 614 s_time: 21 penalty: 0 agent_num: 39 done: False
______________________
id: 52 reward: 0.00248015873015873 service_time: 922 s_time: -5 penalty: 0 agent_num: 36 done: False
______________________
Step:  1504
Pretraining Loss:  tensor(0.2605, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.041666666666666664 service_time: 287 s_time: 35 penalty: 0 agent_num: 15 done: False
______________________
id: 55 reward: 0.0008116883116883117 service_time: 888 s_time: -1 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: 0.0 service_time: 563 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 47 reward: -0.02406832298136646 service_time: 459 s_time: 31 penalty: 0 agent_num: 23 done: False
______________________
id: 40 reward: -0.012362637362637362 service_time: 788 s_time: 18 penalty: 0 agent_num: 26 done: False
______________________
id: 49 reward: 0.0014478764478764478 service_time: 877 s_time: -3 penalty: 0 agent_num: 37 done: False
______________________
id: 48 reward: -0.01744186046511628 service_time: 427 s_time: 42 penalty: 0 agent_num: 43 done: False
______________________
id: 46 reward: 0.0 service_time: 928 s_time: 0 penalty: 0 agent_num: 33 done: False
______________________
id: 54 reward: -0.021258503401360544 service_time: 635 s_time: 50 penalty: 0 agent_num: 42 done: False
______________________
id: 44 reward: -0.009792626728110598 service_time: 1084 s_time: 17 penalty: 0 agent_num: 31 done: False
______________________
id: 42 reward: -0.006868131868131868 service_time: 629 s_time: 15 penalty: 0 agent_num: 39 done: False
______________________
id: 53 reward: -0.008746355685131196 service_time: 986 s_time: 24 penalty: 0 agent_num: 49 done: False
______________________
id: 45 reward: 0.027210884353741496 service_time: 728 s_time: -32 penalty: 0 agent_num: 21 done: False
______________________
id: 50 reward: -0.0166256157635468 service_time: 922 s_time: 27 penalty: 0 agent_num: 29 done: False
______________________
id: 43 reward: -0.020918367346938777 service_time: 732 s_time: 41 penalty: 0 agent_num: 35 done: False
______________________
id: 52 reward: -0.01488095238095238 service_time: 952 s_time: 30 penalty: 0 agent_num: 36 done: False
______________________
Step:  1520
Pretraining Loss:  tensor(0.2822, device='cuda:0', grad_fn=<MeanBackward0>)
id: 47 reward: -0.018633540372670808 service_time: 483 s_time: 24 penalty: 0 agent_num: 23 done: False
______________________
id: 41 reward: -0.02023809523809524 service_time: 304 s_time: 17 penalty: 0 agent_num: 15 done: False
______________________
id: 51 reward: -0.008458646616541353 service_time: 581 s_time: 18 penalty: 0 agent_num: 38 done: False
______________________
id: 55 reward: -0.024350649350649352 service_time: 918 s_time: 30 penalty: 0 agent_num: 22 done: False
______________________
id: 40 reward: 0.003434065934065934 service_time: 783 s_time: -5 penalty: 0 agent_num: 26 done: False
______________________
id: 44 reward: -0.018433179723502304 service_time: 1116 s_time: 32 penalty: 0 agent_num: 31 done: False
______________________
id: 50 reward: 0.007389162561576354 service_time: 910 s_time: -12 penalty: 0 agent_num: 29 done: False
______________________
id: 49 reward: -0.010135135135135136 service_time: 898 s_time: 21 penalty: 0 agent_num: 37 done: False
______________________
id: 42 reward: -0.007326007326007326 service_time: 645 s_time: 16 penalty: 0 agent_num: 39 done: False
______________________
id: 46 reward: -0.01893939393939394 service_time: 963 s_time: 35 penalty: 0 agent_num: 33 done: False
______________________
id: 53 reward: -0.008017492711370262 service_time: 1008 s_time: 22 penalty: 0 agent_num: 49 done: False
______________________
id: 45 reward: -0.09098639455782313 service_time: 835 s_time: 107 penalty: 0 agent_num: 21 done: False
______________________
id: 48 reward: -0.006644518272425249 service_time: 443 s_time: 16 penalty: 0 agent_num: 43 done: False
______________________
id: 54 reward: 0.00042517006802721087 service_time: 634 s_time: -1 penalty: 0 agent_num: 42 done: False
______________________
id: 43 reward: -0.011224489795918367 service_time: 754 s_time: 22 penalty: 0 agent_num: 35 done: False
______________________
id: 52 reward: -0.04811507936507937 service_time: 1049 s_time: 97 penalty: 0 agent_num: 36 done: False
______________________
Step:  1536
Pretraining Loss:  tensor(0.2964, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.014285714285714285 service_time: 316 s_time: 12 penalty: 0 agent_num: 15 done: False
______________________
id: 40 reward: -0.04120879120879121 service_time: 843 s_time: 60 penalty: 0 agent_num: 26 done: False
______________________
id: 51 reward: -0.01362781954887218 service_time: 610 s_time: 29 penalty: 0 agent_num: 38 done: False
______________________
id: 47 reward: 0.0 service_time: 483 s_time: 0 penalty: 0 agent_num: 23 done: False
______________________
id: 46 reward: 0.0 service_time: 963 s_time: 0 penalty: 0 agent_num: 33 done: False
______________________
id: 55 reward: 0.0016233766233766235 service_time: 916 s_time: -2 penalty: 0 agent_num: 22 done: False
______________________
id: 50 reward: 0.003078817733990148 service_time: 905 s_time: -5 penalty: 0 agent_num: 29 done: False
______________________
id: 44 reward: -0.006336405529953917 service_time: 1127 s_time: 11 penalty: 0 agent_num: 31 done: False
______________________
id: 48 reward: 0.0004152823920265781 service_time: 442 s_time: -1 penalty: 0 agent_num: 43 done: False
______________________
id: 42 reward: 0.0 service_time: 645 s_time: 0 penalty: 0 agent_num: 39 done: False
______________________
id: 49 reward: -0.015926640926640926 service_time: 931 s_time: 33 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: 0.0007288629737609329 service_time: 1006 s_time: -2 penalty: 0 agent_num: 49 done: False
______________________
id: 45 reward: -0.015306122448979591 service_time: 853 s_time: 18 penalty: 0 agent_num: 21 done: False
______________________
id: 43 reward: -0.01989795918367347 service_time: 793 s_time: 39 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: -0.017857142857142856 service_time: 676 s_time: 42 penalty: 0 agent_num: 42 done: False
______________________
id: 52 reward: -0.00992063492063492 service_time: 1069 s_time: 20 penalty: 0 agent_num: 36 done: False
______________________
Step:  1552
Pretraining Loss:  tensor(0.2819, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.041666666666666664 service_time: 351 s_time: 35 penalty: 0 agent_num: 15 done: False
______________________
id: 51 reward: -0.0014097744360902255 service_time: 613 s_time: 3 penalty: 0 agent_num: 38 done: False
______________________
id: 47 reward: -0.037267080745341616 service_time: 531 s_time: 48 penalty: 0 agent_num: 23 done: False
______________________
id: 50 reward: -0.03017241379310345 service_time: 954 s_time: 49 penalty: 0 agent_num: 29 done: False
______________________
id: 40 reward: -0.019230769230769232 service_time: 871 s_time: 28 penalty: 0 agent_num: 26 done: False
______________________
id: 46 reward: -0.02867965367965368 service_time: 1016 s_time: 53 penalty: 0 agent_num: 33 done: False
______________________
id: 54 reward: -0.015306122448979591 service_time: 712 s_time: 36 penalty: 0 agent_num: 42 done: False
______________________
id: 44 reward: 0.001152073732718894 service_time: 1125 s_time: -2 penalty: 0 agent_num: 31 done: False
______________________
id: 53 reward: -0.005466472303206997 service_time: 1021 s_time: 15 penalty: 0 agent_num: 49 done: False
______________________
id: 49 reward: -0.006756756756756757 service_time: 945 s_time: 14 penalty: 0 agent_num: 37 done: False
______________________
id: 42 reward: -0.023809523809523808 service_time: 697 s_time: 52 penalty: 0 agent_num: 39 done: False
______________________
id: 55 reward: -0.1444805194805195 service_time: 1094 s_time: 178 penalty: 0 agent_num: 22 done: False
______________________
id: 48 reward: -0.009966777408637873 service_time: 466 s_time: 24 penalty: 0 agent_num: 43 done: False
______________________
id: 43 reward: -0.02295918367346939 service_time: 838 s_time: 45 penalty: 0 agent_num: 35 done: False
______________________
id: 45 reward: 0.02465986394557823 service_time: 824 s_time: -29 penalty: 0 agent_num: 21 done: False
______________________
id: 52 reward: -0.014384920634920634 service_time: 1098 s_time: 29 penalty: 0 agent_num: 36 done: False
______________________
Step:  1568
Pretraining Loss:  tensor(0.2731, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: 0.0 service_time: 351 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 47 reward: -0.03183229813664596 service_time: 572 s_time: 41 penalty: 0 agent_num: 23 done: False
______________________
id: 40 reward: -0.0260989010989011 service_time: 909 s_time: 38 penalty: 0 agent_num: 26 done: False
______________________
id: 44 reward: -0.04550691244239631 service_time: 1204 s_time: 79 penalty: 0 agent_num: 31 done: False
______________________
id: 43 reward: -0.012755102040816327 service_time: 863 s_time: 25 penalty: 0 agent_num: 35 done: False
______________________
id: 51 reward: -0.01268796992481203 service_time: 640 s_time: 27 penalty: 0 agent_num: 38 done: False
______________________
id: 46 reward: -0.0016233766233766235 service_time: 1019 s_time: 3 penalty: 0 agent_num: 33 done: False
______________________
id: 55 reward: -0.018668831168831168 service_time: 1117 s_time: 23 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: -0.010135135135135136 service_time: 966 s_time: 21 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: -0.00619533527696793 service_time: 1038 s_time: 17 penalty: 0 agent_num: 49 done: False
______________________
id: 54 reward: -0.006802721088435374 service_time: 728 s_time: 16 penalty: 0 agent_num: 42 done: False
______________________
id: 50 reward: 0.0 service_time: 954 s_time: 0 penalty: 0 agent_num: 29 done: False
______________________
id: 45 reward: 0.0195578231292517 service_time: 801 s_time: -23 penalty: 0 agent_num: 21 done: False
______________________
id: 42 reward: -0.004120879120879121 service_time: 706 s_time: 9 penalty: 0 agent_num: 39 done: False
______________________
id: 48 reward: -0.014119601328903655 service_time: 500 s_time: 34 penalty: 0 agent_num: 43 done: False
______________________
id: 52 reward: 0.003968253968253968 service_time: 1090 s_time: -8 penalty: 0 agent_num: 36 done: False
______________________
------------------------------------
| time/                 |          |
|    fps                | 8        |
|    iterations         | 100      |
|    time_elapsed       | 196      |
|    total_timesteps    | 1600     |
| train/                |          |
|    entropy_loss       | 0.00101  |
|    explained_variance | -91.8    |
|    learning_rate      | 0.0001   |
|    n_updates          | 99       |
|    policy_loss        | 0.273    |
|    value_loss         | 0.0874   |
------------------------------------
Step:  1584
Pretraining Loss:  tensor(0.3130, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.04642857142857143 service_time: 390 s_time: 39 penalty: 0 agent_num: 15 done: False
______________________
id: 40 reward: -0.03159340659340659 service_time: 955 s_time: 46 penalty: 0 agent_num: 26 done: False
______________________
id: 45 reward: 0.0 service_time: 801 s_time: 0 penalty: 0 agent_num: 21 done: False
______________________
id: 55 reward: 0.00974025974025974 service_time: 1105 s_time: -12 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: 0.0 service_time: 640 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 47 reward: -0.023291925465838508 service_time: 602 s_time: 30 penalty: 0 agent_num: 23 done: False
______________________
id: 50 reward: -0.03140394088669951 service_time: 1005 s_time: 51 penalty: 0 agent_num: 29 done: False
______________________
id: 46 reward: -0.01406926406926407 service_time: 1045 s_time: 26 penalty: 0 agent_num: 33 done: False
______________________
id: 44 reward: -0.006336405529953917 service_time: 1215 s_time: 11 penalty: 0 agent_num: 31 done: False
______________________
id: 49 reward: 0.0 service_time: 966 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: -0.008017492711370262 service_time: 1060 s_time: 22 penalty: 0 agent_num: 49 done: False
______________________
id: 42 reward: 0.0009157509157509158 service_time: 704 s_time: -2 penalty: 0 agent_num: 39 done: False
______________________
id: 54 reward: -0.016156462585034014 service_time: 766 s_time: 38 penalty: 0 agent_num: 42 done: False
______________________
id: 48 reward: 0.0012458471760797341 service_time: 497 s_time: -3 penalty: 0 agent_num: 43 done: False
______________________
id: 52 reward: -0.03571428571428571 service_time: 1162 s_time: 72 penalty: 0 agent_num: 36 done: False
______________________
id: 43 reward: -0.015306122448979591 service_time: 893 s_time: 30 penalty: 0 agent_num: 35 done: False
______________________
Step:  1600
Pretraining Loss:  tensor(0.3048, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.03333333333333333 service_time: 418 s_time: 28 penalty: 0 agent_num: 15 done: False
______________________
id: 40 reward: 0.0013736263736263737 service_time: 953 s_time: -2 penalty: 0 agent_num: 26 done: False
______________________
id: 55 reward: 0.025162337662337664 service_time: 1074 s_time: -31 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: 0.0 service_time: 640 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 44 reward: -0.01728110599078341 service_time: 1245 s_time: 30 penalty: 0 agent_num: 31 done: False
______________________
id: 45 reward: 0.027210884353741496 service_time: 769 s_time: -32 penalty: 0 agent_num: 21 done: False
______________________
id: 42 reward: -0.016025641025641024 service_time: 739 s_time: 35 penalty: 0 agent_num: 39 done: False
______________________
id: 49 reward: -0.008687258687258687 service_time: 984 s_time: 18 penalty: 0 agent_num: 37 done: False
______________________
id: 47 reward: -0.02096273291925466 service_time: 629 s_time: 27 penalty: 0 agent_num: 23 done: False
______________________
id: 53 reward: 0.0 service_time: 1060 s_time: 0 penalty: 0 agent_num: 49 done: False
______________________
id: 46 reward: -0.026515151515151516 service_time: 1094 s_time: 49 penalty: 0 agent_num: 33 done: False
______________________
id: 43 reward: 0.0020408163265306124 service_time: 889 s_time: -4 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: -0.011054421768707483 service_time: 792 s_time: 26 penalty: 0 agent_num: 42 done: False
______________________
id: 48 reward: -0.011627906976744186 service_time: 525 s_time: 28 penalty: 0 agent_num: 43 done: False
______________________
id: 50 reward: -0.019088669950738917 service_time: 1036 s_time: 31 penalty: 0 agent_num: 29 done: False
______________________
id: 52 reward: -0.00992063492063492 service_time: 1182 s_time: 20 penalty: 0 agent_num: 36 done: False
______________________
Step:  1616
Pretraining Loss:  tensor(0.3455, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.02619047619047619 service_time: 440 s_time: 22 penalty: 0 agent_num: 15 done: False
______________________
id: 45 reward: 0.0 service_time: 769 s_time: 0 penalty: 0 agent_num: 21 done: False
______________________
id: 55 reward: -0.041396103896103896 service_time: 1125 s_time: 51 penalty: 0 agent_num: 22 done: False
______________________
id: 40 reward: -0.036401098901098904 service_time: 1006 s_time: 53 penalty: 0 agent_num: 26 done: False
______________________
id: 51 reward: -0.01456766917293233 service_time: 671 s_time: 31 penalty: 0 agent_num: 38 done: False
______________________
id: 44 reward: 0.0 service_time: 1245 s_time: 0 penalty: 0 agent_num: 31 done: False
______________________
id: 50 reward: -0.006157635467980296 service_time: 1046 s_time: 10 penalty: 0 agent_num: 29 done: False
______________________
id: 47 reward: -0.018633540372670808 service_time: 653 s_time: 24 penalty: 0 agent_num: 23 done: False
______________________
id: 54 reward: -0.008503401360544218 service_time: 812 s_time: 20 penalty: 0 agent_num: 42 done: False
______________________
id: 49 reward: -0.03909266409266409 service_time: 1065 s_time: 81 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: -0.0036443148688046646 service_time: 1070 s_time: 10 penalty: 0 agent_num: 49 done: False
______________________
id: 42 reward: -0.006868131868131868 service_time: 754 s_time: 15 penalty: 0 agent_num: 39 done: False
______________________
id: 48 reward: -0.006229235880398671 service_time: 540 s_time: 15 penalty: 0 agent_num: 43 done: False
______________________
id: 43 reward: -0.029081632653061223 service_time: 946 s_time: 57 penalty: 0 agent_num: 35 done: False
______________________
id: 46 reward: -0.01893939393939394 service_time: 1129 s_time: 35 penalty: 0 agent_num: 33 done: False
______________________
id: 52 reward: -0.012896825396825396 service_time: 1208 s_time: 26 penalty: 0 agent_num: 36 done: False
______________________
Step:  1632
Pretraining Loss:  tensor(0.3144, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.030952380952380953 service_time: 466 s_time: 26 penalty: 0 agent_num: 15 done: False
______________________
id: 45 reward: 0.01020408163265306 service_time: 757 s_time: -12 penalty: 0 agent_num: 21 done: False
______________________
id: 55 reward: -0.025162337662337664 service_time: 1156 s_time: 31 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: -0.013198757763975156 service_time: 670 s_time: 17 penalty: 0 agent_num: 23 done: False
______________________
id: 40 reward: -0.0027472527472527475 service_time: 1010 s_time: 4 penalty: 0 agent_num: 26 done: False
______________________
id: 51 reward: -0.012218045112781954 service_time: 697 s_time: 26 penalty: 0 agent_num: 38 done: False
______________________
id: 42 reward: 0.0 service_time: 754 s_time: 0 penalty: 0 agent_num: 39 done: False
______________________
id: 44 reward: -0.04262672811059908 service_time: 1319 s_time: 74 penalty: 0 agent_num: 31 done: False
______________________
id: 54 reward: 0.0 service_time: 812 s_time: 0 penalty: 0 agent_num: 42 done: False
______________________
id: 43 reward: -0.00816326530612245 service_time: 962 s_time: 16 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.0029069767441860465 service_time: 547 s_time: 7 penalty: 0 agent_num: 43 done: False
______________________
id: 53 reward: -0.03097667638483965 service_time: 1155 s_time: 85 penalty: 0 agent_num: 49 done: False
______________________
id: 46 reward: -0.015692640692640692 service_time: 1158 s_time: 29 penalty: 0 agent_num: 33 done: False
______________________
id: 49 reward: -0.010617760617760617 service_time: 1087 s_time: 22 penalty: 0 agent_num: 37 done: False
______________________
id: 52 reward: 0.0 service_time: 1208 s_time: 0 penalty: 0 agent_num: 36 done: False
______________________
id: 50 reward: -0.03571428571428571 service_time: 1104 s_time: 58 penalty: 0 agent_num: 29 done: False
______________________
Step:  1648
Pretraining Loss:  tensor(0.3344, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.039285714285714285 service_time: 499 s_time: 33 penalty: 0 agent_num: 15 done: False
______________________
id: 55 reward: 0.00974025974025974 service_time: 1144 s_time: -12 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: -0.02251552795031056 service_time: 699 s_time: 29 penalty: 0 agent_num: 23 done: False
______________________
id: 40 reward: -0.03021978021978022 service_time: 1054 s_time: 44 penalty: 0 agent_num: 26 done: False
______________________
id: 42 reward: -0.022435897435897436 service_time: 803 s_time: 49 penalty: 0 agent_num: 39 done: False
______________________
id: 44 reward: -0.008640552995391706 service_time: 1334 s_time: 15 penalty: 0 agent_num: 31 done: False
______________________
id: 49 reward: -0.009652509652509652 service_time: 1107 s_time: 20 penalty: 0 agent_num: 37 done: False
______________________
id: 48 reward: -0.018272425249169437 service_time: 591 s_time: 44 penalty: 0 agent_num: 43 done: False
______________________
id: 46 reward: -0.016774891774891776 service_time: 1189 s_time: 31 penalty: 0 agent_num: 33 done: False
______________________
id: 43 reward: -0.013265306122448979 service_time: 988 s_time: 26 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: -0.013180272108843538 service_time: 843 s_time: 31 penalty: 0 agent_num: 42 done: False
______________________
id: 51 reward: -0.015037593984962405 service_time: 729 s_time: 32 penalty: 0 agent_num: 38 done: False
______________________
id: 45 reward: -0.08673469387755102 service_time: 859 s_time: 102 penalty: 0 agent_num: 21 done: False
______________________
id: 52 reward: -0.03422619047619048 service_time: 1277 s_time: 69 penalty: 0 agent_num: 36 done: False
______________________
id: 50 reward: -0.021551724137931036 service_time: 1139 s_time: 35 penalty: 0 agent_num: 29 done: False
______________________
id: 53 reward: -0.012755102040816327 service_time: 1190 s_time: 35 penalty: 0 agent_num: 49 done: False
______________________
Step:  1664
Pretraining Loss:  tensor(0.3443, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: 0.0 service_time: 499 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 40 reward: -0.005494505494505495 service_time: 1062 s_time: 8 penalty: 0 agent_num: 26 done: False
______________________
id: 51 reward: -0.002819548872180451 service_time: 735 s_time: 6 penalty: 0 agent_num: 38 done: False
______________________
id: 47 reward: -0.02562111801242236 service_time: 732 s_time: 33 penalty: 0 agent_num: 23 done: False
______________________
id: 55 reward: -0.03165584415584415 service_time: 1183 s_time: 39 penalty: 0 agent_num: 22 done: False
______________________
id: 42 reward: -0.01282051282051282 service_time: 831 s_time: 28 penalty: 0 agent_num: 39 done: False
______________________
id: 44 reward: -0.028225806451612902 service_time: 1383 s_time: 49 penalty: 0 agent_num: 31 done: False
______________________
id: 54 reward: -0.011479591836734694 service_time: 870 s_time: 27 penalty: 0 agent_num: 42 done: False
______________________
id: 46 reward: -0.0091991341991342 service_time: 1206 s_time: 17 penalty: 0 agent_num: 33 done: False
______________________
id: 48 reward: -0.012458471760797342 service_time: 621 s_time: 30 penalty: 0 agent_num: 43 done: False
______________________
id: 43 reward: 0.0 service_time: 988 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 45 reward: -0.045068027210884355 service_time: 912 s_time: 53 penalty: 0 agent_num: 21 done: False
______________________
id: 49 reward: -0.002413127413127413 service_time: 1112 s_time: 5 penalty: 0 agent_num: 37 done: False
______________________
id: 50 reward: -0.01539408866995074 service_time: 1164 s_time: 25 penalty: 0 agent_num: 29 done: False
______________________
id: 53 reward: -0.01567055393586006 service_time: 1233 s_time: 43 penalty: 0 agent_num: 49 done: False
______________________
id: 52 reward: -0.019345238095238096 service_time: 1316 s_time: 39 penalty: 0 agent_num: 36 done: False
______________________
Step:  1680
Pretraining Loss:  tensor(0.3529, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.03214285714285714 service_time: 526 s_time: 27 penalty: 0 agent_num: 15 done: False
______________________
id: 47 reward: -0.013198757763975156 service_time: 749 s_time: 17 penalty: 0 agent_num: 23 done: False
______________________
id: 40 reward: 0.0 service_time: 1062 s_time: 0 penalty: 0 agent_num: 26 done: False
______________________
id: 51 reward: -0.012218045112781954 service_time: 761 s_time: 26 penalty: 0 agent_num: 38 done: False
______________________
id: 55 reward: 0.0 service_time: 1183 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 44 reward: -0.006336405529953917 service_time: 1394 s_time: 11 penalty: 0 agent_num: 31 done: False
______________________
id: 45 reward: -0.09523809523809523 service_time: 1024 s_time: 112 penalty: 0 agent_num: 21 done: False
______________________
id: 54 reward: -0.004251700680272109 service_time: 880 s_time: 10 penalty: 0 agent_num: 42 done: False
______________________
id: 49 reward: -0.007722007722007722 service_time: 1128 s_time: 16 penalty: 0 agent_num: 37 done: False
______________________
id: 46 reward: -0.011904761904761904 service_time: 1228 s_time: 22 penalty: 0 agent_num: 33 done: False
______________________
id: 42 reward: -0.013278388278388278 service_time: 860 s_time: 29 penalty: 0 agent_num: 39 done: False
______________________
id: 43 reward: -0.013265306122448979 service_time: 1014 s_time: 26 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.011627906976744186 service_time: 649 s_time: 28 penalty: 0 agent_num: 43 done: False
______________________
id: 52 reward: -0.013392857142857142 service_time: 1343 s_time: 27 penalty: 0 agent_num: 36 done: False
______________________
id: 53 reward: -0.00510204081632653 service_time: 1247 s_time: 14 penalty: 0 agent_num: 49 done: False
______________________
id: 50 reward: -0.019088669950738917 service_time: 1195 s_time: 31 penalty: 0 agent_num: 29 done: False
______________________
Step:  1696
Pretraining Loss:  tensor(0.3216, device='cuda:0', grad_fn=<MeanBackward0>)
id: 47 reward: -0.036490683229813664 service_time: 796 s_time: 47 penalty: 0 agent_num: 23 done: False
______________________
id: 41 reward: -0.007142857142857143 service_time: 532 s_time: 6 penalty: 0 agent_num: 15 done: False
______________________
id: 55 reward: 0.012987012987012988 service_time: 1167 s_time: -16 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: 0.0 service_time: 761 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 44 reward: 0.007488479262672811 service_time: 1381 s_time: -13 penalty: 0 agent_num: 31 done: False
______________________
id: 45 reward: 0.0 service_time: 1024 s_time: 0 penalty: 0 agent_num: 21 done: False
______________________
id: 42 reward: -0.00641025641025641 service_time: 874 s_time: 14 penalty: 0 agent_num: 39 done: False
______________________
id: 48 reward: 0.0 service_time: 649 s_time: 0 penalty: 0 agent_num: 43 done: False
______________________
id: 40 reward: -0.04120879120879121 service_time: 1122 s_time: 60 penalty: 0 agent_num: 26 done: False
______________________
id: 49 reward: -0.018822393822393823 service_time: 1167 s_time: 39 penalty: 0 agent_num: 37 done: False
______________________
id: 46 reward: -0.022186147186147188 service_time: 1269 s_time: 41 penalty: 0 agent_num: 33 done: False
______________________
id: 54 reward: 0.0 service_time: 880 s_time: 0 penalty: 0 agent_num: 42 done: False
______________________
id: 53 reward: -0.008017492711370262 service_time: 1269 s_time: 22 penalty: 0 agent_num: 49 done: False
______________________
id: 43 reward: -0.04030612244897959 service_time: 1093 s_time: 79 penalty: 0 agent_num: 35 done: False
______________________
id: 52 reward: -0.017857142857142856 service_time: 1379 s_time: 36 penalty: 0 agent_num: 36 done: False
______________________
id: 50 reward: -0.021551724137931036 service_time: 1230 s_time: 35 penalty: 0 agent_num: 29 done: False
______________________
Step:  1712
Pretraining Loss:  tensor(0.3591, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.05714285714285714 service_time: 580 s_time: 48 penalty: 0 agent_num: 15 done: False
______________________
id: 47 reward: 0.011645962732919254 service_time: 781 s_time: -15 penalty: 0 agent_num: 23 done: False
______________________
id: 55 reward: 0.0 service_time: 1167 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: -0.010338345864661654 service_time: 783 s_time: 22 penalty: 0 agent_num: 38 done: False
______________________
id: 40 reward: -0.022664835164835164 service_time: 1155 s_time: 33 penalty: 0 agent_num: 26 done: False
______________________
id: 44 reward: -0.044930875576036866 service_time: 1459 s_time: 78 penalty: 0 agent_num: 31 done: False
______________________
id: 42 reward: -0.006868131868131868 service_time: 889 s_time: 15 penalty: 0 agent_num: 39 done: False
______________________
id: 49 reward: -0.015444015444015444 service_time: 1199 s_time: 32 penalty: 0 agent_num: 37 done: False
______________________
id: 48 reward: -0.02367109634551495 service_time: 706 s_time: 57 penalty: 0 agent_num: 43 done: False
______________________
id: 45 reward: 0.01020408163265306 service_time: 1012 s_time: -12 penalty: 0 agent_num: 21 done: False
______________________
id: 52 reward: -0.006944444444444444 service_time: 1393 s_time: 14 penalty: 0 agent_num: 36 done: False
______________________
id: 43 reward: -0.01989795918367347 service_time: 1132 s_time: 39 penalty: 0 agent_num: 35 done: False
______________________
id: 46 reward: -0.017857142857142856 service_time: 1302 s_time: 33 penalty: 0 agent_num: 33 done: False
______________________
id: 50 reward: 0.0 service_time: 1230 s_time: 0 penalty: 0 agent_num: 29 done: False
______________________
id: 54 reward: 0.0 service_time: 880 s_time: 0 penalty: 0 agent_num: 42 done: False
______________________
id: 53 reward: -0.01129737609329446 service_time: 1300 s_time: 31 penalty: 0 agent_num: 49 done: False
______________________
Step:  1728
Pretraining Loss:  tensor(0.3642, device='cuda:0', grad_fn=<MeanBackward0>)
id: 55 reward: 0.0 service_time: 1167 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: -0.002819548872180451 service_time: 789 s_time: 6 penalty: 0 agent_num: 38 done: False
______________________
id: 47 reward: -0.017080745341614908 service_time: 803 s_time: 22 penalty: 0 agent_num: 23 done: False
______________________
id: 49 reward: -0.0033783783783783786 service_time: 1206 s_time: 7 penalty: 0 agent_num: 37 done: False
______________________
id: 40 reward: -0.019230769230769232 service_time: 1183 s_time: 28 penalty: 0 agent_num: 26 done: False
______________________
id: 45 reward: -0.026360544217687076 service_time: 1043 s_time: 31 penalty: 0 agent_num: 21 done: False
______________________
id: 53 reward: -0.004008746355685131 service_time: 1311 s_time: 11 penalty: 0 agent_num: 49 done: False
______________________
id: 41 reward: 0.0011904761904761906 service_time: 579 s_time: -1 penalty: 0 agent_num: 15 done: False
______________________
id: 42 reward: -0.010073260073260074 service_time: 911 s_time: 22 penalty: 0 agent_num: 39 done: False
______________________
id: 44 reward: -0.019009216589861752 service_time: 1492 s_time: 33 penalty: 0 agent_num: 31 done: False
______________________
id: 48 reward: 0.0016611295681063123 service_time: 702 s_time: -4 penalty: 0 agent_num: 43 done: False
______________________
id: 46 reward: 0.0016233766233766235 service_time: 1299 s_time: -3 penalty: 0 agent_num: 33 done: False
______________________
id: 43 reward: -0.017857142857142856 service_time: 1167 s_time: 35 penalty: 0 agent_num: 35 done: False
______________________
id: 50 reward: -0.05233990147783251 service_time: 1315 s_time: 85 penalty: 0 agent_num: 29 done: False
______________________
id: 52 reward: 0.001488095238095238 service_time: 1390 s_time: -3 penalty: 0 agent_num: 36 done: False
______________________
id: 54 reward: -0.016156462585034014 service_time: 918 s_time: 38 penalty: 0 agent_num: 42 done: False
______________________
Step:  1744
Pretraining Loss:  tensor(0.3386, device='cuda:0', grad_fn=<MeanBackward0>)
id: 55 reward: 0.0 service_time: 1167 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: -0.031055900621118012 service_time: 843 s_time: 40 penalty: 0 agent_num: 23 done: False
______________________
id: 45 reward: 0.0 service_time: 1043 s_time: 0 penalty: 0 agent_num: 21 done: False
______________________
id: 49 reward: 0.0009652509652509653 service_time: 1204 s_time: -2 penalty: 0 agent_num: 37 done: False
______________________
id: 42 reward: -0.016025641025641024 service_time: 946 s_time: 35 penalty: 0 agent_num: 39 done: False
______________________
id: 40 reward: -0.023351648351648352 service_time: 1217 s_time: 34 penalty: 0 agent_num: 26 done: False
______________________
id: 51 reward: -0.01456766917293233 service_time: 820 s_time: 31 penalty: 0 agent_num: 38 done: False
______________________
id: 52 reward: -0.028273809523809524 service_time: 1447 s_time: 57 penalty: 0 agent_num: 36 done: False
______________________
id: 48 reward: -0.024501661129568107 service_time: 761 s_time: 59 penalty: 0 agent_num: 43 done: False
______________________
id: 50 reward: -0.025246305418719212 service_time: 1356 s_time: 41 penalty: 0 agent_num: 29 done: False
______________________
id: 46 reward: -0.015692640692640692 service_time: 1328 s_time: 29 penalty: 0 agent_num: 33 done: False
______________________
id: 41 reward: 0.0 service_time: 579 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 44 reward: -0.026497695852534562 service_time: 1538 s_time: 46 penalty: 0 agent_num: 31 done: False
______________________
id: 53 reward: -0.00619533527696793 service_time: 1328 s_time: 17 penalty: 0 agent_num: 49 done: False
______________________
id: 54 reward: -0.011904761904761904 service_time: 946 s_time: 28 penalty: 0 agent_num: 42 done: False
______________________
id: 43 reward: -0.008673469387755102 service_time: 1184 s_time: 17 penalty: 0 agent_num: 35 done: False
______________________
Step:  1760
Pretraining Loss:  tensor(0.3549, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.02619047619047619 service_time: 601 s_time: 22 penalty: 0 agent_num: 15 done: False
______________________
id: 55 reward: 0.007305194805194805 service_time: 1158 s_time: -9 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: 0.015527950310559006 service_time: 823 s_time: -20 penalty: 0 agent_num: 23 done: False
______________________
id: 45 reward: -0.027210884353741496 service_time: 1075 s_time: 32 penalty: 0 agent_num: 21 done: False
______________________
id: 51 reward: -0.01644736842105263 service_time: 855 s_time: 35 penalty: 0 agent_num: 38 done: False
______________________
id: 40 reward: -0.026785714285714284 service_time: 1256 s_time: 39 penalty: 0 agent_num: 26 done: False
______________________
id: 42 reward: 0.0004578754578754579 service_time: 945 s_time: -1 penalty: 0 agent_num: 39 done: False
______________________
id: 54 reward: -0.01488095238095238 service_time: 981 s_time: 35 penalty: 0 agent_num: 42 done: False
______________________
id: 49 reward: -0.029922779922779922 service_time: 1266 s_time: 62 penalty: 0 agent_num: 37 done: False
______________________
id: 52 reward: -0.020337301587301588 service_time: 1488 s_time: 41 penalty: 0 agent_num: 36 done: False
______________________
id: 48 reward: 0.0008305647840531562 service_time: 759 s_time: -2 penalty: 0 agent_num: 43 done: False
______________________
id: 43 reward: 0.0 service_time: 1184 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 53 reward: -0.010932944606413994 service_time: 1358 s_time: 30 penalty: 0 agent_num: 49 done: False
______________________
id: 46 reward: -0.04004329004329004 service_time: 1402 s_time: 74 penalty: 0 agent_num: 33 done: False
______________________
id: 44 reward: -0.03052995391705069 service_time: 1591 s_time: 53 penalty: 0 agent_num: 31 done: False
______________________
id: 50 reward: 0.006157635467980296 service_time: 1346 s_time: -10 penalty: 0 agent_num: 29 done: False
______________________
Step:  1776
Pretraining Loss:  tensor(0.3230, device='cuda:0', grad_fn=<MeanBackward0>)
id: 55 reward: 0.008928571428571428 service_time: 1147 s_time: -11 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: 0.006987577639751553 service_time: 814 s_time: -9 penalty: 0 agent_num: 23 done: False
______________________
id: 51 reward: 0.0 service_time: 855 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 49 reward: -0.017857142857142856 service_time: 1303 s_time: 37 penalty: 0 agent_num: 37 done: False
______________________
id: 41 reward: 0.0 service_time: 601 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 45 reward: -0.00935374149659864 service_time: 1086 s_time: 11 penalty: 0 agent_num: 21 done: False
______________________
id: 40 reward: -0.01510989010989011 service_time: 1278 s_time: 22 penalty: 0 agent_num: 26 done: False
______________________
id: 42 reward: -0.02152014652014652 service_time: 992 s_time: 47 penalty: 0 agent_num: 39 done: False
______________________
id: 54 reward: 0.0 service_time: 981 s_time: 0 penalty: 0 agent_num: 42 done: False
______________________
id: 44 reward: -0.013824884792626729 service_time: 1615 s_time: 24 penalty: 0 agent_num: 31 done: False
______________________
id: 46 reward: -0.01461038961038961 service_time: 1429 s_time: 27 penalty: 0 agent_num: 33 done: False
______________________
id: 50 reward: -0.012315270935960592 service_time: 1366 s_time: 20 penalty: 0 agent_num: 29 done: False
______________________
id: 53 reward: -0.009839650145772596 service_time: 1385 s_time: 27 penalty: 0 agent_num: 49 done: False
______________________
id: 48 reward: -0.022425249169435217 service_time: 813 s_time: 54 penalty: 0 agent_num: 43 done: False
______________________
id: 52 reward: -0.013888888888888888 service_time: 1516 s_time: 28 penalty: 0 agent_num: 36 done: False
______________________
id: 43 reward: -0.015306122448979591 service_time: 1214 s_time: 30 penalty: 0 agent_num: 35 done: False
______________________
Step:  1792
Pretraining Loss:  tensor(0.3203, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.02619047619047619 service_time: 623 s_time: 22 penalty: 0 agent_num: 15 done: False
______________________
id: 55 reward: -0.01948051948051948 service_time: 1171 s_time: 24 penalty: 0 agent_num: 22 done: False
______________________
id: 45 reward: 0.0 service_time: 1086 s_time: 0 penalty: 0 agent_num: 21 done: False
______________________
id: 47 reward: -0.09239130434782608 service_time: 933 s_time: 119 penalty: 0 agent_num: 23 done: False
______________________
id: 51 reward: -0.010808270676691729 service_time: 878 s_time: 23 penalty: 0 agent_num: 38 done: False
______________________
id: 40 reward: 0.004807692307692308 service_time: 1271 s_time: -7 penalty: 0 agent_num: 26 done: False
______________________
id: 54 reward: -0.007653061224489796 service_time: 999 s_time: 18 penalty: 0 agent_num: 42 done: False
______________________
id: 42 reward: -0.015567765567765568 service_time: 1026 s_time: 34 penalty: 0 agent_num: 39 done: False
______________________
id: 48 reward: -0.014119601328903655 service_time: 847 s_time: 34 penalty: 0 agent_num: 43 done: False
______________________
id: 49 reward: -0.016891891891891893 service_time: 1338 s_time: 35 penalty: 0 agent_num: 37 done: False
______________________
id: 52 reward: -0.013888888888888888 service_time: 1544 s_time: 28 penalty: 0 agent_num: 36 done: False
______________________
id: 53 reward: 0.0014577259475218659 service_time: 1381 s_time: -4 penalty: 0 agent_num: 49 done: False
______________________
id: 43 reward: -0.03979591836734694 service_time: 1292 s_time: 78 penalty: 0 agent_num: 35 done: False
______________________
id: 46 reward: -0.023268398268398268 service_time: 1472 s_time: 43 penalty: 0 agent_num: 33 done: False
______________________
id: 44 reward: -0.02476958525345622 service_time: 1658 s_time: 43 penalty: 0 agent_num: 31 done: False
______________________
id: 50 reward: -0.03940886699507389 service_time: 1430 s_time: 64 penalty: 0 agent_num: 29 done: False
______________________
Step:  1808
Pretraining Loss:  tensor(0.3499, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.02023809523809524 service_time: 640 s_time: 17 penalty: 0 agent_num: 15 done: False
______________________
id: 55 reward: -0.020292207792207792 service_time: 1196 s_time: 25 penalty: 0 agent_num: 22 done: False
______________________
id: 40 reward: 0.0 service_time: 1271 s_time: 0 penalty: 0 agent_num: 26 done: False
______________________
id: 45 reward: -0.04591836734693878 service_time: 1140 s_time: 54 penalty: 0 agent_num: 21 done: False
______________________
id: 47 reward: -0.034161490683229816 service_time: 977 s_time: 44 penalty: 0 agent_num: 23 done: False
______________________
id: 51 reward: -0.01268796992481203 service_time: 905 s_time: 27 penalty: 0 agent_num: 38 done: False
______________________
id: 54 reward: 0.0 service_time: 999 s_time: 0 penalty: 0 agent_num: 42 done: False
______________________
id: 42 reward: 0.0 service_time: 1026 s_time: 0 penalty: 0 agent_num: 39 done: False
______________________
id: 49 reward: 0.0 service_time: 1338 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: -0.01567055393586006 service_time: 1424 s_time: 43 penalty: 0 agent_num: 49 done: False
______________________
id: 46 reward: -0.017316017316017316 service_time: 1504 s_time: 32 penalty: 0 agent_num: 33 done: False
______________________
id: 52 reward: -0.01240079365079365 service_time: 1569 s_time: 25 penalty: 0 agent_num: 36 done: False
______________________
id: 48 reward: -0.004152823920265781 service_time: 857 s_time: 10 penalty: 0 agent_num: 43 done: False
______________________
id: 43 reward: -0.026020408163265306 service_time: 1343 s_time: 51 penalty: 0 agent_num: 35 done: False
______________________
id: 44 reward: -0.014400921658986175 service_time: 1683 s_time: 25 penalty: 0 agent_num: 31 done: False
______________________
id: 50 reward: -0.017857142857142856 service_time: 1459 s_time: 29 penalty: 0 agent_num: 29 done: False
______________________
Step:  1824
Pretraining Loss:  tensor(0.3309, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: 0.0035714285714285713 service_time: 637 s_time: -3 penalty: 0 agent_num: 15 done: False
______________________
id: 55 reward: 0.015422077922077922 service_time: 1177 s_time: -19 penalty: 0 agent_num: 22 done: False
______________________
id: 45 reward: -0.06887755102040816 service_time: 1221 s_time: 81 penalty: 0 agent_num: 21 done: False
______________________
id: 40 reward: -0.05357142857142857 service_time: 1349 s_time: 78 penalty: 0 agent_num: 26 done: False
______________________
id: 51 reward: -0.0014097744360902255 service_time: 908 s_time: 3 penalty: 0 agent_num: 38 done: False
______________________
id: 47 reward: -0.010869565217391304 service_time: 991 s_time: 14 penalty: 0 agent_num: 23 done: False
______________________
id: 48 reward: 0.003737541528239203 service_time: 848 s_time: -9 penalty: 0 agent_num: 43 done: False
______________________
id: 42 reward: -0.01282051282051282 service_time: 1054 s_time: 28 penalty: 0 agent_num: 39 done: False
______________________
id: 54 reward: -0.011904761904761904 service_time: 1027 s_time: 28 penalty: 0 agent_num: 42 done: False
______________________
id: 52 reward: 0.00248015873015873 service_time: 1564 s_time: -5 penalty: 0 agent_num: 36 done: False
______________________
id: 49 reward: -0.01447876447876448 service_time: 1368 s_time: 30 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: -0.006559766763848397 service_time: 1442 s_time: 18 penalty: 0 agent_num: 49 done: False
______________________
id: 46 reward: 0.0 service_time: 1504 s_time: 0 penalty: 0 agent_num: 33 done: False
______________________
id: 43 reward: -0.01683673469387755 service_time: 1376 s_time: 33 penalty: 0 agent_num: 35 done: False
______________________
id: 50 reward: -0.017857142857142856 service_time: 1488 s_time: 29 penalty: 0 agent_num: 29 done: False
______________________
id: 44 reward: -0.03110599078341014 service_time: 1737 s_time: 54 penalty: 0 agent_num: 31 done: False
______________________
Step:  1840
Pretraining Loss:  tensor(0.3350, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.02738095238095238 service_time: 660 s_time: 23 penalty: 0 agent_num: 15 done: False
______________________
id: 55 reward: -0.060876623376623376 service_time: 1252 s_time: 75 penalty: 0 agent_num: 22 done: False
______________________
id: 40 reward: 0.01304945054945055 service_time: 1330 s_time: -19 penalty: 0 agent_num: 26 done: False
______________________
id: 51 reward: 0.0 service_time: 908 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 45 reward: -0.11479591836734694 service_time: 1356 s_time: 135 penalty: 0 agent_num: 21 done: False
______________________
id: 49 reward: -0.010135135135135136 service_time: 1389 s_time: 21 penalty: 0 agent_num: 37 done: False
______________________
id: 47 reward: -0.029503105590062112 service_time: 1029 s_time: 38 penalty: 0 agent_num: 23 done: False
______________________
id: 42 reward: -0.005952380952380952 service_time: 1067 s_time: 13 penalty: 0 agent_num: 39 done: False
______________________
id: 48 reward: -0.02117940199335548 service_time: 899 s_time: 51 penalty: 0 agent_num: 43 done: False
______________________
id: 53 reward: -0.0047376093294460644 service_time: 1455 s_time: 13 penalty: 0 agent_num: 49 done: False
______________________
id: 52 reward: -0.026785714285714284 service_time: 1618 s_time: 54 penalty: 0 agent_num: 36 done: False
______________________
id: 44 reward: -0.002880184331797235 service_time: 1742 s_time: 5 penalty: 0 agent_num: 31 done: False
______________________
id: 54 reward: -0.008503401360544218 service_time: 1047 s_time: 20 penalty: 0 agent_num: 42 done: False
______________________
id: 43 reward: -0.018877551020408164 service_time: 1413 s_time: 37 penalty: 0 agent_num: 35 done: False
______________________
id: 50 reward: 0.012315270935960592 service_time: 1468 s_time: -20 penalty: 0 agent_num: 29 done: False
______________________
id: 46 reward: -0.038419913419913417 service_time: 1575 s_time: 71 penalty: 0 agent_num: 33 done: False
______________________
Step:  1856
Pretraining Loss:  tensor(0.3399, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.060714285714285714 service_time: 711 s_time: 51 penalty: 0 agent_num: 15 done: False
______________________
id: 47 reward: 0.017080745341614908 service_time: 1007 s_time: -22 penalty: 0 agent_num: 23 done: False
______________________
id: 40 reward: -0.03571428571428571 service_time: 1382 s_time: 52 penalty: 0 agent_num: 26 done: False
______________________
id: 45 reward: -0.0391156462585034 service_time: 1402 s_time: 46 penalty: 0 agent_num: 21 done: False
______________________
id: 51 reward: -0.01926691729323308 service_time: 949 s_time: 41 penalty: 0 agent_num: 38 done: False
______________________
id: 49 reward: -0.00916988416988417 service_time: 1408 s_time: 19 penalty: 0 agent_num: 37 done: False
______________________
id: 48 reward: -0.011627906976744186 service_time: 927 s_time: 28 penalty: 0 agent_num: 43 done: False
______________________
id: 54 reward: -0.012329931972789115 service_time: 1076 s_time: 29 penalty: 0 agent_num: 42 done: False
______________________
id: 52 reward: -0.013392857142857142 service_time: 1645 s_time: 27 penalty: 0 agent_num: 36 done: False
______________________
id: 42 reward: -0.004120879120879121 service_time: 1076 s_time: 9 penalty: 0 agent_num: 39 done: False
______________________
id: 53 reward: -0.0047376093294460644 service_time: 1468 s_time: 13 penalty: 0 agent_num: 49 done: False
______________________
id: 50 reward: -0.021551724137931036 service_time: 1503 s_time: 35 penalty: 0 agent_num: 29 done: False
______________________
id: 46 reward: -0.005411255411255411 service_time: 1585 s_time: 10 penalty: 0 agent_num: 33 done: False
______________________
id: 55 reward: -0.032467532467532464 service_time: 1292 s_time: 40 penalty: 0 agent_num: 22 done: False
______________________
id: 44 reward: -0.010368663594470046 service_time: 1760 s_time: 18 penalty: 0 agent_num: 31 done: False
______________________
id: 43 reward: -0.025510204081632654 service_time: 1463 s_time: 50 penalty: 0 agent_num: 35 done: False
______________________
Step:  1872
Pretraining Loss:  tensor(0.3424, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: 0.0 service_time: 711 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 40 reward: -0.026785714285714284 service_time: 1421 s_time: 39 penalty: 0 agent_num: 26 done: False
______________________
id: 47 reward: 0.0 service_time: 1007 s_time: 0 penalty: 0 agent_num: 23 done: False
______________________
id: 45 reward: -0.05952380952380952 service_time: 1472 s_time: 70 penalty: 0 agent_num: 21 done: False
______________________
id: 51 reward: -0.010338345864661654 service_time: 971 s_time: 22 penalty: 0 agent_num: 38 done: False
______________________
id: 49 reward: -0.0111003861003861 service_time: 1431 s_time: 23 penalty: 0 agent_num: 37 done: False
______________________
id: 54 reward: 0.0 service_time: 1076 s_time: 0 penalty: 0 agent_num: 42 done: False
______________________
id: 42 reward: -0.0027472527472527475 service_time: 1082 s_time: 6 penalty: 0 agent_num: 39 done: False
______________________
id: 48 reward: -0.005813953488372093 service_time: 941 s_time: 14 penalty: 0 agent_num: 43 done: False
______________________
id: 46 reward: -0.01948051948051948 service_time: 1621 s_time: 36 penalty: 0 agent_num: 33 done: False
______________________
id: 55 reward: -0.08766233766233766 service_time: 1400 s_time: 108 penalty: 0 agent_num: 22 done: False
______________________
id: 44 reward: -0.000576036866359447 service_time: 1761 s_time: 1 penalty: 0 agent_num: 31 done: False
______________________
id: 53 reward: 0.0 service_time: 1468 s_time: 0 penalty: 0 agent_num: 49 done: False
______________________
id: 52 reward: -0.008928571428571428 service_time: 1663 s_time: 18 penalty: 0 agent_num: 36 done: False
______________________
id: 50 reward: -0.037561576354679806 service_time: 1564 s_time: 61 penalty: 0 agent_num: 29 done: False
______________________
id: 43 reward: -0.02346938775510204 service_time: 1509 s_time: 46 penalty: 0 agent_num: 35 done: False
______________________
Step:  1888
Pretraining Loss:  tensor(0.3322, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.017857142857142856 service_time: 726 s_time: 15 penalty: 0 agent_num: 15 done: False
______________________
id: 47 reward: 0.0 service_time: 1007 s_time: 0 penalty: 0 agent_num: 23 done: False
______________________
id: 45 reward: -0.0391156462585034 service_time: 1518 s_time: 46 penalty: 0 agent_num: 21 done: False
______________________
id: 51 reward: -0.009398496240601503 service_time: 991 s_time: 20 penalty: 0 agent_num: 38 done: False
______________________
id: 49 reward: -0.02027027027027027 service_time: 1473 s_time: 42 penalty: 0 agent_num: 37 done: False
______________________
id: 54 reward: 0.0 service_time: 1076 s_time: 0 penalty: 0 agent_num: 42 done: False
______________________
id: 42 reward: -0.016025641025641024 service_time: 1117 s_time: 35 penalty: 0 agent_num: 39 done: False
______________________
id: 48 reward: -0.013289036544850499 service_time: 973 s_time: 32 penalty: 0 agent_num: 43 done: False
______________________
id: 44 reward: -0.03168202764976959 service_time: 1816 s_time: 55 penalty: 0 agent_num: 31 done: False
______________________
id: 53 reward: -0.009839650145772596 service_time: 1495 s_time: 27 penalty: 0 agent_num: 49 done: False
______________________
id: 40 reward: -0.032280219780219783 service_time: 1468 s_time: 47 penalty: 0 agent_num: 26 done: False
______________________
id: 55 reward: -0.09577922077922078 service_time: 1518 s_time: 118 penalty: 0 agent_num: 22 done: False
______________________
id: 46 reward: 0.0005411255411255411 service_time: 1620 s_time: -1 penalty: 0 agent_num: 33 done: False
______________________
id: 50 reward: 0.0012315270935960591 service_time: 1562 s_time: -2 penalty: 0 agent_num: 29 done: False
______________________
id: 52 reward: -0.028273809523809524 service_time: 1720 s_time: 57 penalty: 0 agent_num: 36 done: False
______________________
id: 43 reward: -0.0010204081632653062 service_time: 1511 s_time: 2 penalty: 0 agent_num: 35 done: False
______________________
Step:  1904
Pretraining Loss:  tensor(0.3059, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: 0.0 service_time: 726 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 55 reward: -0.008928571428571428 service_time: 1529 s_time: 11 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: -0.040372670807453416 service_time: 1059 s_time: 52 penalty: 0 agent_num: 23 done: False
______________________
id: 45 reward: -0.01870748299319728 service_time: 1540 s_time: 22 penalty: 0 agent_num: 21 done: False
______________________
id: 51 reward: -0.01268796992481203 service_time: 1018 s_time: 27 penalty: 0 agent_num: 38 done: False
______________________
id: 40 reward: 0.014423076923076924 service_time: 1447 s_time: -21 penalty: 0 agent_num: 26 done: False
______________________
id: 48 reward: 0.0008305647840531562 service_time: 971 s_time: -2 penalty: 0 agent_num: 43 done: False
______________________
id: 54 reward: -0.007227891156462585 service_time: 1093 s_time: 17 penalty: 0 agent_num: 42 done: False
______________________
id: 42 reward: -0.00641025641025641 service_time: 1131 s_time: 14 penalty: 0 agent_num: 39 done: False
______________________
id: 44 reward: -0.021889400921658985 service_time: 1854 s_time: 38 penalty: 0 agent_num: 31 done: False
______________________
id: 49 reward: -0.016409266409266408 service_time: 1507 s_time: 34 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: -0.022230320699708456 service_time: 1556 s_time: 61 penalty: 0 agent_num: 49 done: False
______________________
id: 46 reward: -0.03300865800865801 service_time: 1681 s_time: 61 penalty: 0 agent_num: 33 done: False
______________________
id: 50 reward: -0.04187192118226601 service_time: 1630 s_time: 68 penalty: 0 agent_num: 29 done: False
______________________
id: 52 reward: -0.006448412698412698 service_time: 1733 s_time: 13 penalty: 0 agent_num: 36 done: False
______________________
id: 43 reward: -0.019387755102040816 service_time: 1549 s_time: 38 penalty: 0 agent_num: 35 done: False
______________________
Step:  1920
Pretraining Loss:  tensor(0.3092, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.02142857142857143 service_time: 744 s_time: 18 penalty: 0 agent_num: 15 done: False
______________________
id: 47 reward: -0.03260869565217391 service_time: 1101 s_time: 42 penalty: 0 agent_num: 23 done: False
______________________
id: 40 reward: -0.008241758241758242 service_time: 1459 s_time: 12 penalty: 0 agent_num: 26 done: False
______________________
id: 55 reward: -0.045454545454545456 service_time: 1585 s_time: 56 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: 0.0 service_time: 1018 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 42 reward: -0.009157509157509158 service_time: 1151 s_time: 20 penalty: 0 agent_num: 39 done: False
______________________
id: 49 reward: 0.0 service_time: 1507 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 54 reward: -0.010629251700680272 service_time: 1118 s_time: 25 penalty: 0 agent_num: 42 done: False
______________________
id: 48 reward: -0.006644518272425249 service_time: 987 s_time: 16 penalty: 0 agent_num: 43 done: False
______________________
id: 45 reward: -0.007653061224489796 service_time: 1549 s_time: 9 penalty: 0 agent_num: 21 done: False
______________________
id: 44 reward: -0.009792626728110598 service_time: 1871 s_time: 17 penalty: 0 agent_num: 31 done: False
______________________
id: 53 reward: -0.004373177842565598 service_time: 1568 s_time: 12 penalty: 0 agent_num: 49 done: False
______________________
id: 46 reward: -0.015692640692640692 service_time: 1710 s_time: 29 penalty: 0 agent_num: 33 done: False
______________________
id: 43 reward: -0.013775510204081633 service_time: 1576 s_time: 27 penalty: 0 agent_num: 35 done: False
______________________
id: 50 reward: -0.02647783251231527 service_time: 1673 s_time: 43 penalty: 0 agent_num: 29 done: False
______________________
id: 52 reward: -0.016865079365079364 service_time: 1767 s_time: 34 penalty: 0 agent_num: 36 done: False
______________________
Step:  1936
Pretraining Loss:  tensor(0.3120, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: 0.0 service_time: 744 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 47 reward: 0.017080745341614908 service_time: 1079 s_time: -22 penalty: 0 agent_num: 23 done: False
______________________
id: 55 reward: -0.017045454545454544 service_time: 1606 s_time: 21 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: -0.009398496240601503 service_time: 1038 s_time: 20 penalty: 0 agent_num: 38 done: False
______________________
id: 40 reward: -0.07074175824175824 service_time: 1562 s_time: 103 penalty: 0 agent_num: 26 done: False
______________________
id: 54 reward: -0.007227891156462585 service_time: 1135 s_time: 17 penalty: 0 agent_num: 42 done: False
______________________
id: 44 reward: -0.008640552995391706 service_time: 1886 s_time: 15 penalty: 0 agent_num: 31 done: False
______________________
id: 46 reward: -0.023268398268398268 service_time: 1753 s_time: 43 penalty: 0 agent_num: 33 done: False
______________________
id: 48 reward: -0.024916943521594685 service_time: 1047 s_time: 60 penalty: 0 agent_num: 43 done: False
______________________
id: 53 reward: -0.00510204081632653 service_time: 1582 s_time: 14 penalty: 0 agent_num: 49 done: False
______________________
id: 42 reward: -0.022435897435897436 service_time: 1200 s_time: 49 penalty: 0 agent_num: 39 done: False
______________________
id: 50 reward: -0.011083743842364532 service_time: 1691 s_time: 18 penalty: 0 agent_num: 29 done: False
______________________
id: 45 reward: 0.003401360544217687 service_time: 1545 s_time: -4 penalty: 0 agent_num: 21 done: False
______________________
id: 52 reward: -0.006448412698412698 service_time: 1780 s_time: 13 penalty: 0 agent_num: 36 done: False
______________________
id: 49 reward: -0.03426640926640927 service_time: 1578 s_time: 71 penalty: 0 agent_num: 37 done: False
______________________
id: 43 reward: 0.0010204081632653062 service_time: 1574 s_time: -2 penalty: 0 agent_num: 35 done: False
______________________
Step:  1952
Pretraining Loss:  tensor(0.3114, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.02619047619047619 service_time: 766 s_time: 22 penalty: 0 agent_num: 15 done: False
______________________
id: 47 reward: 0.013975155279503106 service_time: 1061 s_time: -18 penalty: 0 agent_num: 23 done: False
______________________
id: 51 reward: -0.009868421052631578 service_time: 1059 s_time: 21 penalty: 0 agent_num: 38 done: False
______________________
id: 40 reward: -0.04120879120879121 service_time: 1622 s_time: 60 penalty: 0 agent_num: 26 done: False
______________________
id: 52 reward: -0.008928571428571428 service_time: 1798 s_time: 18 penalty: 0 agent_num: 36 done: False
______________________
id: 48 reward: -0.006644518272425249 service_time: 1063 s_time: 16 penalty: 0 agent_num: 43 done: False
______________________
id: 54 reward: 0.0 service_time: 1135 s_time: 0 penalty: 0 agent_num: 42 done: False
______________________
id: 55 reward: -0.03977272727272727 service_time: 1655 s_time: 49 penalty: 0 agent_num: 22 done: False
______________________
id: 53 reward: 0.0 service_time: 1582 s_time: 0 penalty: 0 agent_num: 49 done: False
______________________
id: 44 reward: -0.029953917050691243 service_time: 1938 s_time: 52 penalty: 0 agent_num: 31 done: False
______________________
id: 46 reward: -0.01461038961038961 service_time: 1780 s_time: 27 penalty: 0 agent_num: 33 done: False
______________________
id: 42 reward: -0.011904761904761904 service_time: 1226 s_time: 26 penalty: 0 agent_num: 39 done: False
______________________
id: 45 reward: -0.02040816326530612 service_time: 1569 s_time: 24 penalty: 0 agent_num: 21 done: False
______________________
id: 43 reward: -0.0066326530612244895 service_time: 1587 s_time: 13 penalty: 0 agent_num: 35 done: False
______________________
id: 49 reward: 0.0009652509652509653 service_time: 1576 s_time: -2 penalty: 0 agent_num: 37 done: False
______________________
id: 50 reward: -0.022167487684729065 service_time: 1727 s_time: 36 penalty: 0 agent_num: 29 done: False
______________________
Step:  1968
Pretraining Loss:  tensor(0.3159, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.017857142857142856 service_time: 781 s_time: 15 penalty: 0 agent_num: 15 done: False
______________________
id: 45 reward: 0.03316326530612245 service_time: 1530 s_time: -39 penalty: 0 agent_num: 21 done: False
______________________
id: 55 reward: -0.021915584415584416 service_time: 1682 s_time: 27 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: 0.026397515527950312 service_time: 1027 s_time: -34 penalty: 0 agent_num: 23 done: False
______________________
id: 51 reward: -0.01738721804511278 service_time: 1096 s_time: 37 penalty: 0 agent_num: 38 done: False
______________________
id: 54 reward: 0.0 service_time: 1135 s_time: 0 penalty: 0 agent_num: 42 done: False
______________________
id: 46 reward: 0.0010822510822510823 service_time: 1778 s_time: -2 penalty: 0 agent_num: 33 done: False
______________________
id: 40 reward: 0.022664835164835164 service_time: 1589 s_time: -33 penalty: 0 agent_num: 26 done: False
______________________
id: 48 reward: -0.0004152823920265781 service_time: 1064 s_time: 1 penalty: 0 agent_num: 43 done: False
______________________
id: 44 reward: -0.012672811059907835 service_time: 1960 s_time: 22 penalty: 0 agent_num: 31 done: False
______________________
id: 42 reward: -0.014194139194139194 service_time: 1257 s_time: 31 penalty: 0 agent_num: 39 done: False
______________________
id: 49 reward: -0.010617760617760617 service_time: 1598 s_time: 22 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: -0.02259475218658892 service_time: 1644 s_time: 62 penalty: 0 agent_num: 49 done: False
______________________
id: 50 reward: -0.029556650246305417 service_time: 1775 s_time: 48 penalty: 0 agent_num: 29 done: False
______________________
id: 52 reward: 0.000496031746031746 service_time: 1797 s_time: -1 penalty: 0 agent_num: 36 done: False
______________________
id: 43 reward: -0.025510204081632654 service_time: 1637 s_time: 50 penalty: 0 agent_num: 35 done: False
______________________
Step:  1984
Pretraining Loss:  tensor(0.3108, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: 0.0 service_time: 781 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 47 reward: 0.0 service_time: 1027 s_time: 0 penalty: 0 agent_num: 23 done: False
______________________
id: 45 reward: 0.002551020408163265 service_time: 1527 s_time: -3 penalty: 0 agent_num: 21 done: False
______________________
id: 40 reward: 0.017857142857142856 service_time: 1563 s_time: -26 penalty: 0 agent_num: 26 done: False
______________________
id: 51 reward: -0.013157894736842105 service_time: 1124 s_time: 28 penalty: 0 agent_num: 38 done: False
______________________
id: 52 reward: -0.028273809523809524 service_time: 1854 s_time: 57 penalty: 0 agent_num: 36 done: False
______________________
id: 48 reward: -0.0303156146179402 service_time: 1137 s_time: 73 penalty: 0 agent_num: 43 done: False
______________________
id: 44 reward: 0.000576036866359447 service_time: 1959 s_time: -1 penalty: 0 agent_num: 31 done: False
______________________
id: 54 reward: -0.012755102040816327 service_time: 1165 s_time: 30 penalty: 0 agent_num: 42 done: False
______________________
id: 55 reward: -0.025162337662337664 service_time: 1713 s_time: 31 penalty: 0 agent_num: 22 done: False
______________________
id: 50 reward: 0.0012315270935960591 service_time: 1773 s_time: -2 penalty: 0 agent_num: 29 done: False
______________________
id: 46 reward: -0.016233766233766232 service_time: 1808 s_time: 30 penalty: 0 agent_num: 33 done: False
______________________
id: 49 reward: -0.013513513513513514 service_time: 1626 s_time: 28 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: -0.006559766763848397 service_time: 1662 s_time: 18 penalty: 0 agent_num: 49 done: False
______________________
id: 42 reward: -0.003663003663003663 service_time: 1265 s_time: 8 penalty: 0 agent_num: 39 done: False
______________________
id: 43 reward: -0.005612244897959183 service_time: 1648 s_time: 11 penalty: 0 agent_num: 35 done: False
______________________
Step:  2000
Pretraining Loss:  tensor(0.3079, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.036904761904761905 service_time: 812 s_time: 31 penalty: 0 agent_num: 15 done: False
______________________
id: 45 reward: 0.04931972789115646 service_time: 1469 s_time: -58 penalty: 0 agent_num: 21 done: False
______________________
id: 40 reward: -0.01304945054945055 service_time: 1582 s_time: 19 penalty: 0 agent_num: 26 done: False
______________________
id: 55 reward: -0.01948051948051948 service_time: 1737 s_time: 24 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: -0.06599378881987578 service_time: 1112 s_time: 85 penalty: 0 agent_num: 23 done: False
______________________
id: 42 reward: 0.0 service_time: 1265 s_time: 0 penalty: 0 agent_num: 39 done: False
______________________
id: 44 reward: -0.03571428571428571 service_time: 2021 s_time: 62 penalty: 0 agent_num: 31 done: False
______________________
id: 51 reward: -0.015037593984962405 service_time: 1156 s_time: 32 penalty: 0 agent_num: 38 done: False
______________________
id: 49 reward: -0.014961389961389961 service_time: 1657 s_time: 31 penalty: 0 agent_num: 37 done: False
______________________
id: 50 reward: -0.02586206896551724 service_time: 1815 s_time: 42 penalty: 0 agent_num: 29 done: False
______________________
id: 53 reward: -0.007653061224489796 service_time: 1683 s_time: 21 penalty: 0 agent_num: 49 done: False
______________________
id: 54 reward: 0.0 service_time: 1165 s_time: 0 penalty: 0 agent_num: 42 done: False
______________________
id: 48 reward: -0.012458471760797342 service_time: 1167 s_time: 30 penalty: 0 agent_num: 43 done: False
______________________
id: 43 reward: -0.01020408163265306 service_time: 1668 s_time: 20 penalty: 0 agent_num: 35 done: False
______________________
id: 46 reward: -0.024350649350649352 service_time: 1853 s_time: 45 penalty: 0 agent_num: 33 done: False
______________________
id: 52 reward: -0.034722222222222224 service_time: 1924 s_time: 70 penalty: 0 agent_num: 36 done: False
______________________
Step:  2016
Pretraining Loss:  tensor(0.2915, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: 0.0 service_time: 812 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 45 reward: 0.0 service_time: 1469 s_time: 0 penalty: 0 agent_num: 21 done: False
______________________
id: 47 reward: -0.049689440993788817 service_time: 1176 s_time: 64 penalty: 0 agent_num: 23 done: False
______________________
id: 55 reward: -0.07548701298701299 service_time: 1830 s_time: 93 penalty: 0 agent_num: 22 done: False
______________________
id: 40 reward: -0.023351648351648352 service_time: 1616 s_time: 34 penalty: 0 agent_num: 26 done: False
______________________
id: 51 reward: 0.0 service_time: 1156 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 42 reward: -0.009615384615384616 service_time: 1286 s_time: 21 penalty: 0 agent_num: 39 done: False
______________________
id: 46 reward: -0.008116883116883116 service_time: 1868 s_time: 15 penalty: 0 agent_num: 33 done: False
______________________
id: 49 reward: -0.014961389961389961 service_time: 1688 s_time: 31 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: -0.002551020408163265 service_time: 1690 s_time: 7 penalty: 0 agent_num: 49 done: False
______________________
id: 50 reward: -0.021551724137931036 service_time: 1850 s_time: 35 penalty: 0 agent_num: 29 done: False
______________________
id: 52 reward: 0.006448412698412698 service_time: 1911 s_time: -13 penalty: 0 agent_num: 36 done: False
______________________
id: 48 reward: 0.0 service_time: 1167 s_time: 0 penalty: 0 agent_num: 43 done: False
______________________
id: 44 reward: -0.025921658986175114 service_time: 2066 s_time: 45 penalty: 0 agent_num: 31 done: False
______________________
id: 43 reward: -0.003061224489795918 service_time: 1674 s_time: 6 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: -0.00977891156462585 service_time: 1188 s_time: 23 penalty: 0 agent_num: 42 done: False
______________________
Step:  2032
Pretraining Loss:  tensor(0.3093, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.02261904761904762 service_time: 831 s_time: 19 penalty: 0 agent_num: 15 done: False
______________________
id: 45 reward: 0.0 service_time: 1469 s_time: 0 penalty: 0 agent_num: 21 done: False
______________________
id: 55 reward: 0.020292207792207792 service_time: 1805 s_time: -25 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: -0.007988721804511278 service_time: 1173 s_time: 17 penalty: 0 agent_num: 38 done: False
______________________
id: 42 reward: -0.0260989010989011 service_time: 1343 s_time: 57 penalty: 0 agent_num: 39 done: False
______________________
id: 40 reward: -0.01510989010989011 service_time: 1638 s_time: 22 penalty: 0 agent_num: 26 done: False
______________________
id: 53 reward: -0.004008746355685131 service_time: 1701 s_time: 11 penalty: 0 agent_num: 49 done: False
______________________
id: 49 reward: -0.017374517374517374 service_time: 1724 s_time: 36 penalty: 0 agent_num: 37 done: False
______________________
id: 50 reward: -0.01847290640394089 service_time: 1880 s_time: 30 penalty: 0 agent_num: 29 done: False
______________________
id: 47 reward: -0.04503105590062112 service_time: 1234 s_time: 58 penalty: 0 agent_num: 23 done: False
______________________
id: 48 reward: -0.018687707641196014 service_time: 1212 s_time: 45 penalty: 0 agent_num: 43 done: False
______________________
id: 46 reward: -0.013528138528138528 service_time: 1893 s_time: 25 penalty: 0 agent_num: 33 done: False
______________________
id: 44 reward: -0.021889400921658985 service_time: 2104 s_time: 38 penalty: 0 agent_num: 31 done: False
______________________
id: 52 reward: -0.002976190476190476 service_time: 1917 s_time: 6 penalty: 0 agent_num: 36 done: False
______________________
id: 43 reward: -0.011224489795918367 service_time: 1696 s_time: 22 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: -0.012329931972789115 service_time: 1217 s_time: 29 penalty: 0 agent_num: 42 done: False
______________________
Step:  2048
Pretraining Loss:  tensor(0.2969, device='cuda:0', grad_fn=<MeanBackward0>)
id: 55 reward: -0.056006493506493504 service_time: 1874 s_time: 69 penalty: 0 agent_num: 22 done: False
______________________
id: 45 reward: -0.02806122448979592 service_time: 1502 s_time: 33 penalty: 0 agent_num: 21 done: False
______________________
id: 41 reward: -0.039285714285714285 service_time: 864 s_time: 33 penalty: 0 agent_num: 15 done: False
______________________
id: 51 reward: -0.011748120300751879 service_time: 1198 s_time: 25 penalty: 0 agent_num: 38 done: False
______________________
id: 40 reward: 0.019230769230769232 service_time: 1610 s_time: -28 penalty: 0 agent_num: 26 done: False
______________________
id: 42 reward: -0.010073260073260074 service_time: 1365 s_time: 22 penalty: 0 agent_num: 39 done: False
______________________
id: 52 reward: 0.00248015873015873 service_time: 1912 s_time: -5 penalty: 0 agent_num: 36 done: False
______________________
id: 49 reward: -0.009652509652509652 service_time: 1744 s_time: 20 penalty: 0 agent_num: 37 done: False
______________________
id: 48 reward: -0.015365448504983389 service_time: 1249 s_time: 37 penalty: 0 agent_num: 43 done: False
______________________
id: 46 reward: -0.015151515151515152 service_time: 1921 s_time: 28 penalty: 0 agent_num: 33 done: False
______________________
id: 54 reward: -0.013605442176870748 service_time: 1249 s_time: 32 penalty: 0 agent_num: 42 done: False
______________________
id: 53 reward: -0.005466472303206997 service_time: 1716 s_time: 15 penalty: 0 agent_num: 49 done: False
______________________
id: 47 reward: 0.009316770186335404 service_time: 1222 s_time: -12 penalty: 0 agent_num: 23 done: False
______________________
id: 44 reward: -0.02880184331797235 service_time: 2154 s_time: 50 penalty: 0 agent_num: 31 done: False
______________________
id: 50 reward: -0.024630541871921183 service_time: 1920 s_time: 40 penalty: 0 agent_num: 29 done: False
______________________
id: 43 reward: -0.022448979591836733 service_time: 1740 s_time: 44 penalty: 0 agent_num: 35 done: False
______________________
Step:  2064
Pretraining Loss:  tensor(0.2728, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: 0.0 service_time: 864 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 45 reward: 0.0 service_time: 1502 s_time: 0 penalty: 0 agent_num: 21 done: False
______________________
id: 47 reward: -0.10248447204968944 service_time: 1354 s_time: 132 penalty: 0 agent_num: 23 done: False
______________________
id: 55 reward: -0.025162337662337664 service_time: 1905 s_time: 31 penalty: 0 agent_num: 22 done: False
______________________
id: 42 reward: -0.011446886446886446 service_time: 1390 s_time: 25 penalty: 0 agent_num: 39 done: False
______________________
id: 54 reward: -0.006377551020408163 service_time: 1264 s_time: 15 penalty: 0 agent_num: 42 done: False
______________________
id: 51 reward: 0.0 service_time: 1198 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 49 reward: 0.0 service_time: 1744 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 52 reward: -0.005456349206349206 service_time: 1923 s_time: 11 penalty: 0 agent_num: 36 done: False
______________________
id: 40 reward: 0.014423076923076924 service_time: 1589 s_time: -21 penalty: 0 agent_num: 26 done: False
______________________
id: 46 reward: -0.012987012987012988 service_time: 1945 s_time: 24 penalty: 0 agent_num: 33 done: False
______________________
id: 53 reward: -0.009110787172011662 service_time: 1741 s_time: 25 penalty: 0 agent_num: 49 done: False
______________________
id: 48 reward: -0.015365448504983389 service_time: 1286 s_time: 37 penalty: 0 agent_num: 43 done: False
______________________
id: 43 reward: -0.012755102040816327 service_time: 1765 s_time: 25 penalty: 0 agent_num: 35 done: False
______________________
id: 44 reward: 0.002304147465437788 service_time: 2150 s_time: -4 penalty: 0 agent_num: 31 done: False
______________________
id: 50 reward: 0.0018472906403940886 service_time: 1917 s_time: -3 penalty: 0 agent_num: 29 done: False
______________________
Step:  2080
Pretraining Loss:  tensor(0.3062, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.02142857142857143 service_time: 882 s_time: 18 penalty: 0 agent_num: 15 done: False
______________________
id: 45 reward: 0.0 service_time: 1502 s_time: 0 penalty: 0 agent_num: 21 done: False
______________________
id: 55 reward: -0.011363636363636364 service_time: 1919 s_time: 14 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: 0.00046992481203007516 service_time: 1197 s_time: -1 penalty: 0 agent_num: 38 done: False
______________________
id: 42 reward: -0.009157509157509158 service_time: 1410 s_time: 20 penalty: 0 agent_num: 39 done: False
______________________
id: 40 reward: 0.0 service_time: 1589 s_time: 0 penalty: 0 agent_num: 26 done: False
______________________
id: 46 reward: -0.0016233766233766235 service_time: 1948 s_time: 3 penalty: 0 agent_num: 33 done: False
______________________
id: 47 reward: -0.020186335403726708 service_time: 1380 s_time: 26 penalty: 0 agent_num: 23 done: False
______________________
id: 48 reward: -0.008305647840531562 service_time: 1306 s_time: 20 penalty: 0 agent_num: 43 done: False
______________________
id: 49 reward: -0.03426640926640927 service_time: 1815 s_time: 71 penalty: 0 agent_num: 37 done: False
______________________
id: 52 reward: -0.04365079365079365 service_time: 2011 s_time: 88 penalty: 0 agent_num: 36 done: False
______________________
id: 53 reward: -0.0058309037900874635 service_time: 1757 s_time: 16 penalty: 0 agent_num: 49 done: False
______________________
id: 50 reward: 0.0006157635467980296 service_time: 1916 s_time: -1 penalty: 0 agent_num: 29 done: False
______________________
id: 54 reward: -0.01913265306122449 service_time: 1309 s_time: 45 penalty: 0 agent_num: 42 done: False
______________________
id: 43 reward: 0.0 service_time: 1765 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 44 reward: -0.002304147465437788 service_time: 2154 s_time: 4 penalty: 0 agent_num: 31 done: False
______________________
Step:  2096
Pretraining Loss:  tensor(0.3682, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.039285714285714285 service_time: 915 s_time: 33 penalty: 0 agent_num: 15 done: False
______________________
id: 45 reward: -0.0195578231292517 service_time: 1525 s_time: 23 penalty: 0 agent_num: 21 done: False
______________________
id: 51 reward: -0.008928571428571428 service_time: 1216 s_time: 19 penalty: 0 agent_num: 38 done: False
______________________
id: 42 reward: -0.00641025641025641 service_time: 1424 s_time: 14 penalty: 0 agent_num: 39 done: False
______________________
id: 47 reward: -0.02872670807453416 service_time: 1417 s_time: 37 penalty: 0 agent_num: 23 done: False
______________________
id: 55 reward: -0.00974025974025974 service_time: 1931 s_time: 12 penalty: 0 agent_num: 22 done: False
______________________
id: 40 reward: -0.006868131868131868 service_time: 1599 s_time: 10 penalty: 0 agent_num: 26 done: False
______________________
id: 49 reward: -0.008687258687258687 service_time: 1833 s_time: 18 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: -0.0014577259475218659 service_time: 1761 s_time: 4 penalty: 0 agent_num: 49 done: False
______________________
id: 48 reward: -0.005398671096345515 service_time: 1319 s_time: 13 penalty: 0 agent_num: 43 done: False
______________________
id: 50 reward: -0.05233990147783251 service_time: 2001 s_time: 85 penalty: 0 agent_num: 29 done: False
______________________
id: 43 reward: -0.018877551020408164 service_time: 1802 s_time: 37 penalty: 0 agent_num: 35 done: False
______________________
id: 52 reward: -0.01240079365079365 service_time: 2036 s_time: 25 penalty: 0 agent_num: 36 done: False
______________________
id: 46 reward: 0.0005411255411255411 service_time: 1947 s_time: -1 penalty: 0 agent_num: 33 done: False
______________________
id: 54 reward: 0.0 service_time: 1309 s_time: 0 penalty: 0 agent_num: 42 done: False
______________________
id: 44 reward: -0.05011520737327189 service_time: 2241 s_time: 87 penalty: 0 agent_num: 31 done: False
______________________
Step:  2112
Pretraining Loss:  tensor(0.3568, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: 0.0 service_time: 915 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 45 reward: -0.017857142857142856 service_time: 1546 s_time: 21 penalty: 0 agent_num: 21 done: False
______________________
id: 55 reward: 0.036525974025974024 service_time: 1886 s_time: -45 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: -0.006211180124223602 service_time: 1425 s_time: 8 penalty: 0 agent_num: 23 done: False
______________________
id: 42 reward: -0.013278388278388278 service_time: 1453 s_time: 29 penalty: 0 agent_num: 39 done: False
______________________
id: 46 reward: -0.013528138528138528 service_time: 1972 s_time: 25 penalty: 0 agent_num: 33 done: False
______________________
id: 40 reward: -0.034340659340659344 service_time: 1649 s_time: 50 penalty: 0 agent_num: 26 done: False
______________________
id: 51 reward: -0.0042293233082706765 service_time: 1225 s_time: 9 penalty: 0 agent_num: 38 done: False
______________________
id: 50 reward: -0.021551724137931036 service_time: 2036 s_time: 35 penalty: 0 agent_num: 29 done: False
______________________
id: 52 reward: -0.020833333333333332 service_time: 2078 s_time: 42 penalty: 0 agent_num: 36 done: False
______________________
id: 53 reward: -0.0058309037900874635 service_time: 1777 s_time: 16 penalty: 0 agent_num: 49 done: False
______________________
id: 54 reward: 0.0 service_time: 1309 s_time: 0 penalty: 0 agent_num: 42 done: False
______________________
id: 48 reward: -0.0029069767441860465 service_time: 1326 s_time: 7 penalty: 0 agent_num: 43 done: False
______________________
id: 44 reward: -0.02534562211981567 service_time: 2285 s_time: 44 penalty: 0 agent_num: 31 done: False
______________________
id: 43 reward: -0.020918367346938777 service_time: 1843 s_time: 41 penalty: 0 agent_num: 35 done: False
______________________
id: 49 reward: 0.0 service_time: 1833 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
Step:  2128
Pretraining Loss:  tensor(0.3317, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.02857142857142857 service_time: 939 s_time: 24 penalty: 0 agent_num: 15 done: False
______________________
id: 55 reward: -0.06655844155844155 service_time: 1968 s_time: 82 penalty: 0 agent_num: 22 done: False
______________________
id: 45 reward: -0.021258503401360544 service_time: 1571 s_time: 25 penalty: 0 agent_num: 21 done: False
______________________
id: 47 reward: -0.021739130434782608 service_time: 1453 s_time: 28 penalty: 0 agent_num: 23 done: False
______________________
id: 42 reward: -0.00641025641025641 service_time: 1467 s_time: 14 penalty: 0 agent_num: 39 done: False
______________________
id: 51 reward: 0.0 service_time: 1225 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 50 reward: 0.009852216748768473 service_time: 2020 s_time: -16 penalty: 0 agent_num: 29 done: False
______________________
id: 48 reward: -0.010382059800664452 service_time: 1351 s_time: 25 penalty: 0 agent_num: 43 done: False
______________________
id: 46 reward: -0.01948051948051948 service_time: 2008 s_time: 36 penalty: 0 agent_num: 33 done: False
______________________
id: 53 reward: 0.0 service_time: 1777 s_time: 0 penalty: 0 agent_num: 49 done: False
______________________
id: 54 reward: -0.00510204081632653 service_time: 1321 s_time: 12 penalty: 0 agent_num: 42 done: False
______________________
id: 40 reward: 0.0013736263736263737 service_time: 1647 s_time: -2 penalty: 0 agent_num: 26 done: False
______________________
id: 49 reward: -0.036196911196911194 service_time: 1908 s_time: 75 penalty: 0 agent_num: 37 done: False
______________________
id: 43 reward: -0.045408163265306126 service_time: 1932 s_time: 89 penalty: 0 agent_num: 35 done: False
______________________
id: 44 reward: 0.0017281105990783411 service_time: 2282 s_time: -3 penalty: 0 agent_num: 31 done: False
______________________
id: 52 reward: -0.011408730158730158 service_time: 2101 s_time: 23 penalty: 0 agent_num: 36 done: False
______________________
Step:  2144
Pretraining Loss:  tensor(0.3093, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: 0.0 service_time: 939 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 45 reward: -0.06377551020408163 service_time: 1646 s_time: 75 penalty: 0 agent_num: 21 done: False
______________________
id: 40 reward: -0.08585164835164835 service_time: 1772 s_time: 125 penalty: 0 agent_num: 26 done: False
______________________
id: 51 reward: -0.009398496240601503 service_time: 1245 s_time: 20 penalty: 0 agent_num: 38 done: False
______________________
id: 47 reward: -0.006987577639751553 service_time: 1462 s_time: 9 penalty: 0 agent_num: 23 done: False
______________________
id: 55 reward: 0.012987012987012988 service_time: 1952 s_time: -16 penalty: 0 agent_num: 22 done: False
______________________
id: 42 reward: -0.013278388278388278 service_time: 1496 s_time: 29 penalty: 0 agent_num: 39 done: False
______________________
id: 50 reward: 0.0006157635467980296 service_time: 2019 s_time: -1 penalty: 0 agent_num: 29 done: False
______________________
id: 46 reward: -0.03300865800865801 service_time: 2069 s_time: 61 penalty: 0 agent_num: 33 done: False
______________________
id: 53 reward: -0.02587463556851312 service_time: 1848 s_time: 71 penalty: 0 agent_num: 49 done: False
______________________
id: 49 reward: 0.0 service_time: 1908 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 52 reward: -0.010912698412698412 service_time: 2123 s_time: 22 penalty: 0 agent_num: 36 done: False
______________________
id: 48 reward: -0.022425249169435217 service_time: 1405 s_time: 54 penalty: 0 agent_num: 43 done: False
______________________
id: 43 reward: 0.00816326530612245 service_time: 1916 s_time: -16 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: -0.012755102040816327 service_time: 1351 s_time: 30 penalty: 0 agent_num: 42 done: False
______________________
id: 44 reward: 0.012096774193548387 service_time: 2261 s_time: -21 penalty: 0 agent_num: 31 done: False
______________________
Step:  2160
Pretraining Loss:  tensor(0.3155, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.05119047619047619 service_time: 982 s_time: 43 penalty: 0 agent_num: 15 done: False
______________________
id: 55 reward: 0.0 service_time: 1952 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: -0.02251552795031056 service_time: 1491 s_time: 29 penalty: 0 agent_num: 23 done: False
______________________
id: 50 reward: 0.0166256157635468 service_time: 1992 s_time: -27 penalty: 0 agent_num: 29 done: False
______________________
id: 51 reward: -0.020206766917293232 service_time: 1288 s_time: 43 penalty: 0 agent_num: 38 done: False
______________________
id: 45 reward: -0.09948979591836735 service_time: 1763 s_time: 117 penalty: 0 agent_num: 21 done: False
______________________
id: 42 reward: -0.01098901098901099 service_time: 1520 s_time: 24 penalty: 0 agent_num: 39 done: False
______________________
id: 48 reward: -0.0070598006644518275 service_time: 1422 s_time: 17 penalty: 0 agent_num: 43 done: False
______________________
id: 40 reward: -0.015796703296703296 service_time: 1795 s_time: 23 penalty: 0 agent_num: 26 done: False
______________________
id: 54 reward: -0.008928571428571428 service_time: 1372 s_time: 21 penalty: 0 agent_num: 42 done: False
______________________
id: 52 reward: -0.01984126984126984 service_time: 2163 s_time: 40 penalty: 0 agent_num: 36 done: False
______________________
id: 43 reward: -0.04081632653061224 service_time: 1996 s_time: 80 penalty: 0 agent_num: 35 done: False
______________________
id: 44 reward: 0.005184331797235023 service_time: 2252 s_time: -9 penalty: 0 agent_num: 31 done: False
______________________
id: 53 reward: -0.01020408163265306 service_time: 1876 s_time: 28 penalty: 0 agent_num: 49 done: False
______________________
id: 49 reward: -0.037644787644787646 service_time: 1986 s_time: 78 penalty: 0 agent_num: 37 done: False
______________________
id: 46 reward: -0.02002164502164502 service_time: 2106 s_time: 37 penalty: 0 agent_num: 33 done: False
______________________
Step:  2176
Pretraining Loss:  tensor(0.3595, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: 0.009523809523809525 service_time: 974 s_time: -8 penalty: 0 agent_num: 15 done: False
______________________
id: 45 reward: -0.11224489795918367 service_time: 1895 s_time: 132 penalty: 0 agent_num: 21 done: False
______________________
id: 40 reward: -0.02403846153846154 service_time: 1830 s_time: 35 penalty: 0 agent_num: 26 done: False
______________________
id: 51 reward: 0.0009398496240601503 service_time: 1286 s_time: -2 penalty: 0 agent_num: 38 done: False
______________________
id: 50 reward: 0.0012315270935960591 service_time: 1990 s_time: -2 penalty: 0 agent_num: 29 done: False
______________________
id: 55 reward: 0.0 service_time: 1952 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: -0.05046583850931677 service_time: 1556 s_time: 65 penalty: 0 agent_num: 23 done: False
______________________
id: 44 reward: -0.041474654377880185 service_time: 2324 s_time: 72 penalty: 0 agent_num: 31 done: False
______________________
id: 54 reward: 0.0 service_time: 1372 s_time: 0 penalty: 0 agent_num: 42 done: False
______________________
id: 42 reward: -0.021062271062271064 service_time: 1566 s_time: 46 penalty: 0 agent_num: 39 done: False
______________________
id: 48 reward: -0.012043189368770765 service_time: 1451 s_time: 29 penalty: 0 agent_num: 43 done: False
______________________
id: 52 reward: -0.008432539682539682 service_time: 2180 s_time: 17 penalty: 0 agent_num: 36 done: False
______________________
id: 46 reward: -0.0010822510822510823 service_time: 2108 s_time: 2 penalty: 0 agent_num: 33 done: False
______________________
id: 53 reward: -0.014941690962099125 service_time: 1917 s_time: 41 penalty: 0 agent_num: 49 done: False
______________________
id: 49 reward: 0.0014478764478764478 service_time: 1983 s_time: -3 penalty: 0 agent_num: 37 done: False
______________________
id: 43 reward: -0.03316326530612245 service_time: 2061 s_time: 65 penalty: 0 agent_num: 35 done: False
______________________
Step:  2192
Pretraining Loss:  tensor(0.3529, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: 0.0 service_time: 974 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 55 reward: 0.0 service_time: 1952 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 45 reward: -0.031462585034013606 service_time: 1932 s_time: 37 penalty: 0 agent_num: 21 done: False
______________________
id: 47 reward: 0.0007763975155279503 service_time: 1555 s_time: -1 penalty: 0 agent_num: 23 done: False
______________________
id: 50 reward: 0.011083743842364532 service_time: 1972 s_time: -18 penalty: 0 agent_num: 29 done: False
______________________
id: 54 reward: -0.015306122448979591 service_time: 1408 s_time: 36 penalty: 0 agent_num: 42 done: False
______________________
id: 51 reward: -0.017857142857142856 service_time: 1324 s_time: 38 penalty: 0 agent_num: 38 done: False
______________________
id: 48 reward: -0.015365448504983389 service_time: 1488 s_time: 37 penalty: 0 agent_num: 43 done: False
______________________
id: 52 reward: -0.017857142857142856 service_time: 2216 s_time: 36 penalty: 0 agent_num: 36 done: False
______________________
id: 53 reward: 0.0007288629737609329 service_time: 1915 s_time: -2 penalty: 0 agent_num: 49 done: False
______________________
id: 44 reward: -0.06451612903225806 service_time: 2436 s_time: 112 penalty: 0 agent_num: 31 done: False
______________________
id: 42 reward: -0.011904761904761904 service_time: 1592 s_time: 26 penalty: 0 agent_num: 39 done: False
______________________
id: 49 reward: -0.005791505791505791 service_time: 1995 s_time: 12 penalty: 0 agent_num: 37 done: False
______________________
id: 43 reward: -0.014285714285714285 service_time: 2089 s_time: 28 penalty: 0 agent_num: 35 done: False
______________________
id: 40 reward: -0.08241758241758242 service_time: 1950 s_time: 120 penalty: 0 agent_num: 26 done: False
______________________
id: 46 reward: -0.027056277056277056 service_time: 2158 s_time: 50 penalty: 0 agent_num: 33 done: False
______________________
Step:  2208
Pretraining Loss:  tensor(0.3295, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.03571428571428571 service_time: 1004 s_time: 30 penalty: 0 agent_num: 15 done: False
______________________
id: 45 reward: -0.11139455782312925 service_time: 2063 s_time: 131 penalty: 0 agent_num: 21 done: False
______________________
id: 55 reward: -0.0349025974025974 service_time: 1995 s_time: 43 penalty: 0 agent_num: 22 done: False
______________________
id: 50 reward: -0.02832512315270936 service_time: 2018 s_time: 46 penalty: 0 agent_num: 29 done: False
______________________
id: 54 reward: 0.0 service_time: 1408 s_time: 0 penalty: 0 agent_num: 42 done: False
______________________
id: 48 reward: -0.009136212624584718 service_time: 1510 s_time: 22 penalty: 0 agent_num: 43 done: False
______________________
id: 51 reward: 0.002819548872180451 service_time: 1318 s_time: -6 penalty: 0 agent_num: 38 done: False
______________________
id: 40 reward: -0.057005494505494504 service_time: 2033 s_time: 83 penalty: 0 agent_num: 26 done: False
______________________
id: 53 reward: -0.013848396501457727 service_time: 1953 s_time: 38 penalty: 0 agent_num: 49 done: False
______________________
id: 46 reward: 0.006493506493506494 service_time: 2146 s_time: -12 penalty: 0 agent_num: 33 done: False
______________________
id: 47 reward: -0.08540372670807453 service_time: 1665 s_time: 110 penalty: 0 agent_num: 23 done: False
______________________
id: 42 reward: -0.009615384615384616 service_time: 1613 s_time: 21 penalty: 0 agent_num: 39 done: False
______________________
id: 49 reward: -0.005791505791505791 service_time: 2007 s_time: 12 penalty: 0 agent_num: 37 done: False
______________________
id: 52 reward: -0.019345238095238096 service_time: 2255 s_time: 39 penalty: 0 agent_num: 36 done: False
______________________
id: 44 reward: 0.005184331797235023 service_time: 2427 s_time: -9 penalty: 0 agent_num: 31 done: False
______________________
id: 43 reward: 0.0035714285714285713 service_time: 2082 s_time: -7 penalty: 0 agent_num: 35 done: False
______________________
Step:  2224
Pretraining Loss:  tensor(0.3278, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.04047619047619048 service_time: 1038 s_time: 34 penalty: 0 agent_num: 15 done: False
______________________
id: 55 reward: 0.0 service_time: 1995 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 50 reward: 0.006157635467980296 service_time: 2008 s_time: -10 penalty: 0 agent_num: 29 done: False
______________________
id: 45 reward: 0.07993197278911565 service_time: 1969 s_time: -94 penalty: 0 agent_num: 21 done: False
______________________
id: 47 reward: 0.034161490683229816 service_time: 1621 s_time: -44 penalty: 0 agent_num: 23 done: False
______________________
id: 54 reward: -0.011904761904761904 service_time: 1436 s_time: 28 penalty: 0 agent_num: 42 done: False
______________________
id: 44 reward: 0.0069124423963133645 service_time: 2415 s_time: -12 penalty: 0 agent_num: 31 done: False
______________________
id: 51 reward: -0.017857142857142856 service_time: 1356 s_time: 38 penalty: 0 agent_num: 38 done: False
______________________
id: 53 reward: -0.007653061224489796 service_time: 1974 s_time: 21 penalty: 0 agent_num: 49 done: False
______________________
id: 48 reward: -0.013289036544850499 service_time: 1542 s_time: 32 penalty: 0 agent_num: 43 done: False
______________________
id: 40 reward: -0.020604395604395604 service_time: 2063 s_time: 30 penalty: 0 agent_num: 26 done: False
______________________
id: 42 reward: 0.0004578754578754579 service_time: 1612 s_time: -1 penalty: 0 agent_num: 39 done: False
______________________
id: 43 reward: -0.023979591836734693 service_time: 2129 s_time: 47 penalty: 0 agent_num: 35 done: False
______________________
id: 52 reward: -0.007936507936507936 service_time: 2271 s_time: 16 penalty: 0 agent_num: 36 done: False
______________________
id: 49 reward: -0.0111003861003861 service_time: 2030 s_time: 23 penalty: 0 agent_num: 37 done: False
______________________
id: 46 reward: -0.032467532467532464 service_time: 2206 s_time: 60 penalty: 0 agent_num: 33 done: False
______________________
Step:  2240
Pretraining Loss:  tensor(0.3744, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: 0.0 service_time: 1038 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 55 reward: -0.05357142857142857 service_time: 2061 s_time: 66 penalty: 0 agent_num: 22 done: False
______________________
id: 45 reward: -0.026360544217687076 service_time: 2000 s_time: 31 penalty: 0 agent_num: 21 done: False
______________________
id: 47 reward: 0.043478260869565216 service_time: 1565 s_time: -56 penalty: 0 agent_num: 23 done: False
______________________
id: 50 reward: -0.02894088669950739 service_time: 2055 s_time: 47 penalty: 0 agent_num: 29 done: False
______________________
id: 51 reward: 0.0 service_time: 1356 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 42 reward: -0.010073260073260074 service_time: 1634 s_time: 22 penalty: 0 agent_num: 39 done: False
______________________
id: 44 reward: -0.054723502304147464 service_time: 2510 s_time: 95 penalty: 0 agent_num: 31 done: False
______________________
id: 54 reward: -0.0055272108843537416 service_time: 1449 s_time: 13 penalty: 0 agent_num: 42 done: False
______________________
id: 53 reward: -0.01858600583090379 service_time: 2025 s_time: 51 penalty: 0 agent_num: 49 done: False
______________________
id: 46 reward: -0.006493506493506494 service_time: 2218 s_time: 12 penalty: 0 agent_num: 33 done: False
______________________
id: 40 reward: -0.02197802197802198 service_time: 2095 s_time: 32 penalty: 0 agent_num: 26 done: False
______________________
id: 48 reward: 0.0 service_time: 1542 s_time: 0 penalty: 0 agent_num: 43 done: False
______________________
id: 43 reward: -0.01683673469387755 service_time: 2162 s_time: 33 penalty: 0 agent_num: 35 done: False
______________________
id: 49 reward: -0.009652509652509652 service_time: 2050 s_time: 20 penalty: 0 agent_num: 37 done: False
______________________
id: 52 reward: -0.008432539682539682 service_time: 2288 s_time: 17 penalty: 0 agent_num: 36 done: False
______________________
Step:  2256
Pretraining Loss:  tensor(0.3448, device='cuda:0', grad_fn=<MeanBackward0>)
id: 55 reward: -0.028409090909090908 service_time: 2096 s_time: 35 penalty: 0 agent_num: 22 done: False
______________________
id: 45 reward: 0.0017006802721088435 service_time: 1998 s_time: -2 penalty: 0 agent_num: 21 done: False
______________________
id: 41 reward: -0.02619047619047619 service_time: 1060 s_time: 22 penalty: 0 agent_num: 15 done: False
______________________
id: 47 reward: -0.04114906832298137 service_time: 1618 s_time: 53 penalty: 0 agent_num: 23 done: False
______________________
id: 44 reward: 0.014400921658986175 service_time: 2485 s_time: -25 penalty: 0 agent_num: 31 done: False
______________________
id: 54 reward: -0.00935374149659864 service_time: 1471 s_time: 22 penalty: 0 agent_num: 42 done: False
______________________
id: 42 reward: -0.0004578754578754579 service_time: 1635 s_time: 1 penalty: 0 agent_num: 39 done: False
______________________
id: 50 reward: -0.011699507389162561 service_time: 2074 s_time: 19 penalty: 0 agent_num: 29 done: False
______________________
id: 53 reward: -0.0014577259475218659 service_time: 2029 s_time: 4 penalty: 0 agent_num: 49 done: False
______________________
id: 51 reward: -0.009868421052631578 service_time: 1377 s_time: 21 penalty: 0 agent_num: 38 done: False
______________________
id: 40 reward: -0.04120879120879121 service_time: 2155 s_time: 60 penalty: 0 agent_num: 26 done: False
______________________
id: 43 reward: -0.01173469387755102 service_time: 2185 s_time: 23 penalty: 0 agent_num: 35 done: False
______________________
id: 52 reward: -0.014384920634920634 service_time: 2317 s_time: 29 penalty: 0 agent_num: 36 done: False
______________________
id: 48 reward: -0.01287375415282392 service_time: 1573 s_time: 31 penalty: 0 agent_num: 43 done: False
______________________
id: 49 reward: -0.015444015444015444 service_time: 2082 s_time: 32 penalty: 0 agent_num: 37 done: False
______________________
id: 46 reward: -0.011904761904761904 service_time: 2240 s_time: 22 penalty: 0 agent_num: 33 done: False
______________________
Step:  2272
Pretraining Loss:  tensor(0.3687, device='cuda:0', grad_fn=<MeanBackward0>)
id: 55 reward: -0.06168831168831169 service_time: 2172 s_time: 76 penalty: 0 agent_num: 22 done: False
______________________
id: 45 reward: 0.0 service_time: 1998 s_time: 0 penalty: 0 agent_num: 21 done: False
______________________
id: 41 reward: -0.015476190476190477 service_time: 1073 s_time: 13 penalty: 0 agent_num: 15 done: False
______________________
id: 47 reward: 0.0 service_time: 1618 s_time: 0 penalty: 0 agent_num: 23 done: False
______________________
id: 50 reward: -0.042487684729064036 service_time: 2143 s_time: 69 penalty: 0 agent_num: 29 done: False
______________________
id: 51 reward: 0.0009398496240601503 service_time: 1375 s_time: -2 penalty: 0 agent_num: 38 done: False
______________________
id: 42 reward: -0.013278388278388278 service_time: 1664 s_time: 29 penalty: 0 agent_num: 39 done: False
______________________
id: 49 reward: -0.00048262548262548264 service_time: 2083 s_time: 1 penalty: 0 agent_num: 37 done: False
______________________
id: 46 reward: -0.01406926406926407 service_time: 2266 s_time: 26 penalty: 0 agent_num: 33 done: False
______________________
id: 54 reward: 0.0 service_time: 1471 s_time: 0 penalty: 0 agent_num: 42 done: False
______________________
id: 52 reward: -0.009424603174603174 service_time: 2336 s_time: 19 penalty: 0 agent_num: 36 done: False
______________________
id: 40 reward: -0.018543956043956044 service_time: 2182 s_time: 27 penalty: 0 agent_num: 26 done: False
______________________
id: 48 reward: -0.012043189368770765 service_time: 1602 s_time: 29 penalty: 0 agent_num: 43 done: False
______________________
id: 53 reward: -0.013848396501457727 service_time: 2067 s_time: 38 penalty: 0 agent_num: 49 done: False
______________________
id: 44 reward: -0.001152073732718894 service_time: 2487 s_time: 2 penalty: 0 agent_num: 31 done: False
______________________
id: 43 reward: -0.013775510204081633 service_time: 2212 s_time: 27 penalty: 0 agent_num: 35 done: False
______________________
Step:  2288
Pretraining Loss:  tensor(0.3533, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.04047619047619048 service_time: 1107 s_time: 34 penalty: 0 agent_num: 15 done: False
______________________
id: 55 reward: 0.0 service_time: 2172 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 45 reward: 0.0 service_time: 1998 s_time: 0 penalty: 0 agent_num: 21 done: False
______________________
id: 47 reward: -0.017857142857142856 service_time: 1641 s_time: 23 penalty: 0 agent_num: 23 done: False
______________________
id: 50 reward: -0.04926108374384237 service_time: 2223 s_time: 80 penalty: 0 agent_num: 29 done: False
______________________
id: 42 reward: -0.014194139194139194 service_time: 1695 s_time: 31 penalty: 0 agent_num: 39 done: False
______________________
id: 51 reward: -0.01362781954887218 service_time: 1404 s_time: 29 penalty: 0 agent_num: 38 done: False
______________________
id: 44 reward: -0.023617511520737326 service_time: 2528 s_time: 41 penalty: 0 agent_num: 31 done: False
______________________
id: 48 reward: -0.006229235880398671 service_time: 1617 s_time: 15 penalty: 0 agent_num: 43 done: False
______________________
id: 49 reward: -0.03909266409266409 service_time: 2164 s_time: 81 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: -0.01020408163265306 service_time: 2095 s_time: 28 penalty: 0 agent_num: 49 done: False
______________________
id: 52 reward: 0.001984126984126984 service_time: 2332 s_time: -4 penalty: 0 agent_num: 36 done: False
______________________
id: 43 reward: -0.015816326530612244 service_time: 2243 s_time: 31 penalty: 0 agent_num: 35 done: False
______________________
id: 40 reward: -0.005494505494505495 service_time: 2190 s_time: 8 penalty: 0 agent_num: 26 done: False
______________________
id: 54 reward: -0.016156462585034014 service_time: 1509 s_time: 38 penalty: 0 agent_num: 42 done: False
______________________
id: 46 reward: -0.012987012987012988 service_time: 2290 s_time: 24 penalty: 0 agent_num: 33 done: False
______________________
Step:  2304
Pretraining Loss:  tensor(0.3491, device='cuda:0', grad_fn=<MeanBackward0>)
id: 55 reward: 0.011363636363636364 service_time: 2158 s_time: -14 penalty: 0 agent_num: 22 done: False
______________________
id: 41 reward: -0.04880952380952381 service_time: 1148 s_time: 41 penalty: 0 agent_num: 15 done: False
______________________
id: 45 reward: 0.0 service_time: 1998 s_time: 0 penalty: 0 agent_num: 21 done: False
______________________
id: 47 reward: -0.018633540372670808 service_time: 1665 s_time: 24 penalty: 0 agent_num: 23 done: False
______________________
id: 42 reward: 0.0 service_time: 1695 s_time: 0 penalty: 0 agent_num: 39 done: False
______________________
id: 54 reward: -0.00977891156462585 service_time: 1532 s_time: 23 penalty: 0 agent_num: 42 done: False
______________________
id: 48 reward: -0.009136212624584718 service_time: 1639 s_time: 22 penalty: 0 agent_num: 43 done: False
______________________
id: 51 reward: -0.011748120300751879 service_time: 1429 s_time: 25 penalty: 0 agent_num: 38 done: False
______________________
id: 52 reward: -0.03720238095238095 service_time: 2407 s_time: 75 penalty: 0 agent_num: 36 done: False
______________________
id: 40 reward: -0.01304945054945055 service_time: 2209 s_time: 19 penalty: 0 agent_num: 26 done: False
______________________
id: 50 reward: -0.029556650246305417 service_time: 2271 s_time: 48 penalty: 0 agent_num: 29 done: False
______________________
id: 46 reward: -0.01948051948051948 service_time: 2326 s_time: 36 penalty: 0 agent_num: 33 done: False
______________________
id: 53 reward: 0.0 service_time: 2095 s_time: 0 penalty: 0 agent_num: 49 done: False
______________________
id: 43 reward: -0.012755102040816327 service_time: 2268 s_time: 25 penalty: 0 agent_num: 35 done: False
______________________
id: 44 reward: 0.001152073732718894 service_time: 2526 s_time: -2 penalty: 0 agent_num: 31 done: False
______________________
id: 49 reward: -0.0111003861003861 service_time: 2187 s_time: 23 penalty: 0 agent_num: 37 done: False
______________________
Step:  2320
Pretraining Loss:  tensor(0.2998, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: 0.0 service_time: 1148 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 55 reward: -0.017045454545454544 service_time: 2179 s_time: 21 penalty: 0 agent_num: 22 done: False
______________________
id: 45 reward: -0.05357142857142857 service_time: 2061 s_time: 63 penalty: 0 agent_num: 21 done: False
______________________
id: 50 reward: -0.01539408866995074 service_time: 2296 s_time: 25 penalty: 0 agent_num: 29 done: False
______________________
id: 51 reward: -0.006109022556390977 service_time: 1442 s_time: 13 penalty: 0 agent_num: 38 done: False
______________________
id: 47 reward: -0.021739130434782608 service_time: 1693 s_time: 28 penalty: 0 agent_num: 23 done: False
______________________
id: 42 reward: -0.01098901098901099 service_time: 1719 s_time: 24 penalty: 0 agent_num: 39 done: False
______________________
id: 40 reward: -0.008928571428571428 service_time: 2222 s_time: 13 penalty: 0 agent_num: 26 done: False
______________________
id: 44 reward: -0.038018433179723504 service_time: 2592 s_time: 66 penalty: 0 agent_num: 31 done: False
______________________
id: 52 reward: -0.015376984126984126 service_time: 2438 s_time: 31 penalty: 0 agent_num: 36 done: False
______________________
id: 53 reward: -0.013848396501457727 service_time: 2133 s_time: 38 penalty: 0 agent_num: 49 done: False
______________________
id: 49 reward: -0.002413127413127413 service_time: 2192 s_time: 5 penalty: 0 agent_num: 37 done: False
______________________
id: 46 reward: 0.0010822510822510823 service_time: 2324 s_time: -2 penalty: 0 agent_num: 33 done: False
______________________
id: 48 reward: -0.013289036544850499 service_time: 1671 s_time: 32 penalty: 0 agent_num: 43 done: False
______________________
id: 43 reward: -0.0066326530612244895 service_time: 2281 s_time: 13 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: -0.008928571428571428 service_time: 1553 s_time: 21 penalty: 0 agent_num: 42 done: False
______________________
Step:  2336
Pretraining Loss:  tensor(0.3013, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.014285714285714285 service_time: 1160 s_time: 12 penalty: 0 agent_num: 15 done: False
______________________
id: 45 reward: 0.017857142857142856 service_time: 2040 s_time: -21 penalty: 0 agent_num: 21 done: False
______________________
id: 55 reward: -0.030032467532467532 service_time: 2216 s_time: 37 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: 0.0 service_time: 1693 s_time: 0 penalty: 0 agent_num: 23 done: False
______________________
id: 51 reward: 0.0009398496240601503 service_time: 1440 s_time: -2 penalty: 0 agent_num: 38 done: False
______________________
id: 42 reward: 0.0 service_time: 1719 s_time: 0 penalty: 0 agent_num: 39 done: False
______________________
id: 50 reward: -0.019704433497536946 service_time: 2328 s_time: 32 penalty: 0 agent_num: 29 done: False
______________________
id: 49 reward: -0.009652509652509652 service_time: 2212 s_time: 20 penalty: 0 agent_num: 37 done: False
______________________
id: 48 reward: -0.009966777408637873 service_time: 1695 s_time: 24 penalty: 0 agent_num: 43 done: False
______________________
id: 52 reward: -0.015873015873015872 service_time: 2470 s_time: 32 penalty: 0 agent_num: 36 done: False
______________________
id: 46 reward: -0.023809523809523808 service_time: 2368 s_time: 44 penalty: 0 agent_num: 33 done: False
______________________
id: 54 reward: -0.004251700680272109 service_time: 1563 s_time: 10 penalty: 0 agent_num: 42 done: False
______________________
id: 40 reward: 0.0 service_time: 2222 s_time: 0 penalty: 0 agent_num: 26 done: False
______________________
id: 44 reward: -0.008640552995391706 service_time: 2607 s_time: 15 penalty: 0 agent_num: 31 done: False
______________________
id: 53 reward: -0.0029154518950437317 service_time: 2141 s_time: 8 penalty: 0 agent_num: 49 done: False
______________________
id: 43 reward: -0.01173469387755102 service_time: 2304 s_time: 23 penalty: 0 agent_num: 35 done: False
______________________
Step:  2352
Pretraining Loss:  tensor(0.2923, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: 0.0 service_time: 1160 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 55 reward: -0.021915584415584416 service_time: 2243 s_time: 27 penalty: 0 agent_num: 22 done: False
______________________
id: 45 reward: 0.0 service_time: 2040 s_time: 0 penalty: 0 agent_num: 21 done: False
______________________
id: 50 reward: -0.07820197044334976 service_time: 2455 s_time: 127 penalty: 0 agent_num: 29 done: False
______________________
id: 51 reward: -0.007518796992481203 service_time: 1456 s_time: 16 penalty: 0 agent_num: 38 done: False
______________________
id: 40 reward: -0.04807692307692308 service_time: 2292 s_time: 70 penalty: 0 agent_num: 26 done: False
______________________
id: 47 reward: -0.02717391304347826 service_time: 1728 s_time: 35 penalty: 0 agent_num: 23 done: False
______________________
id: 44 reward: -0.016705069124423964 service_time: 2636 s_time: 29 penalty: 0 agent_num: 31 done: False
______________________
id: 42 reward: -0.030677655677655676 service_time: 1786 s_time: 67 penalty: 0 agent_num: 39 done: False
______________________
id: 46 reward: -0.022727272727272728 service_time: 2410 s_time: 42 penalty: 0 agent_num: 33 done: False
______________________
id: 53 reward: 0.0 service_time: 2141 s_time: 0 penalty: 0 agent_num: 49 done: False
______________________
id: 49 reward: -0.018822393822393823 service_time: 2251 s_time: 39 penalty: 0 agent_num: 37 done: False
______________________
id: 48 reward: -0.011627906976744186 service_time: 1723 s_time: 28 penalty: 0 agent_num: 43 done: False
______________________
id: 43 reward: -0.014285714285714285 service_time: 2332 s_time: 28 penalty: 0 agent_num: 35 done: False
______________________
id: 52 reward: -0.013888888888888888 service_time: 2498 s_time: 28 penalty: 0 agent_num: 36 done: False
______________________
id: 54 reward: 0.0 service_time: 1563 s_time: 0 penalty: 0 agent_num: 42 done: False
______________________
Step:  2368
Pretraining Loss:  tensor(0.3248, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.03214285714285714 service_time: 1187 s_time: 27 penalty: 0 agent_num: 15 done: False
______________________
id: 45 reward: -0.03316326530612245 service_time: 2079 s_time: 39 penalty: 0 agent_num: 21 done: False
______________________
id: 55 reward: -0.08603896103896104 service_time: 2349 s_time: 106 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: -0.005434782608695652 service_time: 1735 s_time: 7 penalty: 0 agent_num: 23 done: False
______________________
id: 51 reward: -0.0014097744360902255 service_time: 1459 s_time: 3 penalty: 0 agent_num: 38 done: False
______________________
id: 42 reward: 0.0 service_time: 1786 s_time: 0 penalty: 0 agent_num: 39 done: False
______________________
id: 52 reward: 0.00248015873015873 service_time: 2493 s_time: -5 penalty: 0 agent_num: 36 done: False
______________________
id: 40 reward: 0.004120879120879121 service_time: 2286 s_time: -6 penalty: 0 agent_num: 26 done: False
______________________
id: 50 reward: -0.03140394088669951 service_time: 2506 s_time: 51 penalty: 0 agent_num: 29 done: False
______________________
id: 46 reward: 0.0005411255411255411 service_time: 2409 s_time: -1 penalty: 0 agent_num: 33 done: False
______________________
id: 54 reward: -0.017431972789115645 service_time: 1604 s_time: 41 penalty: 0 agent_num: 42 done: False
______________________
id: 48 reward: 0.0012458471760797341 service_time: 1720 s_time: -3 penalty: 0 agent_num: 43 done: False
______________________
id: 49 reward: -0.013996138996138996 service_time: 2280 s_time: 29 penalty: 0 agent_num: 37 done: False
______________________
id: 43 reward: -0.017857142857142856 service_time: 2367 s_time: 35 penalty: 0 agent_num: 35 done: False
______________________
id: 44 reward: -0.00576036866359447 service_time: 2646 s_time: 10 penalty: 0 agent_num: 31 done: False
______________________
id: 53 reward: -0.01129737609329446 service_time: 2172 s_time: 31 penalty: 0 agent_num: 49 done: False
______________________
Step:  2384
Pretraining Loss:  tensor(0.3047, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: 0.0 service_time: 1187 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 45 reward: -0.05187074829931973 service_time: 2140 s_time: 61 penalty: 0 agent_num: 21 done: False
______________________
id: 55 reward: 0.0 service_time: 2349 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: -0.018633540372670808 service_time: 1759 s_time: 24 penalty: 0 agent_num: 23 done: False
______________________
id: 51 reward: 0.0 service_time: 1459 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 40 reward: -0.02197802197802198 service_time: 2318 s_time: 32 penalty: 0 agent_num: 26 done: False
______________________
id: 44 reward: -0.006336405529953917 service_time: 2657 s_time: 11 penalty: 0 agent_num: 31 done: False
______________________
id: 46 reward: 0.003787878787878788 service_time: 2402 s_time: -7 penalty: 0 agent_num: 33 done: False
______________________
id: 50 reward: -0.022167487684729065 service_time: 2542 s_time: 36 penalty: 0 agent_num: 29 done: False
______________________
id: 42 reward: -0.027472527472527472 service_time: 1846 s_time: 60 penalty: 0 agent_num: 39 done: False
______________________
id: 52 reward: -0.037698412698412696 service_time: 2569 s_time: 76 penalty: 0 agent_num: 36 done: False
______________________
id: 54 reward: -0.008928571428571428 service_time: 1625 s_time: 21 penalty: 0 agent_num: 42 done: False
______________________
id: 43 reward: -0.010714285714285714 service_time: 2388 s_time: 21 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.014950166112956811 service_time: 1756 s_time: 36 penalty: 0 agent_num: 43 done: False
______________________
id: 53 reward: 0.0 service_time: 2172 s_time: 0 penalty: 0 agent_num: 49 done: False
______________________
id: 49 reward: -0.017374517374517374 service_time: 2316 s_time: 36 penalty: 0 agent_num: 37 done: False
______________________
Step:  2400
Pretraining Loss:  tensor(0.3187, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.04642857142857143 service_time: 1226 s_time: 39 penalty: 0 agent_num: 15 done: False
______________________
id: 45 reward: -0.021258503401360544 service_time: 2165 s_time: 25 penalty: 0 agent_num: 21 done: False
______________________
id: 55 reward: -0.028409090909090908 service_time: 2384 s_time: 35 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: -0.03260869565217391 service_time: 1801 s_time: 42 penalty: 0 agent_num: 23 done: False
______________________
id: 51 reward: -0.016917293233082706 service_time: 1495 s_time: 36 penalty: 0 agent_num: 38 done: False
______________________
id: 42 reward: -0.003205128205128205 service_time: 1853 s_time: 7 penalty: 0 agent_num: 39 done: False
______________________
id: 40 reward: 0.006181318681318681 service_time: 2309 s_time: -9 penalty: 0 agent_num: 26 done: False
______________________
id: 44 reward: -0.020737327188940093 service_time: 2693 s_time: 36 penalty: 0 agent_num: 31 done: False
______________________
id: 54 reward: 0.0 service_time: 1625 s_time: 0 penalty: 0 agent_num: 42 done: False
______________________
id: 52 reward: -0.011904761904761904 service_time: 2593 s_time: 24 penalty: 0 agent_num: 36 done: False
______________________
id: 46 reward: -0.04274891774891775 service_time: 2481 s_time: 79 penalty: 0 agent_num: 33 done: False
______________________
id: 43 reward: -0.007142857142857143 service_time: 2402 s_time: 14 penalty: 0 agent_num: 35 done: False
______________________
id: 49 reward: -0.010135135135135136 service_time: 2337 s_time: 21 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: -0.01967930029154519 service_time: 2226 s_time: 54 penalty: 0 agent_num: 49 done: False
______________________
id: 48 reward: -0.03820598006644518 service_time: 1848 s_time: 92 penalty: 0 agent_num: 43 done: False
______________________
id: 50 reward: 0.02647783251231527 service_time: 2499 s_time: -43 penalty: 0 agent_num: 29 done: False
______________________
Step:  2416
Pretraining Loss:  tensor(0.2894, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.03571428571428571 service_time: 1256 s_time: 30 penalty: 0 agent_num: 15 done: False
______________________
id: 45 reward: -0.0824829931972789 service_time: 2262 s_time: 97 penalty: 0 agent_num: 21 done: False
______________________
id: 47 reward: -0.04891304347826087 service_time: 1864 s_time: 63 penalty: 0 agent_num: 23 done: False
______________________
id: 55 reward: 0.0 service_time: 2384 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: -0.007518796992481203 service_time: 1511 s_time: 16 penalty: 0 agent_num: 38 done: False
______________________
id: 40 reward: -0.032280219780219783 service_time: 2356 s_time: 47 penalty: 0 agent_num: 26 done: False
______________________
id: 43 reward: 0.00510204081632653 service_time: 2392 s_time: -10 penalty: 0 agent_num: 35 done: False
______________________
id: 46 reward: -0.015692640692640692 service_time: 2510 s_time: 29 penalty: 0 agent_num: 33 done: False
______________________
id: 54 reward: -0.00935374149659864 service_time: 1647 s_time: 22 penalty: 0 agent_num: 42 done: False
______________________
id: 42 reward: -0.010531135531135532 service_time: 1876 s_time: 23 penalty: 0 agent_num: 39 done: False
______________________
id: 49 reward: 0.0009652509652509653 service_time: 2335 s_time: -2 penalty: 0 agent_num: 37 done: False
______________________
id: 50 reward: 0.006157635467980296 service_time: 2489 s_time: -10 penalty: 0 agent_num: 29 done: False
______________________
id: 44 reward: -0.028225806451612902 service_time: 2742 s_time: 49 penalty: 0 agent_num: 31 done: False
______________________
id: 52 reward: -0.015873015873015872 service_time: 2625 s_time: 32 penalty: 0 agent_num: 36 done: False
______________________
id: 53 reward: -0.0047376093294460644 service_time: 2239 s_time: 13 penalty: 0 agent_num: 49 done: False
______________________
id: 48 reward: -0.012043189368770765 service_time: 1877 s_time: 29 penalty: 0 agent_num: 43 done: False
______________________
Step:  2432
Pretraining Loss:  tensor(0.3133, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.02619047619047619 service_time: 1278 s_time: 22 penalty: 0 agent_num: 15 done: False
______________________
id: 45 reward: 0.013605442176870748 service_time: 2246 s_time: -16 penalty: 0 agent_num: 21 done: False
______________________
id: 55 reward: -0.03165584415584415 service_time: 2423 s_time: 39 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: 0.0 service_time: 1864 s_time: 0 penalty: 0 agent_num: 23 done: False
______________________
id: 51 reward: 0.0 service_time: 1511 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 44 reward: 0.002880184331797235 service_time: 2737 s_time: -5 penalty: 0 agent_num: 31 done: False
______________________
id: 40 reward: -0.024725274725274724 service_time: 2392 s_time: 36 penalty: 0 agent_num: 26 done: False
______________________
id: 49 reward: -0.02364864864864865 service_time: 2384 s_time: 49 penalty: 0 agent_num: 37 done: False
______________________
id: 42 reward: -0.009157509157509158 service_time: 1896 s_time: 20 penalty: 0 agent_num: 39 done: False
______________________
id: 46 reward: -0.0021645021645021645 service_time: 2514 s_time: 4 penalty: 0 agent_num: 33 done: False
______________________
id: 54 reward: 0.0 service_time: 1647 s_time: 0 penalty: 0 agent_num: 42 done: False
______________________
id: 52 reward: 0.001984126984126984 service_time: 2621 s_time: -4 penalty: 0 agent_num: 36 done: False
______________________
id: 50 reward: -0.07635467980295567 service_time: 2613 s_time: 124 penalty: 0 agent_num: 29 done: False
______________________
id: 53 reward: 0.0 service_time: 2239 s_time: 0 penalty: 0 agent_num: 49 done: False
______________________
id: 43 reward: -0.014285714285714285 service_time: 2420 s_time: 28 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.0033222591362126247 service_time: 1885 s_time: 8 penalty: 0 agent_num: 43 done: False
______________________
Step:  2448
Pretraining Loss:  tensor(0.3026, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: 0.0 service_time: 1278 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 45 reward: -0.026360544217687076 service_time: 2277 s_time: 31 penalty: 0 agent_num: 21 done: False
______________________
id: 55 reward: -0.06818181818181818 service_time: 2507 s_time: 84 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: -0.01832706766917293 service_time: 1550 s_time: 39 penalty: 0 agent_num: 38 done: False
______________________
id: 47 reward: -0.020186335403726708 service_time: 1890 s_time: 26 penalty: 0 agent_num: 23 done: False
______________________
id: 40 reward: -0.019230769230769232 service_time: 2420 s_time: 28 penalty: 0 agent_num: 26 done: False
______________________
id: 43 reward: -0.031122448979591835 service_time: 2481 s_time: 61 penalty: 0 agent_num: 35 done: False
______________________
id: 49 reward: -0.010135135135135136 service_time: 2405 s_time: 21 penalty: 0 agent_num: 37 done: False
______________________
id: 46 reward: -0.011904761904761904 service_time: 2536 s_time: 22 penalty: 0 agent_num: 33 done: False
______________________
id: 53 reward: 0.0 service_time: 2239 s_time: 0 penalty: 0 agent_num: 49 done: False
______________________
id: 52 reward: -0.008432539682539682 service_time: 2638 s_time: 17 penalty: 0 agent_num: 36 done: False
______________________
id: 42 reward: -0.013278388278388278 service_time: 1925 s_time: 29 penalty: 0 agent_num: 39 done: False
______________________
id: 54 reward: -0.012329931972789115 service_time: 1676 s_time: 29 penalty: 0 agent_num: 42 done: False
______________________
id: 48 reward: -0.014119601328903655 service_time: 1919 s_time: 34 penalty: 0 agent_num: 43 done: False
______________________
id: 44 reward: -0.038018433179723504 service_time: 2803 s_time: 66 penalty: 0 agent_num: 31 done: False
______________________
id: 50 reward: 0.023399014778325122 service_time: 2575 s_time: -38 penalty: 0 agent_num: 29 done: False
______________________
Step:  2464
Pretraining Loss:  tensor(0.3081, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: 0.0 service_time: 1278 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 45 reward: -0.030612244897959183 service_time: 2313 s_time: 36 penalty: 0 agent_num: 21 done: False
______________________
id: 55 reward: 0.007305194805194805 service_time: 2498 s_time: -9 penalty: 0 agent_num: 22 done: False
______________________
id: 40 reward: 0.0 service_time: 2420 s_time: 0 penalty: 0 agent_num: 26 done: False
______________________
id: 51 reward: -0.010338345864661654 service_time: 1572 s_time: 22 penalty: 0 agent_num: 38 done: False
______________________
id: 47 reward: -0.029503105590062112 service_time: 1928 s_time: 38 penalty: 0 agent_num: 23 done: False
______________________
id: 46 reward: -0.01406926406926407 service_time: 2562 s_time: 26 penalty: 0 agent_num: 33 done: False
______________________
id: 43 reward: -0.01020408163265306 service_time: 2501 s_time: 20 penalty: 0 agent_num: 35 done: False
______________________
id: 50 reward: 0.0018472906403940886 service_time: 2572 s_time: -3 penalty: 0 agent_num: 29 done: False
______________________
id: 54 reward: 0.0 service_time: 1676 s_time: 0 penalty: 0 agent_num: 42 done: False
______________________
id: 49 reward: -0.009652509652509652 service_time: 2425 s_time: 20 penalty: 0 agent_num: 37 done: False
______________________
id: 42 reward: -0.015567765567765568 service_time: 1959 s_time: 34 penalty: 0 agent_num: 39 done: False
______________________
id: 44 reward: -0.02880184331797235 service_time: 2853 s_time: 50 penalty: 0 agent_num: 31 done: False
______________________
id: 48 reward: -0.013704318936877076 service_time: 1952 s_time: 33 penalty: 0 agent_num: 43 done: False
______________________
id: 52 reward: -0.04017857142857143 service_time: 2719 s_time: 81 penalty: 0 agent_num: 36 done: False
______________________
id: 53 reward: 20.002186588921283 service_time: 2233 s_time: -6 penalty: 0 agent_num: 49 done: True
______________________
Step:  2480
Pretraining Loss:  tensor(0.3722, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.02619047619047619 service_time: 1300 s_time: 22 penalty: 0 agent_num: 15 done: False
______________________
id: 53 reward: -0.012218045112781954 service_time: 26 s_time: 26 penalty: 0 agent_num: 38 done: False
______________________
id: 45 reward: 0.011904761904761904 service_time: 2299 s_time: -14 penalty: 0 agent_num: 21 done: False
______________________
id: 51 reward: 0.0 service_time: 1572 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 47 reward: 0.0 service_time: 1928 s_time: 0 penalty: 0 agent_num: 23 done: False
______________________
id: 55 reward: -0.0625 service_time: 2575 s_time: 77 penalty: 0 agent_num: 22 done: False
______________________
id: 40 reward: 0.0027472527472527475 service_time: 2416 s_time: -4 penalty: 0 agent_num: 26 done: False
______________________
id: 43 reward: 0.0010204081632653062 service_time: 2499 s_time: -2 penalty: 0 agent_num: 35 done: False
______________________
id: 46 reward: -0.008116883116883116 service_time: 2577 s_time: 15 penalty: 0 agent_num: 33 done: False
______________________
id: 49 reward: -0.017374517374517374 service_time: 2461 s_time: 36 penalty: 0 agent_num: 37 done: False
______________________
id: 42 reward: 0.0013736263736263737 service_time: 1956 s_time: -3 penalty: 0 agent_num: 39 done: False
______________________
id: 54 reward: -0.006802721088435374 service_time: 1692 s_time: 16 penalty: 0 agent_num: 42 done: False
______________________
id: 50 reward: 0.01539408866995074 service_time: 2547 s_time: -25 penalty: 0 agent_num: 29 done: False
______________________
id: 44 reward: 0.0034562211981566822 service_time: 2847 s_time: -6 penalty: 0 agent_num: 31 done: False
______________________
id: 48 reward: 0.005813953488372093 service_time: 1938 s_time: -14 penalty: 0 agent_num: 43 done: False
______________________
id: 52 reward: 0.0 service_time: 2719 s_time: 0 penalty: 0 agent_num: 36 done: False
______________________
Step:  2496
Pretraining Loss:  tensor(0.3508, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: 0.0 service_time: 1300 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 40 reward: 0.0 service_time: 2416 s_time: 0 penalty: 0 agent_num: 26 done: False
______________________
id: 53 reward: -0.011748120300751879 service_time: 51 s_time: 25 penalty: 0 agent_num: 38 done: False
______________________
id: 45 reward: 0.0 service_time: 2299 s_time: 0 penalty: 0 agent_num: 21 done: False
______________________
id: 55 reward: -0.03165584415584415 service_time: 2614 s_time: 39 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: -0.010338345864661654 service_time: 1594 s_time: 22 penalty: 0 agent_num: 38 done: False
______________________
id: 43 reward: -0.027551020408163266 service_time: 2553 s_time: 54 penalty: 0 agent_num: 35 done: False
______________________
id: 42 reward: -0.01510989010989011 service_time: 1989 s_time: 33 penalty: 0 agent_num: 39 done: False
______________________
id: 47 reward: -0.02251552795031056 service_time: 1957 s_time: 29 penalty: 0 agent_num: 23 done: False
______________________
id: 49 reward: -0.00916988416988417 service_time: 2480 s_time: 19 penalty: 0 agent_num: 37 done: False
______________________
id: 46 reward: 0.0 service_time: 2577 s_time: 0 penalty: 0 agent_num: 33 done: False
______________________
id: 50 reward: -0.03140394088669951 service_time: 2598 s_time: 51 penalty: 0 agent_num: 29 done: False
______________________
id: 44 reward: 0.007488479262672811 service_time: 2834 s_time: -13 penalty: 0 agent_num: 31 done: False
______________________
id: 52 reward: -0.0248015873015873 service_time: 2769 s_time: 50 penalty: 0 agent_num: 36 done: False
______________________
id: 48 reward: -0.019933554817275746 service_time: 1986 s_time: 48 penalty: 0 agent_num: 43 done: False
______________________
id: 54 reward: -0.011479591836734694 service_time: 1719 s_time: 27 penalty: 0 agent_num: 42 done: False
______________________
Step:  2512
Pretraining Loss:  tensor(0.3524, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.02142857142857143 service_time: 1318 s_time: 18 penalty: 0 agent_num: 15 done: False
______________________
id: 53 reward: -0.007048872180451127 service_time: 66 s_time: 15 penalty: 0 agent_num: 38 done: False
______________________
id: 45 reward: 0.055272108843537414 service_time: 2234 s_time: -65 penalty: 0 agent_num: 21 done: False
______________________
id: 47 reward: -0.05822981366459627 service_time: 2032 s_time: 75 penalty: 0 agent_num: 23 done: False
______________________
id: 55 reward: -0.09496753246753246 service_time: 2731 s_time: 117 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: 0.0 service_time: 1594 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 46 reward: 0.0 service_time: 2577 s_time: 0 penalty: 0 agent_num: 33 done: False
______________________
id: 40 reward: 0.0 service_time: 2416 s_time: 0 penalty: 0 agent_num: 26 done: False
______________________
id: 43 reward: -0.0163265306122449 service_time: 2585 s_time: 32 penalty: 0 agent_num: 35 done: False
______________________
id: 50 reward: -0.08435960591133004 service_time: 2735 s_time: 137 penalty: 0 agent_num: 29 done: False
______________________
id: 48 reward: -0.011627906976744186 service_time: 2014 s_time: 28 penalty: 0 agent_num: 43 done: False
______________________
id: 49 reward: 0.0 service_time: 2480 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 42 reward: -0.01282051282051282 service_time: 2017 s_time: 28 penalty: 0 agent_num: 39 done: False
______________________
id: 52 reward: 0.0 service_time: 2769 s_time: 0 penalty: 0 agent_num: 36 done: False
______________________
id: 44 reward: 0.005184331797235023 service_time: 2825 s_time: -9 penalty: 0 agent_num: 31 done: False
______________________
id: 54 reward: -0.010629251700680272 service_time: 1744 s_time: 25 penalty: 0 agent_num: 42 done: False
______________________
Step:  2528
Pretraining Loss:  tensor(0.3485, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: 0.0011904761904761906 service_time: 1317 s_time: -1 penalty: 0 agent_num: 15 done: False
______________________
id: 45 reward: -0.0858843537414966 service_time: 2335 s_time: 101 penalty: 0 agent_num: 21 done: False
______________________
id: 40 reward: -0.011675824175824176 service_time: 2433 s_time: 17 penalty: 0 agent_num: 26 done: False
______________________
id: 53 reward: -0.018796992481203006 service_time: 106 s_time: 40 penalty: 0 agent_num: 38 done: False
______________________
id: 46 reward: 0.003246753246753247 service_time: 2571 s_time: -6 penalty: 0 agent_num: 33 done: False
______________________
id: 51 reward: -0.01832706766917293 service_time: 1633 s_time: 39 penalty: 0 agent_num: 38 done: False
______________________
id: 55 reward: -0.03409090909090909 service_time: 2773 s_time: 42 penalty: 0 agent_num: 22 done: False
______________________
id: 43 reward: 0.0010204081632653062 service_time: 2583 s_time: -2 penalty: 0 agent_num: 35 done: False
______________________
id: 47 reward: 0.018633540372670808 service_time: 2008 s_time: -24 penalty: 0 agent_num: 23 done: False
______________________
id: 52 reward: 0.000992063492063492 service_time: 2767 s_time: -2 penalty: 0 agent_num: 36 done: False
______________________
id: 42 reward: 0.0 service_time: 2017 s_time: 0 penalty: 0 agent_num: 39 done: False
______________________
id: 54 reward: -0.002976190476190476 service_time: 1751 s_time: 7 penalty: 0 agent_num: 42 done: False
______________________
id: 48 reward: -0.01287375415282392 service_time: 2045 s_time: 31 penalty: 0 agent_num: 43 done: False
______________________
id: 50 reward: -0.05295566502463054 service_time: 2821 s_time: 86 penalty: 0 agent_num: 29 done: False
______________________
id: 44 reward: -0.0017281105990783411 service_time: 2828 s_time: 3 penalty: 0 agent_num: 31 done: False
______________________
id: 49 reward: -0.027992277992277992 service_time: 2538 s_time: 58 penalty: 0 agent_num: 37 done: False
______________________
Step:  2544
Pretraining Loss:  tensor(0.3150, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.05119047619047619 service_time: 1360 s_time: 43 penalty: 0 agent_num: 15 done: False
______________________
id: 40 reward: -0.08035714285714286 service_time: 2550 s_time: 117 penalty: 0 agent_num: 26 done: False
______________________
id: 45 reward: 0.04591836734693878 service_time: 2281 s_time: -54 penalty: 0 agent_num: 21 done: False
______________________
id: 46 reward: 0.0 service_time: 2571 s_time: 0 penalty: 0 agent_num: 33 done: False
______________________
id: 55 reward: -0.060876623376623376 service_time: 2848 s_time: 75 penalty: 0 agent_num: 22 done: False
______________________
id: 53 reward: -0.01268796992481203 service_time: 133 s_time: 27 penalty: 0 agent_num: 38 done: False
______________________
id: 51 reward: 0.0 service_time: 1633 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 47 reward: -0.02251552795031056 service_time: 2037 s_time: 29 penalty: 0 agent_num: 23 done: False
______________________
id: 50 reward: -0.01416256157635468 service_time: 2844 s_time: 23 penalty: 0 agent_num: 29 done: False
______________________
id: 42 reward: -0.017857142857142856 service_time: 2056 s_time: 39 penalty: 0 agent_num: 39 done: False
______________________
id: 48 reward: -0.011212624584717609 service_time: 2072 s_time: 27 penalty: 0 agent_num: 43 done: False
______________________
id: 44 reward: 0.005184331797235023 service_time: 2819 s_time: -9 penalty: 0 agent_num: 31 done: False
______________________
id: 54 reward: 0.0 service_time: 1751 s_time: 0 penalty: 0 agent_num: 42 done: False
______________________
id: 52 reward: 0.000496031746031746 service_time: 2766 s_time: -1 penalty: 0 agent_num: 36 done: False
______________________
id: 49 reward: 0.004343629343629344 service_time: 2529 s_time: -9 penalty: 0 agent_num: 37 done: False
______________________
id: 43 reward: -0.055612244897959184 service_time: 2692 s_time: 109 penalty: 0 agent_num: 35 done: False
______________________
Step:  2560
Pretraining Loss:  tensor(0.3280, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: 0.0 service_time: 1360 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 45 reward: -0.09948979591836735 service_time: 2398 s_time: 117 penalty: 0 agent_num: 21 done: False
______________________
id: 47 reward: -0.08229813664596274 service_time: 2143 s_time: 106 penalty: 0 agent_num: 23 done: False
______________________
id: 40 reward: 0.0 service_time: 2550 s_time: 0 penalty: 0 agent_num: 26 done: False
______________________
id: 53 reward: -0.01456766917293233 service_time: 164 s_time: 31 penalty: 0 agent_num: 38 done: False
______________________
id: 51 reward: -0.012218045112781954 service_time: 1659 s_time: 26 penalty: 0 agent_num: 38 done: False
______________________
id: 55 reward: -0.04707792207792208 service_time: 2906 s_time: 58 penalty: 0 agent_num: 22 done: False
______________________
id: 44 reward: 0.0 service_time: 2819 s_time: 0 penalty: 0 agent_num: 31 done: False
______________________
id: 42 reward: -0.013736263736263736 service_time: 2086 s_time: 30 penalty: 0 agent_num: 39 done: False
______________________
id: 52 reward: 0.0 service_time: 2766 s_time: 0 penalty: 0 agent_num: 36 done: False
______________________
id: 50 reward: -0.008004926108374385 service_time: 2857 s_time: 13 penalty: 0 agent_num: 29 done: False
______________________
id: 54 reward: -0.008078231292517007 service_time: 1770 s_time: 19 penalty: 0 agent_num: 42 done: False
______________________
id: 48 reward: 0.0004152823920265781 service_time: 2071 s_time: -1 penalty: 0 agent_num: 43 done: False
______________________
id: 43 reward: -0.007653061224489796 service_time: 2707 s_time: 15 penalty: 0 agent_num: 35 done: False
______________________
id: 49 reward: 0.0 service_time: 2529 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 46 reward: 20.001082251082252 service_time: 2569 s_time: -2 penalty: 0 agent_num: 33 done: True
______________________
Step:  2576
Pretraining Loss:  tensor(0.3566, device='cuda:0', grad_fn=<MeanBackward0>)
id: 46 reward: -0.021103896103896104 service_time: 26 s_time: 26 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: -0.027950310559006212 service_time: 2179 s_time: 36 penalty: 0 agent_num: 23 done: False
______________________
id: 40 reward: -0.023351648351648352 service_time: 2584 s_time: 34 penalty: 0 agent_num: 26 done: False
______________________
id: 45 reward: 0.0 service_time: 2398 s_time: 0 penalty: 0 agent_num: 21 done: False
______________________
id: 41 reward: -0.030952380952380953 service_time: 1386 s_time: 26 penalty: 0 agent_num: 15 done: False
______________________
id: 51 reward: -0.008928571428571428 service_time: 1678 s_time: 19 penalty: 0 agent_num: 38 done: False
______________________
id: 55 reward: -0.04707792207792208 service_time: 2964 s_time: 58 penalty: 0 agent_num: 22 done: False
______________________
id: 50 reward: -0.022167487684729065 service_time: 2893 s_time: 36 penalty: 0 agent_num: 29 done: False
______________________
id: 44 reward: 0.0 service_time: 2819 s_time: 0 penalty: 0 agent_num: 31 done: False
______________________
id: 53 reward: -0.011748120300751879 service_time: 189 s_time: 25 penalty: 0 agent_num: 38 done: False
______________________
id: 42 reward: -0.011904761904761904 service_time: 2112 s_time: 26 penalty: 0 agent_num: 39 done: False
______________________
id: 52 reward: 0.001984126984126984 service_time: 2762 s_time: -4 penalty: 0 agent_num: 36 done: False
______________________
id: 54 reward: 0.0 service_time: 1770 s_time: 0 penalty: 0 agent_num: 42 done: False
______________________
id: 48 reward: -0.026993355481727575 service_time: 2136 s_time: 65 penalty: 0 agent_num: 43 done: False
______________________
id: 43 reward: -0.01479591836734694 service_time: 2736 s_time: 29 penalty: 0 agent_num: 35 done: False
______________________
id: 49 reward: 20.001930501930502 service_time: 2525 s_time: -4 penalty: 0 agent_num: 37 done: True
______________________
Step:  2592
Pretraining Loss:  tensor(0.3587, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.006987577639751553 service_time: 9 s_time: 9 penalty: 0 agent_num: 23 done: False
______________________
id: 46 reward: -0.026785714285714284 service_time: 59 s_time: 33 penalty: 0 agent_num: 22 done: False
______________________
id: 45 reward: 0.0 service_time: 2398 s_time: 0 penalty: 0 agent_num: 21 done: False
______________________
id: 44 reward: -0.001152073732718894 service_time: 2821 s_time: 2 penalty: 0 agent_num: 31 done: False
______________________
id: 51 reward: -0.007518796992481203 service_time: 1694 s_time: 16 penalty: 0 agent_num: 38 done: False
______________________
id: 55 reward: -0.08522727272727272 service_time: 3069 s_time: 105 penalty: 0 agent_num: 22 done: False
______________________
id: 50 reward: 0.004310344827586207 service_time: 2886 s_time: -7 penalty: 0 agent_num: 29 done: False
______________________
id: 53 reward: -0.015977443609022556 service_time: 223 s_time: 34 penalty: 0 agent_num: 38 done: False
______________________
id: 47 reward: -0.1234472049689441 service_time: 2338 s_time: 159 penalty: 0 agent_num: 23 done: False
______________________
id: 40 reward: 0.01304945054945055 service_time: 2565 s_time: -19 penalty: 0 agent_num: 26 done: False
______________________
id: 52 reward: 0.0 service_time: 2762 s_time: 0 penalty: 0 agent_num: 36 done: False
______________________
id: 41 reward: -0.04047619047619048 service_time: 1420 s_time: 34 penalty: 0 agent_num: 15 done: False
______________________
id: 42 reward: -0.018315018315018316 service_time: 2152 s_time: 40 penalty: 0 agent_num: 39 done: False
______________________
id: 43 reward: -0.01173469387755102 service_time: 2759 s_time: 23 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.008305647840531562 service_time: 2156 s_time: 20 penalty: 0 agent_num: 43 done: False
______________________
id: 54 reward: 0.0 service_time: 1770 s_time: 0 penalty: 0 agent_num: 42 done: False
______________________
Step:  2608
Pretraining Loss:  tensor(0.3362, device='cuda:0', grad_fn=<MeanBackward0>)
id: 46 reward: -0.030844155844155844 service_time: 97 s_time: 38 penalty: 0 agent_num: 22 done: False
______________________
id: 41 reward: -0.016666666666666666 service_time: 1434 s_time: 14 penalty: 0 agent_num: 15 done: False
______________________
id: 49 reward: -0.02251552795031056 service_time: 38 s_time: 29 penalty: 0 agent_num: 23 done: False
______________________
id: 40 reward: -0.021291208791208792 service_time: 2596 s_time: 31 penalty: 0 agent_num: 26 done: False
______________________
id: 45 reward: -0.030612244897959183 service_time: 2434 s_time: 36 penalty: 0 agent_num: 21 done: False
______________________
id: 50 reward: -0.0012315270935960591 service_time: 2888 s_time: 2 penalty: 0 agent_num: 29 done: False
______________________
id: 47 reward: 0.034161490683229816 service_time: 2294 s_time: -44 penalty: 0 agent_num: 23 done: False
______________________
id: 44 reward: 0.001152073732718894 service_time: 2819 s_time: -2 penalty: 0 agent_num: 31 done: False
______________________
id: 51 reward: 0.0 service_time: 1694 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 53 reward: -0.01644736842105263 service_time: 258 s_time: 35 penalty: 0 agent_num: 38 done: False
______________________
id: 55 reward: -0.26866883116883117 service_time: 3400 s_time: 331 penalty: 0 agent_num: 22 done: False
______________________
id: 54 reward: -0.01488095238095238 service_time: 1805 s_time: 35 penalty: 0 agent_num: 42 done: False
______________________
id: 42 reward: -0.011446886446886446 service_time: 2177 s_time: 25 penalty: 0 agent_num: 39 done: False
______________________
id: 52 reward: -0.000496031746031746 service_time: 2763 s_time: 1 penalty: 0 agent_num: 36 done: False
______________________
id: 43 reward: -0.013775510204081633 service_time: 2786 s_time: 27 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.011627906976744186 service_time: 2184 s_time: 28 penalty: 0 agent_num: 43 done: False
______________________
Step:  2624
Pretraining Loss:  tensor(0.3072, device='cuda:0', grad_fn=<MeanBackward0>)
id: 46 reward: 0.0 service_time: 97 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: -0.026397515527950312 service_time: 72 s_time: 34 penalty: 0 agent_num: 23 done: False
______________________
id: 41 reward: -0.03571428571428571 service_time: 1464 s_time: 30 penalty: 0 agent_num: 15 done: False
______________________
id: 55 reward: -0.10957792207792208 service_time: 3535 s_time: 135 penalty: 0 agent_num: 22 done: False
______________________
id: 40 reward: -0.034340659340659344 service_time: 2646 s_time: 50 penalty: 0 agent_num: 26 done: False
______________________
id: 44 reward: 0.0 service_time: 2819 s_time: 0 penalty: 0 agent_num: 31 done: False
______________________
id: 45 reward: -0.030612244897959183 service_time: 2470 s_time: 36 penalty: 0 agent_num: 21 done: False
______________________
id: 47 reward: 0.020186335403726708 service_time: 2268 s_time: -26 penalty: 0 agent_num: 23 done: False
______________________
id: 51 reward: -0.011278195488721804 service_time: 1718 s_time: 24 penalty: 0 agent_num: 38 done: False
______________________
id: 52 reward: 0.000496031746031746 service_time: 2762 s_time: -1 penalty: 0 agent_num: 36 done: False
______________________
id: 42 reward: -0.014194139194139194 service_time: 2208 s_time: 31 penalty: 0 agent_num: 39 done: False
______________________
id: 50 reward: 0.0 service_time: 2888 s_time: 0 penalty: 0 agent_num: 29 done: False
______________________
id: 54 reward: -0.008078231292517007 service_time: 1824 s_time: 19 penalty: 0 agent_num: 42 done: False
______________________
id: 53 reward: -0.007988721804511278 service_time: 275 s_time: 17 penalty: 0 agent_num: 38 done: False
______________________
id: 48 reward: 0.0 service_time: 2184 s_time: 0 penalty: 0 agent_num: 43 done: False
______________________
id: 43 reward: -0.03163265306122449 service_time: 2848 s_time: 62 penalty: 0 agent_num: 35 done: False
______________________
Step:  2640
Pretraining Loss:  tensor(0.3543, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.017080745341614908 service_time: 94 s_time: 22 penalty: 0 agent_num: 23 done: False
______________________
id: 46 reward: -0.037337662337662336 service_time: 143 s_time: 46 penalty: 0 agent_num: 22 done: False
______________________
id: 41 reward: -0.02738095238095238 service_time: 1487 s_time: 23 penalty: 0 agent_num: 15 done: False
______________________
id: 44 reward: 0.0 service_time: 2819 s_time: 0 penalty: 0 agent_num: 31 done: False
______________________
id: 45 reward: -0.08078231292517007 service_time: 2565 s_time: 95 penalty: 0 agent_num: 21 done: False
______________________
id: 50 reward: -0.0006157635467980296 service_time: 2889 s_time: 1 penalty: 0 agent_num: 29 done: False
______________________
id: 40 reward: -0.03021978021978022 service_time: 2690 s_time: 44 penalty: 0 agent_num: 26 done: False
______________________
id: 47 reward: -0.043478260869565216 service_time: 2324 s_time: 56 penalty: 0 agent_num: 23 done: False
______________________
id: 51 reward: 0.00046992481203007516 service_time: 1717 s_time: -1 penalty: 0 agent_num: 38 done: False
______________________
id: 53 reward: -0.010808270676691729 service_time: 298 s_time: 23 penalty: 0 agent_num: 38 done: False
______________________
id: 42 reward: -0.003205128205128205 service_time: 2215 s_time: 7 penalty: 0 agent_num: 39 done: False
______________________
id: 55 reward: -0.09902597402597403 service_time: 3657 s_time: 122 penalty: 0 agent_num: 22 done: False
______________________
id: 43 reward: 0.005612244897959183 service_time: 2837 s_time: -11 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.027408637873754152 service_time: 2250 s_time: 66 penalty: 0 agent_num: 43 done: False
______________________
id: 54 reward: 0.0 service_time: 1824 s_time: 0 penalty: 0 agent_num: 42 done: False
______________________
id: 52 reward: 20.001488095238095 service_time: 2759 s_time: -3 penalty: 0 agent_num: 36 done: True
______________________
Step:  2656
Pretraining Loss:  tensor(0.4199, device='cuda:0', grad_fn=<MeanBackward0>)
id: 46 reward: -0.025162337662337664 service_time: 174 s_time: 31 penalty: 0 agent_num: 22 done: False
______________________
id: 52 reward: -0.027597402597402596 service_time: 34 s_time: 34 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: -0.021739130434782608 service_time: 122 s_time: 28 penalty: 0 agent_num: 23 done: False
______________________
id: 41 reward: 0.0 service_time: 1487 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 44 reward: 0.0 service_time: 2819 s_time: 0 penalty: 0 agent_num: 31 done: False
______________________
id: 40 reward: 0.0020604395604395605 service_time: 2687 s_time: -3 penalty: 0 agent_num: 26 done: False
______________________
id: 47 reward: 0.011645962732919254 service_time: 2309 s_time: -15 penalty: 0 agent_num: 23 done: False
______________________
id: 50 reward: 0.0 service_time: 2889 s_time: 0 penalty: 0 agent_num: 29 done: False
______________________
id: 45 reward: -0.0663265306122449 service_time: 2643 s_time: 78 penalty: 0 agent_num: 21 done: False
______________________
id: 42 reward: -0.01510989010989011 service_time: 2248 s_time: 33 penalty: 0 agent_num: 39 done: False
______________________
id: 43 reward: -0.017857142857142856 service_time: 2872 s_time: 35 penalty: 0 agent_num: 35 done: False
______________________
id: 51 reward: -0.013157894736842105 service_time: 1745 s_time: 28 penalty: 0 agent_num: 38 done: False
______________________
id: 53 reward: -0.007518796992481203 service_time: 314 s_time: 16 penalty: 0 agent_num: 38 done: False
______________________
id: 48 reward: -0.011627906976744186 service_time: 2278 s_time: 28 penalty: 0 agent_num: 43 done: False
______________________
id: 55 reward: -0.07873376623376624 service_time: 3754 s_time: 97 penalty: 0 agent_num: 22 done: False
______________________
id: 54 reward: -0.0017006802721088435 service_time: 1828 s_time: 4 penalty: 0 agent_num: 42 done: False
______________________
Step:  2672
Pretraining Loss:  tensor(0.4052, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.006987577639751553 service_time: 131 s_time: 9 penalty: 0 agent_num: 23 done: False
______________________
id: 52 reward: -0.032467532467532464 service_time: 74 s_time: 40 penalty: 0 agent_num: 22 done: False
______________________
id: 46 reward: -0.017045454545454544 service_time: 195 s_time: 21 penalty: 0 agent_num: 22 done: False
______________________
id: 41 reward: -0.02857142857142857 service_time: 1511 s_time: 24 penalty: 0 agent_num: 15 done: False
______________________
id: 40 reward: 0.0 service_time: 2687 s_time: 0 penalty: 0 agent_num: 26 done: False
______________________
id: 50 reward: 0.0 service_time: 2889 s_time: 0 penalty: 0 agent_num: 29 done: False
______________________
id: 47 reward: -0.039596273291925464 service_time: 2360 s_time: 51 penalty: 0 agent_num: 23 done: False
______________________
id: 51 reward: -0.010338345864661654 service_time: 1767 s_time: 22 penalty: 0 agent_num: 38 done: False
______________________
id: 45 reward: -0.15731292517006804 service_time: 2828 s_time: 185 penalty: 0 agent_num: 21 done: False
______________________
id: 53 reward: -0.017857142857142856 service_time: 352 s_time: 38 penalty: 0 agent_num: 38 done: False
______________________
id: 42 reward: 0.0009157509157509158 service_time: 2246 s_time: -2 penalty: 0 agent_num: 39 done: False
______________________
id: 55 reward: 0.0 service_time: 3754 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 43 reward: 0.011224489795918367 service_time: 2850 s_time: -22 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: -0.011479591836734694 service_time: 1855 s_time: 27 penalty: 0 agent_num: 42 done: False
______________________
id: 48 reward: -0.01287375415282392 service_time: 2309 s_time: 31 penalty: 0 agent_num: 43 done: False
______________________
id: 44 reward: 20.002304147465438 service_time: 2815 s_time: -4 penalty: 0 agent_num: 31 done: True
______________________
Step:  2688
Pretraining Loss:  tensor(0.3462, device='cuda:0', grad_fn=<MeanBackward0>)
id: 52 reward: -0.006493506493506494 service_time: 82 s_time: 8 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: -0.033385093167701864 service_time: 174 s_time: 43 penalty: 0 agent_num: 23 done: False
______________________
id: 46 reward: -0.02922077922077922 service_time: 231 s_time: 36 penalty: 0 agent_num: 22 done: False
______________________
id: 41 reward: 0.0 service_time: 1511 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 44 reward: -0.01287375415282392 service_time: 31 s_time: 31 penalty: 0 agent_num: 43 done: False
______________________
id: 45 reward: -0.05357142857142857 service_time: 2891 s_time: 63 penalty: 0 agent_num: 21 done: False
______________________
id: 40 reward: 0.0 service_time: 2687 s_time: 0 penalty: 0 agent_num: 26 done: False
______________________
id: 50 reward: 0.0 service_time: 2889 s_time: 0 penalty: 0 agent_num: 29 done: False
______________________
id: 53 reward: -0.009398496240601503 service_time: 372 s_time: 20 penalty: 0 agent_num: 38 done: False
______________________
id: 42 reward: 0.0013736263736263737 service_time: 2243 s_time: -3 penalty: 0 agent_num: 39 done: False
______________________
id: 43 reward: 0.004591836734693878 service_time: 2841 s_time: -9 penalty: 0 agent_num: 35 done: False
______________________
id: 51 reward: 0.0 service_time: 1767 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 47 reward: -0.006211180124223602 service_time: 2368 s_time: 8 penalty: 0 agent_num: 23 done: False
______________________
id: 55 reward: 0.007305194805194805 service_time: 3745 s_time: -9 penalty: 0 agent_num: 22 done: False
______________________
id: 48 reward: -0.014119601328903655 service_time: 2343 s_time: 34 penalty: 0 agent_num: 43 done: False
______________________
id: 54 reward: -0.01488095238095238 service_time: 1890 s_time: 35 penalty: 0 agent_num: 42 done: False
______________________
Step:  2704
Pretraining Loss:  tensor(0.3159, device='cuda:0', grad_fn=<MeanBackward0>)
id: 52 reward: -0.013798701298701298 service_time: 99 s_time: 17 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: 0.0 service_time: 174 s_time: 0 penalty: 0 agent_num: 23 done: False
______________________
id: 46 reward: -0.003246753246753247 service_time: 235 s_time: 4 penalty: 0 agent_num: 22 done: False
______________________
id: 44 reward: 0.0 service_time: 31 s_time: 0 penalty: 0 agent_num: 43 done: False
______________________
id: 50 reward: 0.0 service_time: 2889 s_time: 0 penalty: 0 agent_num: 29 done: False
______________________
id: 41 reward: -0.039285714285714285 service_time: 1544 s_time: 33 penalty: 0 agent_num: 15 done: False
______________________
id: 40 reward: 0.0 service_time: 2687 s_time: 0 penalty: 0 agent_num: 26 done: False
______________________
id: 47 reward: 0.02251552795031056 service_time: 2339 s_time: -29 penalty: 0 agent_num: 23 done: False
______________________
id: 42 reward: 0.0022893772893772895 service_time: 2238 s_time: -5 penalty: 0 agent_num: 39 done: False
______________________
id: 51 reward: -0.012218045112781954 service_time: 1793 s_time: 26 penalty: 0 agent_num: 38 done: False
______________________
id: 43 reward: 0.0 service_time: 2841 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 45 reward: -0.04931972789115646 service_time: 2949 s_time: 58 penalty: 0 agent_num: 21 done: False
______________________
id: 53 reward: -0.011748120300751879 service_time: 397 s_time: 25 penalty: 0 agent_num: 38 done: False
______________________
id: 55 reward: 0.0008116883116883117 service_time: 3744 s_time: -1 penalty: 0 agent_num: 22 done: False
______________________
id: 54 reward: -0.00977891156462585 service_time: 1913 s_time: 23 penalty: 0 agent_num: 42 done: False
______________________
id: 48 reward: 0.0004152823920265781 service_time: 2342 s_time: -1 penalty: 0 agent_num: 43 done: False
______________________
Step:  2720
Pretraining Loss:  tensor(0.2704, device='cuda:0', grad_fn=<MeanBackward0>)
id: 52 reward: 0.0 service_time: 99 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: -0.010093167701863354 service_time: 187 s_time: 13 penalty: 0 agent_num: 23 done: False
______________________
id: 46 reward: 0.0 service_time: 235 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 41 reward: -0.023809523809523808 service_time: 1564 s_time: 20 penalty: 0 agent_num: 15 done: False
______________________
id: 44 reward: -0.012458471760797342 service_time: 61 s_time: 30 penalty: 0 agent_num: 43 done: False
______________________
id: 53 reward: 0.0 service_time: 397 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 43 reward: 0.0 service_time: 2841 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 55 reward: 0.0016233766233766235 service_time: 3742 s_time: -2 penalty: 0 agent_num: 22 done: False
______________________
id: 42 reward: 0.0004578754578754579 service_time: 2237 s_time: -1 penalty: 0 agent_num: 39 done: False
______________________
id: 40 reward: 0.0 service_time: 2687 s_time: 0 penalty: 0 agent_num: 26 done: False
______________________
id: 47 reward: 0.015527950310559006 service_time: 2319 s_time: -20 penalty: 0 agent_num: 23 done: False
______________________
id: 51 reward: -0.0037593984962406013 service_time: 1801 s_time: 8 penalty: 0 agent_num: 38 done: False
______________________
id: 45 reward: -0.05102040816326531 service_time: 3009 s_time: 60 penalty: 0 agent_num: 21 done: False
______________________
id: 54 reward: -0.01020408163265306 service_time: 1937 s_time: 24 penalty: 0 agent_num: 42 done: False
______________________
id: 48 reward: -0.03156146179401993 service_time: 2418 s_time: 76 penalty: 0 agent_num: 43 done: False
______________________
id: 50 reward: 20.003694581280786 service_time: 2883 s_time: -6 penalty: 0 agent_num: 29 done: True
______________________
Step:  2736
Pretraining Loss:  tensor(0.2684, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.0 service_time: 187 s_time: 0 penalty: 0 agent_num: 23 done: False
______________________
id: 52 reward: -0.03896103896103896 service_time: 147 s_time: 48 penalty: 0 agent_num: 22 done: False
______________________
id: 46 reward: -0.0349025974025974 service_time: 278 s_time: 43 penalty: 0 agent_num: 22 done: False
______________________
id: 41 reward: 0.0 service_time: 1564 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 50 reward: -0.007142857142857143 service_time: 18 s_time: 18 penalty: 0 agent_num: 45 done: False
______________________
id: 44 reward: -0.005813953488372093 service_time: 75 s_time: 14 penalty: 0 agent_num: 43 done: False
______________________
id: 47 reward: 0.005434782608695652 service_time: 2312 s_time: -7 penalty: 0 agent_num: 23 done: False
______________________
id: 43 reward: 0.0010204081632653062 service_time: 2839 s_time: -2 penalty: 0 agent_num: 35 done: False
______________________
id: 51 reward: 0.0 service_time: 1801 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 53 reward: -0.03759398496240601 service_time: 477 s_time: 80 penalty: 0 agent_num: 38 done: False
______________________
id: 45 reward: -0.1284013605442177 service_time: 3160 s_time: 151 penalty: 0 agent_num: 21 done: False
______________________
id: 48 reward: -0.007475083056478406 service_time: 2436 s_time: 18 penalty: 0 agent_num: 43 done: False
______________________
id: 55 reward: -0.0016233766233766235 service_time: 3744 s_time: 2 penalty: 0 agent_num: 22 done: False
______________________
id: 54 reward: -0.011479591836734694 service_time: 1964 s_time: 27 penalty: 0 agent_num: 42 done: False
______________________
id: 40 reward: 20.000686813186814 service_time: 2686 s_time: -1 penalty: 0 agent_num: 26 done: True
______________________
id: 42 reward: 20.000915750915752 service_time: 2235 s_time: -2 penalty: 0 agent_num: 39 done: True
______________________
Step:  2752
Pretraining Loss:  tensor(0.2378, device='cuda:0', grad_fn=<MeanBackward0>)
id: 42 reward: -0.03422619047619048 service_time: 23 s_time: 23 penalty: 0 agent_num: 12 done: False
______________________
id: 40 reward: -0.003826530612244898 service_time: 6 s_time: 6 penalty: 0 agent_num: 28 done: False
______________________
id: 52 reward: -0.002435064935064935 service_time: 150 s_time: 3 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: -0.006211180124223602 service_time: 195 s_time: 8 penalty: 0 agent_num: 23 done: False
______________________
id: 41 reward: 0.0 service_time: 1564 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 46 reward: 0.002435064935064935 service_time: 275 s_time: -3 penalty: 0 agent_num: 22 done: False
______________________
id: 50 reward: 0.0 service_time: 18 s_time: 0 penalty: 0 agent_num: 45 done: False
______________________
id: 45 reward: -0.21173469387755103 service_time: 3409 s_time: 249 penalty: 0 agent_num: 21 done: False
______________________
id: 44 reward: 0.0 service_time: 75 s_time: 0 penalty: 0 agent_num: 43 done: False
______________________
id: 47 reward: -0.034161490683229816 service_time: 2356 s_time: 44 penalty: 0 agent_num: 23 done: False
______________________
id: 43 reward: 0.0 service_time: 2839 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 53 reward: -0.0009398496240601503 service_time: 479 s_time: 2 penalty: 0 agent_num: 38 done: False
______________________
id: 51 reward: -0.0042293233082706765 service_time: 1810 s_time: 9 penalty: 0 agent_num: 38 done: False
______________________
id: 55 reward: 0.0016233766233766235 service_time: 3742 s_time: -2 penalty: 0 agent_num: 22 done: False
______________________
id: 48 reward: -0.0049833887043189366 service_time: 2448 s_time: 12 penalty: 0 agent_num: 43 done: False
______________________
id: 54 reward: -0.00467687074829932 service_time: 1975 s_time: 11 penalty: 0 agent_num: 42 done: False
______________________
Step:  2768
Pretraining Loss:  tensor(0.2238, device='cuda:0', grad_fn=<MeanBackward0>)
id: 42 reward: -0.050595238095238096 service_time: 57 s_time: 34 penalty: 0 agent_num: 12 done: False
______________________
id: 40 reward: -0.01721938775510204 service_time: 33 s_time: 27 penalty: 0 agent_num: 28 done: False
______________________
id: 49 reward: 0.0 service_time: 195 s_time: 0 penalty: 0 agent_num: 23 done: False
______________________
id: 46 reward: -0.04788961038961039 service_time: 334 s_time: 59 penalty: 0 agent_num: 22 done: False
______________________
id: 52 reward: -0.021915584415584416 service_time: 177 s_time: 27 penalty: 0 agent_num: 22 done: False
______________________
id: 41 reward: -0.05 service_time: 1606 s_time: 42 penalty: 0 agent_num: 15 done: False
______________________
id: 55 reward: 0.0 service_time: 3742 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 50 reward: -0.01865079365079365 service_time: 65 s_time: 47 penalty: 0 agent_num: 45 done: False
______________________
id: 44 reward: -0.009551495016611296 service_time: 98 s_time: 23 penalty: 0 agent_num: 43 done: False
______________________
id: 47 reward: 0.010093167701863354 service_time: 2343 s_time: -13 penalty: 0 agent_num: 23 done: False
______________________
id: 53 reward: -0.03477443609022556 service_time: 553 s_time: 74 penalty: 0 agent_num: 38 done: False
______________________
id: 48 reward: 0.0 service_time: 2448 s_time: 0 penalty: 0 agent_num: 43 done: False
______________________
id: 45 reward: -0.08758503401360544 service_time: 3512 s_time: 103 penalty: 0 agent_num: 21 done: False
______________________
id: 54 reward: -0.012755102040816327 service_time: 2005 s_time: 30 penalty: 0 agent_num: 42 done: False
______________________
id: 51 reward: -0.01456766917293233 service_time: 1841 s_time: 31 penalty: 0 agent_num: 38 done: False
______________________
id: 43 reward: 20.00204081632653 service_time: 2835 s_time: -4 penalty: 0 agent_num: 35 done: True
______________________
Step:  2784
Pretraining Loss:  tensor(0.2147, device='cuda:0', grad_fn=<MeanBackward0>)
id: 42 reward: -0.05654761904761905 service_time: 95 s_time: 38 penalty: 0 agent_num: 12 done: False
______________________
id: 40 reward: -0.0031887755102040817 service_time: 38 s_time: 5 penalty: 0 agent_num: 28 done: False
______________________
id: 52 reward: -0.025974025974025976 service_time: 209 s_time: 32 penalty: 0 agent_num: 22 done: False
______________________
id: 46 reward: -0.01948051948051948 service_time: 358 s_time: 24 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: -0.02096273291925466 service_time: 222 s_time: 27 penalty: 0 agent_num: 23 done: False
______________________
id: 43 reward: -0.009615384615384616 service_time: 21 s_time: 21 penalty: 0 agent_num: 39 done: False
______________________
id: 50 reward: -0.005158730158730159 service_time: 78 s_time: 13 penalty: 0 agent_num: 45 done: False
______________________
id: 47 reward: 0.0 service_time: 2343 s_time: 0 penalty: 0 agent_num: 23 done: False
______________________
id: 41 reward: -0.0011904761904761906 service_time: 1607 s_time: 1 penalty: 0 agent_num: 15 done: False
______________________
id: 51 reward: -0.012218045112781954 service_time: 1867 s_time: 26 penalty: 0 agent_num: 38 done: False
______________________
id: 45 reward: -0.20238095238095238 service_time: 3750 s_time: 238 penalty: 0 agent_num: 21 done: False
______________________
id: 48 reward: -0.017857142857142856 service_time: 2491 s_time: 43 penalty: 0 agent_num: 43 done: False
______________________
id: 44 reward: -0.023255813953488372 service_time: 154 s_time: 56 penalty: 0 agent_num: 43 done: False
______________________
id: 53 reward: -0.022556390977443608 service_time: 601 s_time: 48 penalty: 0 agent_num: 38 done: False
______________________
id: 54 reward: 0.0 service_time: 2005 s_time: 0 penalty: 0 agent_num: 42 done: False
______________________
id: 55 reward: 20.0 service_time: 3742 s_time: 0 penalty: 0 agent_num: 22 done: True
______________________
Step:  2800
Pretraining Loss:  tensor(0.2143, device='cuda:0', grad_fn=<MeanBackward0>)
id: 42 reward: -0.041666666666666664 service_time: 123 s_time: 28 penalty: 0 agent_num: 12 done: False
______________________
id: 55 reward: -0.09253246753246754 service_time: 57 s_time: 57 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: 0.0 service_time: 222 s_time: 0 penalty: 0 agent_num: 23 done: False
______________________
id: 40 reward: 0.0006377551020408163 service_time: 37 s_time: -1 penalty: 0 agent_num: 28 done: False
______________________
id: 46 reward: -0.013798701298701298 service_time: 375 s_time: 17 penalty: 0 agent_num: 22 done: False
______________________
id: 52 reward: -0.013798701298701298 service_time: 226 s_time: 17 penalty: 0 agent_num: 22 done: False
______________________
id: 41 reward: -0.02023809523809524 service_time: 1624 s_time: 17 penalty: 0 agent_num: 15 done: False
______________________
id: 43 reward: -0.017857142857142856 service_time: 60 s_time: 39 penalty: 0 agent_num: 39 done: False
______________________
id: 44 reward: 0.0 service_time: 154 s_time: 0 penalty: 0 agent_num: 43 done: False
______________________
id: 51 reward: -0.01268796992481203 service_time: 1894 s_time: 27 penalty: 0 agent_num: 38 done: False
______________________
id: 47 reward: -0.015527950310559006 service_time: 2363 s_time: 20 penalty: 0 agent_num: 23 done: False
______________________
id: 50 reward: -0.017063492063492062 service_time: 121 s_time: 43 penalty: 0 agent_num: 45 done: False
______________________
id: 48 reward: -0.018687707641196014 service_time: 2536 s_time: 45 penalty: 0 agent_num: 43 done: False
______________________
id: 45 reward: -0.070578231292517 service_time: 3833 s_time: 83 penalty: 0 agent_num: 21 done: False
______________________
id: 53 reward: -0.016917293233082706 service_time: 637 s_time: 36 penalty: 0 agent_num: 38 done: False
______________________
id: 54 reward: -0.003401360544217687 service_time: 2013 s_time: 8 penalty: 0 agent_num: 42 done: False
______________________
Step:  2816
Pretraining Loss:  tensor(0.2297, device='cuda:0', grad_fn=<MeanBackward0>)
id: 42 reward: -0.022321428571428572 service_time: 138 s_time: 15 penalty: 0 agent_num: 12 done: False
______________________
id: 55 reward: -0.07305194805194805 service_time: 102 s_time: 45 penalty: 0 agent_num: 11 done: False
______________________
id: 40 reward: -0.017857142857142856 service_time: 65 s_time: 28 penalty: 0 agent_num: 28 done: False
______________________
id: 46 reward: -0.02922077922077922 service_time: 411 s_time: 36 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: -0.011645962732919254 service_time: 237 s_time: 15 penalty: 0 agent_num: 23 done: False
______________________
id: 52 reward: -0.028409090909090908 service_time: 261 s_time: 35 penalty: 0 agent_num: 22 done: False
______________________
id: 43 reward: -0.007326007326007326 service_time: 76 s_time: 16 penalty: 0 agent_num: 39 done: False
______________________
id: 47 reward: -0.052795031055900624 service_time: 2431 s_time: 68 penalty: 0 agent_num: 23 done: False
______________________
id: 41 reward: 0.0 service_time: 1624 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 51 reward: -0.010808270676691729 service_time: 1917 s_time: 23 penalty: 0 agent_num: 38 done: False
______________________
id: 50 reward: 0.0 service_time: 121 s_time: 0 penalty: 0 agent_num: 45 done: False
______________________
id: 44 reward: 0.0029069767441860465 service_time: 147 s_time: -7 penalty: 0 agent_num: 43 done: False
______________________
id: 48 reward: -0.004152823920265781 service_time: 2546 s_time: 10 penalty: 0 agent_num: 43 done: False
______________________
id: 54 reward: -0.006377551020408163 service_time: 2028 s_time: 15 penalty: 0 agent_num: 42 done: False
______________________
id: 53 reward: -0.014097744360902255 service_time: 667 s_time: 30 penalty: 0 agent_num: 38 done: False
______________________
id: 45 reward: -0.0824829931972789 service_time: 3930 s_time: 97 penalty: 0 agent_num: 21 done: False
______________________
Step:  2832
Pretraining Loss:  tensor(0.2346, device='cuda:0', grad_fn=<MeanBackward0>)
id: 42 reward: -0.022321428571428572 service_time: 153 s_time: 15 penalty: 0 agent_num: 12 done: False
______________________
id: 55 reward: -0.024350649350649352 service_time: 117 s_time: 15 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: -0.021739130434782608 service_time: 265 s_time: 28 penalty: 0 agent_num: 23 done: False
______________________
id: 46 reward: -0.01461038961038961 service_time: 429 s_time: 18 penalty: 0 agent_num: 22 done: False
______________________
id: 40 reward: -0.011479591836734694 service_time: 83 s_time: 18 penalty: 0 agent_num: 28 done: False
______________________
id: 52 reward: -0.020292207792207792 service_time: 286 s_time: 25 penalty: 0 agent_num: 22 done: False
______________________
id: 41 reward: -0.039285714285714285 service_time: 1657 s_time: 33 penalty: 0 agent_num: 15 done: False
______________________
id: 43 reward: -0.01510989010989011 service_time: 109 s_time: 33 penalty: 0 agent_num: 39 done: False
______________________
id: 44 reward: -0.005398671096345515 service_time: 160 s_time: 13 penalty: 0 agent_num: 43 done: False
______________________
id: 45 reward: 0.003401360544217687 service_time: 3926 s_time: -4 penalty: 0 agent_num: 21 done: False
______________________
id: 51 reward: 0.0 service_time: 1917 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 47 reward: -0.05434782608695652 service_time: 2501 s_time: 70 penalty: 0 agent_num: 23 done: False
______________________
id: 48 reward: 0.0033222591362126247 service_time: 2538 s_time: -8 penalty: 0 agent_num: 43 done: False
______________________
id: 50 reward: -0.013888888888888888 service_time: 156 s_time: 35 penalty: 0 agent_num: 45 done: False
______________________
id: 53 reward: -0.009868421052631578 service_time: 688 s_time: 21 penalty: 0 agent_num: 38 done: False
______________________
id: 54 reward: 0.0 service_time: 2028 s_time: 0 penalty: 0 agent_num: 42 done: False
______________________
Step:  2848
Pretraining Loss:  tensor(0.2650, device='cuda:0', grad_fn=<MeanBackward0>)
id: 42 reward: 0.002976190476190476 service_time: 151 s_time: -2 penalty: 0 agent_num: 12 done: False
______________________
id: 55 reward: -0.06818181818181818 service_time: 159 s_time: 42 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: -0.008540372670807454 service_time: 276 s_time: 11 penalty: 0 agent_num: 23 done: False
______________________
id: 46 reward: -0.017857142857142856 service_time: 451 s_time: 22 penalty: 0 agent_num: 22 done: False
______________________
id: 40 reward: -0.018494897959183673 service_time: 112 s_time: 29 penalty: 0 agent_num: 28 done: False
______________________
id: 52 reward: -0.007305194805194805 service_time: 295 s_time: 9 penalty: 0 agent_num: 22 done: False
______________________
id: 43 reward: -0.013278388278388278 service_time: 138 s_time: 29 penalty: 0 agent_num: 39 done: False
______________________
id: 47 reward: -0.039596273291925464 service_time: 2552 s_time: 51 penalty: 0 agent_num: 23 done: False
______________________
id: 41 reward: -0.02023809523809524 service_time: 1674 s_time: 17 penalty: 0 agent_num: 15 done: False
______________________
id: 44 reward: 0.0 service_time: 160 s_time: 0 penalty: 0 agent_num: 43 done: False
______________________
id: 51 reward: 0.0 service_time: 1917 s_time: 0 penalty: 0 agent_num: 38 done: False
______________________
id: 50 reward: -0.014285714285714285 service_time: 192 s_time: 36 penalty: 0 agent_num: 45 done: False
______________________
id: 48 reward: 0.0012458471760797341 service_time: 2535 s_time: -3 penalty: 0 agent_num: 43 done: False
______________________
id: 53 reward: -0.012218045112781954 service_time: 714 s_time: 26 penalty: 0 agent_num: 38 done: False
______________________
id: 45 reward: 0.004251700680272109 service_time: 3921 s_time: -5 penalty: 0 agent_num: 21 done: False
______________________
id: 54 reward: -0.01020408163265306 service_time: 2052 s_time: 24 penalty: 0 agent_num: 42 done: False
______________________
Step:  2864
Pretraining Loss:  tensor(0.2728, device='cuda:0', grad_fn=<MeanBackward0>)
id: 42 reward: -0.03422619047619048 service_time: 174 s_time: 23 penalty: 0 agent_num: 12 done: False
______________________
id: 55 reward: -0.060064935064935064 service_time: 196 s_time: 37 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: -0.014751552795031056 service_time: 295 s_time: 19 penalty: 0 agent_num: 23 done: False
______________________
id: 52 reward: 0.0 service_time: 295 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 46 reward: -0.02922077922077922 service_time: 487 s_time: 36 penalty: 0 agent_num: 22 done: False
______________________
id: 41 reward: -0.041666666666666664 service_time: 1709 s_time: 35 penalty: 0 agent_num: 15 done: False
______________________
id: 47 reward: -0.09239130434782608 service_time: 2671 s_time: 119 penalty: 0 agent_num: 23 done: False
______________________
id: 40 reward: -0.008290816326530613 service_time: 125 s_time: 13 penalty: 0 agent_num: 28 done: False
______________________
id: 44 reward: -0.01951827242524917 service_time: 207 s_time: 47 penalty: 0 agent_num: 43 done: False
______________________
id: 51 reward: -0.008928571428571428 service_time: 1936 s_time: 19 penalty: 0 agent_num: 38 done: False
______________________
id: 45 reward: 0.0 service_time: 3921 s_time: 0 penalty: 0 agent_num: 21 done: False
______________________
id: 43 reward: -0.006868131868131868 service_time: 153 s_time: 15 penalty: 0 agent_num: 39 done: False
______________________
id: 53 reward: 0.0018796992481203006 service_time: 710 s_time: -4 penalty: 0 agent_num: 38 done: False
______________________
id: 50 reward: -0.00992063492063492 service_time: 217 s_time: 25 penalty: 0 agent_num: 45 done: False
______________________
id: 54 reward: 0.0 service_time: 2052 s_time: 0 penalty: 0 agent_num: 42 done: False
______________________
id: 48 reward: 20.00124584717608 service_time: 2532 s_time: -3 penalty: 0 agent_num: 43 done: True
______________________
Step:  2880
Pretraining Loss:  tensor(0.2679, device='cuda:0', grad_fn=<MeanBackward0>)
