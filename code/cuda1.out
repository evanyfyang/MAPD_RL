nohup: ignoring input
=============================================
Start Training: GPU=1, LR=1e-5, gamma=0.99, tau=0.1
Task Number: 500, Process Number: 16
Model Directory: ../models/_20250328_1118_lr_1e-5_gamma_0.99_tau_0.1_concat_0_16_500
=============================================
*** Loading map ***
Map size: 21x35 with 352 endpoints and 0 home stations.
Done! (0 s)
*** PreProcessing map ***
*** Loading map ***
Map size: 21x35 with 352 endpoints and 0 home stations.
Done! (0 s)
*** PreProcessing map ***
Done! (0 s)
*** Loading map ***
Map size: 21x35 with 352 endpoints and 0 home stations.
Done! (0 s)
*** PreProcessing map ***
Done! (0 s)
*** Loading map ***
Map size: 21x35 with 352 endpoints and 0 home stations.
Done! (0 s)
*** PreProcessing map ***
*** Loading map ***
Map size: 21x35 with 352 endpoints and 0 home stations.
Done! (0 s)
*** PreProcessing map ***
Done! (0 s)
*** Loading map ***
Map size: 21x35 with 352 endpoints and 0 home stations.
Done! (0 s)
*** PreProcessing map ***
*** Loading map ***
Map size: 21x35 with 352 endpoints and 0 home stations.
Done! (0 s)
*** PreProcessing map ***
Done! (0 s)
Done! (0 s)
*** Loading map ***
Map size: 21x35 with 352 endpoints and 0 home stations.
Done! (0 s)
*** PreProcessing map ***
*** Loading map ***
Map size: 21x35 with 352 endpoints and 0 home stations.
Done! (0 s)
*** PreProcessing map ***
Done! (0 s)
*** Loading map ***
Map size: 21x35 with 352 endpoints and 0 home stations.
Done! (0 s)
*** PreProcessing map ***
Done! (0 s)
Done! (0 s)
Done! (0 s)
*** Loading map ***
Map size: 21x35 with 352 endpoints and 0 home stations.
Done! (0 s)
*** PreProcessing map ***
Done! (0 s)
*** Loading map ***
Map size: 21x35 with 352 endpoints and 0 home stations.
Done! (0 s)
*** PreProcessing map ***
*** Loading map ***
Map size: 21x35 with 352 endpoints and 0 home stations.
Done! (0 s)
*** PreProcessing map ***
*** Loading map ***
Map size: 21x35 with 352 endpoints and 0 home stations.
Done! (0 s)
*** PreProcessing map ***
Done! (0 s)
Done! (0 s)
Done! (0 s)
*** Loading map ***
Map size: 21x35 with 352 endpoints and 0 home stations.
Done! (0 s)
*** PreProcessing map ***
Done! (0 s)
*** Loading map ***
Map size: 21x35 with 352 endpoints and 0 home stations.
Done! (0 s)
*** PreProcessing map ***
Done! (0 s)
Done! (0 s)
/localhome/yya305/miniconda3/envs/MAPD_RL/lib/python3.11/site-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(f"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}")
id: 49 reward: -0.022556390977443608 service_time: 24 s_time: 24 penalty: 0 agent_num: 19 done: False
______________________
id: 53 reward: -0.012276785714285714 service_time: 11 s_time: 11 penalty: 0 agent_num: 16 done: False
______________________
id: 42 reward: -0.016666666666666666 service_time: 14 s_time: 14 penalty: 0 agent_num: 15 done: False
______________________
id: 40 reward: -0.007518796992481203 service_time: 8 s_time: 8 penalty: 0 agent_num: 19 done: False
______________________
id: 51 reward: -0.020535714285714286 service_time: 23 s_time: 23 penalty: 0 agent_num: 20 done: False
______________________
id: 43 reward: -0.016428571428571428 service_time: 23 s_time: 23 penalty: 0 agent_num: 25 done: False
______________________
id: 52 reward: -0.020604395604395604 service_time: 30 s_time: 30 penalty: 0 agent_num: 26 done: False
______________________
id: 45 reward: -0.01369047619047619 service_time: 23 s_time: 23 penalty: 0 agent_num: 30 done: False
______________________
id: 44 reward: -0.009693877551020408 service_time: 19 s_time: 19 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.010452961672473868 service_time: 24 s_time: 24 penalty: 0 agent_num: 41 done: False
______________________
id: 41 reward: -0.011759581881533102 service_time: 27 s_time: 27 penalty: 0 agent_num: 41 done: False
______________________
id: 46 reward: -0.01282051282051282 service_time: 28 s_time: 28 penalty: 0 agent_num: 39 done: False
______________________
id: 50 reward: -0.008928571428571428 service_time: 20 s_time: 20 penalty: 0 agent_num: 40 done: False
______________________
id: 47 reward: -0.008275261324041812 service_time: 19 s_time: 19 penalty: 0 agent_num: 41 done: False
______________________
id: 54 reward: -0.0078397212543554 service_time: 18 s_time: 18 penalty: 0 agent_num: 41 done: False
______________________
id: 55 reward: -0.005226480836236934 service_time: 12 s_time: 12 penalty: 0 agent_num: 41 done: False
______________________
Using cuda device
Step:  0
Pretraining Loss:  tensor(0.0798, device='cuda:0', grad_fn=<MeanBackward0>)
id: 42 reward: -0.02738095238095238 service_time: 37 s_time: 23 penalty: 0 agent_num: 15 done: False
______________________
id: 53 reward: -0.0234375 service_time: 32 s_time: 21 penalty: 0 agent_num: 16 done: False
______________________
id: 51 reward: 0.0 service_time: 23 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 40 reward: -0.03101503759398496 service_time: 41 s_time: 33 penalty: 0 agent_num: 19 done: False
______________________
id: 49 reward: -0.009398496240601503 service_time: 34 s_time: 10 penalty: 0 agent_num: 19 done: False
______________________
id: 52 reward: -0.008241758241758242 service_time: 42 s_time: 12 penalty: 0 agent_num: 26 done: False
______________________
id: 43 reward: -0.015 service_time: 44 s_time: 21 penalty: 0 agent_num: 25 done: False
______________________
id: 45 reward: -0.017857142857142856 service_time: 53 s_time: 30 penalty: 0 agent_num: 30 done: False
______________________
id: 41 reward: -0.013937282229965157 service_time: 59 s_time: 32 penalty: 0 agent_num: 41 done: False
______________________
id: 50 reward: -0.013839285714285714 service_time: 51 s_time: 31 penalty: 0 agent_num: 40 done: False
______________________
id: 47 reward: -0.010452961672473868 service_time: 43 s_time: 24 penalty: 0 agent_num: 41 done: False
______________________
id: 46 reward: -0.004120879120879121 service_time: 37 s_time: 9 penalty: 0 agent_num: 39 done: False
______________________
id: 55 reward: -0.016114982578397212 service_time: 49 s_time: 37 penalty: 0 agent_num: 41 done: False
______________________
id: 44 reward: -0.012755102040816327 service_time: 44 s_time: 25 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: -0.01132404181184669 service_time: 44 s_time: 26 penalty: 0 agent_num: 41 done: False
______________________
id: 48 reward: 0.0 service_time: 24 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
Step:  16
Pretraining Loss:  tensor(0.1049, device='cuda:0', grad_fn=<MeanBackward0>)
id: 42 reward: -0.013095238095238096 service_time: 48 s_time: 11 penalty: 0 agent_num: 15 done: False
______________________
id: 53 reward: -0.03125 service_time: 60 s_time: 28 penalty: 0 agent_num: 16 done: False
______________________
id: 49 reward: -0.017857142857142856 service_time: 53 s_time: 19 penalty: 0 agent_num: 19 done: False
______________________
id: 51 reward: -0.033035714285714286 service_time: 60 s_time: 37 penalty: 0 agent_num: 20 done: False
______________________
id: 40 reward: -0.020676691729323307 service_time: 63 s_time: 22 penalty: 0 agent_num: 19 done: False
______________________
id: 43 reward: -0.019285714285714285 service_time: 71 s_time: 27 penalty: 0 agent_num: 25 done: False
______________________
id: 52 reward: -0.008928571428571428 service_time: 55 s_time: 13 penalty: 0 agent_num: 26 done: False
______________________
id: 45 reward: -0.01369047619047619 service_time: 76 s_time: 23 penalty: 0 agent_num: 30 done: False
______________________
id: 44 reward: -0.006122448979591836 service_time: 56 s_time: 12 penalty: 0 agent_num: 35 done: False
______________________
id: 46 reward: -0.011904761904761904 service_time: 63 s_time: 26 penalty: 0 agent_num: 39 done: False
______________________
id: 41 reward: 0.0 service_time: 59 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 54 reward: -0.005226480836236934 service_time: 56 s_time: 12 penalty: 0 agent_num: 41 done: False
______________________
id: 47 reward: 0.0 service_time: 43 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 48 reward: -0.004790940766550522 service_time: 35 s_time: 11 penalty: 0 agent_num: 41 done: False
______________________
id: 55 reward: -0.01132404181184669 service_time: 75 s_time: 26 penalty: 0 agent_num: 41 done: False
______________________
id: 50 reward: -0.009821428571428571 service_time: 73 s_time: 22 penalty: 0 agent_num: 40 done: False
______________________
Step:  32
Pretraining Loss:  tensor(0.1124, device='cuda:0', grad_fn=<MeanBackward0>)
id: 42 reward: -0.041666666666666664 service_time: 83 s_time: 35 penalty: 0 agent_num: 15 done: False
______________________
id: 43 reward: 0.0014285714285714286 service_time: 69 s_time: -2 penalty: 0 agent_num: 25 done: False
______________________
id: 49 reward: 0.0 service_time: 53 s_time: 0 penalty: 0 agent_num: 19 done: False
______________________
id: 45 reward: 0.0 service_time: 76 s_time: 0 penalty: 0 agent_num: 30 done: False
______________________
id: 53 reward: -0.0546875 service_time: 109 s_time: 49 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: -0.03853383458646616 service_time: 104 s_time: 41 penalty: 0 agent_num: 19 done: False
______________________
id: 52 reward: -0.025412087912087912 service_time: 92 s_time: 37 penalty: 0 agent_num: 26 done: False
______________________
id: 51 reward: -0.05892857142857143 service_time: 126 s_time: 66 penalty: 0 agent_num: 20 done: False
______________________
id: 44 reward: -0.012755102040816327 service_time: 81 s_time: 25 penalty: 0 agent_num: 35 done: False
______________________
id: 46 reward: -0.01282051282051282 service_time: 91 s_time: 28 penalty: 0 agent_num: 39 done: False
______________________
id: 47 reward: -0.020470383275261322 service_time: 90 s_time: 47 penalty: 0 agent_num: 41 done: False
______________________
id: 54 reward: 0.0 service_time: 56 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 41 reward: -0.021341463414634148 service_time: 108 s_time: 49 penalty: 0 agent_num: 41 done: False
______________________
id: 50 reward: -0.010714285714285714 service_time: 97 s_time: 24 penalty: 0 agent_num: 40 done: False
______________________
id: 48 reward: -0.029181184668989547 service_time: 102 s_time: 67 penalty: 0 agent_num: 41 done: False
______________________
id: 55 reward: -0.0195993031358885 service_time: 120 s_time: 45 penalty: 0 agent_num: 41 done: False
______________________
Step:  48
Pretraining Loss:  tensor(0.1266, device='cuda:0', grad_fn=<MeanBackward0>)
id: 42 reward: -0.023809523809523808 service_time: 103 s_time: 20 penalty: 0 agent_num: 15 done: False
______________________
id: 49 reward: -0.02913533834586466 service_time: 84 s_time: 31 penalty: 0 agent_num: 19 done: False
______________________
id: 40 reward: -0.015977443609022556 service_time: 121 s_time: 17 penalty: 0 agent_num: 19 done: False
______________________
id: 43 reward: -0.02 service_time: 97 s_time: 28 penalty: 0 agent_num: 25 done: False
______________________
id: 51 reward: -0.025892857142857145 service_time: 155 s_time: 29 penalty: 0 agent_num: 20 done: False
______________________
id: 52 reward: -0.027472527472527472 service_time: 132 s_time: 40 penalty: 0 agent_num: 26 done: False
______________________
id: 44 reward: 0.0 service_time: 81 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 50 reward: -0.0035714285714285713 service_time: 105 s_time: 8 penalty: 0 agent_num: 40 done: False
______________________
id: 54 reward: -0.011759581881533102 service_time: 83 s_time: 27 penalty: 0 agent_num: 41 done: False
______________________
id: 46 reward: -0.013278388278388278 service_time: 120 s_time: 29 penalty: 0 agent_num: 39 done: False
______________________
id: 53 reward: -0.03459821428571429 service_time: 140 s_time: 31 penalty: 0 agent_num: 16 done: False
______________________
id: 41 reward: -0.009146341463414634 service_time: 129 s_time: 21 penalty: 0 agent_num: 41 done: False
______________________
id: 55 reward: -0.006968641114982578 service_time: 136 s_time: 16 penalty: 0 agent_num: 41 done: False
______________________
id: 47 reward: -0.0078397212543554 service_time: 108 s_time: 18 penalty: 0 agent_num: 41 done: False
______________________
id: 45 reward: -0.033928571428571426 service_time: 133 s_time: 57 penalty: 0 agent_num: 30 done: False
______________________
id: 48 reward: 0.006097560975609756 service_time: 88 s_time: -14 penalty: 0 agent_num: 41 done: False
______________________
Step:  64
Pretraining Loss:  tensor(0.1387, device='cuda:0', grad_fn=<MeanBackward0>)
id: 42 reward: -0.011904761904761904 service_time: 113 s_time: 10 penalty: 0 agent_num: 15 done: False
______________________
id: 49 reward: -0.05733082706766917 service_time: 145 s_time: 61 penalty: 0 agent_num: 19 done: False
______________________
id: 51 reward: 0.0 service_time: 155 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 43 reward: -0.024285714285714285 service_time: 131 s_time: 34 penalty: 0 agent_num: 25 done: False
______________________
id: 40 reward: -0.014097744360902255 service_time: 136 s_time: 15 penalty: 0 agent_num: 19 done: False
______________________
id: 53 reward: -0.024553571428571428 service_time: 162 s_time: 22 penalty: 0 agent_num: 16 done: False
______________________
id: 52 reward: -0.007554945054945055 service_time: 143 s_time: 11 penalty: 0 agent_num: 26 done: False
______________________
id: 47 reward: 0.0 service_time: 108 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 50 reward: 0.0 service_time: 105 s_time: 0 penalty: 0 agent_num: 40 done: False
______________________
id: 41 reward: 0.0 service_time: 129 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 54 reward: 0.003048780487804878 service_time: 76 s_time: -7 penalty: 0 agent_num: 41 done: False
______________________
id: 46 reward: -0.004120879120879121 service_time: 129 s_time: 9 penalty: 0 agent_num: 39 done: False
______________________
id: 55 reward: -0.009581881533101045 service_time: 158 s_time: 22 penalty: 0 agent_num: 41 done: False
______________________
id: 48 reward: -0.027439024390243903 service_time: 151 s_time: 63 penalty: 0 agent_num: 41 done: False
______________________
id: 45 reward: -0.01488095238095238 service_time: 158 s_time: 25 penalty: 0 agent_num: 30 done: False
______________________
id: 44 reward: -0.00510204081632653 service_time: 91 s_time: 10 penalty: 0 agent_num: 35 done: False
______________________
Step:  80
Pretraining Loss:  tensor(0.1506, device='cuda:0', grad_fn=<MeanBackward0>)
id: 42 reward: -0.04642857142857143 service_time: 152 s_time: 39 penalty: 0 agent_num: 15 done: False
______________________
id: 40 reward: -0.020676691729323307 service_time: 158 s_time: 22 penalty: 0 agent_num: 19 done: False
______________________
id: 43 reward: 0.0 service_time: 131 s_time: 0 penalty: 0 agent_num: 25 done: False
______________________
id: 49 reward: 0.0 service_time: 145 s_time: 0 penalty: 0 agent_num: 19 done: False
______________________
id: 51 reward: -0.03125 service_time: 190 s_time: 35 penalty: 0 agent_num: 20 done: False
______________________
id: 52 reward: -0.023351648351648352 service_time: 177 s_time: 34 penalty: 0 agent_num: 26 done: False
______________________
id: 54 reward: -0.013501742160278746 service_time: 107 s_time: 31 penalty: 0 agent_num: 41 done: False
______________________
id: 44 reward: -0.009693877551020408 service_time: 110 s_time: 19 penalty: 0 agent_num: 35 done: False
______________________
id: 53 reward: -0.024553571428571428 service_time: 184 s_time: 22 penalty: 0 agent_num: 16 done: False
______________________
id: 47 reward: -0.032229965156794424 service_time: 182 s_time: 74 penalty: 0 agent_num: 41 done: False
______________________
id: 45 reward: -0.007738095238095238 service_time: 171 s_time: 13 penalty: 0 agent_num: 30 done: False
______________________
id: 41 reward: -0.023519163763066203 service_time: 183 s_time: 54 penalty: 0 agent_num: 41 done: False
______________________
id: 46 reward: -0.014652014652014652 service_time: 161 s_time: 32 penalty: 0 agent_num: 39 done: False
______________________
id: 48 reward: -0.010452961672473868 service_time: 175 s_time: 24 penalty: 0 agent_num: 41 done: False
______________________
id: 55 reward: -0.006097560975609756 service_time: 172 s_time: 14 penalty: 0 agent_num: 41 done: False
______________________
id: 50 reward: -0.03571428571428571 service_time: 185 s_time: 80 penalty: 0 agent_num: 40 done: False
______________________
Step:  96
Pretraining Loss:  tensor(0.1611, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.03665413533834586 service_time: 184 s_time: 39 penalty: 0 agent_num: 19 done: False
______________________
id: 42 reward: -0.04642857142857143 service_time: 191 s_time: 39 penalty: 0 agent_num: 15 done: False
______________________
id: 53 reward: -0.03236607142857143 service_time: 213 s_time: 29 penalty: 0 agent_num: 16 done: False
______________________
id: 44 reward: -0.00510204081632653 service_time: 120 s_time: 10 penalty: 0 agent_num: 35 done: False
______________________
id: 51 reward: -0.03125 service_time: 225 s_time: 35 penalty: 0 agent_num: 20 done: False
______________________
id: 55 reward: -0.007404181184668989 service_time: 189 s_time: 17 penalty: 0 agent_num: 41 done: False
______________________
id: 40 reward: -0.03759398496240601 service_time: 198 s_time: 40 penalty: 0 agent_num: 19 done: False
______________________
id: 54 reward: -0.016114982578397212 service_time: 144 s_time: 37 penalty: 0 agent_num: 41 done: False
______________________
id: 47 reward: 0.0 service_time: 182 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 46 reward: -0.0022893772893772895 service_time: 166 s_time: 5 penalty: 0 agent_num: 39 done: False
______________________
id: 52 reward: 0.0 service_time: 177 s_time: 0 penalty: 0 agent_num: 26 done: False
______________________
id: 45 reward: 0.0 service_time: 171 s_time: 0 penalty: 0 agent_num: 30 done: False
______________________
id: 41 reward: -0.006968641114982578 service_time: 199 s_time: 16 penalty: 0 agent_num: 41 done: False
______________________
id: 48 reward: 0.0 service_time: 175 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 43 reward: -0.04857142857142857 service_time: 199 s_time: 68 penalty: 0 agent_num: 25 done: False
______________________
id: 50 reward: -0.020982142857142855 service_time: 232 s_time: 47 penalty: 0 agent_num: 40 done: False
______________________
Step:  112
Pretraining Loss:  tensor(0.1762, device='cuda:0', grad_fn=<MeanBackward0>)
id: 42 reward: -0.03333333333333333 service_time: 219 s_time: 28 penalty: 0 agent_num: 15 done: False
______________________
id: 51 reward: -0.0125 service_time: 239 s_time: 14 penalty: 0 agent_num: 20 done: False
______________________
id: 49 reward: -0.02631578947368421 service_time: 212 s_time: 28 penalty: 0 agent_num: 19 done: False
______________________
id: 53 reward: -0.026785714285714284 service_time: 237 s_time: 24 penalty: 0 agent_num: 16 done: False
______________________
id: 44 reward: -0.00816326530612245 service_time: 136 s_time: 16 penalty: 0 agent_num: 35 done: False
______________________
id: 43 reward: 0.0 service_time: 199 s_time: 0 penalty: 0 agent_num: 25 done: False
______________________
id: 52 reward: -0.004120879120879121 service_time: 183 s_time: 6 penalty: 0 agent_num: 26 done: False
______________________
id: 45 reward: -0.01904761904761905 service_time: 203 s_time: 32 penalty: 0 agent_num: 30 done: False
______________________
id: 55 reward: -0.007404181184668989 service_time: 206 s_time: 17 penalty: 0 agent_num: 41 done: False
______________________
id: 48 reward: -0.007404181184668989 service_time: 192 s_time: 17 penalty: 0 agent_num: 41 done: False
______________________
id: 46 reward: -0.01510989010989011 service_time: 199 s_time: 33 penalty: 0 agent_num: 39 done: False
______________________
id: 50 reward: -0.014732142857142857 service_time: 265 s_time: 33 penalty: 0 agent_num: 40 done: False
______________________
id: 47 reward: -0.0156794425087108 service_time: 218 s_time: 36 penalty: 0 agent_num: 41 done: False
______________________
id: 40 reward: -0.021616541353383457 service_time: 221 s_time: 23 penalty: 0 agent_num: 19 done: False
______________________
id: 54 reward: -0.004355400696864111 service_time: 154 s_time: 10 penalty: 0 agent_num: 41 done: False
______________________
id: 41 reward: -0.008710801393728223 service_time: 219 s_time: 20 penalty: 0 agent_num: 41 done: False
______________________
Step:  128
Pretraining Loss:  tensor(0.1832, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.009398496240601503 service_time: 222 s_time: 10 penalty: 0 agent_num: 19 done: False
______________________
id: 42 reward: -0.04285714285714286 service_time: 255 s_time: 36 penalty: 0 agent_num: 15 done: False
______________________
id: 44 reward: 0.0 service_time: 136 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 45 reward: -0.025 service_time: 245 s_time: 42 penalty: 0 agent_num: 30 done: False
______________________
id: 46 reward: -0.005952380952380952 service_time: 212 s_time: 13 penalty: 0 agent_num: 39 done: False
______________________
id: 52 reward: -0.038461538461538464 service_time: 239 s_time: 56 penalty: 0 agent_num: 26 done: False
______________________
id: 54 reward: -0.004790940766550522 service_time: 165 s_time: 11 penalty: 0 agent_num: 41 done: False
______________________
id: 51 reward: -0.016964285714285713 service_time: 258 s_time: 19 penalty: 0 agent_num: 20 done: False
______________________
id: 55 reward: -0.007404181184668989 service_time: 223 s_time: 17 penalty: 0 agent_num: 41 done: False
______________________
id: 40 reward: -0.010338345864661654 service_time: 232 s_time: 11 penalty: 0 agent_num: 19 done: False
______________________
id: 53 reward: -0.030133928571428572 service_time: 264 s_time: 27 penalty: 0 agent_num: 16 done: False
______________________
id: 41 reward: -0.010017421602787456 service_time: 242 s_time: 23 penalty: 0 agent_num: 41 done: False
______________________
id: 47 reward: -0.004355400696864111 service_time: 228 s_time: 10 penalty: 0 agent_num: 41 done: False
______________________
id: 50 reward: -0.013839285714285714 service_time: 296 s_time: 31 penalty: 0 agent_num: 40 done: False
______________________
id: 48 reward: -0.02264808362369338 service_time: 244 s_time: 52 penalty: 0 agent_num: 41 done: False
______________________
id: 43 reward: -0.05928571428571429 service_time: 282 s_time: 83 penalty: 0 agent_num: 25 done: False
______________________
Step:  144
Pretraining Loss:  tensor(0.2003, device='cuda:0', grad_fn=<MeanBackward0>)
id: 42 reward: -0.04404761904761905 service_time: 292 s_time: 37 penalty: 0 agent_num: 15 done: False
______________________
id: 49 reward: -0.018796992481203006 service_time: 242 s_time: 20 penalty: 0 agent_num: 19 done: False
______________________
id: 51 reward: -0.033035714285714286 service_time: 295 s_time: 37 penalty: 0 agent_num: 20 done: False
______________________
id: 44 reward: -0.00816326530612245 service_time: 152 s_time: 16 penalty: 0 agent_num: 35 done: False
______________________
id: 40 reward: -0.03665413533834586 service_time: 271 s_time: 39 penalty: 0 agent_num: 19 done: False
______________________
id: 45 reward: -0.010714285714285714 service_time: 263 s_time: 18 penalty: 0 agent_num: 30 done: False
______________________
id: 53 reward: 0.0 service_time: 264 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 54 reward: -0.007404181184668989 service_time: 182 s_time: 17 penalty: 0 agent_num: 41 done: False
______________________
id: 55 reward: 0.0 service_time: 223 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 47 reward: -0.003048780487804878 service_time: 235 s_time: 7 penalty: 0 agent_num: 41 done: False
______________________
id: 43 reward: -0.014285714285714285 service_time: 302 s_time: 20 penalty: 0 agent_num: 25 done: False
______________________
id: 46 reward: -0.009615384615384616 service_time: 233 s_time: 21 penalty: 0 agent_num: 39 done: False
______________________
id: 48 reward: 0.0 service_time: 244 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 52 reward: 0.0 service_time: 239 s_time: 0 penalty: 0 agent_num: 26 done: False
______________________
id: 41 reward: -0.008275261324041812 service_time: 261 s_time: 19 penalty: 0 agent_num: 41 done: False
______________________
id: 50 reward: 0.014285714285714285 service_time: 264 s_time: -32 penalty: 0 agent_num: 40 done: False
______________________
Step:  160
Pretraining Loss:  tensor(0.2117, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.0 service_time: 242 s_time: 0 penalty: 0 agent_num: 19 done: False
______________________
id: 44 reward: 0.0 service_time: 152 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 40 reward: -0.02913533834586466 service_time: 302 s_time: 31 penalty: 0 agent_num: 19 done: False
______________________
id: 42 reward: -0.04285714285714286 service_time: 328 s_time: 36 penalty: 0 agent_num: 15 done: False
______________________
id: 51 reward: 0.0 service_time: 295 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 45 reward: -0.004166666666666667 service_time: 270 s_time: 7 penalty: 0 agent_num: 30 done: False
______________________
id: 55 reward: -0.01088850174216028 service_time: 248 s_time: 25 penalty: 0 agent_num: 41 done: False
______________________
id: 54 reward: -0.01524390243902439 service_time: 217 s_time: 35 penalty: 0 agent_num: 41 done: False
______________________
id: 53 reward: -0.07924107142857142 service_time: 335 s_time: 71 penalty: 0 agent_num: 16 done: False
______________________
id: 46 reward: -0.012362637362637362 service_time: 260 s_time: 27 penalty: 0 agent_num: 39 done: False
______________________
id: 47 reward: 0.0 service_time: 235 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 50 reward: -0.012946428571428572 service_time: 293 s_time: 29 penalty: 0 agent_num: 40 done: False
______________________
id: 41 reward: -0.017421602787456445 service_time: 301 s_time: 40 penalty: 0 agent_num: 41 done: False
______________________
id: 48 reward: -0.020470383275261322 service_time: 291 s_time: 47 penalty: 0 agent_num: 41 done: False
______________________
id: 43 reward: -0.007857142857142858 service_time: 313 s_time: 11 penalty: 0 agent_num: 25 done: False
______________________
id: 52 reward: -0.040521978021978024 service_time: 298 s_time: 59 penalty: 0 agent_num: 26 done: False
______________________
Step:  176
Pretraining Loss:  tensor(0.2341, device='cuda:0', grad_fn=<MeanBackward0>)
id: 42 reward: -0.07380952380952381 service_time: 390 s_time: 62 penalty: 0 agent_num: 15 done: False
______________________
id: 49 reward: -0.05357142857142857 service_time: 299 s_time: 57 penalty: 0 agent_num: 19 done: False
______________________
id: 44 reward: 0.0 service_time: 152 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 43 reward: -0.019285714285714285 service_time: 340 s_time: 27 penalty: 0 agent_num: 25 done: False
______________________
id: 40 reward: -0.016917293233082706 service_time: 320 s_time: 18 penalty: 0 agent_num: 19 done: False
______________________
id: 53 reward: -0.0033482142857142855 service_time: 338 s_time: 3 penalty: 0 agent_num: 16 done: False
______________________
id: 51 reward: -0.055357142857142855 service_time: 357 s_time: 62 penalty: 0 agent_num: 20 done: False
______________________
id: 55 reward: -0.008275261324041812 service_time: 267 s_time: 19 penalty: 0 agent_num: 41 done: False
______________________
id: 45 reward: -0.0125 service_time: 291 s_time: 21 penalty: 0 agent_num: 30 done: False
______________________
id: 46 reward: -0.008241758241758242 service_time: 278 s_time: 18 penalty: 0 agent_num: 39 done: False
______________________
id: 50 reward: -0.024553571428571428 service_time: 348 s_time: 55 penalty: 0 agent_num: 40 done: False
______________________
id: 48 reward: -0.004790940766550522 service_time: 302 s_time: 11 penalty: 0 agent_num: 41 done: False
______________________
id: 54 reward: -0.005662020905923345 service_time: 230 s_time: 13 penalty: 0 agent_num: 41 done: False
______________________
id: 47 reward: -0.043118466898954703 service_time: 334 s_time: 99 penalty: 0 agent_num: 41 done: False
______________________
id: 41 reward: 0.0 service_time: 301 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 52 reward: -0.022664835164835164 service_time: 331 s_time: 33 penalty: 0 agent_num: 26 done: False
______________________
Step:  192
Pretraining Loss:  tensor(0.2388, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.011278195488721804 service_time: 311 s_time: 12 penalty: 0 agent_num: 19 done: False
______________________
id: 42 reward: -0.04523809523809524 service_time: 428 s_time: 38 penalty: 0 agent_num: 15 done: False
______________________
id: 43 reward: 0.0 service_time: 340 s_time: 0 penalty: 0 agent_num: 25 done: False
______________________
id: 40 reward: -0.020676691729323307 service_time: 342 s_time: 22 penalty: 0 agent_num: 19 done: False
______________________
id: 52 reward: 0.0027472527472527475 service_time: 327 s_time: -4 penalty: 0 agent_num: 26 done: False
______________________
id: 44 reward: -0.011224489795918367 service_time: 174 s_time: 22 penalty: 0 agent_num: 35 done: False
______________________
id: 53 reward: -0.027901785714285716 service_time: 363 s_time: 25 penalty: 0 agent_num: 16 done: False
______________________
id: 55 reward: -0.008710801393728223 service_time: 287 s_time: 20 penalty: 0 agent_num: 41 done: False
______________________
id: 45 reward: 0.0 service_time: 291 s_time: 0 penalty: 0 agent_num: 30 done: False
______________________
id: 54 reward: -0.008275261324041812 service_time: 249 s_time: 19 penalty: 0 agent_num: 41 done: False
______________________
id: 46 reward: -0.005952380952380952 service_time: 291 s_time: 13 penalty: 0 agent_num: 39 done: False
______________________
id: 41 reward: -0.024825783972125436 service_time: 358 s_time: 57 penalty: 0 agent_num: 41 done: False
______________________
id: 51 reward: -0.025 service_time: 385 s_time: 28 penalty: 0 agent_num: 20 done: False
______________________
id: 48 reward: -0.004790940766550522 service_time: 313 s_time: 11 penalty: 0 agent_num: 41 done: False
______________________
id: 50 reward: -0.016964285714285713 service_time: 386 s_time: 38 penalty: 0 agent_num: 40 done: False
______________________
id: 47 reward: -0.01524390243902439 service_time: 369 s_time: 35 penalty: 0 agent_num: 41 done: False
______________________
Step:  208
Pretraining Loss:  tensor(0.2638, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.015977443609022556 service_time: 328 s_time: 17 penalty: 0 agent_num: 19 done: False
______________________
id: 53 reward: -0.0390625 service_time: 398 s_time: 35 penalty: 0 agent_num: 16 done: False
______________________
id: 43 reward: -0.007857142857142858 service_time: 351 s_time: 11 penalty: 0 agent_num: 25 done: False
______________________
id: 40 reward: -0.013157894736842105 service_time: 356 s_time: 14 penalty: 0 agent_num: 19 done: False
______________________
id: 54 reward: 0.0 service_time: 249 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 47 reward: 0.0 service_time: 369 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 51 reward: 0.0 service_time: 385 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 55 reward: -0.006097560975609756 service_time: 301 s_time: 14 penalty: 0 agent_num: 41 done: False
______________________
id: 45 reward: -0.014285714285714285 service_time: 315 s_time: 24 penalty: 0 agent_num: 30 done: False
______________________
id: 48 reward: 0.0 service_time: 313 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 46 reward: -0.01098901098901099 service_time: 315 s_time: 24 penalty: 0 agent_num: 39 done: False
______________________
id: 42 reward: -0.05357142857142857 service_time: 473 s_time: 45 penalty: 0 agent_num: 15 done: False
______________________
id: 44 reward: -0.0163265306122449 service_time: 206 s_time: 32 penalty: 0 agent_num: 35 done: False
______________________
id: 52 reward: -0.021291208791208792 service_time: 358 s_time: 31 penalty: 0 agent_num: 26 done: False
______________________
id: 41 reward: -0.005226480836236934 service_time: 370 s_time: 12 penalty: 0 agent_num: 41 done: False
______________________
id: 50 reward: -0.011160714285714286 service_time: 411 s_time: 25 penalty: 0 agent_num: 40 done: False
______________________
Step:  224
Pretraining Loss:  tensor(0.2583, device='cuda:0', grad_fn=<MeanBackward0>)
id: 42 reward: -0.04642857142857143 service_time: 512 s_time: 39 penalty: 0 agent_num: 15 done: False
______________________
id: 53 reward: -0.020089285714285716 service_time: 416 s_time: 18 penalty: 0 agent_num: 16 done: False
______________________
id: 49 reward: -0.045112781954887216 service_time: 376 s_time: 48 penalty: 0 agent_num: 19 done: False
______________________
id: 52 reward: -0.025412087912087912 service_time: 395 s_time: 37 penalty: 0 agent_num: 26 done: False
______________________
id: 40 reward: -0.03195488721804511 service_time: 390 s_time: 34 penalty: 0 agent_num: 19 done: False
______________________
id: 44 reward: -0.010714285714285714 service_time: 227 s_time: 21 penalty: 0 agent_num: 35 done: False
______________________
id: 45 reward: -0.02619047619047619 service_time: 359 s_time: 44 penalty: 0 agent_num: 30 done: False
______________________
id: 43 reward: -0.03357142857142857 service_time: 398 s_time: 47 penalty: 0 agent_num: 25 done: False
______________________
id: 55 reward: -0.009581881533101045 service_time: 323 s_time: 22 penalty: 0 agent_num: 41 done: False
______________________
id: 48 reward: -0.03005226480836237 service_time: 382 s_time: 69 penalty: 0 agent_num: 41 done: False
______________________
id: 46 reward: -0.01694139194139194 service_time: 352 s_time: 37 penalty: 0 agent_num: 39 done: False
______________________
id: 51 reward: -0.07410714285714286 service_time: 468 s_time: 83 penalty: 0 agent_num: 20 done: False
______________________
id: 54 reward: -0.018728222996515678 service_time: 292 s_time: 43 penalty: 0 agent_num: 41 done: False
______________________
id: 50 reward: -0.012946428571428572 service_time: 440 s_time: 29 penalty: 0 agent_num: 40 done: False
______________________
id: 41 reward: 0.0 service_time: 370 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 47 reward: -0.010452961672473868 service_time: 393 s_time: 24 penalty: 0 agent_num: 41 done: False
______________________
Step:  240
Pretraining Loss:  tensor(0.2778, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.03289473684210526 service_time: 411 s_time: 35 penalty: 0 agent_num: 19 done: False
______________________
id: 40 reward: -0.047932330827067667 service_time: 441 s_time: 51 penalty: 0 agent_num: 19 done: False
______________________
id: 43 reward: -0.019285714285714285 service_time: 425 s_time: 27 penalty: 0 agent_num: 25 done: False
______________________
id: 55 reward: -0.013937282229965157 service_time: 355 s_time: 32 penalty: 0 agent_num: 41 done: False
______________________
id: 44 reward: 0.0 service_time: 227 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 45 reward: -0.016666666666666666 service_time: 387 s_time: 28 penalty: 0 agent_num: 30 done: False
______________________
id: 46 reward: -0.005952380952380952 service_time: 365 s_time: 13 penalty: 0 agent_num: 39 done: False
______________________
id: 54 reward: 0.0 service_time: 292 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 42 reward: -0.02857142857142857 service_time: 536 s_time: 24 penalty: 0 agent_num: 15 done: False
______________________
id: 48 reward: -0.011759581881533102 service_time: 409 s_time: 27 penalty: 0 agent_num: 41 done: False
______________________
id: 47 reward: -0.02613240418118467 service_time: 453 s_time: 60 penalty: 0 agent_num: 41 done: False
______________________
id: 50 reward: 0.0 service_time: 440 s_time: 0 penalty: 0 agent_num: 40 done: False
______________________
id: 52 reward: -0.032280219780219783 service_time: 442 s_time: 47 penalty: 0 agent_num: 26 done: False
______________________
id: 41 reward: -0.014372822299651568 service_time: 403 s_time: 33 penalty: 0 agent_num: 41 done: False
______________________
id: 51 reward: -0.03482142857142857 service_time: 507 s_time: 39 penalty: 0 agent_num: 20 done: False
______________________
id: 53 reward: -0.06696428571428571 service_time: 476 s_time: 60 penalty: 0 agent_num: 16 done: False
______________________
Step:  256
Pretraining Loss:  tensor(0.2874, device='cuda:0', grad_fn=<MeanBackward0>)
id: 42 reward: -0.04285714285714286 service_time: 572 s_time: 36 penalty: 0 agent_num: 15 done: False
______________________
id: 40 reward: 0.0 service_time: 441 s_time: 0 penalty: 0 agent_num: 19 done: False
______________________
id: 53 reward: -0.04241071428571429 service_time: 514 s_time: 38 penalty: 0 agent_num: 16 done: False
______________________
id: 55 reward: -0.02221254355400697 service_time: 406 s_time: 51 penalty: 0 agent_num: 41 done: False
______________________
id: 52 reward: -0.028846153846153848 service_time: 484 s_time: 42 penalty: 0 agent_num: 26 done: False
______________________
id: 43 reward: -0.03785714285714286 service_time: 478 s_time: 53 penalty: 0 agent_num: 25 done: False
______________________
id: 45 reward: -0.016666666666666666 service_time: 415 s_time: 28 penalty: 0 agent_num: 30 done: False
______________________
id: 49 reward: -0.03571428571428571 service_time: 449 s_time: 38 penalty: 0 agent_num: 19 done: False
______________________
id: 54 reward: -0.003484320557491289 service_time: 300 s_time: 8 penalty: 0 agent_num: 41 done: False
______________________
id: 44 reward: -0.001530612244897959 service_time: 230 s_time: 3 penalty: 0 agent_num: 35 done: False
______________________
id: 50 reward: -0.020535714285714286 service_time: 486 s_time: 46 penalty: 0 agent_num: 40 done: False
______________________
id: 51 reward: -0.02142857142857143 service_time: 531 s_time: 24 penalty: 0 agent_num: 20 done: False
______________________
id: 48 reward: -0.02003484320557491 service_time: 455 s_time: 46 penalty: 0 agent_num: 41 done: False
______________________
id: 41 reward: -0.03484320557491289 service_time: 483 s_time: 80 penalty: 0 agent_num: 41 done: False
______________________
id: 47 reward: -0.008710801393728223 service_time: 473 s_time: 20 penalty: 0 agent_num: 41 done: False
______________________
id: 46 reward: -0.020604395604395604 service_time: 410 s_time: 45 penalty: 0 agent_num: 39 done: False
______________________
Step:  272
Pretraining Loss:  tensor(0.3085, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.03007518796992481 service_time: 481 s_time: 32 penalty: 0 agent_num: 19 done: False
______________________
id: 53 reward: 0.026785714285714284 service_time: 490 s_time: -24 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: -0.06578947368421052 service_time: 511 s_time: 70 penalty: 0 agent_num: 19 done: False
______________________
id: 54 reward: -0.024825783972125436 service_time: 357 s_time: 57 penalty: 0 agent_num: 41 done: False
______________________
id: 48 reward: -0.012195121951219513 service_time: 483 s_time: 28 penalty: 0 agent_num: 41 done: False
______________________
id: 46 reward: 0.007783882783882784 service_time: 393 s_time: -17 penalty: 0 agent_num: 39 done: False
______________________
id: 45 reward: -0.02023809523809524 service_time: 449 s_time: 34 penalty: 0 agent_num: 30 done: False
______________________
id: 42 reward: 0.013095238095238096 service_time: 561 s_time: -11 penalty: 0 agent_num: 15 done: False
______________________
id: 47 reward: -0.009146341463414634 service_time: 494 s_time: 21 penalty: 0 agent_num: 41 done: False
______________________
id: 43 reward: -0.030714285714285715 service_time: 521 s_time: 43 penalty: 0 agent_num: 25 done: False
______________________
id: 44 reward: -0.017857142857142856 service_time: 265 s_time: 35 penalty: 0 agent_num: 35 done: False
______________________
id: 51 reward: -0.027678571428571427 service_time: 562 s_time: 31 penalty: 0 agent_num: 20 done: False
______________________
id: 50 reward: -0.011160714285714286 service_time: 511 s_time: 25 penalty: 0 agent_num: 40 done: False
______________________
id: 55 reward: -0.0013066202090592336 service_time: 409 s_time: 3 penalty: 0 agent_num: 41 done: False
______________________
id: 52 reward: -0.006181318681318681 service_time: 493 s_time: 9 penalty: 0 agent_num: 26 done: False
______________________
id: 41 reward: -0.010452961672473868 service_time: 507 s_time: 24 penalty: 0 agent_num: 41 done: False
______________________
Step:  288
Pretraining Loss:  tensor(0.3179, device='cuda:0', grad_fn=<MeanBackward0>)
id: 42 reward: 0.04047619047619048 service_time: 527 s_time: -34 penalty: 0 agent_num: 15 done: False
______________________
id: 53 reward: 0.04575892857142857 service_time: 449 s_time: -41 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: -0.046992481203007516 service_time: 561 s_time: 50 penalty: 0 agent_num: 19 done: False
______________________
id: 45 reward: -0.0125 service_time: 470 s_time: 21 penalty: 0 agent_num: 30 done: False
______________________
id: 55 reward: -0.013066202090592335 service_time: 439 s_time: 30 penalty: 0 agent_num: 41 done: False
______________________
id: 50 reward: 0.0008928571428571428 service_time: 509 s_time: -2 penalty: 0 agent_num: 40 done: False
______________________
id: 46 reward: -0.011904761904761904 service_time: 419 s_time: 26 penalty: 0 agent_num: 39 done: False
______________________
id: 43 reward: -0.02142857142857143 service_time: 551 s_time: 30 penalty: 0 agent_num: 25 done: False
______________________
id: 52 reward: -0.025412087912087912 service_time: 530 s_time: 37 penalty: 0 agent_num: 26 done: False
______________________
id: 54 reward: -0.014372822299651568 service_time: 390 s_time: 33 penalty: 0 agent_num: 41 done: False
______________________
id: 49 reward: -0.022556390977443608 service_time: 505 s_time: 24 penalty: 0 agent_num: 19 done: False
______________________
id: 44 reward: -0.006122448979591836 service_time: 277 s_time: 12 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.012195121951219513 service_time: 511 s_time: 28 penalty: 0 agent_num: 41 done: False
______________________
id: 51 reward: 0.0017857142857142857 service_time: 560 s_time: -2 penalty: 0 agent_num: 20 done: False
______________________
id: 47 reward: -0.016986062717770034 service_time: 533 s_time: 39 penalty: 0 agent_num: 41 done: False
______________________
id: 41 reward: 0.0 service_time: 507 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
Step:  304
Pretraining Loss:  tensor(0.3166, device='cuda:0', grad_fn=<MeanBackward0>)
id: 53 reward: -0.04352678571428571 service_time: 488 s_time: 39 penalty: 0 agent_num: 16 done: False
______________________
id: 42 reward: 0.0 service_time: 527 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 44 reward: -0.018877551020408164 service_time: 314 s_time: 37 penalty: 0 agent_num: 35 done: False
______________________
id: 43 reward: -0.023571428571428573 service_time: 584 s_time: 33 penalty: 0 agent_num: 25 done: False
______________________
id: 46 reward: -0.008241758241758242 service_time: 437 s_time: 18 penalty: 0 agent_num: 39 done: False
______________________
id: 49 reward: -0.044172932330827065 service_time: 552 s_time: 47 penalty: 0 agent_num: 19 done: False
______________________
id: 40 reward: -0.013157894736842105 service_time: 575 s_time: 14 penalty: 0 agent_num: 19 done: False
______________________
id: 54 reward: 0.0 service_time: 390 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 50 reward: -0.0040178571428571425 service_time: 518 s_time: 9 penalty: 0 agent_num: 40 done: False
______________________
id: 48 reward: -0.021341463414634148 service_time: 560 s_time: 49 penalty: 0 agent_num: 41 done: False
______________________
id: 52 reward: -0.005494505494505495 service_time: 538 s_time: 8 penalty: 0 agent_num: 26 done: False
______________________
id: 47 reward: 0.0 service_time: 533 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 51 reward: -0.023214285714285715 service_time: 586 s_time: 26 penalty: 0 agent_num: 20 done: False
______________________
id: 45 reward: -0.010714285714285714 service_time: 488 s_time: 18 penalty: 0 agent_num: 30 done: False
______________________
id: 55 reward: -0.007404181184668989 service_time: 456 s_time: 17 penalty: 0 agent_num: 41 done: False
______________________
id: 41 reward: -0.01132404181184669 service_time: 533 s_time: 26 penalty: 0 agent_num: 41 done: False
______________________
Step:  320
Pretraining Loss:  tensor(0.3134, device='cuda:0', grad_fn=<MeanBackward0>)
id: 53 reward: 0.002232142857142857 service_time: 486 s_time: -2 penalty: 0 agent_num: 16 done: False
______________________
id: 42 reward: 0.05476190476190476 service_time: 481 s_time: -46 penalty: 0 agent_num: 15 done: False
______________________
id: 44 reward: -0.007653061224489796 service_time: 329 s_time: 15 penalty: 0 agent_num: 35 done: False
______________________
id: 49 reward: -0.020676691729323307 service_time: 574 s_time: 22 penalty: 0 agent_num: 19 done: False
______________________
id: 54 reward: -0.028745644599303136 service_time: 456 s_time: 66 penalty: 0 agent_num: 41 done: False
______________________
id: 43 reward: -0.03 service_time: 626 s_time: 42 penalty: 0 agent_num: 25 done: False
______________________
id: 46 reward: -0.010531135531135532 service_time: 460 s_time: 23 penalty: 0 agent_num: 39 done: False
______________________
id: 45 reward: -0.016666666666666666 service_time: 516 s_time: 28 penalty: 0 agent_num: 30 done: False
______________________
id: 40 reward: -0.015977443609022556 service_time: 592 s_time: 17 penalty: 0 agent_num: 19 done: False
______________________
id: 55 reward: -0.006533101045296167 service_time: 471 s_time: 15 penalty: 0 agent_num: 41 done: False
______________________
id: 52 reward: -0.010302197802197802 service_time: 553 s_time: 15 penalty: 0 agent_num: 26 done: False
______________________
id: 51 reward: -0.02142857142857143 service_time: 610 s_time: 24 penalty: 0 agent_num: 20 done: False
______________________
id: 50 reward: -0.02544642857142857 service_time: 575 s_time: 57 penalty: 0 agent_num: 40 done: False
______________________
id: 41 reward: -0.002613240418118467 service_time: 539 s_time: 6 penalty: 0 agent_num: 41 done: False
______________________
id: 47 reward: -0.017421602787456445 service_time: 573 s_time: 40 penalty: 0 agent_num: 41 done: False
______________________
id: 48 reward: -0.006097560975609756 service_time: 574 s_time: 14 penalty: 0 agent_num: 41 done: False
______________________
Step:  336
Pretraining Loss:  tensor(0.2931, device='cuda:0', grad_fn=<MeanBackward0>)
id: 42 reward: 0.0 service_time: 481 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 53 reward: 0.0033482142857142855 service_time: 483 s_time: -3 penalty: 0 agent_num: 16 done: False
______________________
id: 44 reward: 0.0 service_time: 329 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 49 reward: -0.03477443609022556 service_time: 611 s_time: 37 penalty: 0 agent_num: 19 done: False
______________________
id: 43 reward: -0.004285714285714286 service_time: 632 s_time: 6 penalty: 0 agent_num: 25 done: False
______________________
id: 52 reward: 0.0 service_time: 553 s_time: 0 penalty: 0 agent_num: 26 done: False
______________________
id: 40 reward: -0.047932330827067667 service_time: 643 s_time: 51 penalty: 0 agent_num: 19 done: False
______________________
id: 46 reward: 0.0009157509157509158 service_time: 458 s_time: -2 penalty: 0 agent_num: 39 done: False
______________________
id: 50 reward: 0.0017857142857142857 service_time: 571 s_time: -4 penalty: 0 agent_num: 40 done: False
______________________
id: 47 reward: -0.01916376306620209 service_time: 617 s_time: 44 penalty: 0 agent_num: 41 done: False
______________________
id: 45 reward: -0.01904761904761905 service_time: 548 s_time: 32 penalty: 0 agent_num: 30 done: False
______________________
id: 55 reward: -0.008275261324041812 service_time: 490 s_time: 19 penalty: 0 agent_num: 41 done: False
______________________
id: 51 reward: -0.027678571428571427 service_time: 641 s_time: 31 penalty: 0 agent_num: 20 done: False
______________________
id: 48 reward: -0.01132404181184669 service_time: 600 s_time: 26 penalty: 0 agent_num: 41 done: False
______________________
id: 41 reward: -0.009146341463414634 service_time: 560 s_time: 21 penalty: 0 agent_num: 41 done: False
______________________
id: 54 reward: -0.008710801393728223 service_time: 476 s_time: 20 penalty: 0 agent_num: 41 done: False
______________________
Step:  352
Pretraining Loss:  tensor(0.2762, device='cuda:0', grad_fn=<MeanBackward0>)
id: 53 reward: -0.004464285714285714 service_time: 487 s_time: 4 penalty: 0 agent_num: 16 done: False
______________________
id: 42 reward: 0.01904761904761905 service_time: 465 s_time: -16 penalty: 0 agent_num: 15 done: False
______________________
id: 44 reward: -0.005612244897959183 service_time: 340 s_time: 11 penalty: 0 agent_num: 35 done: False
______________________
id: 45 reward: 0.0011904761904761906 service_time: 546 s_time: -2 penalty: 0 agent_num: 30 done: False
______________________
id: 40 reward: 0.03289473684210526 service_time: 608 s_time: -35 penalty: 0 agent_num: 19 done: False
______________________
id: 43 reward: -0.009285714285714286 service_time: 645 s_time: 13 penalty: 0 agent_num: 25 done: False
______________________
id: 51 reward: -0.05 service_time: 697 s_time: 56 penalty: 0 agent_num: 20 done: False
______________________
id: 54 reward: -0.0078397212543554 service_time: 494 s_time: 18 penalty: 0 agent_num: 41 done: False
______________________
id: 49 reward: -0.06015037593984962 service_time: 675 s_time: 64 penalty: 0 agent_num: 19 done: False
______________________
id: 52 reward: -0.04601648351648352 service_time: 620 s_time: 67 penalty: 0 agent_num: 26 done: False
______________________
id: 55 reward: 0.0 service_time: 490 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 41 reward: -0.0195993031358885 service_time: 605 s_time: 45 penalty: 0 agent_num: 41 done: False
______________________
id: 47 reward: -0.014372822299651568 service_time: 650 s_time: 33 penalty: 0 agent_num: 41 done: False
______________________
id: 50 reward: -0.03125 service_time: 641 s_time: 70 penalty: 0 agent_num: 40 done: False
______________________
id: 46 reward: -0.018315018315018316 service_time: 498 s_time: 40 penalty: 0 agent_num: 39 done: False
______________________
id: 48 reward: -0.01132404181184669 service_time: 626 s_time: 26 penalty: 0 agent_num: 41 done: False
______________________
Step:  368
Pretraining Loss:  tensor(0.2864, device='cuda:0', grad_fn=<MeanBackward0>)
id: 42 reward: -0.07142857142857142 service_time: 525 s_time: 60 penalty: 0 agent_num: 15 done: False
______________________
id: 53 reward: 0.011160714285714286 service_time: 477 s_time: -10 penalty: 0 agent_num: 16 done: False
______________________
id: 49 reward: 0.0018796992481203006 service_time: 673 s_time: -2 penalty: 0 agent_num: 19 done: False
______________________
id: 44 reward: -0.008673469387755102 service_time: 357 s_time: 17 penalty: 0 agent_num: 35 done: False
______________________
id: 43 reward: -0.017142857142857144 service_time: 669 s_time: 24 penalty: 0 agent_num: 25 done: False
______________________
id: 40 reward: -0.044172932330827065 service_time: 655 s_time: 47 penalty: 0 agent_num: 19 done: False
______________________
id: 41 reward: -0.0156794425087108 service_time: 641 s_time: 36 penalty: 0 agent_num: 41 done: False
______________________
id: 45 reward: -0.036904761904761905 service_time: 608 s_time: 62 penalty: 0 agent_num: 30 done: False
______________________
id: 48 reward: -0.008275261324041812 service_time: 645 s_time: 19 penalty: 0 agent_num: 41 done: False
______________________
id: 52 reward: -0.022664835164835164 service_time: 653 s_time: 33 penalty: 0 agent_num: 26 done: False
______________________
id: 47 reward: -0.0195993031358885 service_time: 695 s_time: 45 penalty: 0 agent_num: 41 done: False
______________________
id: 51 reward: -0.017857142857142856 service_time: 717 s_time: 20 penalty: 0 agent_num: 20 done: False
______________________
id: 55 reward: -0.013501742160278746 service_time: 521 s_time: 31 penalty: 0 agent_num: 41 done: False
______________________
id: 50 reward: -0.009375 service_time: 662 s_time: 21 penalty: 0 agent_num: 40 done: False
______________________
id: 46 reward: -0.014652014652014652 service_time: 530 s_time: 32 penalty: 0 agent_num: 39 done: False
______________________
id: 54 reward: -0.016550522648083623 service_time: 532 s_time: 38 penalty: 0 agent_num: 41 done: False
______________________
Step:  384
Pretraining Loss:  tensor(0.2978, device='cuda:0', grad_fn=<MeanBackward0>)
id: 53 reward: 0.020089285714285716 service_time: 459 s_time: -18 penalty: 0 agent_num: 16 done: False
______________________
id: 42 reward: 0.002380952380952381 service_time: 523 s_time: -2 penalty: 0 agent_num: 15 done: False
______________________
id: 40 reward: -0.0009398496240601503 service_time: 656 s_time: 1 penalty: 0 agent_num: 19 done: False
______________________
id: 49 reward: 0.013157894736842105 service_time: 659 s_time: -14 penalty: 0 agent_num: 19 done: False
______________________
id: 43 reward: -0.027142857142857142 service_time: 707 s_time: 38 penalty: 0 agent_num: 25 done: False
______________________
id: 51 reward: 0.026785714285714284 service_time: 687 s_time: -30 penalty: 0 agent_num: 20 done: False
______________________
id: 44 reward: 0.0 service_time: 357 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: -0.012630662020905924 service_time: 561 s_time: 29 penalty: 0 agent_num: 41 done: False
______________________
id: 45 reward: -0.02142857142857143 service_time: 644 s_time: 36 penalty: 0 agent_num: 30 done: False
______________________
id: 52 reward: -0.014423076923076924 service_time: 674 s_time: 21 penalty: 0 agent_num: 26 done: False
______________________
id: 55 reward: 0.0008710801393728223 service_time: 519 s_time: -2 penalty: 0 agent_num: 41 done: False
______________________
id: 41 reward: -0.006968641114982578 service_time: 657 s_time: 16 penalty: 0 agent_num: 41 done: False
______________________
id: 46 reward: -0.009157509157509158 service_time: 550 s_time: 20 penalty: 0 agent_num: 39 done: False
______________________
id: 48 reward: -0.007404181184668989 service_time: 662 s_time: 17 penalty: 0 agent_num: 41 done: False
______________________
id: 50 reward: -0.008482142857142856 service_time: 681 s_time: 19 penalty: 0 agent_num: 40 done: False
______________________
id: 47 reward: -0.007404181184668989 service_time: 712 s_time: 17 penalty: 0 agent_num: 41 done: False
______________________
Step:  400
Pretraining Loss:  tensor(0.3136, device='cuda:0', grad_fn=<MeanBackward0>)
id: 42 reward: 0.025 service_time: 502 s_time: -21 penalty: 0 agent_num: 15 done: False
______________________
id: 53 reward: 0.016741071428571428 service_time: 444 s_time: -15 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: 0.0009398496240601503 service_time: 655 s_time: -1 penalty: 0 agent_num: 19 done: False
______________________
id: 49 reward: 0.014097744360902255 service_time: 644 s_time: -15 penalty: 0 agent_num: 19 done: False
______________________
id: 44 reward: -0.014285714285714285 service_time: 385 s_time: 28 penalty: 0 agent_num: 35 done: False
______________________
id: 51 reward: 0.0008928571428571428 service_time: 686 s_time: -1 penalty: 0 agent_num: 20 done: False
______________________
id: 41 reward: 0.003484320557491289 service_time: 649 s_time: -8 penalty: 0 agent_num: 41 done: False
______________________
id: 43 reward: -0.03 service_time: 749 s_time: 42 penalty: 0 agent_num: 25 done: False
______________________
id: 52 reward: 0.0 service_time: 674 s_time: 0 penalty: 0 agent_num: 26 done: False
______________________
id: 55 reward: -0.008710801393728223 service_time: 539 s_time: 20 penalty: 0 agent_num: 41 done: False
______________________
id: 45 reward: -0.010714285714285714 service_time: 662 s_time: 18 penalty: 0 agent_num: 30 done: False
______________________
id: 50 reward: -0.0040178571428571425 service_time: 690 s_time: 9 penalty: 0 agent_num: 40 done: False
______________________
id: 47 reward: -0.01088850174216028 service_time: 737 s_time: 25 penalty: 0 agent_num: 41 done: False
______________________
id: 46 reward: -0.00641025641025641 service_time: 564 s_time: 14 penalty: 0 agent_num: 39 done: False
______________________
id: 48 reward: -0.021341463414634148 service_time: 711 s_time: 49 penalty: 0 agent_num: 41 done: False
______________________
id: 54 reward: -0.0078397212543554 service_time: 579 s_time: 18 penalty: 0 agent_num: 41 done: False
______________________
Step:  416
Pretraining Loss:  tensor(0.3480, device='cuda:0', grad_fn=<MeanBackward0>)
id: 42 reward: 0.0 service_time: 502 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 53 reward: -0.03236607142857143 service_time: 473 s_time: 29 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: 0.019736842105263157 service_time: 634 s_time: -21 penalty: 0 agent_num: 19 done: False
______________________
id: 49 reward: -0.04887218045112782 service_time: 696 s_time: 52 penalty: 0 agent_num: 19 done: False
______________________
id: 44 reward: -0.014285714285714285 service_time: 413 s_time: 28 penalty: 0 agent_num: 35 done: False
______________________
id: 51 reward: 0.0017857142857142857 service_time: 684 s_time: -2 penalty: 0 agent_num: 20 done: False
______________________
id: 52 reward: -0.048763736263736264 service_time: 745 s_time: 71 penalty: 0 agent_num: 26 done: False
______________________
id: 45 reward: -0.005357142857142857 service_time: 671 s_time: 9 penalty: 0 agent_num: 30 done: False
______________________
id: 41 reward: -0.02613240418118467 service_time: 709 s_time: 60 penalty: 0 agent_num: 41 done: False
______________________
id: 54 reward: 0.0 service_time: 579 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 46 reward: -0.01694139194139194 service_time: 601 s_time: 37 penalty: 0 agent_num: 39 done: False
______________________
id: 55 reward: -0.013937282229965157 service_time: 571 s_time: 32 penalty: 0 agent_num: 41 done: False
______________________
id: 50 reward: -0.0040178571428571425 service_time: 699 s_time: 9 penalty: 0 agent_num: 40 done: False
______________________
id: 43 reward: -0.032857142857142856 service_time: 795 s_time: 46 penalty: 0 agent_num: 25 done: False
______________________
id: 48 reward: 0.0008710801393728223 service_time: 709 s_time: -2 penalty: 0 agent_num: 41 done: False
______________________
id: 47 reward: -0.010017421602787456 service_time: 760 s_time: 23 penalty: 0 agent_num: 41 done: False
______________________
Step:  432
Pretraining Loss:  tensor(0.3298, device='cuda:0', grad_fn=<MeanBackward0>)
id: 42 reward: 0.0 service_time: 502 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 53 reward: -0.041294642857142856 service_time: 510 s_time: 37 penalty: 0 agent_num: 16 done: False
______________________
id: 49 reward: 0.03289473684210526 service_time: 661 s_time: -35 penalty: 0 agent_num: 19 done: False
______________________
id: 40 reward: -0.007518796992481203 service_time: 642 s_time: 8 penalty: 0 agent_num: 19 done: False
______________________
id: 45 reward: -0.016666666666666666 service_time: 699 s_time: 28 penalty: 0 agent_num: 30 done: False
______________________
id: 55 reward: -0.01916376306620209 service_time: 615 s_time: 44 penalty: 0 agent_num: 41 done: False
______________________
id: 41 reward: 0.0008710801393728223 service_time: 707 s_time: -2 penalty: 0 agent_num: 41 done: False
______________________
id: 47 reward: -0.016114982578397212 service_time: 797 s_time: 37 penalty: 0 agent_num: 41 done: False
______________________
id: 50 reward: -0.007589285714285714 service_time: 716 s_time: 17 penalty: 0 agent_num: 40 done: False
______________________
id: 51 reward: -0.08125 service_time: 775 s_time: 91 penalty: 0 agent_num: 20 done: False
______________________
id: 44 reward: -0.012244897959183673 service_time: 437 s_time: 24 penalty: 0 agent_num: 35 done: False
______________________
id: 43 reward: -0.019285714285714285 service_time: 822 s_time: 27 penalty: 0 agent_num: 25 done: False
______________________
id: 46 reward: -0.019688644688644688 service_time: 644 s_time: 43 penalty: 0 agent_num: 39 done: False
______________________
id: 52 reward: -0.010302197802197802 service_time: 760 s_time: 15 penalty: 0 agent_num: 26 done: False
______________________
id: 48 reward: -0.031794425087108016 service_time: 782 s_time: 73 penalty: 0 agent_num: 41 done: False
______________________
id: 54 reward: -0.006968641114982578 service_time: 595 s_time: 16 penalty: 0 agent_num: 41 done: False
______________________
Step:  448
Pretraining Loss:  tensor(0.3130, device='cuda:0', grad_fn=<MeanBackward0>)
id: 42 reward: 0.0 service_time: 502 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 53 reward: 0.0 service_time: 510 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: 0.0 service_time: 642 s_time: 0 penalty: 0 agent_num: 19 done: False
______________________
id: 49 reward: 0.0 service_time: 661 s_time: 0 penalty: 0 agent_num: 19 done: False
______________________
id: 44 reward: -0.013775510204081633 service_time: 464 s_time: 27 penalty: 0 agent_num: 35 done: False
______________________
id: 51 reward: 0.01875 service_time: 754 s_time: -21 penalty: 0 agent_num: 20 done: False
______________________
id: 45 reward: -0.01607142857142857 service_time: 726 s_time: 27 penalty: 0 agent_num: 30 done: False
______________________
id: 52 reward: -0.03159340659340659 service_time: 806 s_time: 46 penalty: 0 agent_num: 26 done: False
______________________
id: 43 reward: -0.0064285714285714285 service_time: 831 s_time: 9 penalty: 0 agent_num: 25 done: False
______________________
id: 41 reward: -0.02177700348432056 service_time: 757 s_time: 50 penalty: 0 agent_num: 41 done: False
______________________
id: 55 reward: -0.010017421602787456 service_time: 638 s_time: 23 penalty: 0 agent_num: 41 done: False
______________________
id: 47 reward: -0.009581881533101045 service_time: 819 s_time: 22 penalty: 0 agent_num: 41 done: False
______________________
id: 54 reward: -0.021341463414634148 service_time: 644 s_time: 49 penalty: 0 agent_num: 41 done: False
______________________
id: 50 reward: -0.013392857142857142 service_time: 746 s_time: 30 penalty: 0 agent_num: 40 done: False
______________________
id: 46 reward: -0.003663003663003663 service_time: 652 s_time: 8 penalty: 0 agent_num: 39 done: False
______________________
id: 48 reward: 0.003484320557491289 service_time: 774 s_time: -8 penalty: 0 agent_num: 41 done: False
______________________
Step:  464
Pretraining Loss:  tensor(0.3387, device='cuda:0', grad_fn=<MeanBackward0>)
id: 42 reward: 0.030952380952380953 service_time: 476 s_time: -26 penalty: 0 agent_num: 15 done: False
______________________
id: 53 reward: -0.05357142857142857 service_time: 558 s_time: 48 penalty: 0 agent_num: 16 done: False
______________________
id: 49 reward: -0.015977443609022556 service_time: 678 s_time: 17 penalty: 0 agent_num: 19 done: False
______________________
id: 40 reward: -0.03477443609022556 service_time: 679 s_time: 37 penalty: 0 agent_num: 19 done: False
______________________
id: 45 reward: -0.023214285714285715 service_time: 765 s_time: 39 penalty: 0 agent_num: 30 done: False
______________________
id: 44 reward: 0.0 service_time: 464 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 43 reward: -0.017142857142857144 service_time: 855 s_time: 24 penalty: 0 agent_num: 25 done: False
______________________
id: 51 reward: 0.020535714285714286 service_time: 731 s_time: -23 penalty: 0 agent_num: 20 done: False
______________________
id: 55 reward: -0.010452961672473868 service_time: 662 s_time: 24 penalty: 0 agent_num: 41 done: False
______________________
id: 41 reward: -0.01132404181184669 service_time: 783 s_time: 26 penalty: 0 agent_num: 41 done: False
______________________
id: 46 reward: -0.013736263736263736 service_time: 682 s_time: 30 penalty: 0 agent_num: 39 done: False
______________________
id: 52 reward: -0.015796703296703296 service_time: 829 s_time: 23 penalty: 0 agent_num: 26 done: False
______________________
id: 47 reward: -0.007404181184668989 service_time: 836 s_time: 17 penalty: 0 agent_num: 41 done: False
______________________
id: 50 reward: -0.008035714285714285 service_time: 764 s_time: 18 penalty: 0 agent_num: 40 done: False
______________________
id: 54 reward: -0.005662020905923345 service_time: 657 s_time: 13 penalty: 0 agent_num: 41 done: False
______________________
id: 48 reward: -0.016114982578397212 service_time: 811 s_time: 37 penalty: 0 agent_num: 41 done: False
______________________
Step:  480
Pretraining Loss:  tensor(0.3283, device='cuda:0', grad_fn=<MeanBackward0>)
id: 53 reward: 0.0 service_time: 558 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 42 reward: 0.0 service_time: 476 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 40 reward: 0.012218045112781954 service_time: 666 s_time: -13 penalty: 0 agent_num: 19 done: False
______________________
id: 51 reward: 0.0 service_time: 731 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 49 reward: -0.045112781954887216 service_time: 726 s_time: 48 penalty: 0 agent_num: 19 done: False
______________________
id: 43 reward: -0.01 service_time: 869 s_time: 14 penalty: 0 agent_num: 25 done: False
______________________
id: 44 reward: -0.012244897959183673 service_time: 488 s_time: 24 penalty: 0 agent_num: 35 done: False
______________________
id: 45 reward: 0.0 service_time: 765 s_time: 0 penalty: 0 agent_num: 30 done: False
______________________
id: 52 reward: 0.0006868131868131869 service_time: 828 s_time: -1 penalty: 0 agent_num: 26 done: False
______________________
id: 46 reward: 0.0 service_time: 682 s_time: 0 penalty: 0 agent_num: 39 done: False
______________________
id: 41 reward: -0.005662020905923345 service_time: 796 s_time: 13 penalty: 0 agent_num: 41 done: False
______________________
id: 54 reward: -0.007404181184668989 service_time: 674 s_time: 17 penalty: 0 agent_num: 41 done: False
______________________
id: 47 reward: -0.011759581881533102 service_time: 863 s_time: 27 penalty: 0 agent_num: 41 done: False
______________________
id: 55 reward: -0.018292682926829267 service_time: 704 s_time: 42 penalty: 0 agent_num: 41 done: False
______________________
id: 50 reward: 0.0 service_time: 764 s_time: 0 penalty: 0 agent_num: 40 done: False
______________________
id: 48 reward: -0.0013066202090592336 service_time: 814 s_time: 3 penalty: 0 agent_num: 41 done: False
______________________
Step:  496
Pretraining Loss:  tensor(0.3623, device='cuda:0', grad_fn=<MeanBackward0>)
id: 53 reward: -0.03125 service_time: 586 s_time: 28 penalty: 0 agent_num: 16 done: False
______________________
id: 42 reward: 0.01904761904761905 service_time: 460 s_time: -16 penalty: 0 agent_num: 15 done: False
______________________
id: 40 reward: 0.0 service_time: 666 s_time: 0 penalty: 0 agent_num: 19 done: False
______________________
id: 51 reward: 0.0 service_time: 731 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 44 reward: 0.0 service_time: 488 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 52 reward: 0.0 service_time: 828 s_time: 0 penalty: 0 agent_num: 26 done: False
______________________
id: 41 reward: -0.011759581881533102 service_time: 823 s_time: 27 penalty: 0 agent_num: 41 done: False
______________________
id: 46 reward: -0.017857142857142856 service_time: 721 s_time: 39 penalty: 0 agent_num: 39 done: False
______________________
id: 49 reward: -0.02537593984962406 service_time: 753 s_time: 27 penalty: 0 agent_num: 19 done: False
______________________
id: 55 reward: -0.005662020905923345 service_time: 717 s_time: 13 penalty: 0 agent_num: 41 done: False
______________________
id: 45 reward: -0.026785714285714284 service_time: 810 s_time: 45 penalty: 0 agent_num: 30 done: False
______________________
id: 47 reward: -0.016550522648083623 service_time: 901 s_time: 38 penalty: 0 agent_num: 41 done: False
______________________
id: 48 reward: 0.0021777003484320556 service_time: 809 s_time: -5 penalty: 0 agent_num: 41 done: False
______________________
id: 50 reward: -0.02142857142857143 service_time: 812 s_time: 48 penalty: 0 agent_num: 40 done: False
______________________
id: 54 reward: -0.010017421602787456 service_time: 697 s_time: 23 penalty: 0 agent_num: 41 done: False
______________________
id: 43 reward: -0.03 service_time: 911 s_time: 42 penalty: 0 agent_num: 25 done: False
______________________
Step:  512
Pretraining Loss:  tensor(0.3598, device='cuda:0', grad_fn=<MeanBackward0>)
id: 53 reward: 0.0234375 service_time: 565 s_time: -21 penalty: 0 agent_num: 16 done: False
______________________
id: 49 reward: 0.02631578947368421 service_time: 725 s_time: -28 penalty: 0 agent_num: 19 done: False
______________________
id: 42 reward: 0.0 service_time: 460 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 40 reward: -0.015037593984962405 service_time: 682 s_time: 16 penalty: 0 agent_num: 19 done: False
______________________
id: 51 reward: -0.029464285714285714 service_time: 764 s_time: 33 penalty: 0 agent_num: 20 done: False
______________________
id: 52 reward: -0.014423076923076924 service_time: 849 s_time: 21 penalty: 0 agent_num: 26 done: False
______________________
id: 45 reward: -0.026785714285714284 service_time: 855 s_time: 45 penalty: 0 agent_num: 30 done: False
______________________
id: 41 reward: 0.0013066202090592336 service_time: 820 s_time: -3 penalty: 0 agent_num: 41 done: False
______________________
id: 47 reward: -0.016550522648083623 service_time: 939 s_time: 38 penalty: 0 agent_num: 41 done: False
______________________
id: 46 reward: -0.005036630036630037 service_time: 732 s_time: 11 penalty: 0 agent_num: 39 done: False
______________________
id: 50 reward: 0.0008928571428571428 service_time: 810 s_time: -2 penalty: 0 agent_num: 40 done: False
______________________
id: 48 reward: -0.027874564459930314 service_time: 873 s_time: 64 penalty: 0 agent_num: 41 done: False
______________________
id: 54 reward: -0.008275261324041812 service_time: 716 s_time: 19 penalty: 0 agent_num: 41 done: False
______________________
id: 55 reward: -0.020470383275261322 service_time: 764 s_time: 47 penalty: 0 agent_num: 41 done: False
______________________
id: 44 reward: -0.018367346938775512 service_time: 524 s_time: 36 penalty: 0 agent_num: 35 done: False
______________________
id: 43 reward: -0.02 service_time: 939 s_time: 28 penalty: 0 agent_num: 25 done: False
______________________
Step:  528
Pretraining Loss:  tensor(0.4201, device='cuda:0', grad_fn=<MeanBackward0>)
id: 53 reward: -0.046875 service_time: 607 s_time: 42 penalty: 0 agent_num: 16 done: False
______________________
id: 42 reward: 0.0 service_time: 460 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 40 reward: -0.07706766917293233 service_time: 764 s_time: 82 penalty: 0 agent_num: 19 done: False
______________________
id: 49 reward: -0.08458646616541353 service_time: 815 s_time: 90 penalty: 0 agent_num: 19 done: False
______________________
id: 45 reward: -0.017857142857142856 service_time: 885 s_time: 30 penalty: 0 agent_num: 30 done: False
______________________
id: 51 reward: 0.0 service_time: 764 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 52 reward: -0.03365384615384615 service_time: 898 s_time: 49 penalty: 0 agent_num: 26 done: False
______________________
id: 44 reward: -0.008673469387755102 service_time: 541 s_time: 17 penalty: 0 agent_num: 35 done: False
______________________
id: 46 reward: 0.0 service_time: 732 s_time: 0 penalty: 0 agent_num: 39 done: False
______________________
id: 50 reward: -0.03571428571428571 service_time: 890 s_time: 80 penalty: 0 agent_num: 40 done: False
______________________
id: 55 reward: -0.008710801393728223 service_time: 784 s_time: 20 penalty: 0 agent_num: 41 done: False
______________________
id: 48 reward: -0.010017421602787456 service_time: 896 s_time: 23 penalty: 0 agent_num: 41 done: False
______________________
id: 41 reward: -0.037456445993031356 service_time: 906 s_time: 86 penalty: 0 agent_num: 41 done: False
______________________
id: 54 reward: -0.010452961672473868 service_time: 740 s_time: 24 penalty: 0 agent_num: 41 done: False
______________________
id: 47 reward: -0.01916376306620209 service_time: 983 s_time: 44 penalty: 0 agent_num: 41 done: False
______________________
id: 43 reward: -0.016428571428571428 service_time: 962 s_time: 23 penalty: 0 agent_num: 25 done: False
______________________
Step:  544
Pretraining Loss:  tensor(0.4361, device='cuda:0', grad_fn=<MeanBackward0>)
id: 42 reward: -0.07023809523809524 service_time: 519 s_time: 59 penalty: 0 agent_num: 15 done: False
______________________
id: 53 reward: -0.16964285714285715 service_time: 759 s_time: 152 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: -0.018796992481203006 service_time: 784 s_time: 20 penalty: 0 agent_num: 19 done: False
______________________
id: 51 reward: -0.038392857142857145 service_time: 807 s_time: 43 penalty: 0 agent_num: 20 done: False
______________________
id: 45 reward: -0.0125 service_time: 906 s_time: 21 penalty: 0 agent_num: 30 done: False
______________________
id: 44 reward: 0.0 service_time: 541 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 49 reward: 0.020676691729323307 service_time: 793 s_time: -22 penalty: 0 agent_num: 19 done: False
______________________
id: 52 reward: -0.019230769230769232 service_time: 926 s_time: 28 penalty: 0 agent_num: 26 done: False
______________________
id: 46 reward: -0.0027472527472527475 service_time: 738 s_time: 6 penalty: 0 agent_num: 39 done: False
______________________
id: 47 reward: -0.006097560975609756 service_time: 997 s_time: 14 penalty: 0 agent_num: 41 done: False
______________________
id: 54 reward: -0.008275261324041812 service_time: 759 s_time: 19 penalty: 0 agent_num: 41 done: False
______________________
id: 55 reward: -0.006533101045296167 service_time: 799 s_time: 15 penalty: 0 agent_num: 41 done: False
______________________
id: 50 reward: -0.007142857142857143 service_time: 906 s_time: 16 penalty: 0 agent_num: 40 done: False
______________________
id: 41 reward: -0.005662020905923345 service_time: 919 s_time: 13 penalty: 0 agent_num: 41 done: False
______________________
id: 43 reward: -0.0035714285714285713 service_time: 967 s_time: 5 penalty: 0 agent_num: 25 done: False
______________________
id: 48 reward: -0.020470383275261322 service_time: 943 s_time: 47 penalty: 0 agent_num: 41 done: False
______________________
Step:  560
Pretraining Loss:  tensor(0.3662, device='cuda:0', grad_fn=<MeanBackward0>)
id: 42 reward: -0.03214285714285714 service_time: 546 s_time: 27 penalty: 0 agent_num: 15 done: False
______________________
id: 49 reward: -0.046992481203007516 service_time: 843 s_time: 50 penalty: 0 agent_num: 19 done: False
______________________
id: 40 reward: -0.018796992481203006 service_time: 804 s_time: 20 penalty: 0 agent_num: 19 done: False
______________________
id: 43 reward: 0.012142857142857143 service_time: 950 s_time: -17 penalty: 0 agent_num: 25 done: False
______________________
id: 44 reward: 0.0 service_time: 541 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 51 reward: 0.0017857142857142857 service_time: 805 s_time: -2 penalty: 0 agent_num: 20 done: False
______________________
id: 53 reward: -0.0011160714285714285 service_time: 760 s_time: 1 penalty: 0 agent_num: 16 done: False
______________________
id: 52 reward: -0.017170329670329672 service_time: 951 s_time: 25 penalty: 0 agent_num: 26 done: False
______________________
id: 46 reward: -0.003663003663003663 service_time: 746 s_time: 8 penalty: 0 agent_num: 39 done: False
______________________
id: 55 reward: 0.00043554006968641115 service_time: 798 s_time: -1 penalty: 0 agent_num: 41 done: False
______________________
id: 50 reward: -0.012053571428571429 service_time: 933 s_time: 27 penalty: 0 agent_num: 40 done: False
______________________
id: 45 reward: -0.009523809523809525 service_time: 922 s_time: 16 penalty: 0 agent_num: 30 done: False
______________________
id: 47 reward: -0.018292682926829267 service_time: 1039 s_time: 42 penalty: 0 agent_num: 41 done: False
______________________
id: 54 reward: -0.01524390243902439 service_time: 794 s_time: 35 penalty: 0 agent_num: 41 done: False
______________________
id: 41 reward: -0.0195993031358885 service_time: 964 s_time: 45 penalty: 0 agent_num: 41 done: False
______________________
id: 48 reward: -0.0156794425087108 service_time: 979 s_time: 36 penalty: 0 agent_num: 41 done: False
______________________
Step:  576
Pretraining Loss:  tensor(0.3840, device='cuda:0', grad_fn=<MeanBackward0>)
id: 42 reward: 0.0 service_time: 546 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 51 reward: 0.0 service_time: 805 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 49 reward: 0.0 service_time: 843 s_time: 0 penalty: 0 agent_num: 19 done: False
______________________
id: 40 reward: -0.021616541353383457 service_time: 827 s_time: 23 penalty: 0 agent_num: 19 done: False
______________________
id: 53 reward: 0.036830357142857144 service_time: 727 s_time: -33 penalty: 0 agent_num: 16 done: False
______________________
id: 44 reward: -0.007142857142857143 service_time: 555 s_time: 14 penalty: 0 agent_num: 35 done: False
______________________
id: 45 reward: -0.007738095238095238 service_time: 935 s_time: 13 penalty: 0 agent_num: 30 done: False
______________________
id: 52 reward: -0.038461538461538464 service_time: 1007 s_time: 56 penalty: 0 agent_num: 26 done: False
______________________
id: 41 reward: -0.01088850174216028 service_time: 989 s_time: 25 penalty: 0 agent_num: 41 done: False
______________________
id: 48 reward: -0.016986062717770034 service_time: 1018 s_time: 39 penalty: 0 agent_num: 41 done: False
______________________
id: 54 reward: 0.0 service_time: 794 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 43 reward: -0.035 service_time: 999 s_time: 49 penalty: 0 agent_num: 25 done: False
______________________
id: 55 reward: -0.018292682926829267 service_time: 840 s_time: 42 penalty: 0 agent_num: 41 done: False
______________________
id: 47 reward: -0.018292682926829267 service_time: 1081 s_time: 42 penalty: 0 agent_num: 41 done: False
______________________
id: 50 reward: -0.017857142857142856 service_time: 973 s_time: 40 penalty: 0 agent_num: 40 done: False
______________________
id: 46 reward: -0.028388278388278388 service_time: 808 s_time: 62 penalty: 0 agent_num: 39 done: False
______________________
Step:  592
Pretraining Loss:  tensor(0.3840, device='cuda:0', grad_fn=<MeanBackward0>)
id: 42 reward: -0.058333333333333334 service_time: 595 s_time: 49 penalty: 0 agent_num: 15 done: False
______________________
id: 53 reward: 0.0078125 service_time: 720 s_time: -7 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: 0.0 service_time: 827 s_time: 0 penalty: 0 agent_num: 19 done: False
______________________
id: 51 reward: -0.025 service_time: 833 s_time: 28 penalty: 0 agent_num: 20 done: False
______________________
id: 52 reward: -0.019230769230769232 service_time: 1035 s_time: 28 penalty: 0 agent_num: 26 done: False
______________________
id: 43 reward: 0.0014285714285714286 service_time: 997 s_time: -2 penalty: 0 agent_num: 25 done: False
______________________
id: 49 reward: 0.016917293233082706 service_time: 825 s_time: -18 penalty: 0 agent_num: 19 done: False
______________________
id: 45 reward: -0.01011904761904762 service_time: 952 s_time: 17 penalty: 0 agent_num: 30 done: False
______________________
id: 47 reward: -0.020470383275261322 service_time: 1128 s_time: 47 penalty: 0 agent_num: 41 done: False
______________________
id: 55 reward: 0.0 service_time: 840 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 48 reward: -0.009581881533101045 service_time: 1040 s_time: 22 penalty: 0 agent_num: 41 done: False
______________________
id: 54 reward: -0.011759581881533102 service_time: 821 s_time: 27 penalty: 0 agent_num: 41 done: False
______________________
id: 41 reward: -0.009146341463414634 service_time: 1010 s_time: 21 penalty: 0 agent_num: 41 done: False
______________________
id: 50 reward: -0.003125 service_time: 980 s_time: 7 penalty: 0 agent_num: 40 done: False
______________________
id: 44 reward: -0.009693877551020408 service_time: 574 s_time: 19 penalty: 0 agent_num: 35 done: False
______________________
id: 46 reward: -0.004120879120879121 service_time: 817 s_time: 9 penalty: 0 agent_num: 39 done: False
______________________
Step:  608
Pretraining Loss:  tensor(0.3734, device='cuda:0', grad_fn=<MeanBackward0>)
id: 53 reward: 0.0 service_time: 720 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 42 reward: -0.005952380952380952 service_time: 600 s_time: 5 penalty: 0 agent_num: 15 done: False
______________________
id: 49 reward: 0.0 service_time: 825 s_time: 0 penalty: 0 agent_num: 19 done: False
______________________
id: 51 reward: -0.022321428571428572 service_time: 858 s_time: 25 penalty: 0 agent_num: 20 done: False
______________________
id: 40 reward: 0.014097744360902255 service_time: 812 s_time: -15 penalty: 0 agent_num: 19 done: False
______________________
id: 52 reward: -0.026785714285714284 service_time: 1074 s_time: 39 penalty: 0 agent_num: 26 done: False
______________________
id: 45 reward: -0.018452380952380953 service_time: 983 s_time: 31 penalty: 0 agent_num: 30 done: False
______________________
id: 43 reward: -0.03357142857142857 service_time: 1044 s_time: 47 penalty: 0 agent_num: 25 done: False
______________________
id: 48 reward: 0.0008710801393728223 service_time: 1038 s_time: -2 penalty: 0 agent_num: 41 done: False
______________________
id: 41 reward: -0.004790940766550522 service_time: 1021 s_time: 11 penalty: 0 agent_num: 41 done: False
______________________
id: 54 reward: -0.01524390243902439 service_time: 856 s_time: 35 penalty: 0 agent_num: 41 done: False
______________________
id: 47 reward: -0.011759581881533102 service_time: 1155 s_time: 27 penalty: 0 agent_num: 41 done: False
______________________
id: 55 reward: -0.028310104529616725 service_time: 905 s_time: 65 penalty: 0 agent_num: 41 done: False
______________________
id: 46 reward: -0.013278388278388278 service_time: 846 s_time: 29 penalty: 0 agent_num: 39 done: False
______________________
id: 50 reward: -0.008035714285714285 service_time: 998 s_time: 18 penalty: 0 agent_num: 40 done: False
______________________
id: 44 reward: -0.0020408163265306124 service_time: 578 s_time: 4 penalty: 0 agent_num: 35 done: False
______________________
Step:  624
Pretraining Loss:  tensor(0.3618, device='cuda:0', grad_fn=<MeanBackward0>)
id: 42 reward: -0.06666666666666667 service_time: 656 s_time: 56 penalty: 0 agent_num: 15 done: False
______________________
id: 53 reward: -0.04017857142857143 service_time: 756 s_time: 36 penalty: 0 agent_num: 16 done: False
______________________
id: 51 reward: 0.020535714285714286 service_time: 835 s_time: -23 penalty: 0 agent_num: 20 done: False
______________________
id: 40 reward: 0.0 service_time: 812 s_time: 0 penalty: 0 agent_num: 19 done: False
______________________
id: 44 reward: -0.008673469387755102 service_time: 595 s_time: 17 penalty: 0 agent_num: 35 done: False
______________________
id: 43 reward: 0.0 service_time: 1044 s_time: 0 penalty: 0 agent_num: 25 done: False
______________________
id: 45 reward: -0.007738095238095238 service_time: 996 s_time: 13 penalty: 0 agent_num: 30 done: False
______________________
id: 52 reward: -0.03365384615384615 service_time: 1123 s_time: 49 penalty: 0 agent_num: 26 done: False
______________________
id: 49 reward: 0.0 service_time: 825 s_time: 0 penalty: 0 agent_num: 19 done: False
______________________
id: 48 reward: -0.013066202090592335 service_time: 1068 s_time: 30 penalty: 0 agent_num: 41 done: False
______________________
id: 55 reward: -0.023519163763066203 service_time: 959 s_time: 54 penalty: 0 agent_num: 41 done: False
______________________
id: 41 reward: -0.005226480836236934 service_time: 1033 s_time: 12 penalty: 0 agent_num: 41 done: False
______________________
id: 50 reward: -0.012946428571428572 service_time: 1027 s_time: 29 penalty: 0 agent_num: 40 done: False
______________________
id: 54 reward: -0.006968641114982578 service_time: 872 s_time: 16 penalty: 0 agent_num: 41 done: False
______________________
id: 47 reward: -0.016550522648083623 service_time: 1193 s_time: 38 penalty: 0 agent_num: 41 done: False
______________________
id: 46 reward: -0.013736263736263736 service_time: 876 s_time: 30 penalty: 0 agent_num: 39 done: False
______________________
Step:  640
Pretraining Loss:  tensor(0.3537, device='cuda:0', grad_fn=<MeanBackward0>)
id: 42 reward: -0.041666666666666664 service_time: 691 s_time: 35 penalty: 0 agent_num: 15 done: False
______________________
id: 49 reward: 0.0 service_time: 825 s_time: 0 penalty: 0 agent_num: 19 done: False
______________________
id: 53 reward: 0.0 service_time: 756 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: -0.03571428571428571 service_time: 850 s_time: 38 penalty: 0 agent_num: 19 done: False
______________________
id: 44 reward: -0.007142857142857143 service_time: 609 s_time: 14 penalty: 0 agent_num: 35 done: False
______________________
id: 52 reward: 0.006868131868131868 service_time: 1113 s_time: -10 penalty: 0 agent_num: 26 done: False
______________________
id: 51 reward: -0.07589285714285714 service_time: 920 s_time: 85 penalty: 0 agent_num: 20 done: False
______________________
id: 45 reward: -0.01488095238095238 service_time: 1021 s_time: 25 penalty: 0 agent_num: 30 done: False
______________________
id: 41 reward: -0.004355400696864111 service_time: 1043 s_time: 10 penalty: 0 agent_num: 41 done: False
______________________
id: 54 reward: -0.017421602787456445 service_time: 912 s_time: 40 penalty: 0 agent_num: 41 done: False
______________________
id: 48 reward: -0.012195121951219513 service_time: 1096 s_time: 28 penalty: 0 agent_num: 41 done: False
______________________
id: 46 reward: -0.013278388278388278 service_time: 905 s_time: 29 penalty: 0 agent_num: 39 done: False
______________________
id: 50 reward: -0.008928571428571428 service_time: 1047 s_time: 20 penalty: 0 agent_num: 40 done: False
______________________
id: 43 reward: -0.1 service_time: 1184 s_time: 140 penalty: 0 agent_num: 25 done: False
______________________
id: 47 reward: -0.017421602787456445 service_time: 1233 s_time: 40 penalty: 0 agent_num: 41 done: False
______________________
id: 55 reward: 0.0013066202090592336 service_time: 956 s_time: -3 penalty: 0 agent_num: 41 done: False
______________________
Step:  656
Pretraining Loss:  tensor(0.3470, device='cuda:0', grad_fn=<MeanBackward0>)
id: 53 reward: 0.005580357142857143 service_time: 751 s_time: -5 penalty: 0 agent_num: 16 done: False
______________________
id: 42 reward: 0.0 service_time: 691 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 40 reward: -0.044172932330827065 service_time: 897 s_time: 47 penalty: 0 agent_num: 19 done: False
______________________
id: 51 reward: -0.06785714285714285 service_time: 996 s_time: 76 penalty: 0 agent_num: 20 done: False
______________________
id: 45 reward: -0.01488095238095238 service_time: 1046 s_time: 25 penalty: 0 agent_num: 30 done: False
______________________
id: 49 reward: -0.02725563909774436 service_time: 854 s_time: 29 penalty: 0 agent_num: 19 done: False
______________________
id: 44 reward: 0.0 service_time: 609 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 43 reward: 0.015 service_time: 1163 s_time: -21 penalty: 0 agent_num: 25 done: False
______________________
id: 41 reward: 0.0 service_time: 1043 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 52 reward: -0.015796703296703296 service_time: 1136 s_time: 23 penalty: 0 agent_num: 26 done: False
______________________
id: 54 reward: -0.004355400696864111 service_time: 922 s_time: 10 penalty: 0 agent_num: 41 done: False
______________________
id: 48 reward: -0.0078397212543554 service_time: 1114 s_time: 18 penalty: 0 agent_num: 41 done: False
______________________
id: 46 reward: 0.0009157509157509158 service_time: 903 s_time: -2 penalty: 0 agent_num: 39 done: False
______________________
id: 50 reward: -0.013392857142857142 service_time: 1077 s_time: 30 penalty: 0 agent_num: 40 done: False
______________________
id: 47 reward: 0.0 service_time: 1233 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 55 reward: -0.02221254355400697 service_time: 1007 s_time: 51 penalty: 0 agent_num: 41 done: False
______________________
Step:  672
Pretraining Loss:  tensor(0.3301, device='cuda:0', grad_fn=<MeanBackward0>)
id: 53 reward: 0.012276785714285714 service_time: 740 s_time: -11 penalty: 0 agent_num: 16 done: False
______________________
id: 42 reward: -0.03571428571428571 service_time: 721 s_time: 30 penalty: 0 agent_num: 15 done: False
______________________
id: 49 reward: -0.045112781954887216 service_time: 902 s_time: 48 penalty: 0 agent_num: 19 done: False
______________________
id: 44 reward: -0.007653061224489796 service_time: 624 s_time: 15 penalty: 0 agent_num: 35 done: False
______________________
id: 51 reward: 0.01875 service_time: 975 s_time: -21 penalty: 0 agent_num: 20 done: False
______________________
id: 54 reward: 0.0 service_time: 922 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 45 reward: -0.016666666666666666 service_time: 1074 s_time: 28 penalty: 0 agent_num: 30 done: False
______________________
id: 41 reward: -0.009146341463414634 service_time: 1064 s_time: 21 penalty: 0 agent_num: 41 done: False
______________________
id: 40 reward: -0.039473684210526314 service_time: 939 s_time: 42 penalty: 0 agent_num: 19 done: False
______________________
id: 52 reward: 0.0013736263736263737 service_time: 1134 s_time: -2 penalty: 0 agent_num: 26 done: False
______________________
id: 48 reward: -0.013066202090592335 service_time: 1144 s_time: 30 penalty: 0 agent_num: 41 done: False
______________________
id: 46 reward: -0.03708791208791209 service_time: 984 s_time: 81 penalty: 0 agent_num: 39 done: False
______________________
id: 47 reward: -0.016550522648083623 service_time: 1271 s_time: 38 penalty: 0 agent_num: 41 done: False
______________________
id: 50 reward: -0.02142857142857143 service_time: 1125 s_time: 48 penalty: 0 agent_num: 40 done: False
______________________
id: 55 reward: -0.008275261324041812 service_time: 1026 s_time: 19 penalty: 0 agent_num: 41 done: False
______________________
id: 43 reward: 0.0035714285714285713 service_time: 1158 s_time: -5 penalty: 0 agent_num: 25 done: False
______________________
Step:  688
Pretraining Loss:  tensor(0.3254, device='cuda:0', grad_fn=<MeanBackward0>)
id: 42 reward: 0.0 service_time: 721 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 53 reward: -0.03459821428571429 service_time: 771 s_time: 31 penalty: 0 agent_num: 16 done: False
______________________
id: 51 reward: -0.03214285714285714 service_time: 1011 s_time: 36 penalty: 0 agent_num: 20 done: False
______________________
id: 49 reward: 0.0 service_time: 902 s_time: 0 penalty: 0 agent_num: 19 done: False
______________________
id: 45 reward: -0.005952380952380952 service_time: 1084 s_time: 10 penalty: 0 agent_num: 30 done: False
______________________
id: 44 reward: 0.0 service_time: 624 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 40 reward: -0.13815789473684212 service_time: 1086 s_time: 147 penalty: 0 agent_num: 19 done: False
______________________
id: 54 reward: -0.005662020905923345 service_time: 935 s_time: 13 penalty: 0 agent_num: 41 done: False
______________________
id: 52 reward: 0.008928571428571428 service_time: 1121 s_time: -13 penalty: 0 agent_num: 26 done: False
______________________
id: 41 reward: -0.020905923344947737 service_time: 1112 s_time: 48 penalty: 0 agent_num: 41 done: False
______________________
id: 46 reward: -0.010531135531135532 service_time: 1007 s_time: 23 penalty: 0 agent_num: 39 done: False
______________________
id: 48 reward: -0.02656794425087108 service_time: 1205 s_time: 61 penalty: 0 agent_num: 41 done: False
______________________
id: 55 reward: 0.0 service_time: 1026 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 50 reward: -0.008928571428571428 service_time: 1145 s_time: 20 penalty: 0 agent_num: 40 done: False
______________________
id: 43 reward: -0.015714285714285715 service_time: 1180 s_time: 22 penalty: 0 agent_num: 25 done: False
______________________
id: 47 reward: -0.017857142857142856 service_time: 1312 s_time: 41 penalty: 0 agent_num: 41 done: False
______________________
Step:  704
Pretraining Loss:  tensor(0.3173, device='cuda:0', grad_fn=<MeanBackward0>)
id: 42 reward: -0.07142857142857142 service_time: 781 s_time: 60 penalty: 0 agent_num: 15 done: False
______________________
id: 53 reward: -0.015625 service_time: 785 s_time: 14 penalty: 0 agent_num: 16 done: False
______________________
id: 49 reward: 0.0 service_time: 902 s_time: 0 penalty: 0 agent_num: 19 done: False
______________________
id: 51 reward: -0.03125 service_time: 1046 s_time: 35 penalty: 0 agent_num: 20 done: False
______________________
id: 43 reward: -0.07571428571428572 service_time: 1286 s_time: 106 penalty: 0 agent_num: 25 done: False
______________________
id: 44 reward: -0.017346938775510204 service_time: 658 s_time: 34 penalty: 0 agent_num: 35 done: False
______________________
id: 52 reward: -0.08722527472527472 service_time: 1248 s_time: 127 penalty: 0 agent_num: 26 done: False
______________________
id: 40 reward: 0.03477443609022556 service_time: 1049 s_time: -37 penalty: 0 agent_num: 19 done: False
______________________
id: 45 reward: 0.0 service_time: 1084 s_time: 0 penalty: 0 agent_num: 30 done: False
______________________
id: 46 reward: 0.0 service_time: 1007 s_time: 0 penalty: 0 agent_num: 39 done: False
______________________
id: 54 reward: -0.02613240418118467 service_time: 995 s_time: 60 penalty: 0 agent_num: 41 done: False
______________________
id: 41 reward: -0.014808362369337979 service_time: 1146 s_time: 34 penalty: 0 agent_num: 41 done: False
______________________
id: 47 reward: 0.0039198606271777 service_time: 1303 s_time: -9 penalty: 0 agent_num: 41 done: False
______________________
id: 50 reward: -0.011607142857142858 service_time: 1171 s_time: 26 penalty: 0 agent_num: 40 done: False
______________________
id: 55 reward: -0.021341463414634148 service_time: 1075 s_time: 49 penalty: 0 agent_num: 41 done: False
______________________
id: 48 reward: -0.016986062717770034 service_time: 1244 s_time: 39 penalty: 0 agent_num: 41 done: False
______________________
Step:  720
Pretraining Loss:  tensor(0.3282, device='cuda:0', grad_fn=<MeanBackward0>)
id: 42 reward: -0.0380952380952381 service_time: 813 s_time: 32 penalty: 0 agent_num: 15 done: False
______________________
id: 53 reward: -0.03459821428571429 service_time: 816 s_time: 31 penalty: 0 agent_num: 16 done: False
______________________
id: 51 reward: -0.007142857142857143 service_time: 1054 s_time: 8 penalty: 0 agent_num: 20 done: False
______________________
id: 49 reward: 0.009398496240601503 service_time: 892 s_time: -10 penalty: 0 agent_num: 19 done: False
______________________
id: 44 reward: -0.011224489795918367 service_time: 680 s_time: 22 penalty: 0 agent_num: 35 done: False
______________________
id: 45 reward: -0.0125 service_time: 1105 s_time: 21 penalty: 0 agent_num: 30 done: False
______________________
id: 52 reward: 0.006868131868131868 service_time: 1238 s_time: -10 penalty: 0 agent_num: 26 done: False
______________________
id: 40 reward: 0.015977443609022556 service_time: 1032 s_time: -17 penalty: 0 agent_num: 19 done: False
______________________
id: 46 reward: -0.006868131868131868 service_time: 1022 s_time: 15 penalty: 0 agent_num: 39 done: False
______________________
id: 41 reward: -0.01088850174216028 service_time: 1171 s_time: 25 penalty: 0 agent_num: 41 done: False
______________________
id: 55 reward: -0.010452961672473868 service_time: 1099 s_time: 24 penalty: 0 agent_num: 41 done: False
______________________
id: 54 reward: -0.004790940766550522 service_time: 1006 s_time: 11 penalty: 0 agent_num: 41 done: False
______________________
id: 43 reward: 0.0014285714285714286 service_time: 1284 s_time: -2 penalty: 0 agent_num: 25 done: False
______________________
id: 50 reward: -0.022767857142857142 service_time: 1222 s_time: 51 penalty: 0 agent_num: 40 done: False
______________________
id: 48 reward: 0.0 service_time: 1244 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 47 reward: -0.03571428571428571 service_time: 1385 s_time: 82 penalty: 0 agent_num: 41 done: False
______________________
Step:  736
Pretraining Loss:  tensor(0.3331, device='cuda:0', grad_fn=<MeanBackward0>)
id: 42 reward: -0.1738095238095238 service_time: 959 s_time: 146 penalty: 0 agent_num: 15 done: False
______________________
id: 49 reward: -0.03007518796992481 service_time: 924 s_time: 32 penalty: 0 agent_num: 19 done: False
______________________
id: 53 reward: -0.020089285714285716 service_time: 834 s_time: 18 penalty: 0 agent_num: 16 done: False
______________________
id: 51 reward: -0.01607142857142857 service_time: 1072 s_time: 18 penalty: 0 agent_num: 20 done: False
______________________
id: 40 reward: -0.03195488721804511 service_time: 1066 s_time: 34 penalty: 0 agent_num: 19 done: False
______________________
id: 52 reward: 0.005494505494505495 service_time: 1230 s_time: -8 penalty: 0 agent_num: 26 done: False
______________________
id: 44 reward: 0.0 service_time: 680 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 43 reward: 0.022857142857142857 service_time: 1252 s_time: -32 penalty: 0 agent_num: 25 done: False
______________________
id: 41 reward: -0.006533101045296167 service_time: 1186 s_time: 15 penalty: 0 agent_num: 41 done: False
______________________
id: 54 reward: -0.013066202090592335 service_time: 1036 s_time: 30 penalty: 0 agent_num: 41 done: False
______________________
id: 45 reward: -0.01369047619047619 service_time: 1128 s_time: 23 penalty: 0 agent_num: 30 done: False
______________________
id: 46 reward: -0.011446886446886446 service_time: 1047 s_time: 25 penalty: 0 agent_num: 39 done: False
______________________
id: 55 reward: -0.0078397212543554 service_time: 1117 s_time: 18 penalty: 0 agent_num: 41 done: False
______________________
id: 47 reward: -0.01132404181184669 service_time: 1411 s_time: 26 penalty: 0 agent_num: 41 done: False
______________________
id: 48 reward: -0.017421602787456445 service_time: 1284 s_time: 40 penalty: 0 agent_num: 41 done: False
______________________
id: 50 reward: -0.015625 service_time: 1257 s_time: 35 penalty: 0 agent_num: 40 done: False
______________________
Step:  752
Pretraining Loss:  tensor(0.3089, device='cuda:0', grad_fn=<MeanBackward0>)
id: 42 reward: 0.010714285714285714 service_time: 950 s_time: -9 penalty: 0 agent_num: 15 done: False
______________________
id: 53 reward: -0.04017857142857143 service_time: 870 s_time: 36 penalty: 0 agent_num: 16 done: False
______________________
id: 49 reward: -0.06954887218045112 service_time: 998 s_time: 74 penalty: 0 agent_num: 19 done: False
______________________
id: 51 reward: 0.0017857142857142857 service_time: 1070 s_time: -2 penalty: 0 agent_num: 20 done: False
______________________
id: 45 reward: 0.0 service_time: 1128 s_time: 0 penalty: 0 agent_num: 30 done: False
______________________
id: 44 reward: -0.012244897959183673 service_time: 704 s_time: 24 penalty: 0 agent_num: 35 done: False
______________________
id: 40 reward: 0.0018796992481203006 service_time: 1064 s_time: -2 penalty: 0 agent_num: 19 done: False
______________________
id: 52 reward: -0.06456043956043957 service_time: 1324 s_time: 94 penalty: 0 agent_num: 26 done: False
______________________
id: 43 reward: -0.027857142857142858 service_time: 1291 s_time: 39 penalty: 0 agent_num: 25 done: False
______________________
id: 46 reward: -0.020604395604395604 service_time: 1092 s_time: 45 penalty: 0 agent_num: 39 done: False
______________________
id: 41 reward: -0.012630662020905924 service_time: 1215 s_time: 29 penalty: 0 agent_num: 41 done: False
______________________
id: 48 reward: -0.003484320557491289 service_time: 1292 s_time: 8 penalty: 0 agent_num: 41 done: False
______________________
id: 55 reward: -0.013937282229965157 service_time: 1149 s_time: 32 penalty: 0 agent_num: 41 done: False
______________________
id: 54 reward: -0.006968641114982578 service_time: 1052 s_time: 16 penalty: 0 agent_num: 41 done: False
______________________
id: 50 reward: -0.009375 service_time: 1278 s_time: 21 penalty: 0 agent_num: 40 done: False
______________________
id: 47 reward: -0.011759581881533102 service_time: 1438 s_time: 27 penalty: 0 agent_num: 41 done: False
______________________
Step:  768
Pretraining Loss:  tensor(0.2987, device='cuda:0', grad_fn=<MeanBackward0>)
id: 42 reward: 0.0011904761904761906 service_time: 949 s_time: -1 penalty: 0 agent_num: 15 done: False
______________________
id: 49 reward: -0.047932330827067667 service_time: 1049 s_time: 51 penalty: 0 agent_num: 19 done: False
______________________
id: 53 reward: 0.006696428571428571 service_time: 864 s_time: -6 penalty: 0 agent_num: 16 done: False
______________________
id: 44 reward: -0.004591836734693878 service_time: 713 s_time: 9 penalty: 0 agent_num: 35 done: False
______________________
id: 40 reward: -0.09210526315789473 service_time: 1162 s_time: 98 penalty: 0 agent_num: 19 done: False
______________________
id: 45 reward: -0.0375 service_time: 1191 s_time: 63 penalty: 0 agent_num: 30 done: False
______________________
id: 51 reward: -0.024107142857142858 service_time: 1097 s_time: 27 penalty: 0 agent_num: 20 done: False
______________________
id: 52 reward: -0.008241758241758242 service_time: 1336 s_time: 12 penalty: 0 agent_num: 26 done: False
______________________
id: 41 reward: -0.002613240418118467 service_time: 1221 s_time: 6 penalty: 0 agent_num: 41 done: False
______________________
id: 46 reward: -0.007326007326007326 service_time: 1108 s_time: 16 penalty: 0 agent_num: 39 done: False
______________________
id: 43 reward: 0.009285714285714286 service_time: 1278 s_time: -13 penalty: 0 agent_num: 25 done: False
______________________
id: 55 reward: 0.002613240418118467 service_time: 1143 s_time: -6 penalty: 0 agent_num: 41 done: False
______________________
id: 48 reward: -0.004355400696864111 service_time: 1302 s_time: 10 penalty: 0 agent_num: 41 done: False
______________________
id: 47 reward: 0.00043554006968641115 service_time: 1437 s_time: -1 penalty: 0 agent_num: 41 done: False
______________________
id: 50 reward: -0.011160714285714286 service_time: 1303 s_time: 25 penalty: 0 agent_num: 40 done: False
______________________
id: 54 reward: 20.00130662020906 service_time: 1049 s_time: -3 penalty: 0 agent_num: 41 done: True
______________________
Step:  784
Pretraining Loss:  tensor(0.3028, device='cuda:0', grad_fn=<MeanBackward0>)
id: 54 reward: -0.003078817733990148 service_time: 5 s_time: 5 penalty: 0 agent_num: 29 done: False
______________________
id: 53 reward: 0.0 service_time: 864 s_time: 0 penalty: 0 agent_num: 16 done: False
______________________
id: 49 reward: -0.018796992481203006 service_time: 1069 s_time: 20 penalty: 0 agent_num: 19 done: False
______________________
id: 51 reward: -0.10803571428571429 service_time: 1218 s_time: 121 penalty: 0 agent_num: 20 done: False
______________________
id: 42 reward: -0.05119047619047619 service_time: 992 s_time: 43 penalty: 0 agent_num: 15 done: False
______________________
id: 45 reward: 0.002976190476190476 service_time: 1186 s_time: -5 penalty: 0 agent_num: 30 done: False
______________________
id: 44 reward: -0.026020408163265306 service_time: 764 s_time: 51 penalty: 0 agent_num: 35 done: False
______________________
id: 46 reward: 0.0027472527472527475 service_time: 1102 s_time: -6 penalty: 0 agent_num: 39 done: False
______________________
id: 43 reward: -0.07214285714285715 service_time: 1379 s_time: 101 penalty: 0 agent_num: 25 done: False
______________________
id: 41 reward: 0.0008710801393728223 service_time: 1219 s_time: -2 penalty: 0 agent_num: 41 done: False
______________________
id: 55 reward: -0.00043554006968641115 service_time: 1144 s_time: 1 penalty: 0 agent_num: 41 done: False
______________________
id: 48 reward: 0.0 service_time: 1302 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 40 reward: -0.02913533834586466 service_time: 1193 s_time: 31 penalty: 0 agent_num: 19 done: False
______________________
id: 50 reward: 0.0 service_time: 1303 s_time: 0 penalty: 0 agent_num: 40 done: False
______________________
id: 47 reward: 0.00043554006968641115 service_time: 1436 s_time: -1 penalty: 0 agent_num: 41 done: False
______________________
id: 52 reward: 0.0020604395604395605 service_time: 1333 s_time: -3 penalty: 0 agent_num: 26 done: False
______________________
Step:  800
Pretraining Loss:  tensor(0.3288, device='cuda:0', grad_fn=<MeanBackward0>)
id: 54 reward: -0.03263546798029557 service_time: 58 s_time: 53 penalty: 0 agent_num: 29 done: False
______________________
id: 42 reward: -0.058333333333333334 service_time: 1041 s_time: 49 penalty: 0 agent_num: 15 done: False
______________________
id: 49 reward: -0.08082706766917293 service_time: 1155 s_time: 86 penalty: 0 agent_num: 19 done: False
______________________
id: 51 reward: -0.1375 service_time: 1372 s_time: 154 penalty: 0 agent_num: 20 done: False
______________________
id: 53 reward: -0.05915178571428571 service_time: 917 s_time: 53 penalty: 0 agent_num: 16 done: False
______________________
id: 45 reward: -0.0017857142857142857 service_time: 1189 s_time: 3 penalty: 0 agent_num: 30 done: False
______________________
id: 44 reward: 0.0 service_time: 764 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 41 reward: 0.0 service_time: 1219 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 52 reward: -0.038461538461538464 service_time: 1389 s_time: 56 penalty: 0 agent_num: 26 done: False
______________________
id: 43 reward: -0.04071428571428572 service_time: 1436 s_time: 57 penalty: 0 agent_num: 25 done: False
______________________
id: 46 reward: 0.0 service_time: 1102 s_time: 0 penalty: 0 agent_num: 39 done: False
______________________
id: 40 reward: -0.06390977443609022 service_time: 1261 s_time: 68 penalty: 0 agent_num: 19 done: False
______________________
id: 48 reward: 0.0 service_time: 1302 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 50 reward: 0.0 service_time: 1303 s_time: 0 penalty: 0 agent_num: 40 done: False
______________________
id: 47 reward: 0.0 service_time: 1436 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 55 reward: 20.001742160278745 service_time: 1140 s_time: -4 penalty: 0 agent_num: 41 done: True
______________________
Step:  816
Pretraining Loss:  tensor(0.3215, device='cuda:0', grad_fn=<MeanBackward0>)
id: 53 reward: -0.06696428571428571 service_time: 977 s_time: 60 penalty: 0 agent_num: 16 done: False
______________________
id: 54 reward: -0.014778325123152709 service_time: 82 s_time: 24 penalty: 0 agent_num: 29 done: False
______________________
id: 42 reward: -0.15595238095238095 service_time: 1172 s_time: 131 penalty: 0 agent_num: 15 done: False
______________________
id: 49 reward: -0.12593984962406016 service_time: 1289 s_time: 134 penalty: 0 agent_num: 19 done: False
______________________
id: 40 reward: -0.05639097744360902 service_time: 1321 s_time: 60 penalty: 0 agent_num: 19 done: False
______________________
id: 45 reward: 0.002976190476190476 service_time: 1184 s_time: -5 penalty: 0 agent_num: 30 done: False
______________________
id: 55 reward: -0.007783882783882784 service_time: 17 s_time: 17 penalty: 0 agent_num: 39 done: False
______________________
id: 44 reward: -0.008673469387755102 service_time: 781 s_time: 17 penalty: 0 agent_num: 35 done: False
______________________
id: 51 reward: -0.059821428571428574 service_time: 1439 s_time: 67 penalty: 0 agent_num: 20 done: False
______________________
id: 41 reward: 0.0 service_time: 1219 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 50 reward: 0.0 service_time: 1303 s_time: 0 penalty: 0 agent_num: 40 done: False
______________________
id: 46 reward: 0.0 service_time: 1102 s_time: 0 penalty: 0 agent_num: 39 done: False
______________________
id: 52 reward: -0.03983516483516483 service_time: 1447 s_time: 58 penalty: 0 agent_num: 26 done: False
______________________
id: 48 reward: 0.0 service_time: 1302 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 43 reward: -0.05 service_time: 1506 s_time: 70 penalty: 0 agent_num: 25 done: False
______________________
id: 47 reward: 0.00043554006968641115 service_time: 1435 s_time: -1 penalty: 0 agent_num: 41 done: False
______________________
Step:  832
Pretraining Loss:  tensor(0.2631, device='cuda:0', grad_fn=<MeanBackward0>)
id: 53 reward: -0.2421875 service_time: 1194 s_time: 217 penalty: 0 agent_num: 16 done: False
______________________
id: 55 reward: 0.0 service_time: 17 s_time: 0 penalty: 0 agent_num: 39 done: False
______________________
id: 51 reward: -0.05267857142857143 service_time: 1498 s_time: 59 penalty: 0 agent_num: 20 done: False
______________________
id: 54 reward: -0.011699507389162561 service_time: 101 s_time: 19 penalty: 0 agent_num: 29 done: False
______________________
id: 42 reward: -0.06190476190476191 service_time: 1224 s_time: 52 penalty: 0 agent_num: 15 done: False
______________________
id: 40 reward: -0.05733082706766917 service_time: 1382 s_time: 61 penalty: 0 agent_num: 19 done: False
______________________
id: 45 reward: 0.0005952380952380953 service_time: 1183 s_time: -1 penalty: 0 agent_num: 30 done: False
______________________
id: 46 reward: 0.0 service_time: 1102 s_time: 0 penalty: 0 agent_num: 39 done: False
______________________
id: 44 reward: 0.0 service_time: 781 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 41 reward: 0.0 service_time: 1219 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 49 reward: -0.08176691729323309 service_time: 1376 s_time: 87 penalty: 0 agent_num: 19 done: False
______________________
id: 52 reward: 0.0 service_time: 1447 s_time: 0 penalty: 0 agent_num: 26 done: False
______________________
id: 47 reward: 0.0021777003484320556 service_time: 1430 s_time: -5 penalty: 0 agent_num: 41 done: False
______________________
id: 43 reward: 0.0064285714285714285 service_time: 1497 s_time: -9 penalty: 0 agent_num: 25 done: False
______________________
id: 50 reward: 0.0 service_time: 1303 s_time: 0 penalty: 0 agent_num: 40 done: False
______________________
id: 48 reward: 0.0021777003484320556 service_time: 1297 s_time: -5 penalty: 0 agent_num: 41 done: False
______________________
Step:  848
Pretraining Loss:  tensor(0.2707, device='cuda:0', grad_fn=<MeanBackward0>)
id: 40 reward: -0.06296992481203008 service_time: 1449 s_time: 67 penalty: 0 agent_num: 19 done: False
______________________
id: 53 reward: -0.060267857142857144 service_time: 1248 s_time: 54 penalty: 0 agent_num: 16 done: False
______________________
id: 51 reward: -0.08035714285714286 service_time: 1588 s_time: 90 penalty: 0 agent_num: 20 done: False
______________________
id: 45 reward: 0.004166666666666667 service_time: 1176 s_time: -7 penalty: 0 agent_num: 30 done: False
______________________
id: 42 reward: -0.07976190476190476 service_time: 1291 s_time: 67 penalty: 0 agent_num: 15 done: False
______________________
id: 54 reward: -0.01600985221674877 service_time: 127 s_time: 26 penalty: 0 agent_num: 29 done: False
______________________
id: 55 reward: -0.0260989010989011 service_time: 74 s_time: 57 penalty: 0 agent_num: 39 done: False
______________________
id: 49 reward: -0.05545112781954887 service_time: 1435 s_time: 59 penalty: 0 agent_num: 19 done: False
______________________
id: 41 reward: 0.0 service_time: 1219 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 46 reward: 0.0 service_time: 1102 s_time: 0 penalty: 0 agent_num: 39 done: False
______________________
id: 50 reward: 0.0 service_time: 1303 s_time: 0 penalty: 0 agent_num: 40 done: False
______________________
id: 52 reward: 0.017857142857142856 service_time: 1421 s_time: -26 penalty: 0 agent_num: 26 done: False
______________________
id: 43 reward: 0.0035714285714285713 service_time: 1492 s_time: -5 penalty: 0 agent_num: 25 done: False
______________________
id: 48 reward: 0.0013066202090592336 service_time: 1294 s_time: -3 penalty: 0 agent_num: 41 done: False
______________________
id: 47 reward: 0.0 service_time: 1430 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 44 reward: -0.001530612244897959 service_time: 784 s_time: 3 penalty: 0 agent_num: 35 done: False
______________________
Step:  864
Pretraining Loss:  tensor(0.2701, device='cuda:0', grad_fn=<MeanBackward0>)
id: 54 reward: 0.0 service_time: 127 s_time: 0 penalty: 0 agent_num: 29 done: False
______________________
id: 53 reward: -0.07366071428571429 service_time: 1314 s_time: 66 penalty: 0 agent_num: 16 done: False
______________________
id: 51 reward: -0.06160714285714286 service_time: 1657 s_time: 69 penalty: 0 agent_num: 20 done: False
______________________
id: 45 reward: 0.0 service_time: 1176 s_time: 0 penalty: 0 agent_num: 30 done: False
______________________
id: 42 reward: -0.1357142857142857 service_time: 1405 s_time: 114 penalty: 0 agent_num: 15 done: False
______________________
id: 52 reward: 0.0 service_time: 1421 s_time: 0 penalty: 0 agent_num: 26 done: False
______________________
id: 41 reward: 0.0 service_time: 1219 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 55 reward: -0.016483516483516484 service_time: 110 s_time: 36 penalty: 0 agent_num: 39 done: False
______________________
id: 48 reward: 0.0 service_time: 1294 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 40 reward: -0.05827067669172932 service_time: 1511 s_time: 62 penalty: 0 agent_num: 19 done: False
______________________
id: 43 reward: -0.0014285714285714286 service_time: 1494 s_time: 2 penalty: 0 agent_num: 25 done: False
______________________
id: 47 reward: 0.0 service_time: 1430 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 44 reward: -0.008673469387755102 service_time: 801 s_time: 17 penalty: 0 agent_num: 35 done: False
______________________
id: 49 reward: -0.06296992481203008 service_time: 1502 s_time: 67 penalty: 0 agent_num: 19 done: False
______________________
id: 46 reward: 20.0 service_time: 1102 s_time: 0 penalty: 0 agent_num: 39 done: True
______________________
id: 50 reward: 20.00267857142857 service_time: 1297 s_time: -6 penalty: 0 agent_num: 40 done: True
______________________
Step:  880
Pretraining Loss:  tensor(0.2899, device='cuda:0', grad_fn=<MeanBackward0>)
id: 46 reward: -0.019642857142857142 service_time: 11 s_time: 11 penalty: 0 agent_num: 10 done: False
______________________
id: 53 reward: -0.09598214285714286 service_time: 1400 s_time: 86 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: -0.08458646616541353 service_time: 1601 s_time: 90 penalty: 0 agent_num: 19 done: False
______________________
id: 42 reward: -0.058333333333333334 service_time: 1454 s_time: 49 penalty: 0 agent_num: 15 done: False
______________________
id: 54 reward: -0.014778325123152709 service_time: 151 s_time: 24 penalty: 0 agent_num: 29 done: False
______________________
id: 51 reward: -0.04732142857142857 service_time: 1710 s_time: 53 penalty: 0 agent_num: 20 done: False
______________________
id: 52 reward: 0.0020604395604395605 service_time: 1418 s_time: -3 penalty: 0 agent_num: 26 done: False
______________________
id: 50 reward: -0.013996138996138996 service_time: 29 s_time: 29 penalty: 0 agent_num: 37 done: False
______________________
id: 49 reward: -0.06015037593984962 service_time: 1566 s_time: 64 penalty: 0 agent_num: 19 done: False
______________________
id: 55 reward: -0.005952380952380952 service_time: 123 s_time: 13 penalty: 0 agent_num: 39 done: False
______________________
id: 41 reward: 0.0 service_time: 1219 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 43 reward: 0.0 service_time: 1494 s_time: 0 penalty: 0 agent_num: 25 done: False
______________________
id: 44 reward: -0.006122448979591836 service_time: 813 s_time: 12 penalty: 0 agent_num: 35 done: False
______________________
id: 45 reward: 20.004166666666666 service_time: 1169 s_time: -7 penalty: 0 agent_num: 30 done: True
______________________
id: 48 reward: 20.002613240418118 service_time: 1288 s_time: -6 penalty: 0 agent_num: 41 done: True
______________________
id: 47 reward: 20.000871080139373 service_time: 1428 s_time: -2 penalty: 0 agent_num: 41 done: True
______________________
Step:  896
Pretraining Loss:  tensor(0.3380, device='cuda:0', grad_fn=<MeanBackward0>)
id: 46 reward: -0.039285714285714285 service_time: 33 s_time: 22 penalty: 0 agent_num: 10 done: False
______________________
id: 45 reward: -0.01020408163265306 service_time: 20 s_time: 20 penalty: 0 agent_num: 35 done: False
______________________
id: 47 reward: -0.017857142857142856 service_time: 37 s_time: 37 penalty: 0 agent_num: 37 done: False
______________________
id: 52 reward: 0.0 service_time: 1418 s_time: 0 penalty: 0 agent_num: 26 done: False
______________________
id: 42 reward: -0.05238095238095238 service_time: 1498 s_time: 44 penalty: 0 agent_num: 15 done: False
______________________
id: 54 reward: -0.0166256157635468 service_time: 178 s_time: 27 penalty: 0 agent_num: 29 done: False
______________________
id: 51 reward: 0.0017857142857142857 service_time: 1708 s_time: -2 penalty: 0 agent_num: 20 done: False
______________________
id: 49 reward: -0.08364661654135339 service_time: 1655 s_time: 89 penalty: 0 agent_num: 19 done: False
______________________
id: 48 reward: -0.009136212624584718 service_time: 22 s_time: 22 penalty: 0 agent_num: 43 done: False
______________________
id: 44 reward: -0.009693877551020408 service_time: 832 s_time: 19 penalty: 0 agent_num: 35 done: False
______________________
id: 41 reward: 0.00043554006968641115 service_time: 1218 s_time: -1 penalty: 0 agent_num: 41 done: False
______________________
id: 50 reward: -0.019787644787644786 service_time: 70 s_time: 41 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: -0.07589285714285714 service_time: 1468 s_time: 68 penalty: 0 agent_num: 16 done: False
______________________
id: 55 reward: -0.007783882783882784 service_time: 140 s_time: 17 penalty: 0 agent_num: 39 done: False
______________________
id: 40 reward: -0.05827067669172932 service_time: 1663 s_time: 62 penalty: 0 agent_num: 19 done: False
______________________
id: 43 reward: 0.0014285714285714286 service_time: 1492 s_time: -2 penalty: 0 agent_num: 25 done: False
______________________
Step:  912
Pretraining Loss:  tensor(0.2494, device='cuda:0', grad_fn=<MeanBackward0>)
id: 46 reward: -0.05 service_time: 61 s_time: 28 penalty: 0 agent_num: 10 done: False
______________________
id: 45 reward: -0.012244897959183673 service_time: 44 s_time: 24 penalty: 0 agent_num: 35 done: False
______________________
id: 51 reward: 0.0017857142857142857 service_time: 1706 s_time: -2 penalty: 0 agent_num: 20 done: False
______________________
id: 52 reward: 0.0 service_time: 1418 s_time: 0 penalty: 0 agent_num: 26 done: False
______________________
id: 53 reward: -0.09040178571428571 service_time: 1549 s_time: 81 penalty: 0 agent_num: 16 done: False
______________________
id: 42 reward: -0.16785714285714284 service_time: 1639 s_time: 141 penalty: 0 agent_num: 15 done: False
______________________
id: 49 reward: 0.02443609022556391 service_time: 1629 s_time: -26 penalty: 0 agent_num: 19 done: False
______________________
id: 55 reward: -0.011446886446886446 service_time: 165 s_time: 25 penalty: 0 agent_num: 39 done: False
______________________
id: 47 reward: -0.007722007722007722 service_time: 53 s_time: 16 penalty: 0 agent_num: 37 done: False
______________________
id: 54 reward: -0.010467980295566502 service_time: 195 s_time: 17 penalty: 0 agent_num: 29 done: False
______________________
id: 44 reward: -0.012244897959183673 service_time: 856 s_time: 24 penalty: 0 agent_num: 35 done: False
______________________
id: 43 reward: -0.0014285714285714286 service_time: 1494 s_time: 2 penalty: 0 agent_num: 25 done: False
______________________
id: 48 reward: -0.0024916943521594683 service_time: 28 s_time: 6 penalty: 0 agent_num: 43 done: False
______________________
id: 40 reward: 0.0 service_time: 1663 s_time: 0 penalty: 0 agent_num: 19 done: False
______________________
id: 50 reward: -0.008687258687258687 service_time: 88 s_time: 18 penalty: 0 agent_num: 37 done: False
______________________
id: 41 reward: 20.0 service_time: 1218 s_time: 0 penalty: 0 agent_num: 41 done: True
______________________
Step:  928
Pretraining Loss:  tensor(0.3128, device='cuda:0', grad_fn=<MeanBackward0>)
id: 46 reward: -0.02857142857142857 service_time: 77 s_time: 16 penalty: 0 agent_num: 10 done: False
______________________
id: 42 reward: -0.05 service_time: 1681 s_time: 42 penalty: 0 agent_num: 15 done: False
______________________
id: 54 reward: 0.0 service_time: 195 s_time: 0 penalty: 0 agent_num: 29 done: False
______________________
id: 45 reward: 0.0 service_time: 44 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 47 reward: -0.006274131274131274 service_time: 66 s_time: 13 penalty: 0 agent_num: 37 done: False
______________________
id: 52 reward: 0.0013736263736263737 service_time: 1416 s_time: -2 penalty: 0 agent_num: 26 done: False
______________________
id: 48 reward: 0.0 service_time: 28 s_time: 0 penalty: 0 agent_num: 43 done: False
______________________
id: 51 reward: 0.0 service_time: 1706 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 41 reward: -0.0034937888198757765 service_time: 9 s_time: 9 penalty: 0 agent_num: 46 done: False
______________________
id: 49 reward: 0.0018796992481203006 service_time: 1627 s_time: -2 penalty: 0 agent_num: 19 done: False
______________________
id: 44 reward: 0.0 service_time: 856 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 55 reward: -0.007326007326007326 service_time: 181 s_time: 16 penalty: 0 agent_num: 39 done: False
______________________
id: 43 reward: 0.002142857142857143 service_time: 1491 s_time: -3 penalty: 0 agent_num: 25 done: False
______________________
id: 50 reward: -0.02702702702702703 service_time: 144 s_time: 56 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: -0.22433035714285715 service_time: 1750 s_time: 201 penalty: 0 agent_num: 16 done: False
______________________
id: 40 reward: 20.007518796992482 service_time: 1655 s_time: -8 penalty: 0 agent_num: 19 done: True
______________________
Step:  944
Pretraining Loss:  tensor(0.2600, device='cuda:0', grad_fn=<MeanBackward0>)
id: 46 reward: -0.048214285714285716 service_time: 104 s_time: 27 penalty: 0 agent_num: 10 done: False
______________________
id: 45 reward: -0.015306122448979591 service_time: 74 s_time: 30 penalty: 0 agent_num: 35 done: False
______________________
id: 42 reward: -0.12380952380952381 service_time: 1785 s_time: 104 penalty: 0 agent_num: 15 done: False
______________________
id: 49 reward: -0.0018796992481203006 service_time: 1629 s_time: 2 penalty: 0 agent_num: 19 done: False
______________________
id: 54 reward: -0.04495073891625616 service_time: 268 s_time: 73 penalty: 0 agent_num: 29 done: False
______________________
id: 40 reward: -0.014372822299651568 service_time: 33 s_time: 33 penalty: 0 agent_num: 41 done: False
______________________
id: 53 reward: 0.0078125 service_time: 1743 s_time: -7 penalty: 0 agent_num: 16 done: False
______________________
id: 47 reward: -0.010135135135135136 service_time: 87 s_time: 21 penalty: 0 agent_num: 37 done: False
______________________
id: 48 reward: -0.023255813953488372 service_time: 84 s_time: 56 penalty: 0 agent_num: 43 done: False
______________________
id: 51 reward: 0.0 service_time: 1706 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 43 reward: 0.002142857142857143 service_time: 1488 s_time: -3 penalty: 0 agent_num: 25 done: False
______________________
id: 55 reward: 0.0 service_time: 181 s_time: 0 penalty: 0 agent_num: 39 done: False
______________________
id: 44 reward: -0.013775510204081633 service_time: 883 s_time: 27 penalty: 0 agent_num: 35 done: False
______________________
id: 50 reward: 0.002413127413127413 service_time: 139 s_time: -5 penalty: 0 agent_num: 37 done: False
______________________
id: 41 reward: -0.010093167701863354 service_time: 35 s_time: 26 penalty: 0 agent_num: 46 done: False
______________________
id: 52 reward: 20.002747252747252 service_time: 1412 s_time: -4 penalty: 0 agent_num: 26 done: True
______________________
Step:  960
Pretraining Loss:  tensor(0.2199, device='cuda:0', grad_fn=<MeanBackward0>)
id: 46 reward: -0.060714285714285714 service_time: 138 s_time: 34 penalty: 0 agent_num: 10 done: False
______________________
id: 45 reward: -0.006122448979591836 service_time: 86 s_time: 12 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: -0.021551724137931036 service_time: 303 s_time: 35 penalty: 0 agent_num: 29 done: False
______________________
id: 51 reward: 0.0 service_time: 1706 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 42 reward: -0.12261904761904761 service_time: 1888 s_time: 103 penalty: 0 agent_num: 15 done: False
______________________
id: 40 reward: -0.010017421602787456 service_time: 56 s_time: 23 penalty: 0 agent_num: 41 done: False
______________________
id: 50 reward: -0.014961389961389961 service_time: 170 s_time: 31 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: 0.004464285714285714 service_time: 1739 s_time: -4 penalty: 0 agent_num: 16 done: False
______________________
id: 49 reward: 0.0018796992481203006 service_time: 1627 s_time: -2 penalty: 0 agent_num: 19 done: False
______________________
id: 48 reward: -0.009966777408637873 service_time: 108 s_time: 24 penalty: 0 agent_num: 43 done: False
______________________
id: 41 reward: -0.01048136645962733 service_time: 62 s_time: 27 penalty: 0 agent_num: 46 done: False
______________________
id: 47 reward: -0.006274131274131274 service_time: 100 s_time: 13 penalty: 0 agent_num: 37 done: False
______________________
id: 55 reward: -0.013278388278388278 service_time: 210 s_time: 29 penalty: 0 agent_num: 39 done: False
______________________
id: 52 reward: -0.005357142857142857 service_time: 12 s_time: 12 penalty: 0 agent_num: 40 done: False
______________________
id: 43 reward: 0.0007142857142857143 service_time: 1487 s_time: -1 penalty: 0 agent_num: 25 done: False
______________________
id: 44 reward: -0.015306122448979591 service_time: 913 s_time: 30 penalty: 0 agent_num: 35 done: False
______________________
Step:  976
Pretraining Loss:  tensor(0.2118, device='cuda:0', grad_fn=<MeanBackward0>)
id: 46 reward: -0.017857142857142856 service_time: 148 s_time: 10 penalty: 0 agent_num: 10 done: False
______________________
id: 54 reward: -0.01293103448275862 service_time: 324 s_time: 21 penalty: 0 agent_num: 29 done: False
______________________
id: 45 reward: -0.014285714285714285 service_time: 114 s_time: 28 penalty: 0 agent_num: 35 done: False
______________________
id: 52 reward: -0.005357142857142857 service_time: 24 s_time: 12 penalty: 0 agent_num: 40 done: False
______________________
id: 40 reward: -0.008710801393728223 service_time: 76 s_time: 20 penalty: 0 agent_num: 41 done: False
______________________
id: 41 reward: -0.009316770186335404 service_time: 86 s_time: 24 penalty: 0 agent_num: 46 done: False
______________________
id: 47 reward: -0.010617760617760617 service_time: 122 s_time: 22 penalty: 0 agent_num: 37 done: False
______________________
id: 50 reward: -0.005791505791505791 service_time: 182 s_time: 12 penalty: 0 agent_num: 37 done: False
______________________
id: 44 reward: -0.008673469387755102 service_time: 930 s_time: 17 penalty: 0 agent_num: 35 done: False
______________________
id: 43 reward: 0.0 service_time: 1487 s_time: 0 penalty: 0 agent_num: 25 done: False
______________________
id: 55 reward: -0.023809523809523808 service_time: 262 s_time: 52 penalty: 0 agent_num: 39 done: False
______________________
id: 48 reward: -0.03322259136212625 service_time: 188 s_time: 80 penalty: 0 agent_num: 43 done: False
______________________
id: 49 reward: 20.00093984962406 service_time: 1626 s_time: -1 penalty: 0 agent_num: 19 done: True
______________________
id: 53 reward: 20.0 service_time: 1739 s_time: 0 penalty: 0 agent_num: 16 done: True
______________________
id: 42 reward: -0.1773809523809524 service_time: 2037 s_time: 149 penalty: 0 agent_num: 15 done: False
______________________
id: 51 reward: 20.0 service_time: 1706 s_time: 0 penalty: 0 agent_num: 20 done: True
______________________
Step:  992
Pretraining Loss:  tensor(0.2482, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.033928571428571426 service_time: 19 s_time: 19 penalty: 0 agent_num: 10 done: False
______________________
id: 46 reward: -0.044642857142857144 service_time: 173 s_time: 25 penalty: 0 agent_num: 10 done: False
______________________
id: 42 reward: 0.017857142857142856 service_time: 2022 s_time: -15 penalty: 0 agent_num: 15 done: False
______________________
id: 53 reward: -0.01461038961038961 service_time: 27 s_time: 27 penalty: 0 agent_num: 33 done: False
______________________
id: 54 reward: -0.014778325123152709 service_time: 348 s_time: 24 penalty: 0 agent_num: 29 done: False
______________________
id: 47 reward: -0.03812741312741313 service_time: 201 s_time: 79 penalty: 0 agent_num: 37 done: False
______________________
id: 52 reward: -0.013392857142857142 service_time: 54 s_time: 30 penalty: 0 agent_num: 40 done: False
______________________
id: 51 reward: -0.013289036544850499 service_time: 32 s_time: 32 penalty: 0 agent_num: 43 done: False
______________________
id: 40 reward: -0.008710801393728223 service_time: 96 s_time: 20 penalty: 0 agent_num: 41 done: False
______________________
id: 50 reward: -0.012065637065637066 service_time: 207 s_time: 25 penalty: 0 agent_num: 37 done: False
______________________
id: 45 reward: 0.0 service_time: 114 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 41 reward: -0.01203416149068323 service_time: 117 s_time: 31 penalty: 0 agent_num: 46 done: False
______________________
id: 55 reward: -0.031135531135531136 service_time: 330 s_time: 68 penalty: 0 agent_num: 39 done: False
______________________
id: 48 reward: -0.014534883720930232 service_time: 223 s_time: 35 penalty: 0 agent_num: 43 done: False
______________________
id: 44 reward: -0.012244897959183673 service_time: 954 s_time: 24 penalty: 0 agent_num: 35 done: False
______________________
id: 43 reward: 20.0 service_time: 1487 s_time: 0 penalty: 0 agent_num: 25 done: True
______________________
Step:  1008
Pretraining Loss:  tensor(0.1665, device='cuda:0', grad_fn=<MeanBackward0>)
id: 43 reward: -0.016233766233766232 service_time: 10 s_time: 10 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: -0.04642857142857143 service_time: 45 s_time: 26 penalty: 0 agent_num: 10 done: False
______________________
id: 53 reward: -0.008116883116883116 service_time: 42 s_time: 15 penalty: 0 agent_num: 33 done: False
______________________
id: 46 reward: -0.05 service_time: 201 s_time: 28 penalty: 0 agent_num: 10 done: False
______________________
id: 45 reward: -0.008673469387755102 service_time: 131 s_time: 17 penalty: 0 agent_num: 35 done: False
______________________
id: 51 reward: -0.007475083056478406 service_time: 50 s_time: 18 penalty: 0 agent_num: 43 done: False
______________________
id: 54 reward: -0.017241379310344827 service_time: 376 s_time: 28 penalty: 0 agent_num: 29 done: False
______________________
id: 40 reward: -0.008275261324041812 service_time: 115 s_time: 19 penalty: 0 agent_num: 41 done: False
______________________
id: 47 reward: -0.015926640926640926 service_time: 234 s_time: 33 penalty: 0 agent_num: 37 done: False
______________________
id: 50 reward: 0.0 service_time: 207 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 41 reward: 0.0 service_time: 117 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 44 reward: -0.010714285714285714 service_time: 975 s_time: 21 penalty: 0 agent_num: 35 done: False
______________________
id: 52 reward: 0.0 service_time: 54 s_time: 0 penalty: 0 agent_num: 40 done: False
______________________
id: 55 reward: 0.007783882783882784 service_time: 313 s_time: -17 penalty: 0 agent_num: 39 done: False
______________________
id: 42 reward: 0.0 service_time: 2022 s_time: 0 penalty: 0 agent_num: 15 done: False
______________________
id: 48 reward: 0.014950166112956811 service_time: 187 s_time: -36 penalty: 0 agent_num: 43 done: False
______________________
Step:  1024
Pretraining Loss:  tensor(0.1819, device='cuda:0', grad_fn=<MeanBackward0>)
id: 43 reward: -0.017857142857142856 service_time: 21 s_time: 11 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: -0.06607142857142857 service_time: 82 s_time: 37 penalty: 0 agent_num: 10 done: False
______________________
id: 46 reward: -0.06607142857142857 service_time: 238 s_time: 37 penalty: 0 agent_num: 10 done: False
______________________
id: 53 reward: -0.007034632034632035 service_time: 55 s_time: 13 penalty: 0 agent_num: 33 done: False
______________________
id: 45 reward: -0.009183673469387756 service_time: 149 s_time: 18 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: -0.011699507389162561 service_time: 395 s_time: 19 penalty: 0 agent_num: 29 done: False
______________________
id: 51 reward: -0.011627906976744186 service_time: 78 s_time: 28 penalty: 0 agent_num: 43 done: False
______________________
id: 52 reward: -0.005357142857142857 service_time: 66 s_time: 12 penalty: 0 agent_num: 40 done: False
______________________
id: 50 reward: -0.02557915057915058 service_time: 260 s_time: 53 penalty: 0 agent_num: 37 done: False
______________________
id: 40 reward: -0.006097560975609756 service_time: 129 s_time: 14 penalty: 0 agent_num: 41 done: False
______________________
id: 41 reward: -0.006599378881987578 service_time: 134 s_time: 17 penalty: 0 agent_num: 46 done: False
______________________
id: 55 reward: -0.007783882783882784 service_time: 330 s_time: 17 penalty: 0 agent_num: 39 done: False
______________________
id: 44 reward: -0.01020408163265306 service_time: 995 s_time: 20 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.02782392026578073 service_time: 254 s_time: 67 penalty: 0 agent_num: 43 done: False
______________________
id: 42 reward: 20.01309523809524 service_time: 2011 s_time: -11 penalty: 0 agent_num: 15 done: True
______________________
id: 47 reward: 0.006756756756756757 service_time: 220 s_time: -14 penalty: 0 agent_num: 37 done: False
______________________
Step:  1040
Pretraining Loss:  tensor(0.1891, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.05 service_time: 110 s_time: 28 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: -0.048701298701298704 service_time: 51 s_time: 30 penalty: 0 agent_num: 11 done: False
______________________
id: 46 reward: 0.017857142857142856 service_time: 228 s_time: -10 penalty: 0 agent_num: 10 done: False
______________________
id: 42 reward: -0.009978991596638655 service_time: 19 s_time: 19 penalty: 0 agent_num: 34 done: False
______________________
id: 53 reward: -0.007034632034632035 service_time: 68 s_time: 13 penalty: 0 agent_num: 33 done: False
______________________
id: 45 reward: 0.0 service_time: 149 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: -0.01293103448275862 service_time: 416 s_time: 21 penalty: 0 agent_num: 29 done: False
______________________
id: 52 reward: 0.0 service_time: 66 s_time: 0 penalty: 0 agent_num: 40 done: False
______________________
id: 51 reward: 0.0 service_time: 78 s_time: 0 penalty: 0 agent_num: 43 done: False
______________________
id: 40 reward: -0.01132404181184669 service_time: 155 s_time: 26 penalty: 0 agent_num: 41 done: False
______________________
id: 41 reward: -0.01281055900621118 service_time: 167 s_time: 33 penalty: 0 agent_num: 46 done: False
______________________
id: 50 reward: -0.00916988416988417 service_time: 279 s_time: 19 penalty: 0 agent_num: 37 done: False
______________________
id: 55 reward: -0.024267399267399268 service_time: 383 s_time: 53 penalty: 0 agent_num: 39 done: False
______________________
id: 47 reward: -0.0014478764478764478 service_time: 223 s_time: 3 penalty: 0 agent_num: 37 done: False
______________________
id: 48 reward: -0.004568106312292359 service_time: 265 s_time: 11 penalty: 0 agent_num: 43 done: False
______________________
id: 44 reward: 0.0 service_time: 995 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
Step:  1056
Pretraining Loss:  tensor(0.1573, device='cuda:0', grad_fn=<MeanBackward0>)
id: 46 reward: -0.03571428571428571 service_time: 248 s_time: 20 penalty: 0 agent_num: 10 done: False
______________________
id: 49 reward: -0.026785714285714284 service_time: 125 s_time: 15 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: -0.06493506493506493 service_time: 91 s_time: 40 penalty: 0 agent_num: 11 done: False
______________________
id: 53 reward: -0.025974025974025976 service_time: 116 s_time: 48 penalty: 0 agent_num: 33 done: False
______________________
id: 42 reward: -0.003676470588235294 service_time: 26 s_time: 7 penalty: 0 agent_num: 34 done: False
______________________
id: 52 reward: -0.017410714285714286 service_time: 105 s_time: 39 penalty: 0 agent_num: 40 done: False
______________________
id: 51 reward: -0.013704318936877076 service_time: 111 s_time: 33 penalty: 0 agent_num: 43 done: False
______________________
id: 45 reward: -0.01683673469387755 service_time: 182 s_time: 33 penalty: 0 agent_num: 35 done: False
______________________
id: 40 reward: -0.009146341463414634 service_time: 176 s_time: 21 penalty: 0 agent_num: 41 done: False
______________________
id: 47 reward: -0.018822393822393823 service_time: 262 s_time: 39 penalty: 0 agent_num: 37 done: False
______________________
id: 54 reward: -0.022783251231527094 service_time: 453 s_time: 37 penalty: 0 agent_num: 29 done: False
______________________
id: 55 reward: 0.0 service_time: 383 s_time: 0 penalty: 0 agent_num: 39 done: False
______________________
id: 41 reward: -0.025232919254658384 service_time: 232 s_time: 65 penalty: 0 agent_num: 46 done: False
______________________
id: 50 reward: -0.041023166023166024 service_time: 364 s_time: 85 penalty: 0 agent_num: 37 done: False
______________________
id: 48 reward: -0.011212624584717609 service_time: 292 s_time: 27 penalty: 0 agent_num: 43 done: False
______________________
id: 44 reward: 19.99642857142857 service_time: 1002 s_time: 7 penalty: 0 agent_num: 35 done: True
______________________
Step:  1072
Pretraining Loss:  tensor(0.1590, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.06785714285714285 service_time: 163 s_time: 38 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: -0.048701298701298704 service_time: 121 s_time: 30 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: -0.014136904761904762 service_time: 19 s_time: 19 penalty: 0 agent_num: 24 done: False
______________________
id: 46 reward: 0.007142857142857143 service_time: 244 s_time: -4 penalty: 0 agent_num: 10 done: False
______________________
id: 42 reward: -0.0031512605042016808 service_time: 32 s_time: 6 penalty: 0 agent_num: 34 done: False
______________________
id: 53 reward: 0.0 service_time: 116 s_time: 0 penalty: 0 agent_num: 33 done: False
______________________
id: 45 reward: -0.009183673469387756 service_time: 200 s_time: 18 penalty: 0 agent_num: 35 done: False
______________________
id: 52 reward: -0.007589285714285714 service_time: 122 s_time: 17 penalty: 0 agent_num: 40 done: False
______________________
id: 54 reward: -0.01600985221674877 service_time: 479 s_time: 26 penalty: 0 agent_num: 29 done: False
______________________
id: 41 reward: -0.006599378881987578 service_time: 249 s_time: 17 penalty: 0 agent_num: 46 done: False
______________________
id: 40 reward: 0.0 service_time: 176 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 55 reward: -0.018772893772893772 service_time: 424 s_time: 41 penalty: 0 agent_num: 39 done: False
______________________
id: 51 reward: 0.0012458471760797341 service_time: 108 s_time: -3 penalty: 0 agent_num: 43 done: False
______________________
id: 47 reward: -0.025096525096525095 service_time: 314 s_time: 52 penalty: 0 agent_num: 37 done: False
______________________
id: 48 reward: -0.009136212624584718 service_time: 314 s_time: 22 penalty: 0 agent_num: 43 done: False
______________________
id: 50 reward: -0.01447876447876448 service_time: 394 s_time: 30 penalty: 0 agent_num: 37 done: False
______________________
Step:  1088
Pretraining Loss:  tensor(0.1718, device='cuda:0', grad_fn=<MeanBackward0>)
id: 46 reward: 0.03214285714285714 service_time: 226 s_time: -18 penalty: 0 agent_num: 10 done: False
______________________
id: 49 reward: -0.0375 service_time: 184 s_time: 21 penalty: 0 agent_num: 10 done: False
______________________
id: 44 reward: -0.018601190476190476 service_time: 44 s_time: 25 penalty: 0 agent_num: 24 done: False
______________________
id: 43 reward: -0.05519480519480519 service_time: 155 s_time: 34 penalty: 0 agent_num: 11 done: False
______________________
id: 42 reward: -0.007878151260504201 service_time: 47 s_time: 15 penalty: 0 agent_num: 34 done: False
______________________
id: 53 reward: -0.005411255411255411 service_time: 126 s_time: 10 penalty: 0 agent_num: 33 done: False
______________________
id: 40 reward: -0.009146341463414634 service_time: 197 s_time: 21 penalty: 0 agent_num: 41 done: False
______________________
id: 45 reward: -0.01020408163265306 service_time: 220 s_time: 20 penalty: 0 agent_num: 35 done: False
______________________
id: 52 reward: 0.0 service_time: 122 s_time: 0 penalty: 0 agent_num: 40 done: False
______________________
id: 55 reward: -0.013736263736263736 service_time: 454 s_time: 30 penalty: 0 agent_num: 39 done: False
______________________
id: 51 reward: -0.024916943521594685 service_time: 168 s_time: 60 penalty: 0 agent_num: 43 done: False
______________________
id: 41 reward: -0.005434782608695652 service_time: 263 s_time: 14 penalty: 0 agent_num: 46 done: False
______________________
id: 54 reward: -0.024630541871921183 service_time: 519 s_time: 40 penalty: 0 agent_num: 29 done: False
______________________
id: 47 reward: 0.0009652509652509653 service_time: 312 s_time: -2 penalty: 0 agent_num: 37 done: False
______________________
id: 48 reward: -0.007475083056478406 service_time: 332 s_time: 18 penalty: 0 agent_num: 43 done: False
______________________
id: 50 reward: -0.019787644787644786 service_time: 435 s_time: 41 penalty: 0 agent_num: 37 done: False
______________________
Step:  1104
Pretraining Loss:  tensor(0.1778, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.0375 service_time: 205 s_time: 21 penalty: 0 agent_num: 10 done: False
______________________
id: 46 reward: 0.007142857142857143 service_time: 222 s_time: -4 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: -0.08279220779220779 service_time: 206 s_time: 51 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: -0.017857142857142856 service_time: 68 s_time: 24 penalty: 0 agent_num: 24 done: False
______________________
id: 53 reward: -0.00487012987012987 service_time: 135 s_time: 9 penalty: 0 agent_num: 33 done: False
______________________
id: 42 reward: -0.0063025210084033615 service_time: 59 s_time: 12 penalty: 0 agent_num: 34 done: False
______________________
id: 45 reward: -0.011224489795918367 service_time: 242 s_time: 22 penalty: 0 agent_num: 35 done: False
______________________
id: 52 reward: -0.015625 service_time: 157 s_time: 35 penalty: 0 agent_num: 40 done: False
______________________
id: 40 reward: -0.016114982578397212 service_time: 234 s_time: 37 penalty: 0 agent_num: 41 done: False
______________________
id: 54 reward: -0.017857142857142856 service_time: 548 s_time: 29 penalty: 0 agent_num: 29 done: False
______________________
id: 47 reward: -0.023166023166023165 service_time: 360 s_time: 48 penalty: 0 agent_num: 37 done: False
______________________
id: 51 reward: -0.018272425249169437 service_time: 212 s_time: 44 penalty: 0 agent_num: 43 done: False
______________________
id: 41 reward: -0.01048136645962733 service_time: 290 s_time: 27 penalty: 0 agent_num: 46 done: False
______________________
id: 55 reward: 0.0 service_time: 454 s_time: 0 penalty: 0 agent_num: 39 done: False
______________________
id: 48 reward: -0.0049833887043189366 service_time: 344 s_time: 12 penalty: 0 agent_num: 43 done: False
______________________
id: 50 reward: -0.004826254826254826 service_time: 445 s_time: 10 penalty: 0 agent_num: 37 done: False
______________________
Step:  1120
Pretraining Loss:  tensor(0.1912, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.05178571428571429 service_time: 234 s_time: 29 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: -0.04220779220779221 service_time: 232 s_time: 26 penalty: 0 agent_num: 11 done: False
______________________
id: 46 reward: 0.0 service_time: 222 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 44 reward: -0.01488095238095238 service_time: 88 s_time: 20 penalty: 0 agent_num: 24 done: False
______________________
id: 53 reward: 0.0 service_time: 135 s_time: 0 penalty: 0 agent_num: 33 done: False
______________________
id: 42 reward: 0.0 service_time: 59 s_time: 0 penalty: 0 agent_num: 34 done: False
______________________
id: 45 reward: -0.00816326530612245 service_time: 258 s_time: 16 penalty: 0 agent_num: 35 done: False
______________________
id: 52 reward: -0.005803571428571429 service_time: 170 s_time: 13 penalty: 0 agent_num: 40 done: False
______________________
id: 40 reward: -0.004790940766550522 service_time: 245 s_time: 11 penalty: 0 agent_num: 41 done: False
______________________
id: 47 reward: -0.013513513513513514 service_time: 388 s_time: 28 penalty: 0 agent_num: 37 done: False
______________________
id: 55 reward: -0.018772893772893772 service_time: 495 s_time: 41 penalty: 0 agent_num: 39 done: False
______________________
id: 54 reward: -0.008620689655172414 service_time: 562 s_time: 14 penalty: 0 agent_num: 29 done: False
______________________
id: 41 reward: -0.005046583850931677 service_time: 303 s_time: 13 penalty: 0 agent_num: 46 done: False
______________________
id: 50 reward: -0.00723938223938224 service_time: 460 s_time: 15 penalty: 0 agent_num: 37 done: False
______________________
id: 51 reward: -0.006229235880398671 service_time: 227 s_time: 15 penalty: 0 agent_num: 43 done: False
______________________
id: 48 reward: -0.030730897009966777 service_time: 418 s_time: 74 penalty: 0 agent_num: 43 done: False
______________________
Step:  1136
Pretraining Loss:  tensor(0.2047, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.05178571428571429 service_time: 263 s_time: 29 penalty: 0 agent_num: 10 done: False
______________________
id: 46 reward: -0.07142857142857142 service_time: 262 s_time: 40 penalty: 0 agent_num: 10 done: False
______________________
id: 44 reward: -0.012648809523809524 service_time: 105 s_time: 17 penalty: 0 agent_num: 24 done: False
______________________
id: 42 reward: -0.01207983193277311 service_time: 82 s_time: 23 penalty: 0 agent_num: 34 done: False
______________________
id: 53 reward: -0.032467532467532464 service_time: 195 s_time: 60 penalty: 0 agent_num: 33 done: False
______________________
id: 45 reward: 0.0 service_time: 258 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: -0.024630541871921183 service_time: 602 s_time: 40 penalty: 0 agent_num: 29 done: False
______________________
id: 43 reward: -0.032467532467532464 service_time: 252 s_time: 20 penalty: 0 agent_num: 11 done: False
______________________
id: 40 reward: 0.0 service_time: 245 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 51 reward: -0.01079734219269103 service_time: 253 s_time: 26 penalty: 0 agent_num: 43 done: False
______________________
id: 41 reward: -0.0038819875776397515 service_time: 313 s_time: 10 penalty: 0 agent_num: 46 done: False
______________________
id: 52 reward: -0.009821428571428571 service_time: 192 s_time: 22 penalty: 0 agent_num: 40 done: False
______________________
id: 55 reward: 0.0 service_time: 495 s_time: 0 penalty: 0 agent_num: 39 done: False
______________________
id: 47 reward: -0.016891891891891893 service_time: 423 s_time: 35 penalty: 0 agent_num: 37 done: False
______________________
id: 50 reward: 0.0028957528957528956 service_time: 454 s_time: -6 penalty: 0 agent_num: 37 done: False
______________________
id: 48 reward: 0.0070598006644518275 service_time: 401 s_time: -17 penalty: 0 agent_num: 43 done: False
______________________
Step:  1152
Pretraining Loss:  tensor(0.2350, device='cuda:0', grad_fn=<MeanBackward0>)
id: 46 reward: 0.007142857142857143 service_time: 258 s_time: -4 penalty: 0 agent_num: 10 done: False
______________________
id: 49 reward: 0.0 service_time: 263 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: -0.056818181818181816 service_time: 287 s_time: 35 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: -0.009672619047619048 service_time: 118 s_time: 13 penalty: 0 agent_num: 24 done: False
______________________
id: 42 reward: -0.01365546218487395 service_time: 108 s_time: 26 penalty: 0 agent_num: 34 done: False
______________________
id: 45 reward: -0.011224489795918367 service_time: 280 s_time: 22 penalty: 0 agent_num: 35 done: False
______________________
id: 52 reward: 0.0 service_time: 192 s_time: 0 penalty: 0 agent_num: 40 done: False
______________________
id: 51 reward: 0.0 service_time: 253 s_time: 0 penalty: 0 agent_num: 43 done: False
______________________
id: 53 reward: -0.020562770562770564 service_time: 233 s_time: 38 penalty: 0 agent_num: 33 done: False
______________________
id: 40 reward: -0.016986062717770034 service_time: 284 s_time: 39 penalty: 0 agent_num: 41 done: False
______________________
id: 50 reward: -0.00916988416988417 service_time: 473 s_time: 19 penalty: 0 agent_num: 37 done: False
______________________
id: 41 reward: -0.005822981366459627 service_time: 328 s_time: 15 penalty: 0 agent_num: 46 done: False
______________________
id: 47 reward: -0.006274131274131274 service_time: 436 s_time: 13 penalty: 0 agent_num: 37 done: False
______________________
id: 55 reward: -0.021062271062271064 service_time: 541 s_time: 46 penalty: 0 agent_num: 39 done: False
______________________
id: 54 reward: -0.025246305418719212 service_time: 643 s_time: 41 penalty: 0 agent_num: 29 done: False
______________________
id: 48 reward: -0.007890365448504983 service_time: 420 s_time: 19 penalty: 0 agent_num: 43 done: False
______________________
Step:  1168
Pretraining Loss:  tensor(0.2318, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.0 service_time: 263 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 46 reward: 0.0 service_time: 258 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 44 reward: -0.021577380952380952 service_time: 147 s_time: 29 penalty: 0 agent_num: 24 done: False
______________________
id: 53 reward: -0.00974025974025974 service_time: 251 s_time: 18 penalty: 0 agent_num: 33 done: False
______________________
id: 42 reward: -0.01050420168067227 service_time: 128 s_time: 20 penalty: 0 agent_num: 34 done: False
______________________
id: 45 reward: -0.011224489795918367 service_time: 302 s_time: 22 penalty: 0 agent_num: 35 done: False
______________________
id: 51 reward: -0.0024916943521594683 service_time: 259 s_time: 6 penalty: 0 agent_num: 43 done: False
______________________
id: 54 reward: 0.0012315270935960591 service_time: 641 s_time: -2 penalty: 0 agent_num: 29 done: False
______________________
id: 43 reward: -0.003246753246753247 service_time: 289 s_time: 2 penalty: 0 agent_num: 11 done: False
______________________
id: 40 reward: -0.013937282229965157 service_time: 316 s_time: 32 penalty: 0 agent_num: 41 done: False
______________________
id: 55 reward: -0.008241758241758242 service_time: 559 s_time: 18 penalty: 0 agent_num: 39 done: False
______________________
id: 52 reward: -0.015178571428571428 service_time: 226 s_time: 34 penalty: 0 agent_num: 40 done: False
______________________
id: 50 reward: -0.011583011583011582 service_time: 497 s_time: 24 penalty: 0 agent_num: 37 done: False
______________________
id: 48 reward: -0.008305647840531562 service_time: 440 s_time: 20 penalty: 0 agent_num: 43 done: False
______________________
id: 47 reward: -0.01447876447876448 service_time: 466 s_time: 30 penalty: 0 agent_num: 37 done: False
______________________
id: 41 reward: -0.017857142857142856 service_time: 374 s_time: 46 penalty: 0 agent_num: 46 done: False
______________________
Step:  1184
Pretraining Loss:  tensor(0.2253, device='cuda:0', grad_fn=<MeanBackward0>)
id: 46 reward: -0.044642857142857144 service_time: 283 s_time: 25 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: -0.06818181818181818 service_time: 331 s_time: 42 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: 0.0125 service_time: 256 s_time: -7 penalty: 0 agent_num: 10 done: False
______________________
id: 42 reward: -0.003676470588235294 service_time: 135 s_time: 7 penalty: 0 agent_num: 34 done: False
______________________
id: 44 reward: -0.014136904761904762 service_time: 166 s_time: 19 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: 0.0 service_time: 302 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 53 reward: -0.011904761904761904 service_time: 273 s_time: 22 penalty: 0 agent_num: 33 done: False
______________________
id: 52 reward: -0.014732142857142857 service_time: 259 s_time: 33 penalty: 0 agent_num: 40 done: False
______________________
id: 40 reward: -0.014372822299651568 service_time: 349 s_time: 33 penalty: 0 agent_num: 41 done: False
______________________
id: 54 reward: -0.04926108374384237 service_time: 721 s_time: 80 penalty: 0 agent_num: 29 done: False
______________________
id: 50 reward: -0.00916988416988417 service_time: 516 s_time: 19 penalty: 0 agent_num: 37 done: False
______________________
id: 55 reward: 0.0027472527472527475 service_time: 553 s_time: -6 penalty: 0 agent_num: 39 done: False
______________________
id: 51 reward: -0.009136212624584718 service_time: 281 s_time: 22 penalty: 0 agent_num: 43 done: False
______________________
id: 47 reward: -0.014961389961389961 service_time: 497 s_time: 31 penalty: 0 agent_num: 37 done: False
______________________
id: 41 reward: -0.015527950310559006 service_time: 414 s_time: 40 penalty: 0 agent_num: 46 done: False
______________________
id: 48 reward: 0.0 service_time: 440 s_time: 0 penalty: 0 agent_num: 43 done: False
______________________
Step:  1200
Pretraining Loss:  tensor(0.2355, device='cuda:0', grad_fn=<MeanBackward0>)
id: 46 reward: 0.0 service_time: 283 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 49 reward: 0.0 service_time: 256 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 44 reward: -0.005208333333333333 service_time: 173 s_time: 7 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: -0.010714285714285714 service_time: 323 s_time: 21 penalty: 0 agent_num: 35 done: False
______________________
id: 42 reward: -0.013130252100840336 service_time: 160 s_time: 25 penalty: 0 agent_num: 34 done: False
______________________
id: 53 reward: -0.007575757575757576 service_time: 287 s_time: 14 penalty: 0 agent_num: 33 done: False
______________________
id: 43 reward: -0.05032467532467533 service_time: 362 s_time: 31 penalty: 0 agent_num: 11 done: False
______________________
id: 51 reward: -0.006644518272425249 service_time: 297 s_time: 16 penalty: 0 agent_num: 43 done: False
______________________
id: 55 reward: -0.00641025641025641 service_time: 567 s_time: 14 penalty: 0 agent_num: 39 done: False
______________________
id: 50 reward: -0.020752895752895753 service_time: 559 s_time: 43 penalty: 0 agent_num: 37 done: False
______________________
id: 40 reward: 0.0 service_time: 349 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 48 reward: -0.018272425249169437 service_time: 484 s_time: 44 penalty: 0 agent_num: 43 done: False
______________________
id: 54 reward: -0.020935960591133004 service_time: 755 s_time: 34 penalty: 0 agent_num: 29 done: False
______________________
id: 52 reward: -0.014285714285714285 service_time: 291 s_time: 32 penalty: 0 agent_num: 40 done: False
______________________
id: 47 reward: 0.0 service_time: 497 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 41 reward: 0.0 service_time: 414 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
Step:  1216
Pretraining Loss:  tensor(0.2552, device='cuda:0', grad_fn=<MeanBackward0>)
id: 46 reward: -0.02857142857142857 service_time: 299 s_time: 16 penalty: 0 agent_num: 10 done: False
______________________
id: 49 reward: 0.0 service_time: 256 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: 0.024350649350649352 service_time: 347 s_time: -15 penalty: 0 agent_num: 11 done: False
______________________
id: 42 reward: -0.01050420168067227 service_time: 180 s_time: 20 penalty: 0 agent_num: 34 done: False
______________________
id: 45 reward: -0.014285714285714285 service_time: 351 s_time: 28 penalty: 0 agent_num: 35 done: False
______________________
id: 44 reward: -0.018601190476190476 service_time: 198 s_time: 25 penalty: 0 agent_num: 24 done: False
______________________
id: 50 reward: -0.019787644787644786 service_time: 600 s_time: 41 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: -0.024891774891774892 service_time: 333 s_time: 46 penalty: 0 agent_num: 33 done: False
______________________
id: 40 reward: -0.02613240418118467 service_time: 409 s_time: 60 penalty: 0 agent_num: 41 done: False
______________________
id: 52 reward: -0.014732142857142857 service_time: 324 s_time: 33 penalty: 0 agent_num: 40 done: False
______________________
id: 54 reward: -0.006157635467980296 service_time: 765 s_time: 10 penalty: 0 agent_num: 29 done: False
______________________
id: 55 reward: -0.011446886446886446 service_time: 592 s_time: 25 penalty: 0 agent_num: 39 done: False
______________________
id: 51 reward: -0.009966777408637873 service_time: 321 s_time: 24 penalty: 0 agent_num: 43 done: False
______________________
id: 41 reward: -0.010093167701863354 service_time: 440 s_time: 26 penalty: 0 agent_num: 46 done: False
______________________
id: 48 reward: 0.0008305647840531562 service_time: 482 s_time: -2 penalty: 0 agent_num: 43 done: False
______________________
id: 47 reward: -0.023166023166023165 service_time: 545 s_time: 48 penalty: 0 agent_num: 37 done: False
______________________
Step:  1232
Pretraining Loss:  tensor(0.2529, device='cuda:0', grad_fn=<MeanBackward0>)
id: 46 reward: 0.0 service_time: 299 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 49 reward: 0.0 service_time: 256 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 44 reward: 0.0 service_time: 198 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 42 reward: -0.003676470588235294 service_time: 187 s_time: 7 penalty: 0 agent_num: 34 done: False
______________________
id: 43 reward: 0.032467532467532464 service_time: 327 s_time: -20 penalty: 0 agent_num: 11 done: False
______________________
id: 53 reward: -0.023809523809523808 service_time: 377 s_time: 44 penalty: 0 agent_num: 33 done: False
______________________
id: 45 reward: -0.00816326530612245 service_time: 367 s_time: 16 penalty: 0 agent_num: 35 done: False
______________________
id: 52 reward: -0.019196428571428573 service_time: 367 s_time: 43 penalty: 0 agent_num: 40 done: False
______________________
id: 51 reward: -0.01079734219269103 service_time: 347 s_time: 26 penalty: 0 agent_num: 43 done: False
______________________
id: 40 reward: 0.0 service_time: 409 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 54 reward: -0.019088669950738917 service_time: 796 s_time: 31 penalty: 0 agent_num: 29 done: False
______________________
id: 55 reward: -0.019230769230769232 service_time: 634 s_time: 42 penalty: 0 agent_num: 39 done: False
______________________
id: 50 reward: -0.021235521235521235 service_time: 644 s_time: 44 penalty: 0 agent_num: 37 done: False
______________________
id: 47 reward: -0.004826254826254826 service_time: 555 s_time: 10 penalty: 0 agent_num: 37 done: False
______________________
id: 48 reward: -0.02823920265780731 service_time: 550 s_time: 68 penalty: 0 agent_num: 43 done: False
______________________
id: 41 reward: -0.008928571428571428 service_time: 463 s_time: 23 penalty: 0 agent_num: 46 done: False
______________________
Step:  1248
Pretraining Loss:  tensor(0.2640, device='cuda:0', grad_fn=<MeanBackward0>)
id: 46 reward: -0.03571428571428571 service_time: 319 s_time: 20 penalty: 0 agent_num: 10 done: False
______________________
id: 49 reward: -0.07678571428571429 service_time: 299 s_time: 43 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: 0.0 service_time: 327 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 42 reward: -0.013130252100840336 service_time: 212 s_time: 25 penalty: 0 agent_num: 34 done: False
______________________
id: 45 reward: -0.01020408163265306 service_time: 387 s_time: 20 penalty: 0 agent_num: 35 done: False
______________________
id: 50 reward: 0.0 service_time: 644 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 52 reward: -0.011160714285714286 service_time: 392 s_time: 25 penalty: 0 agent_num: 40 done: False
______________________
id: 51 reward: -0.0049833887043189366 service_time: 359 s_time: 12 penalty: 0 agent_num: 43 done: False
______________________
id: 55 reward: -0.008241758241758242 service_time: 652 s_time: 18 penalty: 0 agent_num: 39 done: False
______________________
id: 53 reward: 0.0 service_time: 377 s_time: 0 penalty: 0 agent_num: 33 done: False
______________________
id: 54 reward: -0.008004926108374385 service_time: 809 s_time: 13 penalty: 0 agent_num: 29 done: False
______________________
id: 44 reward: -0.04017857142857143 service_time: 252 s_time: 54 penalty: 0 agent_num: 24 done: False
______________________
id: 40 reward: -0.029616724738675958 service_time: 477 s_time: 68 penalty: 0 agent_num: 41 done: False
______________________
id: 48 reward: -0.012458471760797342 service_time: 580 s_time: 30 penalty: 0 agent_num: 43 done: False
______________________
id: 41 reward: -0.007763975155279503 service_time: 483 s_time: 20 penalty: 0 agent_num: 46 done: False
______________________
id: 47 reward: -0.023166023166023165 service_time: 603 s_time: 48 penalty: 0 agent_num: 37 done: False
______________________
Step:  1264
Pretraining Loss:  tensor(0.2491, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.03214285714285714 service_time: 281 s_time: -18 penalty: 0 agent_num: 10 done: False
______________________
id: 46 reward: 0.0 service_time: 319 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 44 reward: -0.03050595238095238 service_time: 293 s_time: 41 penalty: 0 agent_num: 24 done: False
______________________
id: 42 reward: -0.008928571428571428 service_time: 229 s_time: 17 penalty: 0 agent_num: 34 done: False
______________________
id: 45 reward: -0.009183673469387756 service_time: 405 s_time: 18 penalty: 0 agent_num: 35 done: False
______________________
id: 43 reward: 0.0 service_time: 327 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 52 reward: -0.01607142857142857 service_time: 428 s_time: 36 penalty: 0 agent_num: 40 done: False
______________________
id: 50 reward: -0.02944015444015444 service_time: 705 s_time: 61 penalty: 0 agent_num: 37 done: False
______________________
id: 51 reward: -0.014534883720930232 service_time: 394 s_time: 35 penalty: 0 agent_num: 43 done: False
______________________
id: 53 reward: -0.04220779220779221 service_time: 455 s_time: 78 penalty: 0 agent_num: 33 done: False
______________________
id: 40 reward: -0.010452961672473868 service_time: 501 s_time: 24 penalty: 0 agent_num: 41 done: False
______________________
id: 55 reward: -0.005036630036630037 service_time: 663 s_time: 11 penalty: 0 agent_num: 39 done: False
______________________
id: 54 reward: -0.006157635467980296 service_time: 819 s_time: 10 penalty: 0 agent_num: 29 done: False
______________________
id: 47 reward: -0.006756756756756757 service_time: 617 s_time: 14 penalty: 0 agent_num: 37 done: False
______________________
id: 48 reward: 0.0020764119601328905 service_time: 575 s_time: -5 penalty: 0 agent_num: 43 done: False
______________________
id: 41 reward: -0.008152173913043478 service_time: 504 s_time: 21 penalty: 0 agent_num: 46 done: False
______________________
Step:  1280
Pretraining Loss:  tensor(0.2645, device='cuda:0', grad_fn=<MeanBackward0>)
id: 43 reward: -0.04707792207792208 service_time: 356 s_time: 29 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: 0.0 service_time: 281 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 46 reward: 0.0 service_time: 319 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 42 reward: -0.022058823529411766 service_time: 271 s_time: 42 penalty: 0 agent_num: 34 done: False
______________________
id: 44 reward: 0.011160714285714286 service_time: 278 s_time: -15 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: -0.015306122448979591 service_time: 435 s_time: 30 penalty: 0 agent_num: 35 done: False
______________________
id: 52 reward: -0.00625 service_time: 442 s_time: 14 penalty: 0 agent_num: 40 done: False
______________________
id: 55 reward: -0.006868131868131868 service_time: 678 s_time: 15 penalty: 0 agent_num: 39 done: False
______________________
id: 47 reward: -0.014961389961389961 service_time: 648 s_time: 31 penalty: 0 agent_num: 37 done: False
______________________
id: 54 reward: -0.017857142857142856 service_time: 848 s_time: 29 penalty: 0 agent_num: 29 done: False
______________________
id: 40 reward: -0.005662020905923345 service_time: 514 s_time: 13 penalty: 0 agent_num: 41 done: False
______________________
id: 53 reward: -0.003246753246753247 service_time: 461 s_time: 6 penalty: 0 agent_num: 33 done: False
______________________
id: 51 reward: -0.016196013289036543 service_time: 433 s_time: 39 penalty: 0 agent_num: 43 done: False
______________________
id: 50 reward: -0.012548262548262547 service_time: 731 s_time: 26 penalty: 0 agent_num: 37 done: False
______________________
id: 48 reward: -0.02823920265780731 service_time: 643 s_time: 68 penalty: 0 agent_num: 43 done: False
______________________
id: 41 reward: -0.009704968944099378 service_time: 529 s_time: 25 penalty: 0 agent_num: 46 done: False
______________________
Step:  1296
Pretraining Loss:  tensor(0.2757, device='cuda:0', grad_fn=<MeanBackward0>)
id: 46 reward: 0.0 service_time: 319 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 49 reward: -0.05357142857142857 service_time: 311 s_time: 30 penalty: 0 agent_num: 10 done: False
______________________
id: 44 reward: -0.024553571428571428 service_time: 311 s_time: 33 penalty: 0 agent_num: 24 done: False
______________________
id: 43 reward: 0.030844155844155844 service_time: 337 s_time: -19 penalty: 0 agent_num: 11 done: False
______________________
id: 45 reward: 0.0 service_time: 435 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 42 reward: -0.016281512605042018 service_time: 302 s_time: 31 penalty: 0 agent_num: 34 done: False
______________________
id: 55 reward: -0.010531135531135532 service_time: 701 s_time: 23 penalty: 0 agent_num: 39 done: False
______________________
id: 40 reward: -0.012195121951219513 service_time: 542 s_time: 28 penalty: 0 agent_num: 41 done: False
______________________
id: 54 reward: -0.03078817733990148 service_time: 898 s_time: 50 penalty: 0 agent_num: 29 done: False
______________________
id: 53 reward: -0.0183982683982684 service_time: 495 s_time: 34 penalty: 0 agent_num: 33 done: False
______________________
id: 50 reward: -0.010135135135135136 service_time: 752 s_time: 21 penalty: 0 agent_num: 37 done: False
______________________
id: 47 reward: -0.01447876447876448 service_time: 678 s_time: 30 penalty: 0 agent_num: 37 done: False
______________________
id: 52 reward: 0.0 service_time: 442 s_time: 0 penalty: 0 agent_num: 40 done: False
______________________
id: 51 reward: -0.0033222591362126247 service_time: 441 s_time: 8 penalty: 0 agent_num: 43 done: False
______________________
id: 48 reward: -0.01744186046511628 service_time: 685 s_time: 42 penalty: 0 agent_num: 43 done: False
______________________
id: 41 reward: -0.009316770186335404 service_time: 553 s_time: 24 penalty: 0 agent_num: 46 done: False
______________________
Step:  1312
Pretraining Loss:  tensor(0.2772, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.01607142857142857 service_time: 302 s_time: -9 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: 0.0016233766233766235 service_time: 336 s_time: -1 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: 0.012648809523809524 service_time: 294 s_time: -17 penalty: 0 agent_num: 24 done: False
______________________
id: 46 reward: 0.0 service_time: 319 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 45 reward: -0.01683673469387755 service_time: 468 s_time: 33 penalty: 0 agent_num: 35 done: False
______________________
id: 52 reward: -0.015178571428571428 service_time: 476 s_time: 34 penalty: 0 agent_num: 40 done: False
______________________
id: 42 reward: 0.0 service_time: 302 s_time: 0 penalty: 0 agent_num: 34 done: False
______________________
id: 40 reward: 0.0 service_time: 542 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 55 reward: -0.0086996336996337 service_time: 720 s_time: 19 penalty: 0 agent_num: 39 done: False
______________________
id: 51 reward: -0.015365448504983389 service_time: 478 s_time: 37 penalty: 0 agent_num: 43 done: False
______________________
id: 47 reward: -0.016409266409266408 service_time: 712 s_time: 34 penalty: 0 agent_num: 37 done: False
______________________
id: 48 reward: -0.009966777408637873 service_time: 709 s_time: 24 penalty: 0 agent_num: 43 done: False
______________________
id: 54 reward: -0.022167487684729065 service_time: 934 s_time: 36 penalty: 0 agent_num: 29 done: False
______________________
id: 41 reward: -0.003105590062111801 service_time: 561 s_time: 8 penalty: 0 agent_num: 46 done: False
______________________
id: 50 reward: -0.019787644787644786 service_time: 793 s_time: 41 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: -0.037337662337662336 service_time: 564 s_time: 69 penalty: 0 agent_num: 33 done: False
______________________
Step:  1328
Pretraining Loss:  tensor(0.3089, device='cuda:0', grad_fn=<MeanBackward0>)
id: 46 reward: -0.09821428571428571 service_time: 374 s_time: 55 penalty: 0 agent_num: 10 done: False
______________________
id: 49 reward: 0.0 service_time: 302 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 44 reward: -0.023065476190476192 service_time: 325 s_time: 31 penalty: 0 agent_num: 24 done: False
______________________
id: 43 reward: 0.0 service_time: 336 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 45 reward: -0.00510204081632653 service_time: 478 s_time: 10 penalty: 0 agent_num: 35 done: False
______________________
id: 42 reward: -0.017331932773109245 service_time: 335 s_time: 33 penalty: 0 agent_num: 34 done: False
______________________
id: 52 reward: 0.0 service_time: 476 s_time: 0 penalty: 0 agent_num: 40 done: False
______________________
id: 55 reward: -0.013278388278388278 service_time: 749 s_time: 29 penalty: 0 agent_num: 39 done: False
______________________
id: 40 reward: -0.013066202090592335 service_time: 572 s_time: 30 penalty: 0 agent_num: 41 done: False
______________________
id: 51 reward: -0.008305647840531562 service_time: 498 s_time: 20 penalty: 0 agent_num: 43 done: False
______________________
id: 54 reward: -0.011083743842364532 service_time: 952 s_time: 18 penalty: 0 agent_num: 29 done: False
______________________
id: 50 reward: -0.0111003861003861 service_time: 816 s_time: 23 penalty: 0 agent_num: 37 done: False
______________________
id: 47 reward: 0.0 service_time: 712 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 48 reward: -0.005813953488372093 service_time: 723 s_time: 14 penalty: 0 agent_num: 43 done: False
______________________
id: 41 reward: -0.005822981366459627 service_time: 576 s_time: 15 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: 0.017857142857142856 service_time: 531 s_time: -33 penalty: 0 agent_num: 33 done: False
______________________
Step:  1344
Pretraining Loss:  tensor(0.2615, device='cuda:0', grad_fn=<MeanBackward0>)
id: 43 reward: 0.0 service_time: 336 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 46 reward: 0.0 service_time: 374 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 49 reward: 0.0 service_time: 302 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 44 reward: 0.0 service_time: 325 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: 0.0 service_time: 478 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 42 reward: -0.01838235294117647 service_time: 370 s_time: 35 penalty: 0 agent_num: 34 done: False
______________________
id: 54 reward: 0.011699507389162561 service_time: 933 s_time: -19 penalty: 0 agent_num: 29 done: False
______________________
id: 47 reward: -0.02895752895752896 service_time: 772 s_time: 60 penalty: 0 agent_num: 37 done: False
______________________
id: 55 reward: 0.0 service_time: 749 s_time: 0 penalty: 0 agent_num: 39 done: False
______________________
id: 40 reward: -0.014808362369337979 service_time: 606 s_time: 34 penalty: 0 agent_num: 41 done: False
______________________
id: 41 reward: -0.01281055900621118 service_time: 609 s_time: 33 penalty: 0 agent_num: 46 done: False
______________________
id: 48 reward: -0.0029069767441860465 service_time: 730 s_time: 7 penalty: 0 agent_num: 43 done: False
______________________
id: 50 reward: 0.0 service_time: 816 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 51 reward: -0.016196013289036543 service_time: 537 s_time: 39 penalty: 0 agent_num: 43 done: False
______________________
id: 53 reward: -0.03300865800865801 service_time: 592 s_time: 61 penalty: 0 agent_num: 33 done: False
______________________
id: 52 reward: -0.005357142857142857 service_time: 488 s_time: 12 penalty: 0 agent_num: 40 done: False
______________________
Step:  1360
Pretraining Loss:  tensor(0.3909, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.0 service_time: 302 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 46 reward: -0.025 service_time: 388 s_time: 14 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: -0.03896103896103896 service_time: 360 s_time: 24 penalty: 0 agent_num: 11 done: False
______________________
id: 45 reward: -0.01479591836734694 service_time: 507 s_time: 29 penalty: 0 agent_num: 35 done: False
______________________
id: 44 reward: -0.010416666666666666 service_time: 339 s_time: 14 penalty: 0 agent_num: 24 done: False
______________________
id: 40 reward: -0.013501742160278746 service_time: 637 s_time: 31 penalty: 0 agent_num: 41 done: False
______________________
id: 54 reward: -0.022783251231527094 service_time: 970 s_time: 37 penalty: 0 agent_num: 29 done: False
______________________
id: 42 reward: -0.011554621848739496 service_time: 392 s_time: 22 penalty: 0 agent_num: 34 done: False
______________________
id: 48 reward: -0.008305647840531562 service_time: 750 s_time: 20 penalty: 0 agent_num: 43 done: False
______________________
id: 52 reward: -0.019642857142857142 service_time: 532 s_time: 44 penalty: 0 agent_num: 40 done: False
______________________
id: 50 reward: -0.008204633204633204 service_time: 833 s_time: 17 penalty: 0 agent_num: 37 done: False
______________________
id: 51 reward: -0.015780730897009966 service_time: 575 s_time: 38 penalty: 0 agent_num: 43 done: False
______________________
id: 47 reward: -0.013513513513513514 service_time: 800 s_time: 28 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: -0.015692640692640692 service_time: 621 s_time: 29 penalty: 0 agent_num: 33 done: False
______________________
id: 41 reward: -0.01436335403726708 service_time: 646 s_time: 37 penalty: 0 agent_num: 46 done: False
______________________
id: 55 reward: -0.038461538461538464 service_time: 833 s_time: 84 penalty: 0 agent_num: 39 done: False
______________________
Step:  1376
Pretraining Loss:  tensor(0.2778, device='cuda:0', grad_fn=<MeanBackward0>)
id: 43 reward: 0.0 service_time: 360 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: -0.030357142857142857 service_time: 319 s_time: 17 penalty: 0 agent_num: 10 done: False
______________________
id: 46 reward: -0.05892857142857143 service_time: 421 s_time: 33 penalty: 0 agent_num: 10 done: False
______________________
id: 44 reward: 0.0 service_time: 339 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: -0.022448979591836733 service_time: 551 s_time: 44 penalty: 0 agent_num: 35 done: False
______________________
id: 42 reward: 0.0 service_time: 392 s_time: 0 penalty: 0 agent_num: 34 done: False
______________________
id: 54 reward: -0.038177339901477834 service_time: 1032 s_time: 62 penalty: 0 agent_num: 29 done: False
______________________
id: 40 reward: -0.008710801393728223 service_time: 657 s_time: 20 penalty: 0 agent_num: 41 done: False
______________________
id: 47 reward: 0.0 service_time: 800 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 50 reward: -0.02364864864864865 service_time: 882 s_time: 49 penalty: 0 agent_num: 37 done: False
______________________
id: 52 reward: -0.007589285714285714 service_time: 549 s_time: 17 penalty: 0 agent_num: 40 done: False
______________________
id: 48 reward: -0.0070598006644518275 service_time: 767 s_time: 17 penalty: 0 agent_num: 43 done: False
______________________
id: 53 reward: -0.010822510822510822 service_time: 641 s_time: 20 penalty: 0 agent_num: 33 done: False
______________________
id: 41 reward: -0.006599378881987578 service_time: 663 s_time: 17 penalty: 0 agent_num: 46 done: False
______________________
id: 51 reward: 0.0008305647840531562 service_time: 573 s_time: -2 penalty: 0 agent_num: 43 done: False
______________________
id: 55 reward: -0.013736263736263736 service_time: 863 s_time: 30 penalty: 0 agent_num: 39 done: False
______________________
Step:  1392
Pretraining Loss:  tensor(0.2567, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.0125 service_time: 312 s_time: -7 penalty: 0 agent_num: 10 done: False
______________________
id: 46 reward: 0.0 service_time: 421 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: 0.011363636363636364 service_time: 353 s_time: -7 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: -0.021577380952380952 service_time: 368 s_time: 29 penalty: 0 agent_num: 24 done: False
______________________
id: 42 reward: -0.03046218487394958 service_time: 450 s_time: 58 penalty: 0 agent_num: 34 done: False
______________________
id: 40 reward: -0.01088850174216028 service_time: 682 s_time: 25 penalty: 0 agent_num: 41 done: False
______________________
id: 54 reward: -0.02586206896551724 service_time: 1074 s_time: 42 penalty: 0 agent_num: 29 done: False
______________________
id: 45 reward: 0.0 service_time: 551 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 50 reward: 0.00048262548262548264 service_time: 881 s_time: -1 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: -0.017857142857142856 service_time: 674 s_time: 33 penalty: 0 agent_num: 33 done: False
______________________
id: 52 reward: 0.0 service_time: 549 s_time: 0 penalty: 0 agent_num: 40 done: False
______________________
id: 55 reward: -0.005036630036630037 service_time: 874 s_time: 11 penalty: 0 agent_num: 39 done: False
______________________
id: 48 reward: -0.004152823920265781 service_time: 777 s_time: 10 penalty: 0 agent_num: 43 done: False
______________________
id: 47 reward: -0.019305019305019305 service_time: 840 s_time: 40 penalty: 0 agent_num: 37 done: False
______________________
id: 51 reward: -0.018272425249169437 service_time: 617 s_time: 44 penalty: 0 agent_num: 43 done: False
______________________
id: 41 reward: -0.014751552795031056 service_time: 701 s_time: 38 penalty: 0 agent_num: 46 done: False
______________________
Step:  1408
Pretraining Loss:  tensor(0.2622, device='cuda:0', grad_fn=<MeanBackward0>)
id: 43 reward: 0.0 service_time: 353 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: 0.0 service_time: 312 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 46 reward: 0.0 service_time: 421 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 44 reward: -0.013392857142857142 service_time: 386 s_time: 18 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: -0.01479591836734694 service_time: 580 s_time: 29 penalty: 0 agent_num: 35 done: False
______________________
id: 40 reward: -0.010452961672473868 service_time: 706 s_time: 24 penalty: 0 agent_num: 41 done: False
______________________
id: 54 reward: -0.024630541871921183 service_time: 1114 s_time: 40 penalty: 0 agent_num: 29 done: False
______________________
id: 47 reward: -0.012065637065637066 service_time: 865 s_time: 25 penalty: 0 agent_num: 37 done: False
______________________
id: 52 reward: -0.020535714285714286 service_time: 595 s_time: 46 penalty: 0 agent_num: 40 done: False
______________________
id: 42 reward: -0.004726890756302521 service_time: 459 s_time: 9 penalty: 0 agent_num: 34 done: False
______________________
id: 48 reward: 0.0008305647840531562 service_time: 775 s_time: -2 penalty: 0 agent_num: 43 done: False
______________________
id: 53 reward: -0.016233766233766232 service_time: 704 s_time: 30 penalty: 0 agent_num: 33 done: False
______________________
id: 51 reward: -0.008305647840531562 service_time: 637 s_time: 20 penalty: 0 agent_num: 43 done: False
______________________
id: 41 reward: -0.010869565217391304 service_time: 729 s_time: 28 penalty: 0 agent_num: 46 done: False
______________________
id: 50 reward: -0.03957528957528957 service_time: 963 s_time: 82 penalty: 0 agent_num: 37 done: False
______________________
id: 55 reward: -0.0086996336996337 service_time: 893 s_time: 19 penalty: 0 agent_num: 39 done: False
______________________
Step:  1424
Pretraining Loss:  tensor(0.2941, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.0 service_time: 312 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: -0.05844155844155844 service_time: 389 s_time: 36 penalty: 0 agent_num: 11 done: False
______________________
id: 46 reward: -0.12857142857142856 service_time: 493 s_time: 72 penalty: 0 agent_num: 10 done: False
______________________
id: 44 reward: 0.000744047619047619 service_time: 385 s_time: -1 penalty: 0 agent_num: 24 done: False
______________________
id: 42 reward: -0.01995798319327731 service_time: 497 s_time: 38 penalty: 0 agent_num: 34 done: False
______________________
id: 45 reward: 0.0 service_time: 580 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: -0.008004926108374385 service_time: 1127 s_time: 13 penalty: 0 agent_num: 29 done: False
______________________
id: 40 reward: -0.008275261324041812 service_time: 725 s_time: 19 penalty: 0 agent_num: 41 done: False
______________________
id: 55 reward: -0.01282051282051282 service_time: 921 s_time: 28 penalty: 0 agent_num: 39 done: False
______________________
id: 53 reward: 0.003787878787878788 service_time: 697 s_time: -7 penalty: 0 agent_num: 33 done: False
______________________
id: 48 reward: -0.018687707641196014 service_time: 820 s_time: 45 penalty: 0 agent_num: 43 done: False
______________________
id: 52 reward: 0.0 service_time: 595 s_time: 0 penalty: 0 agent_num: 40 done: False
______________________
id: 51 reward: -0.018687707641196014 service_time: 682 s_time: 45 penalty: 0 agent_num: 43 done: False
______________________
id: 41 reward: -0.006211180124223602 service_time: 745 s_time: 16 penalty: 0 agent_num: 46 done: False
______________________
id: 47 reward: -0.02413127413127413 service_time: 915 s_time: 50 penalty: 0 agent_num: 37 done: False
______________________
id: 50 reward: -0.013513513513513514 service_time: 991 s_time: 28 penalty: 0 agent_num: 37 done: False
______________________
Step:  1440
Pretraining Loss:  tensor(0.2741, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.0 service_time: 312 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: 0.0 service_time: 389 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 46 reward: 0.0 service_time: 493 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 44 reward: -0.011904761904761904 service_time: 401 s_time: 16 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: -0.009183673469387756 service_time: 598 s_time: 18 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: 0.0 service_time: 1127 s_time: 0 penalty: 0 agent_num: 29 done: False
______________________
id: 40 reward: 0.0008710801393728223 service_time: 723 s_time: -2 penalty: 0 agent_num: 41 done: False
______________________
id: 52 reward: -0.01830357142857143 service_time: 636 s_time: 41 penalty: 0 agent_num: 40 done: False
______________________
id: 53 reward: -0.01406926406926407 service_time: 723 s_time: 26 penalty: 0 agent_num: 33 done: False
______________________
id: 48 reward: -0.006644518272425249 service_time: 836 s_time: 16 penalty: 0 agent_num: 43 done: False
______________________
id: 42 reward: -0.02153361344537815 service_time: 538 s_time: 41 penalty: 0 agent_num: 34 done: False
______________________
id: 41 reward: -0.009316770186335404 service_time: 769 s_time: 24 penalty: 0 agent_num: 46 done: False
______________________
id: 55 reward: 0.0018315018315018315 service_time: 917 s_time: -4 penalty: 0 agent_num: 39 done: False
______________________
id: 51 reward: -0.004152823920265781 service_time: 692 s_time: 10 penalty: 0 agent_num: 43 done: False
______________________
id: 47 reward: -0.00723938223938224 service_time: 930 s_time: 15 penalty: 0 agent_num: 37 done: False
______________________
id: 50 reward: -0.011583011583011582 service_time: 1015 s_time: 24 penalty: 0 agent_num: 37 done: False
______________________
Step:  1456
Pretraining Loss:  tensor(0.2933, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.0 service_time: 312 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: -0.048701298701298704 service_time: 419 s_time: 30 penalty: 0 agent_num: 11 done: False
______________________
id: 46 reward: 0.014285714285714285 service_time: 485 s_time: -8 penalty: 0 agent_num: 10 done: False
______________________
id: 44 reward: -0.012648809523809524 service_time: 418 s_time: 17 penalty: 0 agent_num: 24 done: False
______________________
id: 55 reward: -0.014194139194139194 service_time: 948 s_time: 31 penalty: 0 agent_num: 39 done: False
______________________
id: 40 reward: -0.020905923344947737 service_time: 771 s_time: 48 penalty: 0 agent_num: 41 done: False
______________________
id: 42 reward: 0.0 service_time: 538 s_time: 0 penalty: 0 agent_num: 34 done: False
______________________
id: 53 reward: -0.04491341991341991 service_time: 806 s_time: 83 penalty: 0 agent_num: 33 done: False
______________________
id: 45 reward: -0.012755102040816327 service_time: 623 s_time: 25 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.009966777408637873 service_time: 860 s_time: 24 penalty: 0 agent_num: 43 done: False
______________________
id: 47 reward: -0.007722007722007722 service_time: 946 s_time: 16 penalty: 0 agent_num: 37 done: False
______________________
id: 51 reward: -0.011212624584717609 service_time: 719 s_time: 27 penalty: 0 agent_num: 43 done: False
______________________
id: 52 reward: 0.0 service_time: 636 s_time: 0 penalty: 0 agent_num: 40 done: False
______________________
id: 50 reward: -0.017857142857142856 service_time: 1052 s_time: 37 penalty: 0 agent_num: 37 done: False
______________________
id: 54 reward: -0.0437192118226601 service_time: 1198 s_time: 71 penalty: 0 agent_num: 29 done: False
______________________
id: 41 reward: -0.02096273291925466 service_time: 823 s_time: 54 penalty: 0 agent_num: 46 done: False
______________________
Step:  1472
Pretraining Loss:  tensor(0.2832, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.044642857142857144 service_time: 337 s_time: 25 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: 0.0 service_time: 419 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 46 reward: 0.0125 service_time: 478 s_time: -7 penalty: 0 agent_num: 10 done: False
______________________
id: 44 reward: -0.023065476190476192 service_time: 449 s_time: 31 penalty: 0 agent_num: 24 done: False
______________________
id: 40 reward: -0.009146341463414634 service_time: 792 s_time: 21 penalty: 0 agent_num: 41 done: False
______________________
id: 47 reward: -0.006274131274131274 service_time: 959 s_time: 13 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: 0.0 service_time: 806 s_time: 0 penalty: 0 agent_num: 33 done: False
______________________
id: 55 reward: -0.020146520146520148 service_time: 992 s_time: 44 penalty: 0 agent_num: 39 done: False
______________________
id: 52 reward: -0.019642857142857142 service_time: 680 s_time: 44 penalty: 0 agent_num: 40 done: False
______________________
id: 45 reward: -0.019387755102040816 service_time: 661 s_time: 38 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: -0.017241379310344827 service_time: 1226 s_time: 28 penalty: 0 agent_num: 29 done: False
______________________
id: 48 reward: -0.013289036544850499 service_time: 892 s_time: 32 penalty: 0 agent_num: 43 done: False
______________________
id: 42 reward: -0.01838235294117647 service_time: 573 s_time: 35 penalty: 0 agent_num: 34 done: False
______________________
id: 51 reward: 0.0004152823920265781 service_time: 718 s_time: -1 penalty: 0 agent_num: 43 done: False
______________________
id: 50 reward: -0.015926640926640926 service_time: 1085 s_time: 33 penalty: 0 agent_num: 37 done: False
______________________
id: 41 reward: -0.010869565217391304 service_time: 851 s_time: 28 penalty: 0 agent_num: 46 done: False
______________________
Step:  1488
Pretraining Loss:  tensor(0.2705, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.055357142857142855 service_time: 368 s_time: 31 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: 0.0 service_time: 419 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 46 reward: 0.0035714285714285713 service_time: 476 s_time: -2 penalty: 0 agent_num: 10 done: False
______________________
id: 44 reward: -0.023809523809523808 service_time: 481 s_time: 32 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: -0.002551020408163265 service_time: 666 s_time: 5 penalty: 0 agent_num: 35 done: False
______________________
id: 40 reward: 0.0 service_time: 792 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 53 reward: -0.027597402597402596 service_time: 857 s_time: 51 penalty: 0 agent_num: 33 done: False
______________________
id: 42 reward: -0.012605042016806723 service_time: 597 s_time: 24 penalty: 0 agent_num: 34 done: False
______________________
id: 55 reward: -0.014652014652014652 service_time: 1024 s_time: 32 penalty: 0 agent_num: 39 done: False
______________________
id: 52 reward: 0.0 service_time: 680 s_time: 0 penalty: 0 agent_num: 40 done: False
______________________
id: 47 reward: -0.009652509652509652 service_time: 979 s_time: 20 penalty: 0 agent_num: 37 done: False
______________________
id: 51 reward: -0.02367109634551495 service_time: 775 s_time: 57 penalty: 0 agent_num: 43 done: False
______________________
id: 48 reward: -0.007890365448504983 service_time: 911 s_time: 19 penalty: 0 agent_num: 43 done: False
______________________
id: 50 reward: 0.00048262548262548264 service_time: 1084 s_time: -1 penalty: 0 agent_num: 37 done: False
______________________
id: 54 reward: -0.02586206896551724 service_time: 1268 s_time: 42 penalty: 0 agent_num: 29 done: False
______________________
id: 41 reward: -0.008540372670807454 service_time: 873 s_time: 22 penalty: 0 agent_num: 46 done: False
______________________
Step:  1504
Pretraining Loss:  tensor(0.2569, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.0 service_time: 368 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: 0.003246753246753247 service_time: 417 s_time: -2 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: 0.0 service_time: 481 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 47 reward: -0.017374517374517374 service_time: 1015 s_time: 36 penalty: 0 agent_num: 37 done: False
______________________
id: 46 reward: -0.18571428571428572 service_time: 580 s_time: 104 penalty: 0 agent_num: 10 done: False
______________________
id: 40 reward: -0.0195993031358885 service_time: 837 s_time: 45 penalty: 0 agent_num: 41 done: False
______________________
id: 48 reward: 0.0 service_time: 911 s_time: 0 penalty: 0 agent_num: 43 done: False
______________________
id: 52 reward: 0.0 service_time: 680 s_time: 0 penalty: 0 agent_num: 40 done: False
______________________
id: 55 reward: -0.0018315018315018315 service_time: 1028 s_time: 4 penalty: 0 agent_num: 39 done: False
______________________
id: 51 reward: 0.0 service_time: 775 s_time: 0 penalty: 0 agent_num: 43 done: False
______________________
id: 50 reward: -0.0222007722007722 service_time: 1130 s_time: 46 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: -0.0183982683982684 service_time: 891 s_time: 34 penalty: 0 agent_num: 33 done: False
______________________
id: 42 reward: -0.02153361344537815 service_time: 638 s_time: 41 penalty: 0 agent_num: 34 done: False
______________________
id: 45 reward: -0.011224489795918367 service_time: 688 s_time: 22 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: -0.0067733990147783255 service_time: 1279 s_time: 11 penalty: 0 agent_num: 29 done: False
______________________
id: 41 reward: -0.006987577639751553 service_time: 891 s_time: 18 penalty: 0 agent_num: 46 done: False
______________________
Step:  1520
Pretraining Loss:  tensor(0.2978, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.0 service_time: 368 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: -0.12175324675324675 service_time: 492 s_time: 75 penalty: 0 agent_num: 11 done: False
______________________
id: 46 reward: 0.0017857142857142857 service_time: 579 s_time: -1 penalty: 0 agent_num: 10 done: False
______________________
id: 44 reward: -0.023065476190476192 service_time: 512 s_time: 31 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: -0.009693877551020408 service_time: 707 s_time: 19 penalty: 0 agent_num: 35 done: False
______________________
id: 40 reward: 0.0 service_time: 837 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 55 reward: -0.0022893772893772895 service_time: 1033 s_time: 5 penalty: 0 agent_num: 39 done: False
______________________
id: 53 reward: -0.013528138528138528 service_time: 916 s_time: 25 penalty: 0 agent_num: 33 done: False
______________________
id: 48 reward: -0.022009966777408636 service_time: 964 s_time: 53 penalty: 0 agent_num: 43 done: False
______________________
id: 47 reward: -0.018822393822393823 service_time: 1054 s_time: 39 penalty: 0 agent_num: 37 done: False
______________________
id: 52 reward: -0.008035714285714285 service_time: 698 s_time: 18 penalty: 0 agent_num: 40 done: False
______________________
id: 42 reward: -0.009978991596638655 service_time: 657 s_time: 19 penalty: 0 agent_num: 34 done: False
______________________
id: 51 reward: -0.030730897009966777 service_time: 849 s_time: 74 penalty: 0 agent_num: 43 done: False
______________________
id: 54 reward: -0.021551724137931036 service_time: 1314 s_time: 35 penalty: 0 agent_num: 29 done: False
______________________
id: 41 reward: -0.009704968944099378 service_time: 916 s_time: 25 penalty: 0 agent_num: 46 done: False
______________________
id: 50 reward: -0.022683397683397683 service_time: 1177 s_time: 47 penalty: 0 agent_num: 37 done: False
______________________
Step:  1536
Pretraining Loss:  tensor(0.2569, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.0875 service_time: 417 s_time: 49 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: 0.003246753246753247 service_time: 490 s_time: -2 penalty: 0 agent_num: 11 done: False
______________________
id: 46 reward: 0.0 service_time: 579 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 44 reward: -0.020833333333333332 service_time: 540 s_time: 28 penalty: 0 agent_num: 24 done: False
______________________
id: 42 reward: 0.0010504201680672268 service_time: 655 s_time: -2 penalty: 0 agent_num: 34 done: False
______________________
id: 55 reward: -0.009615384615384616 service_time: 1054 s_time: 21 penalty: 0 agent_num: 39 done: False
______________________
id: 45 reward: 0.0 service_time: 707 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 47 reward: -0.008687258687258687 service_time: 1072 s_time: 18 penalty: 0 agent_num: 37 done: False
______________________
id: 52 reward: -0.007142857142857143 service_time: 714 s_time: 16 penalty: 0 agent_num: 40 done: False
______________________
id: 48 reward: -0.010382059800664452 service_time: 989 s_time: 25 penalty: 0 agent_num: 43 done: False
______________________
id: 40 reward: -0.018728222996515678 service_time: 880 s_time: 43 penalty: 0 agent_num: 41 done: False
______________________
id: 53 reward: -0.022186147186147188 service_time: 957 s_time: 41 penalty: 0 agent_num: 33 done: False
______________________
id: 51 reward: -0.013289036544850499 service_time: 881 s_time: 32 penalty: 0 agent_num: 43 done: False
______________________
id: 50 reward: -0.005791505791505791 service_time: 1189 s_time: 12 penalty: 0 agent_num: 37 done: False
______________________
id: 54 reward: -0.006157635467980296 service_time: 1324 s_time: 10 penalty: 0 agent_num: 29 done: False
______________________
id: 41 reward: -0.01125776397515528 service_time: 945 s_time: 29 penalty: 0 agent_num: 46 done: False
______________________
Step:  1552
Pretraining Loss:  tensor(0.3159, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.14642857142857144 service_time: 499 s_time: 82 penalty: 0 agent_num: 10 done: False
______________________
id: 46 reward: -0.1 service_time: 635 s_time: 56 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: 0.0 service_time: 490 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: -0.018601190476190476 service_time: 565 s_time: 25 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: -0.008673469387755102 service_time: 724 s_time: 17 penalty: 0 agent_num: 35 done: False
______________________
id: 40 reward: 0.0 service_time: 880 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 42 reward: -0.026260504201680673 service_time: 705 s_time: 50 penalty: 0 agent_num: 34 done: False
______________________
id: 52 reward: -0.01607142857142857 service_time: 750 s_time: 36 penalty: 0 agent_num: 40 done: False
______________________
id: 55 reward: 0.0009157509157509158 service_time: 1052 s_time: -2 penalty: 0 agent_num: 39 done: False
______________________
id: 48 reward: -0.010382059800664452 service_time: 1014 s_time: 25 penalty: 0 agent_num: 43 done: False
______________________
id: 53 reward: -0.017316017316017316 service_time: 989 s_time: 32 penalty: 0 agent_num: 33 done: False
______________________
id: 47 reward: -0.012065637065637066 service_time: 1097 s_time: 25 penalty: 0 agent_num: 37 done: False
______________________
id: 51 reward: -0.006229235880398671 service_time: 896 s_time: 15 penalty: 0 agent_num: 43 done: False
______________________
id: 54 reward: -0.02586206896551724 service_time: 1366 s_time: 42 penalty: 0 agent_num: 29 done: False
______________________
id: 50 reward: 0.00048262548262548264 service_time: 1188 s_time: -1 penalty: 0 agent_num: 37 done: False
______________________
id: 41 reward: -0.006599378881987578 service_time: 962 s_time: 17 penalty: 0 agent_num: 46 done: False
______________________
Step:  1568
Pretraining Loss:  tensor(0.3172, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.0 service_time: 499 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: 0.0 service_time: 490 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 46 reward: -0.023214285714285715 service_time: 648 s_time: 13 penalty: 0 agent_num: 10 done: False
______________________
id: 44 reward: -0.015625 service_time: 586 s_time: 21 penalty: 0 agent_num: 24 done: False
______________________
id: 42 reward: -0.008403361344537815 service_time: 721 s_time: 16 penalty: 0 agent_num: 34 done: False
______________________
id: 45 reward: 0.001530612244897959 service_time: 721 s_time: -3 penalty: 0 agent_num: 35 done: False
______________________
id: 40 reward: -0.01088850174216028 service_time: 905 s_time: 25 penalty: 0 agent_num: 41 done: False
______________________
id: 52 reward: -0.0040178571428571425 service_time: 759 s_time: 9 penalty: 0 agent_num: 40 done: False
______________________
id: 55 reward: -0.029304029304029304 service_time: 1116 s_time: 64 penalty: 0 agent_num: 39 done: False
______________________
id: 47 reward: -0.006756756756756757 service_time: 1111 s_time: 14 penalty: 0 agent_num: 37 done: False
______________________
id: 50 reward: -0.0222007722007722 service_time: 1234 s_time: 46 penalty: 0 agent_num: 37 done: False
______________________
id: 48 reward: -0.018272425249169437 service_time: 1058 s_time: 44 penalty: 0 agent_num: 43 done: False
______________________
id: 53 reward: -0.02867965367965368 service_time: 1042 s_time: 53 penalty: 0 agent_num: 33 done: False
______________________
id: 51 reward: -0.013704318936877076 service_time: 929 s_time: 33 penalty: 0 agent_num: 43 done: False
______________________
id: 54 reward: -0.029556650246305417 service_time: 1414 s_time: 48 penalty: 0 agent_num: 29 done: False
______________________
id: 41 reward: -0.006987577639751553 service_time: 980 s_time: 18 penalty: 0 agent_num: 46 done: False
______________________
------------------------------------
| time/                 |          |
|    fps                | 8        |
|    iterations         | 100      |
|    time_elapsed       | 198      |
|    total_timesteps    | 1600     |
| train/                |          |
|    entropy_loss       | 0.00111  |
|    explained_variance | -63.5    |
|    learning_rate      | 1e-05    |
|    n_updates          | 99       |
|    policy_loss        | 0.317    |
|    value_loss         | 0.458    |
------------------------------------
Step:  1584
Pretraining Loss:  tensor(0.3270, device='cuda:0', grad_fn=<MeanBackward0>)
id: 46 reward: 0.0 service_time: 648 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 49 reward: 0.0 service_time: 499 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: 0.0 service_time: 490 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: -0.014136904761904762 service_time: 605 s_time: 19 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: -0.00816326530612245 service_time: 737 s_time: 16 penalty: 0 agent_num: 35 done: False
______________________
id: 42 reward: -0.01365546218487395 service_time: 747 s_time: 26 penalty: 0 agent_num: 34 done: False
______________________
id: 55 reward: 0.0 service_time: 1116 s_time: 0 penalty: 0 agent_num: 39 done: False
______________________
id: 40 reward: -0.024390243902439025 service_time: 961 s_time: 56 penalty: 0 agent_num: 41 done: False
______________________
id: 47 reward: -0.010135135135135136 service_time: 1132 s_time: 21 penalty: 0 agent_num: 37 done: False
______________________
id: 54 reward: -0.008004926108374385 service_time: 1427 s_time: 13 penalty: 0 agent_num: 29 done: False
______________________
id: 53 reward: -0.013528138528138528 service_time: 1067 s_time: 25 penalty: 0 agent_num: 33 done: False
______________________
id: 48 reward: -0.012458471760797342 service_time: 1088 s_time: 30 penalty: 0 agent_num: 43 done: False
______________________
id: 52 reward: 0.0 service_time: 759 s_time: 0 penalty: 0 agent_num: 40 done: False
______________________
id: 50 reward: -0.019787644787644786 service_time: 1275 s_time: 41 penalty: 0 agent_num: 37 done: False
______________________
id: 51 reward: -0.006644518272425249 service_time: 945 s_time: 16 penalty: 0 agent_num: 43 done: False
______________________
id: 41 reward: -0.005046583850931677 service_time: 993 s_time: 13 penalty: 0 agent_num: 46 done: False
______________________
Step:  1600
Pretraining Loss:  tensor(0.3242, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.0 service_time: 499 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: 0.01461038961038961 service_time: 481 s_time: -9 penalty: 0 agent_num: 11 done: False
______________________
id: 46 reward: 0.05 service_time: 620 s_time: -28 penalty: 0 agent_num: 10 done: False
______________________
id: 44 reward: 0.0 service_time: 605 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: -0.011224489795918367 service_time: 759 s_time: 22 penalty: 0 agent_num: 35 done: False
______________________
id: 55 reward: -0.015567765567765568 service_time: 1150 s_time: 34 penalty: 0 agent_num: 39 done: False
______________________
id: 42 reward: 0.0 service_time: 747 s_time: 0 penalty: 0 agent_num: 34 done: False
______________________
id: 47 reward: -0.005308880308880309 service_time: 1143 s_time: 11 penalty: 0 agent_num: 37 done: False
______________________
id: 52 reward: -0.012053571428571429 service_time: 786 s_time: 27 penalty: 0 agent_num: 40 done: False
______________________
id: 50 reward: 0.0 service_time: 1275 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 48 reward: -0.009136212624584718 service_time: 1110 s_time: 22 penalty: 0 agent_num: 43 done: False
______________________
id: 54 reward: 0.006157635467980296 service_time: 1417 s_time: -10 penalty: 0 agent_num: 29 done: False
______________________
id: 40 reward: -0.012195121951219513 service_time: 989 s_time: 28 penalty: 0 agent_num: 41 done: False
______________________
id: 51 reward: -0.005813953488372093 service_time: 959 s_time: 14 penalty: 0 agent_num: 43 done: False
______________________
id: 41 reward: -0.009316770186335404 service_time: 1017 s_time: 24 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: -0.020562770562770564 service_time: 1105 s_time: 38 penalty: 0 agent_num: 33 done: False
______________________
Step:  1616
Pretraining Loss:  tensor(0.3127, device='cuda:0', grad_fn=<MeanBackward0>)
id: 43 reward: -0.07792207792207792 service_time: 529 s_time: 48 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: -0.08214285714285714 service_time: 545 s_time: 46 penalty: 0 agent_num: 10 done: False
______________________
id: 46 reward: 0.0 service_time: 620 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 44 reward: -0.010416666666666666 service_time: 619 s_time: 14 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: -0.013775510204081633 service_time: 786 s_time: 27 penalty: 0 agent_num: 35 done: False
______________________
id: 47 reward: 0.0009652509652509653 service_time: 1141 s_time: -2 penalty: 0 agent_num: 37 done: False
______________________
id: 54 reward: -0.02770935960591133 service_time: 1462 s_time: 45 penalty: 0 agent_num: 29 done: False
______________________
id: 42 reward: -0.02100840336134454 service_time: 787 s_time: 40 penalty: 0 agent_num: 34 done: False
______________________
id: 40 reward: -0.005662020905923345 service_time: 1002 s_time: 13 penalty: 0 agent_num: 41 done: False
______________________
id: 48 reward: -0.007475083056478406 service_time: 1128 s_time: 18 penalty: 0 agent_num: 43 done: False
______________________
id: 50 reward: -0.01833976833976834 service_time: 1313 s_time: 38 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: -0.020562770562770564 service_time: 1143 s_time: 38 penalty: 0 agent_num: 33 done: False
______________________
id: 52 reward: 0.0 service_time: 786 s_time: 0 penalty: 0 agent_num: 40 done: False
______________________
id: 55 reward: -0.021062271062271064 service_time: 1196 s_time: 46 penalty: 0 agent_num: 39 done: False
______________________
id: 51 reward: 0.0 service_time: 959 s_time: 0 penalty: 0 agent_num: 43 done: False
______________________
id: 41 reward: 0.0 service_time: 1017 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
Step:  1632
Pretraining Loss:  tensor(0.2877, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.0 service_time: 545 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: 0.0 service_time: 529 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 46 reward: 0.0 service_time: 620 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 44 reward: 0.0 service_time: 619 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 55 reward: -0.016025641025641024 service_time: 1231 s_time: 35 penalty: 0 agent_num: 39 done: False
______________________
id: 52 reward: -0.016517857142857143 service_time: 823 s_time: 37 penalty: 0 agent_num: 40 done: False
______________________
id: 50 reward: -0.004343629343629344 service_time: 1322 s_time: 9 penalty: 0 agent_num: 37 done: False
______________________
id: 42 reward: -0.016281512605042018 service_time: 818 s_time: 31 penalty: 0 agent_num: 34 done: False
______________________
id: 47 reward: -0.004343629343629344 service_time: 1150 s_time: 9 penalty: 0 agent_num: 37 done: False
______________________
id: 48 reward: -0.013704318936877076 service_time: 1161 s_time: 33 penalty: 0 agent_num: 43 done: False
______________________
id: 45 reward: -0.013775510204081633 service_time: 813 s_time: 27 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: -0.03263546798029557 service_time: 1515 s_time: 53 penalty: 0 agent_num: 29 done: False
______________________
id: 40 reward: -0.01524390243902439 service_time: 1037 s_time: 35 penalty: 0 agent_num: 41 done: False
______________________
id: 41 reward: -0.019409937888198756 service_time: 1067 s_time: 50 penalty: 0 agent_num: 46 done: False
______________________
id: 51 reward: -0.01079734219269103 service_time: 985 s_time: 26 penalty: 0 agent_num: 43 done: False
______________________
id: 53 reward: -0.0027056277056277055 service_time: 1148 s_time: 5 penalty: 0 agent_num: 33 done: False
______________________
Step:  1648
Pretraining Loss:  tensor(0.2882, device='cuda:0', grad_fn=<MeanBackward0>)
id: 43 reward: 0.0 service_time: 529 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 46 reward: 0.0 service_time: 620 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 49 reward: 0.0 service_time: 545 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 44 reward: -0.019345238095238096 service_time: 645 s_time: 26 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: -0.020918367346938777 service_time: 854 s_time: 41 penalty: 0 agent_num: 35 done: False
______________________
id: 52 reward: -0.015625 service_time: 858 s_time: 35 penalty: 0 agent_num: 40 done: False
______________________
id: 42 reward: 0.0 service_time: 818 s_time: 0 penalty: 0 agent_num: 34 done: False
______________________
id: 40 reward: -0.014808362369337979 service_time: 1071 s_time: 34 penalty: 0 agent_num: 41 done: False
______________________
id: 50 reward: -0.002413127413127413 service_time: 1327 s_time: 5 penalty: 0 agent_num: 37 done: False
______________________
id: 48 reward: -0.004152823920265781 service_time: 1171 s_time: 10 penalty: 0 agent_num: 43 done: False
______________________
id: 53 reward: 0.0 service_time: 1148 s_time: 0 penalty: 0 agent_num: 33 done: False
______________________
id: 41 reward: -0.018245341614906832 service_time: 1114 s_time: 47 penalty: 0 agent_num: 46 done: False
______________________
id: 55 reward: 0.0004578754578754579 service_time: 1230 s_time: -1 penalty: 0 agent_num: 39 done: False
______________________
id: 54 reward: -0.020320197044334975 service_time: 1548 s_time: 33 penalty: 0 agent_num: 29 done: False
______________________
id: 47 reward: -0.029922779922779922 service_time: 1212 s_time: 62 penalty: 0 agent_num: 37 done: False
______________________
id: 51 reward: -0.028654485049833887 service_time: 1054 s_time: 69 penalty: 0 agent_num: 43 done: False
______________________
Step:  1664
Pretraining Loss:  tensor(0.3031, device='cuda:0', grad_fn=<MeanBackward0>)
id: 43 reward: -0.09415584415584416 service_time: 587 s_time: 58 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: -0.044642857142857144 service_time: 570 s_time: 25 penalty: 0 agent_num: 10 done: False
______________________
id: 46 reward: 0.0 service_time: 620 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 44 reward: -0.015625 service_time: 666 s_time: 21 penalty: 0 agent_num: 24 done: False
______________________
id: 55 reward: -0.02564102564102564 service_time: 1286 s_time: 56 penalty: 0 agent_num: 39 done: False
______________________
id: 45 reward: 0.0 service_time: 854 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 42 reward: -0.023109243697478993 service_time: 862 s_time: 44 penalty: 0 agent_num: 34 done: False
______________________
id: 50 reward: 0.0 service_time: 1327 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 48 reward: 0.004568106312292359 service_time: 1160 s_time: -11 penalty: 0 agent_num: 43 done: False
______________________
id: 54 reward: -0.006157635467980296 service_time: 1558 s_time: 10 penalty: 0 agent_num: 29 done: False
______________________
id: 52 reward: 0.0004464285714285714 service_time: 857 s_time: -1 penalty: 0 agent_num: 40 done: False
______________________
id: 40 reward: -0.004790940766550522 service_time: 1082 s_time: 11 penalty: 0 agent_num: 41 done: False
______________________
id: 47 reward: -0.023166023166023165 service_time: 1260 s_time: 48 penalty: 0 agent_num: 37 done: False
______________________
id: 51 reward: 0.0 service_time: 1054 s_time: 0 penalty: 0 agent_num: 43 done: False
______________________
id: 41 reward: -0.01281055900621118 service_time: 1147 s_time: 33 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: -0.03192640692640693 service_time: 1207 s_time: 59 penalty: 0 agent_num: 33 done: False
______________________
Step:  1680
Pretraining Loss:  tensor(0.2888, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.033928571428571426 service_time: 589 s_time: 19 penalty: 0 agent_num: 10 done: False
______________________
id: 46 reward: 0.0 service_time: 620 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: 0.003246753246753247 service_time: 585 s_time: -2 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: 0.0 service_time: 666 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: -0.010714285714285714 service_time: 875 s_time: 21 penalty: 0 agent_num: 35 done: False
______________________
id: 50 reward: -0.02750965250965251 service_time: 1384 s_time: 57 penalty: 0 agent_num: 37 done: False
______________________
id: 40 reward: -0.013501742160278746 service_time: 1113 s_time: 31 penalty: 0 agent_num: 41 done: False
______________________
id: 51 reward: -0.024916943521594685 service_time: 1114 s_time: 60 penalty: 0 agent_num: 43 done: False
______________________
id: 48 reward: -0.004152823920265781 service_time: 1170 s_time: 10 penalty: 0 agent_num: 43 done: False
______________________
id: 41 reward: -0.0034937888198757765 service_time: 1156 s_time: 9 penalty: 0 agent_num: 46 done: False
______________________
id: 42 reward: -0.016281512605042018 service_time: 893 s_time: 31 penalty: 0 agent_num: 34 done: False
______________________
id: 55 reward: -0.015567765567765568 service_time: 1320 s_time: 34 penalty: 0 agent_num: 39 done: False
______________________
id: 53 reward: -0.03571428571428571 service_time: 1273 s_time: 66 penalty: 0 agent_num: 33 done: False
______________________
id: 54 reward: -0.012315270935960592 service_time: 1578 s_time: 20 penalty: 0 agent_num: 29 done: False
______________________
id: 52 reward: -0.0035714285714285713 service_time: 865 s_time: 8 penalty: 0 agent_num: 40 done: False
______________________
id: 47 reward: -0.015926640926640926 service_time: 1293 s_time: 33 penalty: 0 agent_num: 37 done: False
______________________
Step:  1696
Pretraining Loss:  tensor(0.2784, device='cuda:0', grad_fn=<MeanBackward0>)
id: 46 reward: 0.0 service_time: 620 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 49 reward: 0.0125 service_time: 582 s_time: -7 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: -0.05194805194805195 service_time: 617 s_time: 32 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: -0.033482142857142856 service_time: 711 s_time: 45 penalty: 0 agent_num: 24 done: False
______________________
id: 48 reward: -0.01287375415282392 service_time: 1201 s_time: 31 penalty: 0 agent_num: 43 done: False
______________________
id: 55 reward: -0.007326007326007326 service_time: 1336 s_time: 16 penalty: 0 agent_num: 39 done: False
______________________
id: 42 reward: 0.0 service_time: 893 s_time: 0 penalty: 0 agent_num: 34 done: False
______________________
id: 50 reward: -0.016409266409266408 service_time: 1418 s_time: 34 penalty: 0 agent_num: 37 done: False
______________________
id: 45 reward: -0.018367346938775512 service_time: 911 s_time: 36 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: -0.012315270935960592 service_time: 1598 s_time: 20 penalty: 0 agent_num: 29 done: False
______________________
id: 51 reward: -0.014119601328903655 service_time: 1148 s_time: 34 penalty: 0 agent_num: 43 done: False
______________________
id: 40 reward: -0.016986062717770034 service_time: 1152 s_time: 39 penalty: 0 agent_num: 41 done: False
______________________
id: 41 reward: -0.01048136645962733 service_time: 1183 s_time: 27 penalty: 0 agent_num: 46 done: False
______________________
id: 47 reward: 0.0 service_time: 1293 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: -0.0367965367965368 service_time: 1341 s_time: 68 penalty: 0 agent_num: 33 done: False
______________________
id: 52 reward: -0.0125 service_time: 893 s_time: 28 penalty: 0 agent_num: 40 done: False
______________________
Step:  1712
Pretraining Loss:  tensor(0.2693, device='cuda:0', grad_fn=<MeanBackward0>)
id: 46 reward: 0.0035714285714285713 service_time: 618 s_time: -2 penalty: 0 agent_num: 10 done: False
______________________
id: 49 reward: -0.04107142857142857 service_time: 605 s_time: 23 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: 0.0 service_time: 617 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: 0.0 service_time: 711 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: 0.0 service_time: 911 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.010382059800664452 service_time: 1226 s_time: 25 penalty: 0 agent_num: 43 done: False
______________________
id: 50 reward: 0.0009652509652509653 service_time: 1416 s_time: -2 penalty: 0 agent_num: 37 done: False
______________________
id: 42 reward: -0.028361344537815126 service_time: 947 s_time: 54 penalty: 0 agent_num: 34 done: False
______________________
id: 41 reward: -0.008152173913043478 service_time: 1204 s_time: 21 penalty: 0 agent_num: 46 done: False
______________________
id: 55 reward: -0.015567765567765568 service_time: 1370 s_time: 34 penalty: 0 agent_num: 39 done: False
______________________
id: 51 reward: -0.01079734219269103 service_time: 1174 s_time: 26 penalty: 0 agent_num: 43 done: False
______________________
id: 40 reward: 0.0013066202090592336 service_time: 1149 s_time: -3 penalty: 0 agent_num: 41 done: False
______________________
id: 54 reward: -0.020320197044334975 service_time: 1631 s_time: 33 penalty: 0 agent_num: 29 done: False
______________________
id: 52 reward: -0.006696428571428571 service_time: 908 s_time: 15 penalty: 0 agent_num: 40 done: False
______________________
id: 47 reward: -0.023166023166023165 service_time: 1341 s_time: 48 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: -0.012987012987012988 service_time: 1365 s_time: 24 penalty: 0 agent_num: 33 done: False
______________________
Step:  1728
Pretraining Loss:  tensor(0.2617, device='cuda:0', grad_fn=<MeanBackward0>)
id: 46 reward: -0.06428571428571428 service_time: 654 s_time: 36 penalty: 0 agent_num: 10 done: False
______________________
id: 49 reward: -0.05714285714285714 service_time: 637 s_time: 32 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: 0.0 service_time: 617 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: 0.0 service_time: 711 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 52 reward: -0.012946428571428572 service_time: 937 s_time: 29 penalty: 0 agent_num: 40 done: False
______________________
id: 48 reward: 0.0 service_time: 1226 s_time: 0 penalty: 0 agent_num: 43 done: False
______________________
id: 55 reward: -0.016483516483516484 service_time: 1406 s_time: 36 penalty: 0 agent_num: 39 done: False
______________________
id: 42 reward: -0.02415966386554622 service_time: 993 s_time: 46 penalty: 0 agent_num: 34 done: False
______________________
id: 54 reward: 0.0024630541871921183 service_time: 1627 s_time: -4 penalty: 0 agent_num: 29 done: False
______________________
id: 45 reward: -0.0163265306122449 service_time: 943 s_time: 32 penalty: 0 agent_num: 35 done: False
______________________
id: 40 reward: -0.018292682926829267 service_time: 1191 s_time: 42 penalty: 0 agent_num: 41 done: False
______________________
id: 51 reward: -0.012043189368770765 service_time: 1203 s_time: 29 penalty: 0 agent_num: 43 done: False
______________________
id: 41 reward: -0.008540372670807454 service_time: 1226 s_time: 22 penalty: 0 agent_num: 46 done: False
______________________
id: 50 reward: -0.033301158301158304 service_time: 1485 s_time: 69 penalty: 0 agent_num: 37 done: False
______________________
id: 47 reward: -0.026061776061776062 service_time: 1395 s_time: 54 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: -0.01406926406926407 service_time: 1391 s_time: 26 penalty: 0 agent_num: 33 done: False
______________________
Step:  1744
Pretraining Loss:  tensor(0.2549, device='cuda:0', grad_fn=<MeanBackward0>)
id: 46 reward: 0.0 service_time: 654 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: 0.0 service_time: 617 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: 0.0 service_time: 637 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 44 reward: -0.028273809523809524 service_time: 749 s_time: 38 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: 0.0 service_time: 943 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.02117940199335548 service_time: 1277 s_time: 51 penalty: 0 agent_num: 43 done: False
______________________
id: 40 reward: 0.0 service_time: 1191 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 55 reward: 0.0 service_time: 1406 s_time: 0 penalty: 0 agent_num: 39 done: False
______________________
id: 54 reward: -0.04433497536945813 service_time: 1699 s_time: 72 penalty: 0 agent_num: 29 done: False
______________________
id: 41 reward: -0.005046583850931677 service_time: 1239 s_time: 13 penalty: 0 agent_num: 46 done: False
______________________
id: 50 reward: -0.009652509652509652 service_time: 1505 s_time: 20 penalty: 0 agent_num: 37 done: False
______________________
id: 42 reward: -0.013130252100840336 service_time: 1018 s_time: 25 penalty: 0 agent_num: 34 done: False
______________________
id: 52 reward: -0.014732142857142857 service_time: 970 s_time: 33 penalty: 0 agent_num: 40 done: False
______________________
id: 51 reward: 0.0 service_time: 1203 s_time: 0 penalty: 0 agent_num: 43 done: False
______________________
id: 53 reward: 0.004329004329004329 service_time: 1383 s_time: -8 penalty: 0 agent_num: 33 done: False
______________________
id: 47 reward: -0.00916988416988417 service_time: 1414 s_time: 19 penalty: 0 agent_num: 37 done: False
______________________
Step:  1760
Pretraining Loss:  tensor(0.2773, device='cuda:0', grad_fn=<MeanBackward0>)
id: 43 reward: -0.056818181818181816 service_time: 652 s_time: 35 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: 0.0 service_time: 637 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 46 reward: -0.14821428571428572 service_time: 737 s_time: 83 penalty: 0 agent_num: 10 done: False
______________________
id: 44 reward: -0.017857142857142856 service_time: 773 s_time: 24 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: -0.008673469387755102 service_time: 960 s_time: 17 penalty: 0 agent_num: 35 done: False
______________________
id: 55 reward: -0.02197802197802198 service_time: 1454 s_time: 48 penalty: 0 agent_num: 39 done: False
______________________
id: 52 reward: -0.010267857142857143 service_time: 993 s_time: 23 penalty: 0 agent_num: 40 done: False
______________________
id: 42 reward: -0.008403361344537815 service_time: 1034 s_time: 16 penalty: 0 agent_num: 34 done: False
______________________
id: 48 reward: -0.018687707641196014 service_time: 1322 s_time: 45 penalty: 0 agent_num: 43 done: False
______________________
id: 54 reward: -0.02586206896551724 service_time: 1741 s_time: 42 penalty: 0 agent_num: 29 done: False
______________________
id: 41 reward: -0.011645962732919254 service_time: 1269 s_time: 30 penalty: 0 agent_num: 46 done: False
______________________
id: 40 reward: -0.013501742160278746 service_time: 1222 s_time: 31 penalty: 0 agent_num: 41 done: False
______________________
id: 50 reward: 0.0 service_time: 1505 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 51 reward: -0.010382059800664452 service_time: 1228 s_time: 25 penalty: 0 agent_num: 43 done: False
______________________
id: 47 reward: -0.006274131274131274 service_time: 1427 s_time: 13 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: -0.027597402597402596 service_time: 1434 s_time: 51 penalty: 0 agent_num: 33 done: False
______________________
Step:  1776
Pretraining Loss:  tensor(0.2526, device='cuda:0', grad_fn=<MeanBackward0>)
id: 43 reward: -0.025974025974025976 service_time: 668 s_time: 16 penalty: 0 agent_num: 11 done: False
______________________
id: 46 reward: -0.1 service_time: 793 s_time: 56 penalty: 0 agent_num: 10 done: False
______________________
id: 49 reward: -0.05892857142857143 service_time: 670 s_time: 33 penalty: 0 agent_num: 10 done: False
______________________
id: 44 reward: -0.002232142857142857 service_time: 776 s_time: 3 penalty: 0 agent_num: 24 done: False
______________________
id: 52 reward: 0.0008928571428571428 service_time: 991 s_time: -2 penalty: 0 agent_num: 40 done: False
______________________
id: 48 reward: -0.010382059800664452 service_time: 1347 s_time: 25 penalty: 0 agent_num: 43 done: False
______________________
id: 54 reward: 0.0 service_time: 1741 s_time: 0 penalty: 0 agent_num: 29 done: False
______________________
id: 41 reward: -0.01281055900621118 service_time: 1302 s_time: 33 penalty: 0 agent_num: 46 done: False
______________________
id: 51 reward: -0.01744186046511628 service_time: 1270 s_time: 42 penalty: 0 agent_num: 43 done: False
______________________
id: 55 reward: 0.0 service_time: 1454 s_time: 0 penalty: 0 agent_num: 39 done: False
______________________
id: 45 reward: -0.009693877551020408 service_time: 979 s_time: 19 penalty: 0 agent_num: 35 done: False
______________________
id: 50 reward: -0.019787644787644786 service_time: 1546 s_time: 41 penalty: 0 agent_num: 37 done: False
______________________
id: 40 reward: -0.018728222996515678 service_time: 1265 s_time: 43 penalty: 0 agent_num: 41 done: False
______________________
id: 42 reward: -0.0063025210084033615 service_time: 1046 s_time: 12 penalty: 0 agent_num: 34 done: False
______________________
id: 53 reward: -0.005952380952380952 service_time: 1445 s_time: 11 penalty: 0 agent_num: 33 done: False
______________________
id: 47 reward: -0.020752895752895753 service_time: 1470 s_time: 43 penalty: 0 agent_num: 37 done: False
______________________
Step:  1792
Pretraining Loss:  tensor(0.2431, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.026785714285714284 service_time: 655 s_time: -15 penalty: 0 agent_num: 10 done: False
______________________
id: 46 reward: 0.0 service_time: 793 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: 0.0 service_time: 668 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: 0.0 service_time: 776 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: -0.015306122448979591 service_time: 1009 s_time: 30 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: -0.03940886699507389 service_time: 1805 s_time: 64 penalty: 0 agent_num: 29 done: False
______________________
id: 55 reward: -0.004578754578754579 service_time: 1464 s_time: 10 penalty: 0 agent_num: 39 done: False
______________________
id: 50 reward: 0.00048262548262548264 service_time: 1545 s_time: -1 penalty: 0 agent_num: 37 done: False
______________________
id: 52 reward: 0.0 service_time: 991 s_time: 0 penalty: 0 agent_num: 40 done: False
______________________
id: 42 reward: -0.023634453781512604 service_time: 1091 s_time: 45 penalty: 0 agent_num: 34 done: False
______________________
id: 48 reward: 0.0 service_time: 1347 s_time: 0 penalty: 0 agent_num: 43 done: False
______________________
id: 51 reward: -0.01287375415282392 service_time: 1301 s_time: 31 penalty: 0 agent_num: 43 done: False
______________________
id: 40 reward: -0.013937282229965157 service_time: 1297 s_time: 32 penalty: 0 agent_num: 41 done: False
______________________
id: 41 reward: -0.014751552795031056 service_time: 1340 s_time: 38 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: 0.0021645021645021645 service_time: 1441 s_time: -4 penalty: 0 agent_num: 33 done: False
______________________
id: 47 reward: -0.017857142857142856 service_time: 1507 s_time: 37 penalty: 0 agent_num: 37 done: False
______________________
Step:  1808
Pretraining Loss:  tensor(0.2466, device='cuda:0', grad_fn=<MeanBackward0>)
id: 43 reward: 0.0 service_time: 668 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 46 reward: -0.0017857142857142857 service_time: 794 s_time: 1 penalty: 0 agent_num: 10 done: False
______________________
id: 49 reward: -0.04642857142857143 service_time: 681 s_time: 26 penalty: 0 agent_num: 10 done: False
______________________
id: 44 reward: -0.020089285714285716 service_time: 803 s_time: 27 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: -0.013775510204081633 service_time: 1036 s_time: 27 penalty: 0 agent_num: 35 done: False
______________________
id: 55 reward: -0.020604395604395604 service_time: 1509 s_time: 45 penalty: 0 agent_num: 39 done: False
______________________
id: 52 reward: -0.014285714285714285 service_time: 1023 s_time: 32 penalty: 0 agent_num: 40 done: False
______________________
id: 54 reward: -0.017857142857142856 service_time: 1834 s_time: 29 penalty: 0 agent_num: 29 done: False
______________________
id: 42 reward: -0.003676470588235294 service_time: 1098 s_time: 7 penalty: 0 agent_num: 34 done: False
______________________
id: 40 reward: -0.004355400696864111 service_time: 1307 s_time: 10 penalty: 0 agent_num: 41 done: False
______________________
id: 51 reward: 0.0 service_time: 1301 s_time: 0 penalty: 0 agent_num: 43 done: False
______________________
id: 48 reward: -0.020348837209302327 service_time: 1396 s_time: 49 penalty: 0 agent_num: 43 done: False
______________________
id: 41 reward: 0.0019409937888198758 service_time: 1335 s_time: -5 penalty: 0 agent_num: 46 done: False
______________________
id: 50 reward: -0.03523166023166023 service_time: 1618 s_time: 73 penalty: 0 agent_num: 37 done: False
______________________
id: 47 reward: -0.005791505791505791 service_time: 1519 s_time: 12 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: 0.0027056277056277055 service_time: 1436 s_time: -5 penalty: 0 agent_num: 33 done: False
______________________
Step:  1824
Pretraining Loss:  tensor(0.2302, device='cuda:0', grad_fn=<MeanBackward0>)
id: 43 reward: 0.03571428571428571 service_time: 646 s_time: -22 penalty: 0 agent_num: 11 done: False
______________________
id: 46 reward: 0.0 service_time: 794 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 49 reward: -0.04107142857142857 service_time: 704 s_time: 23 penalty: 0 agent_num: 10 done: False
______________________
id: 44 reward: -0.026041666666666668 service_time: 838 s_time: 35 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: -0.009693877551020408 service_time: 1055 s_time: 19 penalty: 0 agent_num: 35 done: False
______________________
id: 55 reward: -0.007783882783882784 service_time: 1526 s_time: 17 penalty: 0 agent_num: 39 done: False
______________________
id: 42 reward: -0.018907563025210083 service_time: 1134 s_time: 36 penalty: 0 agent_num: 34 done: False
______________________
id: 54 reward: 0.0006157635467980296 service_time: 1833 s_time: -1 penalty: 0 agent_num: 29 done: False
______________________
id: 53 reward: -0.027597402597402596 service_time: 1487 s_time: 51 penalty: 0 agent_num: 33 done: False
______________________
id: 50 reward: -0.010135135135135136 service_time: 1639 s_time: 21 penalty: 0 agent_num: 37 done: False
______________________
id: 40 reward: 0.003048780487804878 service_time: 1300 s_time: -7 penalty: 0 agent_num: 41 done: False
______________________
id: 48 reward: 0.0 service_time: 1396 s_time: 0 penalty: 0 agent_num: 43 done: False
______________________
id: 51 reward: -0.022840531561461794 service_time: 1356 s_time: 55 penalty: 0 agent_num: 43 done: False
______________________
id: 52 reward: 0.0 service_time: 1023 s_time: 0 penalty: 0 agent_num: 40 done: False
______________________
id: 41 reward: -0.01591614906832298 service_time: 1376 s_time: 41 penalty: 0 agent_num: 46 done: False
______________________
id: 47 reward: -0.011583011583011582 service_time: 1543 s_time: 24 penalty: 0 agent_num: 37 done: False
______________________
Step:  1840
Pretraining Loss:  tensor(0.2368, device='cuda:0', grad_fn=<MeanBackward0>)
id: 46 reward: 0.0 service_time: 794 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 49 reward: 0.0 service_time: 704 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: -0.05032467532467533 service_time: 677 s_time: 31 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: 0.000744047619047619 service_time: 837 s_time: -1 penalty: 0 agent_num: 24 done: False
______________________
id: 42 reward: -0.012605042016806723 service_time: 1158 s_time: 24 penalty: 0 agent_num: 34 done: False
______________________
id: 55 reward: -0.019688644688644688 service_time: 1569 s_time: 43 penalty: 0 agent_num: 39 done: False
______________________
id: 45 reward: -0.019387755102040816 service_time: 1093 s_time: 38 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.0049833887043189366 service_time: 1408 s_time: 12 penalty: 0 agent_num: 43 done: False
______________________
id: 54 reward: -0.04926108374384237 service_time: 1913 s_time: 80 penalty: 0 agent_num: 29 done: False
______________________
id: 51 reward: 0.0016611295681063123 service_time: 1352 s_time: -4 penalty: 0 agent_num: 43 done: False
______________________
id: 40 reward: -0.03571428571428571 service_time: 1382 s_time: 82 penalty: 0 agent_num: 41 done: False
______________________
id: 41 reward: -0.012422360248447204 service_time: 1408 s_time: 32 penalty: 0 agent_num: 46 done: False
______________________
id: 52 reward: -0.013392857142857142 service_time: 1053 s_time: 30 penalty: 0 agent_num: 40 done: False
______________________
id: 53 reward: -0.01948051948051948 service_time: 1523 s_time: 36 penalty: 0 agent_num: 33 done: False
______________________
id: 47 reward: -0.014961389961389961 service_time: 1574 s_time: 31 penalty: 0 agent_num: 37 done: False
______________________
id: 50 reward: -0.01833976833976834 service_time: 1677 s_time: 38 penalty: 0 agent_num: 37 done: False
______________________
Step:  1856
Pretraining Loss:  tensor(0.2434, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.0125 service_time: 697 s_time: -7 penalty: 0 agent_num: 10 done: False
______________________
id: 46 reward: 0.0 service_time: 794 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: -0.056818181818181816 service_time: 712 s_time: 35 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: -0.00818452380952381 service_time: 848 s_time: 11 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: -0.014285714285714285 service_time: 1121 s_time: 28 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: -0.017857142857142856 service_time: 1942 s_time: 29 penalty: 0 agent_num: 29 done: False
______________________
id: 40 reward: -0.0156794425087108 service_time: 1418 s_time: 36 penalty: 0 agent_num: 41 done: False
______________________
id: 55 reward: -0.011446886446886446 service_time: 1594 s_time: 25 penalty: 0 agent_num: 39 done: False
______________________
id: 51 reward: -0.00872093023255814 service_time: 1373 s_time: 21 penalty: 0 agent_num: 43 done: False
______________________
id: 48 reward: -0.008305647840531562 service_time: 1428 s_time: 20 penalty: 0 agent_num: 43 done: False
______________________
id: 53 reward: -0.01406926406926407 service_time: 1549 s_time: 26 penalty: 0 agent_num: 33 done: False
______________________
id: 42 reward: -0.025735294117647058 service_time: 1207 s_time: 49 penalty: 0 agent_num: 34 done: False
______________________
id: 41 reward: -0.0019409937888198758 service_time: 1413 s_time: 5 penalty: 0 agent_num: 46 done: False
______________________
id: 52 reward: -0.00625 service_time: 1067 s_time: 14 penalty: 0 agent_num: 40 done: False
______________________
id: 47 reward: 0.0 service_time: 1574 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 50 reward: -0.03426640926640927 service_time: 1748 s_time: 71 penalty: 0 agent_num: 37 done: False
______________________
Step:  1872
Pretraining Loss:  tensor(0.2477, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.0 service_time: 697 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: -0.05357142857142857 service_time: 745 s_time: 33 penalty: 0 agent_num: 11 done: False
______________________
id: 46 reward: -0.1392857142857143 service_time: 872 s_time: 78 penalty: 0 agent_num: 10 done: False
______________________
id: 44 reward: 0.0 service_time: 848 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 42 reward: -0.011554621848739496 service_time: 1229 s_time: 22 penalty: 0 agent_num: 34 done: False
______________________
id: 54 reward: -0.021551724137931036 service_time: 1977 s_time: 35 penalty: 0 agent_num: 29 done: False
______________________
id: 55 reward: -0.009157509157509158 service_time: 1614 s_time: 20 penalty: 0 agent_num: 39 done: False
______________________
id: 52 reward: -0.012053571428571429 service_time: 1094 s_time: 27 penalty: 0 agent_num: 40 done: False
______________________
id: 45 reward: -0.015816326530612244 service_time: 1152 s_time: 31 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.01744186046511628 service_time: 1470 s_time: 42 penalty: 0 agent_num: 43 done: False
______________________
id: 40 reward: -0.009581881533101045 service_time: 1440 s_time: 22 penalty: 0 agent_num: 41 done: False
______________________
id: 51 reward: -0.010382059800664452 service_time: 1398 s_time: 25 penalty: 0 agent_num: 43 done: False
______________________
id: 41 reward: -0.026785714285714284 service_time: 1482 s_time: 69 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: 0.0010822510822510823 service_time: 1547 s_time: -2 penalty: 0 agent_num: 33 done: False
______________________
id: 47 reward: -0.012548262548262547 service_time: 1600 s_time: 26 penalty: 0 agent_num: 37 done: False
______________________
id: 50 reward: -0.019305019305019305 service_time: 1788 s_time: 40 penalty: 0 agent_num: 37 done: False
______________________
Step:  1888
Pretraining Loss:  tensor(0.2440, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.039285714285714285 service_time: 719 s_time: 22 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: -0.07305194805194805 service_time: 790 s_time: 45 penalty: 0 agent_num: 11 done: False
______________________
id: 46 reward: -0.09642857142857143 service_time: 926 s_time: 54 penalty: 0 agent_num: 10 done: False
______________________
id: 44 reward: -0.019345238095238096 service_time: 874 s_time: 26 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: 0.0020408163265306124 service_time: 1148 s_time: -4 penalty: 0 agent_num: 35 done: False
______________________
id: 55 reward: 0.0009157509157509158 service_time: 1612 s_time: -2 penalty: 0 agent_num: 39 done: False
______________________
id: 52 reward: 0.0 service_time: 1094 s_time: 0 penalty: 0 agent_num: 40 done: False
______________________
id: 40 reward: -0.012630662020905924 service_time: 1469 s_time: 29 penalty: 0 agent_num: 41 done: False
______________________
id: 53 reward: -0.020562770562770564 service_time: 1585 s_time: 38 penalty: 0 agent_num: 33 done: False
______________________
id: 48 reward: 0.0008305647840531562 service_time: 1468 s_time: -2 penalty: 0 agent_num: 43 done: False
______________________
id: 51 reward: -0.005398671096345515 service_time: 1411 s_time: 13 penalty: 0 agent_num: 43 done: False
______________________
id: 54 reward: -0.01600985221674877 service_time: 2003 s_time: 26 penalty: 0 agent_num: 29 done: False
______________________
id: 41 reward: 0.0 service_time: 1482 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 42 reward: -0.011554621848739496 service_time: 1251 s_time: 22 penalty: 0 agent_num: 34 done: False
______________________
id: 47 reward: -0.02027027027027027 service_time: 1642 s_time: 42 penalty: 0 agent_num: 37 done: False
______________________
id: 50 reward: -0.017857142857142856 service_time: 1825 s_time: 37 penalty: 0 agent_num: 37 done: False
______________________
Step:  1904
Pretraining Loss:  tensor(0.2296, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.0 service_time: 719 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: -0.037337662337662336 service_time: 813 s_time: 23 penalty: 0 agent_num: 11 done: False
______________________
id: 46 reward: -0.16071428571428573 service_time: 1016 s_time: 90 penalty: 0 agent_num: 10 done: False
______________________
id: 44 reward: 0.0 service_time: 874 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: 0.0 service_time: 1148 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 42 reward: 0.0 service_time: 1251 s_time: 0 penalty: 0 agent_num: 34 done: False
______________________
id: 52 reward: -0.013839285714285714 service_time: 1125 s_time: 31 penalty: 0 agent_num: 40 done: False
______________________
id: 48 reward: -0.008305647840531562 service_time: 1488 s_time: 20 penalty: 0 agent_num: 43 done: False
______________________
id: 54 reward: -0.019704433497536946 service_time: 2035 s_time: 32 penalty: 0 agent_num: 29 done: False
______________________
id: 40 reward: -0.01524390243902439 service_time: 1504 s_time: 35 penalty: 0 agent_num: 41 done: False
______________________
id: 51 reward: -0.030730897009966777 service_time: 1485 s_time: 74 penalty: 0 agent_num: 43 done: False
______________________
id: 55 reward: -0.024725274725274724 service_time: 1666 s_time: 54 penalty: 0 agent_num: 39 done: False
______________________
id: 50 reward: -0.0222007722007722 service_time: 1871 s_time: 46 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: -0.035173160173160176 service_time: 1650 s_time: 65 penalty: 0 agent_num: 33 done: False
______________________
id: 47 reward: 0.0009652509652509653 service_time: 1640 s_time: -2 penalty: 0 agent_num: 37 done: False
______________________
id: 41 reward: -0.03454968944099379 service_time: 1571 s_time: 89 penalty: 0 agent_num: 46 done: False
______________________
Step:  1920
Pretraining Loss:  tensor(0.2586, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.0 service_time: 719 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: -0.08116883116883117 service_time: 863 s_time: 50 penalty: 0 agent_num: 11 done: False
______________________
id: 46 reward: 0.0 service_time: 1016 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 44 reward: -0.020089285714285716 service_time: 901 s_time: 27 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: -0.012755102040816327 service_time: 1173 s_time: 25 penalty: 0 agent_num: 35 done: False
______________________
id: 53 reward: -0.007575757575757576 service_time: 1664 s_time: 14 penalty: 0 agent_num: 33 done: False
______________________
id: 54 reward: 0.0024630541871921183 service_time: 2031 s_time: -4 penalty: 0 agent_num: 29 done: False
______________________
id: 48 reward: -0.004152823920265781 service_time: 1498 s_time: 10 penalty: 0 agent_num: 43 done: False
______________________
id: 55 reward: -0.00641025641025641 service_time: 1680 s_time: 14 penalty: 0 agent_num: 39 done: False
______________________
id: 42 reward: -0.03466386554621849 service_time: 1317 s_time: 66 penalty: 0 agent_num: 34 done: False
______________________
id: 51 reward: -0.014950166112956811 service_time: 1521 s_time: 36 penalty: 0 agent_num: 43 done: False
______________________
id: 41 reward: -0.005046583850931677 service_time: 1584 s_time: 13 penalty: 0 agent_num: 46 done: False
______________________
id: 40 reward: -0.023519163763066203 service_time: 1558 s_time: 54 penalty: 0 agent_num: 41 done: False
______________________
id: 52 reward: 0.0 service_time: 1125 s_time: 0 penalty: 0 agent_num: 40 done: False
______________________
id: 47 reward: -0.011583011583011582 service_time: 1664 s_time: 24 penalty: 0 agent_num: 37 done: False
______________________
id: 50 reward: -0.01833976833976834 service_time: 1909 s_time: 38 penalty: 0 agent_num: 37 done: False
______________________
Step:  1936
Pretraining Loss:  tensor(0.2421, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.14821428571428572 service_time: 802 s_time: 83 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: 0.0 service_time: 863 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 46 reward: 0.0 service_time: 1016 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 44 reward: -0.009672619047619048 service_time: 914 s_time: 13 penalty: 0 agent_num: 24 done: False
______________________
id: 54 reward: -0.027093596059113302 service_time: 2075 s_time: 44 penalty: 0 agent_num: 29 done: False
______________________
id: 40 reward: -0.010017421602787456 service_time: 1581 s_time: 23 penalty: 0 agent_num: 41 done: False
______________________
id: 45 reward: -0.010714285714285714 service_time: 1194 s_time: 21 penalty: 0 agent_num: 35 done: False
______________________
id: 55 reward: -0.009157509157509158 service_time: 1700 s_time: 20 penalty: 0 agent_num: 39 done: False
______________________
id: 42 reward: -0.0063025210084033615 service_time: 1329 s_time: 12 penalty: 0 agent_num: 34 done: False
______________________
id: 48 reward: -0.01287375415282392 service_time: 1529 s_time: 31 penalty: 0 agent_num: 43 done: False
______________________
id: 53 reward: -0.015692640692640692 service_time: 1693 s_time: 29 penalty: 0 agent_num: 33 done: False
______________________
id: 51 reward: 0.0 service_time: 1521 s_time: 0 penalty: 0 agent_num: 43 done: False
______________________
id: 52 reward: -0.012053571428571429 service_time: 1152 s_time: 27 penalty: 0 agent_num: 40 done: False
______________________
id: 41 reward: 0.0007763975155279503 service_time: 1582 s_time: -2 penalty: 0 agent_num: 46 done: False
______________________
id: 47 reward: -0.02364864864864865 service_time: 1713 s_time: 49 penalty: 0 agent_num: 37 done: False
______________________
id: 50 reward: -0.015926640926640926 service_time: 1942 s_time: 33 penalty: 0 agent_num: 37 done: False
______________________
Step:  1952
Pretraining Loss:  tensor(0.2659, device='cuda:0', grad_fn=<MeanBackward0>)
id: 43 reward: 0.0 service_time: 863 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: -0.03571428571428571 service_time: 822 s_time: 20 penalty: 0 agent_num: 10 done: False
______________________
id: 46 reward: 0.0 service_time: 1016 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 44 reward: -0.014136904761904762 service_time: 933 s_time: 19 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: 0.0 service_time: 1194 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 53 reward: -0.011904761904761904 service_time: 1715 s_time: 22 penalty: 0 agent_num: 33 done: False
______________________
id: 48 reward: -0.010382059800664452 service_time: 1554 s_time: 25 penalty: 0 agent_num: 43 done: False
______________________
id: 55 reward: -0.010073260073260074 service_time: 1722 s_time: 22 penalty: 0 agent_num: 39 done: False
______________________
id: 54 reward: 0.0012315270935960591 service_time: 2073 s_time: -2 penalty: 0 agent_num: 29 done: False
______________________
id: 40 reward: 0.0008710801393728223 service_time: 1579 s_time: -2 penalty: 0 agent_num: 41 done: False
______________________
id: 42 reward: -0.012605042016806723 service_time: 1353 s_time: 24 penalty: 0 agent_num: 34 done: False
______________________
id: 51 reward: -0.014534883720930232 service_time: 1556 s_time: 35 penalty: 0 agent_num: 43 done: False
______________________
id: 52 reward: -0.016964285714285713 service_time: 1190 s_time: 38 penalty: 0 agent_num: 40 done: False
______________________
id: 47 reward: -0.013996138996138996 service_time: 1742 s_time: 29 penalty: 0 agent_num: 37 done: False
______________________
id: 41 reward: -0.019409937888198756 service_time: 1632 s_time: 50 penalty: 0 agent_num: 46 done: False
______________________
id: 50 reward: -0.010617760617760617 service_time: 1964 s_time: 22 penalty: 0 agent_num: 37 done: False
______________________
Step:  1968
Pretraining Loss:  tensor(0.2534, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.0 service_time: 822 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: 0.0 service_time: 863 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 46 reward: 0.0 service_time: 1016 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 44 reward: 0.0 service_time: 933 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: -0.004591836734693878 service_time: 1203 s_time: 9 penalty: 0 agent_num: 35 done: False
______________________
id: 55 reward: 0.0 service_time: 1722 s_time: 0 penalty: 0 agent_num: 39 done: False
______________________
id: 42 reward: -0.01050420168067227 service_time: 1373 s_time: 20 penalty: 0 agent_num: 34 done: False
______________________
id: 54 reward: -0.033866995073891626 service_time: 2128 s_time: 55 penalty: 0 agent_num: 29 done: False
______________________
id: 40 reward: -0.03092334494773519 service_time: 1650 s_time: 71 penalty: 0 agent_num: 41 done: False
______________________
id: 52 reward: 0.0 service_time: 1190 s_time: 0 penalty: 0 agent_num: 40 done: False
______________________
id: 48 reward: -0.012458471760797342 service_time: 1584 s_time: 30 penalty: 0 agent_num: 43 done: False
______________________
id: 53 reward: -0.01948051948051948 service_time: 1751 s_time: 36 penalty: 0 agent_num: 33 done: False
______________________
id: 47 reward: -0.009652509652509652 service_time: 1762 s_time: 20 penalty: 0 agent_num: 37 done: False
______________________
id: 51 reward: -0.016196013289036543 service_time: 1595 s_time: 39 penalty: 0 agent_num: 43 done: False
______________________
id: 41 reward: -0.01281055900621118 service_time: 1665 s_time: 33 penalty: 0 agent_num: 46 done: False
______________________
id: 50 reward: -0.005791505791505791 service_time: 1976 s_time: 12 penalty: 0 agent_num: 37 done: False
______________________
Step:  1984
Pretraining Loss:  tensor(0.2754, device='cuda:0', grad_fn=<MeanBackward0>)
id: 43 reward: -0.032467532467532464 service_time: 883 s_time: 20 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: -0.15714285714285714 service_time: 910 s_time: 88 penalty: 0 agent_num: 10 done: False
______________________
id: 46 reward: 0.0 service_time: 1016 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 44 reward: -0.017857142857142856 service_time: 957 s_time: 24 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: -0.00816326530612245 service_time: 1219 s_time: 16 penalty: 0 agent_num: 35 done: False
______________________
id: 53 reward: -0.02002164502164502 service_time: 1788 s_time: 37 penalty: 0 agent_num: 33 done: False
______________________
id: 52 reward: -0.007589285714285714 service_time: 1207 s_time: 17 penalty: 0 agent_num: 40 done: False
______________________
id: 48 reward: -0.009551495016611296 service_time: 1607 s_time: 23 penalty: 0 agent_num: 43 done: False
______________________
id: 42 reward: -0.012605042016806723 service_time: 1397 s_time: 24 penalty: 0 agent_num: 34 done: False
______________________
id: 55 reward: -0.00641025641025641 service_time: 1736 s_time: 14 penalty: 0 agent_num: 39 done: False
______________________
id: 51 reward: 0.0 service_time: 1595 s_time: 0 penalty: 0 agent_num: 43 done: False
______________________
id: 54 reward: -0.05665024630541872 service_time: 2220 s_time: 92 penalty: 0 agent_num: 29 done: False
______________________
id: 47 reward: -0.010617760617760617 service_time: 1784 s_time: 22 penalty: 0 agent_num: 37 done: False
______________________
id: 41 reward: 0.0007763975155279503 service_time: 1663 s_time: -2 penalty: 0 agent_num: 46 done: False
______________________
id: 40 reward: -0.009581881533101045 service_time: 1672 s_time: 22 penalty: 0 agent_num: 41 done: False
______________________
id: 50 reward: -0.006756756756756757 service_time: 1990 s_time: 14 penalty: 0 agent_num: 37 done: False
______________________
Step:  2000
Pretraining Loss:  tensor(0.2624, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.0 service_time: 910 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: -0.12337662337662338 service_time: 959 s_time: 76 penalty: 0 agent_num: 11 done: False
______________________
id: 46 reward: -0.0625 service_time: 1051 s_time: 35 penalty: 0 agent_num: 10 done: False
______________________
id: 44 reward: -0.029017857142857144 service_time: 996 s_time: 39 penalty: 0 agent_num: 24 done: False
______________________
id: 48 reward: -0.0029069767441860465 service_time: 1614 s_time: 7 penalty: 0 agent_num: 43 done: False
______________________
id: 52 reward: 0.0 service_time: 1207 s_time: 0 penalty: 0 agent_num: 40 done: False
______________________
id: 42 reward: -0.0026260504201680674 service_time: 1402 s_time: 5 penalty: 0 agent_num: 34 done: False
______________________
id: 54 reward: 0.0012315270935960591 service_time: 2218 s_time: -2 penalty: 0 agent_num: 29 done: False
______________________
id: 55 reward: -0.013278388278388278 service_time: 1765 s_time: 29 penalty: 0 agent_num: 39 done: False
______________________
id: 45 reward: -0.017857142857142856 service_time: 1254 s_time: 35 penalty: 0 agent_num: 35 done: False
______________________
id: 47 reward: -0.019305019305019305 service_time: 1824 s_time: 40 penalty: 0 agent_num: 37 done: False
______________________
id: 51 reward: -0.01744186046511628 service_time: 1637 s_time: 42 penalty: 0 agent_num: 43 done: False
______________________
id: 53 reward: -0.02002164502164502 service_time: 1825 s_time: 37 penalty: 0 agent_num: 33 done: False
______________________
id: 40 reward: -0.0156794425087108 service_time: 1708 s_time: 36 penalty: 0 agent_num: 41 done: False
______________________
id: 50 reward: -0.022683397683397683 service_time: 2037 s_time: 47 penalty: 0 agent_num: 37 done: False
______________________
id: 41 reward: -0.013975155279503106 service_time: 1699 s_time: 36 penalty: 0 agent_num: 46 done: False
______________________
Step:  2016
Pretraining Loss:  tensor(0.2612, device='cuda:0', grad_fn=<MeanBackward0>)
id: 46 reward: 0.0 service_time: 1051 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 49 reward: 0.0 service_time: 910 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: 0.0 service_time: 959 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 54 reward: 0.006157635467980296 service_time: 2208 s_time: -10 penalty: 0 agent_num: 29 done: False
______________________
id: 48 reward: 0.0 service_time: 1614 s_time: 0 penalty: 0 agent_num: 43 done: False
______________________
id: 45 reward: 0.0 service_time: 1254 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 44 reward: 0.0 service_time: 996 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 52 reward: -0.005357142857142857 service_time: 1219 s_time: 12 penalty: 0 agent_num: 40 done: False
______________________
id: 55 reward: -0.020146520146520148 service_time: 1809 s_time: 44 penalty: 0 agent_num: 39 done: False
______________________
id: 42 reward: -0.027836134453781514 service_time: 1455 s_time: 53 penalty: 0 agent_num: 34 done: False
______________________
id: 53 reward: -0.02922077922077922 service_time: 1879 s_time: 54 penalty: 0 agent_num: 33 done: False
______________________
id: 47 reward: 0.00048262548262548264 service_time: 1823 s_time: -1 penalty: 0 agent_num: 37 done: False
______________________
id: 40 reward: 0.0 service_time: 1708 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 51 reward: -0.025332225913621262 service_time: 1698 s_time: 61 penalty: 0 agent_num: 43 done: False
______________________
id: 41 reward: -0.005434782608695652 service_time: 1713 s_time: 14 penalty: 0 agent_num: 46 done: False
______________________
id: 50 reward: -0.019305019305019305 service_time: 2077 s_time: 40 penalty: 0 agent_num: 37 done: False
______________________
Step:  2032
Pretraining Loss:  tensor(0.2436, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.0 service_time: 910 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 46 reward: 0.0 service_time: 1051 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: 0.0 service_time: 959 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: -0.020089285714285716 service_time: 1023 s_time: 27 penalty: 0 agent_num: 24 done: False
______________________
id: 54 reward: -0.01416256157635468 service_time: 2231 s_time: 23 penalty: 0 agent_num: 29 done: False
______________________
id: 48 reward: -0.006229235880398671 service_time: 1629 s_time: 15 penalty: 0 agent_num: 43 done: False
______________________
id: 52 reward: 0.0008928571428571428 service_time: 1217 s_time: -2 penalty: 0 agent_num: 40 done: False
______________________
id: 47 reward: -0.015926640926640926 service_time: 1856 s_time: 33 penalty: 0 agent_num: 37 done: False
______________________
id: 55 reward: 0.0 service_time: 1809 s_time: 0 penalty: 0 agent_num: 39 done: False
______________________
id: 42 reward: -0.013130252100840336 service_time: 1480 s_time: 25 penalty: 0 agent_num: 34 done: False
______________________
id: 51 reward: -0.010382059800664452 service_time: 1723 s_time: 25 penalty: 0 agent_num: 43 done: False
______________________
id: 53 reward: -0.01461038961038961 service_time: 1906 s_time: 27 penalty: 0 agent_num: 33 done: False
______________________
id: 45 reward: -0.02346938775510204 service_time: 1300 s_time: 46 penalty: 0 agent_num: 35 done: False
______________________
id: 40 reward: -0.03092334494773519 service_time: 1779 s_time: 71 penalty: 0 agent_num: 41 done: False
______________________
id: 50 reward: -0.008204633204633204 service_time: 2094 s_time: 17 penalty: 0 agent_num: 37 done: False
______________________
id: 41 reward: -0.013198757763975156 service_time: 1747 s_time: 34 penalty: 0 agent_num: 46 done: False
______________________
Step:  2048
Pretraining Loss:  tensor(0.2598, device='cuda:0', grad_fn=<MeanBackward0>)
id: 46 reward: 0.0 service_time: 1051 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 49 reward: 0.0 service_time: 910 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: -0.0698051948051948 service_time: 1002 s_time: 43 penalty: 0 agent_num: 11 done: False
______________________
id: 54 reward: -0.017241379310344827 service_time: 2259 s_time: 28 penalty: 0 agent_num: 29 done: False
______________________
id: 44 reward: -0.010416666666666666 service_time: 1037 s_time: 14 penalty: 0 agent_num: 24 done: False
______________________
id: 42 reward: -0.01680672268907563 service_time: 1512 s_time: 32 penalty: 0 agent_num: 34 done: False
______________________
id: 52 reward: 0.0 service_time: 1217 s_time: 0 penalty: 0 agent_num: 40 done: False
______________________
id: 45 reward: -0.015816326530612244 service_time: 1331 s_time: 31 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.013289036544850499 service_time: 1661 s_time: 32 penalty: 0 agent_num: 43 done: False
______________________
id: 47 reward: -0.010135135135135136 service_time: 1877 s_time: 21 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: -0.017857142857142856 service_time: 1939 s_time: 33 penalty: 0 agent_num: 33 done: False
______________________
id: 55 reward: -0.02564102564102564 service_time: 1865 s_time: 56 penalty: 0 agent_num: 39 done: False
______________________
id: 51 reward: -0.0049833887043189366 service_time: 1735 s_time: 12 penalty: 0 agent_num: 43 done: False
______________________
id: 41 reward: -0.008928571428571428 service_time: 1770 s_time: 23 penalty: 0 agent_num: 46 done: False
______________________
id: 50 reward: -0.019305019305019305 service_time: 2134 s_time: 40 penalty: 0 agent_num: 37 done: False
______________________
id: 40 reward: -0.006968641114982578 service_time: 1795 s_time: 16 penalty: 0 agent_num: 41 done: False
______________________
Step:  2064
Pretraining Loss:  tensor(0.2639, device='cuda:0', grad_fn=<MeanBackward0>)
id: 46 reward: 0.0 service_time: 1051 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 49 reward: -0.033928571428571426 service_time: 929 s_time: 19 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: 0.021103896103896104 service_time: 989 s_time: -13 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: -0.027529761904761904 service_time: 1074 s_time: 37 penalty: 0 agent_num: 24 done: False
______________________
id: 47 reward: -0.016891891891891893 service_time: 1912 s_time: 35 penalty: 0 agent_num: 37 done: False
______________________
id: 48 reward: -0.004568106312292359 service_time: 1672 s_time: 11 penalty: 0 agent_num: 43 done: False
______________________
id: 52 reward: -0.013392857142857142 service_time: 1247 s_time: 30 penalty: 0 agent_num: 40 done: False
______________________
id: 54 reward: 0.008004926108374385 service_time: 2246 s_time: -13 penalty: 0 agent_num: 29 done: False
______________________
id: 42 reward: 0.0010504201680672268 service_time: 1510 s_time: -2 penalty: 0 agent_num: 34 done: False
______________________
id: 55 reward: -0.020604395604395604 service_time: 1910 s_time: 45 penalty: 0 agent_num: 39 done: False
______________________
id: 45 reward: 0.0 service_time: 1331 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 50 reward: -0.02364864864864865 service_time: 2183 s_time: 49 penalty: 0 agent_num: 37 done: False
______________________
id: 40 reward: -0.006968641114982578 service_time: 1811 s_time: 16 penalty: 0 agent_num: 41 done: False
______________________
id: 53 reward: 0.0021645021645021645 service_time: 1935 s_time: -4 penalty: 0 agent_num: 33 done: False
______________________
id: 41 reward: -0.015139751552795032 service_time: 1809 s_time: 39 penalty: 0 agent_num: 46 done: False
______________________
id: 51 reward: -0.010382059800664452 service_time: 1760 s_time: 25 penalty: 0 agent_num: 43 done: False
______________________
Step:  2080
Pretraining Loss:  tensor(0.2505, device='cuda:0', grad_fn=<MeanBackward0>)
id: 46 reward: -0.1 service_time: 1107 s_time: 56 penalty: 0 agent_num: 10 done: False
______________________
id: 49 reward: -0.03571428571428571 service_time: 949 s_time: 20 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: -0.03896103896103896 service_time: 1013 s_time: 24 penalty: 0 agent_num: 11 done: False
______________________
id: 45 reward: -0.009183673469387756 service_time: 1349 s_time: 18 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: 0.0 service_time: 2246 s_time: 0 penalty: 0 agent_num: 29 done: False
______________________
id: 42 reward: -0.014705882352941176 service_time: 1538 s_time: 28 penalty: 0 agent_num: 34 done: False
______________________
id: 44 reward: 0.000744047619047619 service_time: 1073 s_time: -1 penalty: 0 agent_num: 24 done: False
______________________
id: 52 reward: -0.01875 service_time: 1289 s_time: 42 penalty: 0 agent_num: 40 done: False
______________________
id: 47 reward: -0.012548262548262547 service_time: 1938 s_time: 26 penalty: 0 agent_num: 37 done: False
______________________
id: 48 reward: -0.019933554817275746 service_time: 1720 s_time: 48 penalty: 0 agent_num: 43 done: False
______________________
id: 55 reward: -0.0173992673992674 service_time: 1948 s_time: 38 penalty: 0 agent_num: 39 done: False
______________________
id: 50 reward: -0.008204633204633204 service_time: 2200 s_time: 17 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: -0.040584415584415584 service_time: 2010 s_time: 75 penalty: 0 agent_num: 33 done: False
______________________
id: 51 reward: 0.0 service_time: 1760 s_time: 0 penalty: 0 agent_num: 43 done: False
______________________
id: 41 reward: -0.01125776397515528 service_time: 1838 s_time: 29 penalty: 0 agent_num: 46 done: False
______________________
id: 40 reward: 0.0 service_time: 1811 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
Step:  2096
Pretraining Loss:  tensor(0.2501, device='cuda:0', grad_fn=<MeanBackward0>)
id: 46 reward: -0.04107142857142857 service_time: 1130 s_time: 23 penalty: 0 agent_num: 10 done: False
______________________
id: 49 reward: -0.09464285714285714 service_time: 1002 s_time: 53 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: 0.012987012987012988 service_time: 1005 s_time: -8 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: -0.023065476190476192 service_time: 1104 s_time: 31 penalty: 0 agent_num: 24 done: False
______________________
id: 54 reward: -0.0166256157635468 service_time: 2273 s_time: 27 penalty: 0 agent_num: 29 done: False
______________________
id: 52 reward: 0.0 service_time: 1289 s_time: 0 penalty: 0 agent_num: 40 done: False
______________________
id: 45 reward: 0.0 service_time: 1349 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.0070598006644518275 service_time: 1737 s_time: 17 penalty: 0 agent_num: 43 done: False
______________________
id: 47 reward: 0.0 service_time: 1938 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 42 reward: -0.01365546218487395 service_time: 1564 s_time: 26 penalty: 0 agent_num: 34 done: False
______________________
id: 50 reward: -0.0009652509652509653 service_time: 2202 s_time: 2 penalty: 0 agent_num: 37 done: False
______________________
id: 41 reward: 0.0 service_time: 1838 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 55 reward: -0.007326007326007326 service_time: 1964 s_time: 16 penalty: 0 agent_num: 39 done: False
______________________
id: 40 reward: -0.016550522648083623 service_time: 1849 s_time: 38 penalty: 0 agent_num: 41 done: False
______________________
id: 51 reward: -0.010382059800664452 service_time: 1785 s_time: 25 penalty: 0 agent_num: 43 done: False
______________________
id: 53 reward: -0.012445887445887446 service_time: 2033 s_time: 23 penalty: 0 agent_num: 33 done: False
______________________
Step:  2112
Pretraining Loss:  tensor(0.2400, device='cuda:0', grad_fn=<MeanBackward0>)
id: 46 reward: 0.0 service_time: 1130 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 49 reward: -0.03214285714285714 service_time: 1020 s_time: 18 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: 0.0 service_time: 1005 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: 0.0 service_time: 1104 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 42 reward: 0.0 service_time: 1564 s_time: 0 penalty: 0 agent_num: 34 done: False
______________________
id: 47 reward: -0.013996138996138996 service_time: 1967 s_time: 29 penalty: 0 agent_num: 37 done: False
______________________
id: 52 reward: 0.0017857142857142857 service_time: 1285 s_time: -4 penalty: 0 agent_num: 40 done: False
______________________
id: 45 reward: -0.01989795918367347 service_time: 1388 s_time: 39 penalty: 0 agent_num: 35 done: False
______________________
id: 53 reward: -0.005411255411255411 service_time: 2043 s_time: 10 penalty: 0 agent_num: 33 done: False
______________________
id: 51 reward: -0.011212624584717609 service_time: 1812 s_time: 27 penalty: 0 agent_num: 43 done: False
______________________
id: 48 reward: -0.006229235880398671 service_time: 1752 s_time: 15 penalty: 0 agent_num: 43 done: False
______________________
id: 50 reward: -0.037644787644787646 service_time: 2280 s_time: 78 penalty: 0 agent_num: 37 done: False
______________________
id: 55 reward: -0.011446886446886446 service_time: 1989 s_time: 25 penalty: 0 agent_num: 39 done: False
______________________
id: 54 reward: -0.022783251231527094 service_time: 2310 s_time: 37 penalty: 0 agent_num: 29 done: False
______________________
id: 40 reward: -0.012195121951219513 service_time: 1877 s_time: 28 penalty: 0 agent_num: 41 done: False
______________________
id: 41 reward: -0.029891304347826088 service_time: 1915 s_time: 77 penalty: 0 agent_num: 46 done: False
______________________
Step:  2128
Pretraining Loss:  tensor(0.2310, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.0 service_time: 1020 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 46 reward: 0.0 service_time: 1130 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: -0.0633116883116883 service_time: 1044 s_time: 39 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: -0.017857142857142856 service_time: 1128 s_time: 24 penalty: 0 agent_num: 24 done: False
______________________
id: 42 reward: -0.02153361344537815 service_time: 1605 s_time: 41 penalty: 0 agent_num: 34 done: False
______________________
id: 45 reward: 0.001530612244897959 service_time: 1385 s_time: -3 penalty: 0 agent_num: 35 done: False
______________________
id: 52 reward: -0.009375 service_time: 1306 s_time: 21 penalty: 0 agent_num: 40 done: False
______________________
id: 48 reward: -0.015780730897009966 service_time: 1790 s_time: 38 penalty: 0 agent_num: 43 done: False
______________________
id: 55 reward: -0.0173992673992674 service_time: 2027 s_time: 38 penalty: 0 agent_num: 39 done: False
______________________
id: 47 reward: -0.017374517374517374 service_time: 2003 s_time: 36 penalty: 0 agent_num: 37 done: False
______________________
id: 51 reward: -0.007890365448504983 service_time: 1831 s_time: 19 penalty: 0 agent_num: 43 done: False
______________________
id: 40 reward: 0.00043554006968641115 service_time: 1876 s_time: -1 penalty: 0 agent_num: 41 done: False
______________________
id: 54 reward: 0.0 service_time: 2310 s_time: 0 penalty: 0 agent_num: 29 done: False
______________________
id: 50 reward: -0.02413127413127413 service_time: 2330 s_time: 50 penalty: 0 agent_num: 37 done: False
______________________
id: 41 reward: -0.009316770186335404 service_time: 1939 s_time: 24 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: -0.007034632034632035 service_time: 2056 s_time: 13 penalty: 0 agent_num: 33 done: False
______________________
Step:  2144
Pretraining Loss:  tensor(0.2138, device='cuda:0', grad_fn=<MeanBackward0>)
id: 46 reward: -0.05357142857142857 service_time: 1160 s_time: 30 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: 0.0 service_time: 1044 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: 0.0 service_time: 1020 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 44 reward: 0.0 service_time: 1128 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: -0.01479591836734694 service_time: 1414 s_time: 29 penalty: 0 agent_num: 35 done: False
______________________
id: 42 reward: -0.017331932773109245 service_time: 1638 s_time: 33 penalty: 0 agent_num: 34 done: False
______________________
id: 48 reward: -0.006644518272425249 service_time: 1806 s_time: 16 penalty: 0 agent_num: 43 done: False
______________________
id: 55 reward: -0.010531135531135532 service_time: 2050 s_time: 23 penalty: 0 agent_num: 39 done: False
______________________
id: 51 reward: -0.005813953488372093 service_time: 1845 s_time: 14 penalty: 0 agent_num: 43 done: False
______________________
id: 47 reward: -0.02027027027027027 service_time: 2045 s_time: 42 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: -0.017316017316017316 service_time: 2088 s_time: 32 penalty: 0 agent_num: 33 done: False
______________________
id: 40 reward: -0.010017421602787456 service_time: 1899 s_time: 23 penalty: 0 agent_num: 41 done: False
______________________
id: 52 reward: -0.005357142857142857 service_time: 1318 s_time: 12 penalty: 0 agent_num: 40 done: False
______________________
id: 41 reward: -0.006211180124223602 service_time: 1955 s_time: 16 penalty: 0 agent_num: 46 done: False
______________________
id: 50 reward: -0.0028957528957528956 service_time: 2336 s_time: 6 penalty: 0 agent_num: 37 done: False
______________________
id: 54 reward: -0.023399014778325122 service_time: 2348 s_time: 38 penalty: 0 agent_num: 29 done: False
______________________
Step:  2160
Pretraining Loss:  tensor(0.2190, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.13392857142857142 service_time: 1095 s_time: 75 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: 0.0 service_time: 1044 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 46 reward: 0.0 service_time: 1160 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 44 reward: -0.017857142857142856 service_time: 1152 s_time: 24 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: 0.0 service_time: 1414 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 42 reward: -0.017857142857142856 service_time: 1672 s_time: 34 penalty: 0 agent_num: 34 done: False
______________________
id: 48 reward: 0.0 service_time: 1806 s_time: 0 penalty: 0 agent_num: 43 done: False
______________________
id: 53 reward: -0.005411255411255411 service_time: 2098 s_time: 10 penalty: 0 agent_num: 33 done: False
______________________
id: 40 reward: -0.01524390243902439 service_time: 1934 s_time: 35 penalty: 0 agent_num: 41 done: False
______________________
id: 47 reward: -0.00916988416988417 service_time: 2064 s_time: 19 penalty: 0 agent_num: 37 done: False
______________________
id: 54 reward: -0.13669950738916256 service_time: 2570 s_time: 222 penalty: 0 agent_num: 29 done: False
______________________
id: 51 reward: -0.00872093023255814 service_time: 1866 s_time: 21 penalty: 0 agent_num: 43 done: False
______________________
id: 52 reward: -0.01830357142857143 service_time: 1359 s_time: 41 penalty: 0 agent_num: 40 done: False
______________________
id: 41 reward: -0.013198757763975156 service_time: 1989 s_time: 34 penalty: 0 agent_num: 46 done: False
______________________
id: 55 reward: -0.01282051282051282 service_time: 2078 s_time: 28 penalty: 0 agent_num: 39 done: False
______________________
id: 50 reward: -0.016409266409266408 service_time: 2370 s_time: 34 penalty: 0 agent_num: 37 done: False
______________________
Step:  2176
Pretraining Loss:  tensor(0.2372, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.0 service_time: 1095 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: 0.0 service_time: 1044 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 46 reward: -0.025 service_time: 1174 s_time: 14 penalty: 0 agent_num: 10 done: False
______________________
id: 44 reward: 0.0 service_time: 1152 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: -0.012755102040816327 service_time: 1439 s_time: 25 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.012458471760797342 service_time: 1836 s_time: 30 penalty: 0 agent_num: 43 done: False
______________________
id: 47 reward: -0.00723938223938224 service_time: 2079 s_time: 15 penalty: 0 agent_num: 37 done: False
______________________
id: 42 reward: -0.022058823529411766 service_time: 1714 s_time: 42 penalty: 0 agent_num: 34 done: False
______________________
id: 51 reward: -0.0070598006644518275 service_time: 1883 s_time: 17 penalty: 0 agent_num: 43 done: False
______________________
id: 52 reward: -0.01607142857142857 service_time: 1395 s_time: 36 penalty: 0 agent_num: 40 done: False
______________________
id: 53 reward: -0.026515151515151516 service_time: 2147 s_time: 49 penalty: 0 agent_num: 33 done: False
______________________
id: 41 reward: -0.010093167701863354 service_time: 2015 s_time: 26 penalty: 0 agent_num: 46 done: False
______________________
id: 40 reward: 0.0008710801393728223 service_time: 1932 s_time: -2 penalty: 0 agent_num: 41 done: False
______________________
id: 55 reward: 0.0009157509157509158 service_time: 2076 s_time: -2 penalty: 0 agent_num: 39 done: False
______________________
id: 54 reward: 0.029556650246305417 service_time: 2522 s_time: -48 penalty: 0 agent_num: 29 done: False
______________________
id: 50 reward: -0.025096525096525095 service_time: 2422 s_time: 52 penalty: 0 agent_num: 37 done: False
______________________
Step:  2192
Pretraining Loss:  tensor(0.2410, device='cuda:0', grad_fn=<MeanBackward0>)
id: 43 reward: 0.0 service_time: 1044 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: 0.0 service_time: 1095 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 46 reward: 0.0 service_time: 1174 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 45 reward: -0.019387755102040816 service_time: 1477 s_time: 38 penalty: 0 agent_num: 35 done: False
______________________
id: 44 reward: -0.03125 service_time: 1194 s_time: 42 penalty: 0 agent_num: 24 done: False
______________________
id: 53 reward: -0.02002164502164502 service_time: 2184 s_time: 37 penalty: 0 agent_num: 33 done: False
______________________
id: 48 reward: -0.0029069767441860465 service_time: 1843 s_time: 7 penalty: 0 agent_num: 43 done: False
______________________
id: 52 reward: 0.0 service_time: 1395 s_time: 0 penalty: 0 agent_num: 40 done: False
______________________
id: 51 reward: -0.006644518272425249 service_time: 1899 s_time: 16 penalty: 0 agent_num: 43 done: False
______________________
id: 42 reward: -0.01523109243697479 service_time: 1743 s_time: 29 penalty: 0 agent_num: 34 done: False
______________________
id: 40 reward: -0.010017421602787456 service_time: 1955 s_time: 23 penalty: 0 agent_num: 41 done: False
______________________
id: 47 reward: -0.017374517374517374 service_time: 2115 s_time: 36 penalty: 0 agent_num: 37 done: False
______________________
id: 41 reward: -0.0019409937888198758 service_time: 2020 s_time: 5 penalty: 0 agent_num: 46 done: False
______________________
id: 55 reward: -0.037545787545787544 service_time: 2158 s_time: 82 penalty: 0 agent_num: 39 done: False
______________________
id: 50 reward: -0.032335907335907334 service_time: 2489 s_time: 67 penalty: 0 agent_num: 37 done: False
______________________
id: 54 reward: -0.021551724137931036 service_time: 2557 s_time: 35 penalty: 0 agent_num: 29 done: False
______________________
Step:  2208
Pretraining Loss:  tensor(0.2411, device='cuda:0', grad_fn=<MeanBackward0>)
id: 43 reward: 0.0 service_time: 1044 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: 0.0 service_time: 1095 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 46 reward: -0.06964285714285715 service_time: 1213 s_time: 39 penalty: 0 agent_num: 10 done: False
______________________
id: 45 reward: 0.0035714285714285713 service_time: 1470 s_time: -7 penalty: 0 agent_num: 35 done: False
______________________
id: 44 reward: -0.01711309523809524 service_time: 1217 s_time: 23 penalty: 0 agent_num: 24 done: False
______________________
id: 47 reward: -0.024613899613899613 service_time: 2166 s_time: 51 penalty: 0 agent_num: 37 done: False
______________________
id: 51 reward: -0.009551495016611296 service_time: 1922 s_time: 23 penalty: 0 agent_num: 43 done: False
______________________
id: 48 reward: -0.01079734219269103 service_time: 1869 s_time: 26 penalty: 0 agent_num: 43 done: False
______________________
id: 52 reward: -0.007589285714285714 service_time: 1412 s_time: 17 penalty: 0 agent_num: 40 done: False
______________________
id: 42 reward: -0.009978991596638655 service_time: 1762 s_time: 19 penalty: 0 agent_num: 34 done: False
______________________
id: 41 reward: -0.01281055900621118 service_time: 2053 s_time: 33 penalty: 0 agent_num: 46 done: False
______________________
id: 55 reward: -0.004120879120879121 service_time: 2167 s_time: 9 penalty: 0 agent_num: 39 done: False
______________________
id: 53 reward: -0.01948051948051948 service_time: 2220 s_time: 36 penalty: 0 agent_num: 33 done: False
______________________
id: 54 reward: -0.020935960591133004 service_time: 2591 s_time: 34 penalty: 0 agent_num: 29 done: False
______________________
id: 40 reward: -0.036585365853658534 service_time: 2039 s_time: 84 penalty: 0 agent_num: 41 done: False
______________________
id: 50 reward: -0.0111003861003861 service_time: 2512 s_time: 23 penalty: 0 agent_num: 37 done: False
______________________
Step:  2224
Pretraining Loss:  tensor(0.2343, device='cuda:0', grad_fn=<MeanBackward0>)
id: 43 reward: 0.0 service_time: 1044 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 46 reward: 0.0 service_time: 1213 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 49 reward: 0.0 service_time: 1095 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 44 reward: -0.01488095238095238 service_time: 1237 s_time: 20 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: -0.01989795918367347 service_time: 1509 s_time: 39 penalty: 0 agent_num: 35 done: False
______________________
id: 53 reward: -0.016233766233766232 service_time: 2250 s_time: 30 penalty: 0 agent_num: 33 done: False
______________________
id: 54 reward: 0.0 service_time: 2591 s_time: 0 penalty: 0 agent_num: 29 done: False
______________________
id: 48 reward: -0.007890365448504983 service_time: 1888 s_time: 19 penalty: 0 agent_num: 43 done: False
______________________
id: 52 reward: 0.0 service_time: 1412 s_time: 0 penalty: 0 agent_num: 40 done: False
______________________
id: 51 reward: 0.0 service_time: 1922 s_time: 0 penalty: 0 agent_num: 43 done: False
______________________
id: 47 reward: -0.005308880308880309 service_time: 2177 s_time: 11 penalty: 0 agent_num: 37 done: False
______________________
id: 55 reward: -0.01282051282051282 service_time: 2195 s_time: 28 penalty: 0 agent_num: 39 done: False
______________________
id: 42 reward: 0.0005252100840336134 service_time: 1761 s_time: -1 penalty: 0 agent_num: 34 done: False
______________________
id: 41 reward: 0.0 service_time: 2053 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 40 reward: -0.009581881533101045 service_time: 2061 s_time: 22 penalty: 0 agent_num: 41 done: False
______________________
id: 50 reward: -0.013513513513513514 service_time: 2540 s_time: 28 penalty: 0 agent_num: 37 done: False
______________________
Step:  2240
Pretraining Loss:  tensor(0.2323, device='cuda:0', grad_fn=<MeanBackward0>)
id: 46 reward: 0.0 service_time: 1213 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 49 reward: 0.0 service_time: 1095 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: -0.09740259740259741 service_time: 1104 s_time: 60 penalty: 0 agent_num: 11 done: False
______________________
id: 45 reward: -0.01683673469387755 service_time: 1542 s_time: 33 penalty: 0 agent_num: 35 done: False
______________________
id: 47 reward: -0.0111003861003861 service_time: 2200 s_time: 23 penalty: 0 agent_num: 37 done: False
______________________
id: 51 reward: -0.014950166112956811 service_time: 1958 s_time: 36 penalty: 0 agent_num: 43 done: False
______________________
id: 42 reward: -0.0063025210084033615 service_time: 1773 s_time: 12 penalty: 0 agent_num: 34 done: False
______________________
id: 52 reward: -0.008928571428571428 service_time: 1432 s_time: 20 penalty: 0 agent_num: 40 done: False
______________________
id: 55 reward: -0.01510989010989011 service_time: 2228 s_time: 33 penalty: 0 agent_num: 39 done: False
______________________
id: 48 reward: -0.005398671096345515 service_time: 1901 s_time: 13 penalty: 0 agent_num: 43 done: False
______________________
id: 53 reward: -0.015151515151515152 service_time: 2278 s_time: 28 penalty: 0 agent_num: 33 done: False
______________________
id: 44 reward: 0.001488095238095238 service_time: 1235 s_time: -2 penalty: 0 agent_num: 24 done: False
______________________
id: 41 reward: -0.012422360248447204 service_time: 2085 s_time: 32 penalty: 0 agent_num: 46 done: False
______________________
id: 54 reward: 0.029556650246305417 service_time: 2543 s_time: -48 penalty: 0 agent_num: 29 done: False
______________________
id: 40 reward: 0.0013066202090592336 service_time: 2058 s_time: -3 penalty: 0 agent_num: 41 done: False
______________________
id: 50 reward: 0.0 service_time: 2540 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
Step:  2256
Pretraining Loss:  tensor(0.2425, device='cuda:0', grad_fn=<MeanBackward0>)
id: 46 reward: -0.04107142857142857 service_time: 1236 s_time: 23 penalty: 0 agent_num: 10 done: False
______________________
id: 49 reward: -0.16964285714285715 service_time: 1190 s_time: 95 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: -0.01948051948051948 service_time: 1116 s_time: 12 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: -0.008928571428571428 service_time: 1247 s_time: 12 penalty: 0 agent_num: 24 done: False
______________________
id: 53 reward: -0.017316017316017316 service_time: 2310 s_time: 32 penalty: 0 agent_num: 33 done: False
______________________
id: 48 reward: 0.0 service_time: 1901 s_time: 0 penalty: 0 agent_num: 43 done: False
______________________
id: 45 reward: 0.0 service_time: 1542 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 52 reward: -0.013392857142857142 service_time: 1462 s_time: 30 penalty: 0 agent_num: 40 done: False
______________________
id: 42 reward: -0.03308823529411765 service_time: 1836 s_time: 63 penalty: 0 agent_num: 34 done: False
______________________
id: 51 reward: -0.016611295681063124 service_time: 1998 s_time: 40 penalty: 0 agent_num: 43 done: False
______________________
id: 40 reward: -0.017857142857142856 service_time: 2099 s_time: 41 penalty: 0 agent_num: 41 done: False
______________________
id: 55 reward: 0.0 service_time: 2228 s_time: 0 penalty: 0 agent_num: 39 done: False
______________________
id: 54 reward: -0.0480295566502463 service_time: 2621 s_time: 78 penalty: 0 agent_num: 29 done: False
______________________
id: 47 reward: -0.008687258687258687 service_time: 2218 s_time: 18 penalty: 0 agent_num: 37 done: False
______________________
id: 41 reward: -0.019021739130434784 service_time: 2134 s_time: 49 penalty: 0 agent_num: 46 done: False
______________________
id: 50 reward: -0.017857142857142856 service_time: 2577 s_time: 37 penalty: 0 agent_num: 37 done: False
______________________
Step:  2272
Pretraining Loss:  tensor(0.2415, device='cuda:0', grad_fn=<MeanBackward0>)
id: 46 reward: -0.06785714285714285 service_time: 1274 s_time: 38 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: -0.13474025974025974 service_time: 1199 s_time: 83 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: 0.0 service_time: 1190 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 44 reward: 0.0 service_time: 1247 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 47 reward: 0.0 service_time: 2218 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 45 reward: -0.009183673469387756 service_time: 1560 s_time: 18 penalty: 0 agent_num: 35 done: False
______________________
id: 42 reward: -0.011029411764705883 service_time: 1857 s_time: 21 penalty: 0 agent_num: 34 done: False
______________________
id: 52 reward: 0.0 service_time: 1462 s_time: 0 penalty: 0 agent_num: 40 done: False
______________________
id: 48 reward: -0.0170265780730897 service_time: 1942 s_time: 41 penalty: 0 agent_num: 43 done: False
______________________
id: 55 reward: -0.03021978021978022 service_time: 2294 s_time: 66 penalty: 0 agent_num: 39 done: False
______________________
id: 51 reward: 0.0 service_time: 1998 s_time: 0 penalty: 0 agent_num: 43 done: False
______________________
id: 41 reward: 0.0015527950310559005 service_time: 2130 s_time: -4 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: -0.02867965367965368 service_time: 2363 s_time: 53 penalty: 0 agent_num: 33 done: False
______________________
id: 40 reward: -0.031794425087108016 service_time: 2172 s_time: 73 penalty: 0 agent_num: 41 done: False
______________________
id: 50 reward: -0.02364864864864865 service_time: 2626 s_time: 49 penalty: 0 agent_num: 37 done: False
______________________
id: 54 reward: -0.02770935960591133 service_time: 2666 s_time: 45 penalty: 0 agent_num: 29 done: False
______________________
Step:  2288
Pretraining Loss:  tensor(0.2328, device='cuda:0', grad_fn=<MeanBackward0>)
id: 46 reward: -0.02857142857142857 service_time: 1290 s_time: 16 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: 0.0 service_time: 1199 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: 0.039285714285714285 service_time: 1168 s_time: -22 penalty: 0 agent_num: 10 done: False
______________________
id: 44 reward: -0.009672619047619048 service_time: 1260 s_time: 13 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: -0.01173469387755102 service_time: 1583 s_time: 23 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.0024916943521594683 service_time: 1948 s_time: 6 penalty: 0 agent_num: 43 done: False
______________________
id: 42 reward: -0.012605042016806723 service_time: 1881 s_time: 24 penalty: 0 agent_num: 34 done: False
______________________
id: 55 reward: 0.0 service_time: 2294 s_time: 0 penalty: 0 agent_num: 39 done: False
______________________
id: 40 reward: 0.0 service_time: 2172 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 47 reward: -0.03137065637065637 service_time: 2283 s_time: 65 penalty: 0 agent_num: 37 done: False
______________________
id: 51 reward: -0.003737541528239203 service_time: 2007 s_time: 9 penalty: 0 agent_num: 43 done: False
______________________
id: 54 reward: -0.04556650246305419 service_time: 2740 s_time: 74 penalty: 0 agent_num: 29 done: False
______________________
id: 52 reward: -0.009821428571428571 service_time: 1484 s_time: 22 penalty: 0 agent_num: 40 done: False
______________________
id: 41 reward: -0.010093167701863354 service_time: 2156 s_time: 26 penalty: 0 agent_num: 46 done: False
______________________
id: 50 reward: -0.005308880308880309 service_time: 2637 s_time: 11 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: -0.0021645021645021645 service_time: 2367 s_time: 4 penalty: 0 agent_num: 33 done: False
______________________
Step:  2304
Pretraining Loss:  tensor(0.2446, device='cuda:0', grad_fn=<MeanBackward0>)
id: 43 reward: -0.11201298701298701 service_time: 1268 s_time: 69 penalty: 0 agent_num: 11 done: False
______________________
id: 46 reward: 0.033928571428571426 service_time: 1271 s_time: -19 penalty: 0 agent_num: 10 done: False
______________________
id: 49 reward: 0.023214285714285715 service_time: 1155 s_time: -13 penalty: 0 agent_num: 10 done: False
______________________
id: 44 reward: -0.018601190476190476 service_time: 1285 s_time: 25 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: -0.0066326530612244895 service_time: 1596 s_time: 13 penalty: 0 agent_num: 35 done: False
______________________
id: 47 reward: 0.00048262548262548264 service_time: 2282 s_time: -1 penalty: 0 agent_num: 37 done: False
______________________
id: 42 reward: -0.005777310924369748 service_time: 1892 s_time: 11 penalty: 0 agent_num: 34 done: False
______________________
id: 52 reward: -0.010714285714285714 service_time: 1508 s_time: 24 penalty: 0 agent_num: 40 done: False
______________________
id: 48 reward: -0.0170265780730897 service_time: 1989 s_time: 41 penalty: 0 agent_num: 43 done: False
______________________
id: 51 reward: -0.025332225913621262 service_time: 2068 s_time: 61 penalty: 0 agent_num: 43 done: False
______________________
id: 55 reward: -0.027472527472527472 service_time: 2354 s_time: 60 penalty: 0 agent_num: 39 done: False
______________________
id: 41 reward: -0.01125776397515528 service_time: 2185 s_time: 29 penalty: 0 agent_num: 46 done: False
______________________
id: 40 reward: -0.028745644599303136 service_time: 2238 s_time: 66 penalty: 0 agent_num: 41 done: False
______________________
id: 50 reward: -0.010135135135135136 service_time: 2658 s_time: 21 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: -0.04112554112554113 service_time: 2443 s_time: 76 penalty: 0 agent_num: 33 done: False
______________________
id: 54 reward: 0.0006157635467980296 service_time: 2739 s_time: -1 penalty: 0 agent_num: 29 done: False
______________________
Step:  2320
Pretraining Loss:  tensor(0.2460, device='cuda:0', grad_fn=<MeanBackward0>)
id: 43 reward: 0.0 service_time: 1268 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: -0.04107142857142857 service_time: 1178 s_time: 23 penalty: 0 agent_num: 10 done: False
______________________
id: 46 reward: 0.0 service_time: 1271 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 44 reward: -0.008928571428571428 service_time: 1297 s_time: 12 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: -0.013265306122448979 service_time: 1622 s_time: 26 penalty: 0 agent_num: 35 done: False
______________________
id: 40 reward: 0.0 service_time: 2238 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 48 reward: -0.01079734219269103 service_time: 2015 s_time: 26 penalty: 0 agent_num: 43 done: False
______________________
id: 47 reward: -0.025096525096525095 service_time: 2334 s_time: 52 penalty: 0 agent_num: 37 done: False
______________________
id: 51 reward: -0.006644518272425249 service_time: 2084 s_time: 16 penalty: 0 agent_num: 43 done: False
______________________
id: 55 reward: -0.011446886446886446 service_time: 2379 s_time: 25 penalty: 0 agent_num: 39 done: False
______________________
id: 42 reward: -0.012605042016806723 service_time: 1916 s_time: 24 penalty: 0 agent_num: 34 done: False
______________________
id: 52 reward: -0.004464285714285714 service_time: 1518 s_time: 10 penalty: 0 agent_num: 40 done: False
______________________
id: 41 reward: -0.03571428571428571 service_time: 2277 s_time: 92 penalty: 0 agent_num: 46 done: False
______________________
id: 50 reward: -0.026544401544401543 service_time: 2713 s_time: 55 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: -0.008116883116883116 service_time: 2458 s_time: 15 penalty: 0 agent_num: 33 done: False
______________________
id: 54 reward: -0.0437192118226601 service_time: 2810 s_time: 71 penalty: 0 agent_num: 29 done: False
______________________
Step:  2336
Pretraining Loss:  tensor(0.2634, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.0 service_time: 1178 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 46 reward: -0.12321428571428572 service_time: 1340 s_time: 69 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: 0.0 service_time: 1268 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: -0.01488095238095238 service_time: 1317 s_time: 20 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: 0.0 service_time: 1622 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 42 reward: -0.015756302521008403 service_time: 1946 s_time: 30 penalty: 0 agent_num: 34 done: False
______________________
id: 47 reward: -0.008204633204633204 service_time: 2351 s_time: 17 penalty: 0 agent_num: 37 done: False
______________________
id: 52 reward: -0.011607142857142858 service_time: 1544 s_time: 26 penalty: 0 agent_num: 40 done: False
______________________
id: 51 reward: -0.005813953488372093 service_time: 2098 s_time: 14 penalty: 0 agent_num: 43 done: False
______________________
id: 48 reward: -0.009136212624584718 service_time: 2037 s_time: 22 penalty: 0 agent_num: 43 done: False
______________________
id: 55 reward: -0.01510989010989011 service_time: 2412 s_time: 33 penalty: 0 agent_num: 39 done: False
______________________
id: 41 reward: -0.007375776397515528 service_time: 2296 s_time: 19 penalty: 0 agent_num: 46 done: False
______________________
id: 40 reward: -0.016114982578397212 service_time: 2275 s_time: 37 penalty: 0 agent_num: 41 done: False
______________________
id: 53 reward: -0.010822510822510822 service_time: 2478 s_time: 20 penalty: 0 agent_num: 33 done: False
______________________
id: 50 reward: -0.0019305019305019305 service_time: 2717 s_time: 4 penalty: 0 agent_num: 37 done: False
______________________
id: 54 reward: 0.003694581280788177 service_time: 2804 s_time: -6 penalty: 0 agent_num: 29 done: False
______________________
Step:  2352
Pretraining Loss:  tensor(0.2615, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.13392857142857142 service_time: 1253 s_time: 75 penalty: 0 agent_num: 10 done: False
______________________
id: 46 reward: -0.10714285714285714 service_time: 1400 s_time: 60 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: 0.0 service_time: 1268 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: 0.0 service_time: 1317 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 47 reward: -0.015926640926640926 service_time: 2384 s_time: 33 penalty: 0 agent_num: 37 done: False
______________________
id: 45 reward: -0.014285714285714285 service_time: 1650 s_time: 28 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.018687707641196014 service_time: 2082 s_time: 45 penalty: 0 agent_num: 43 done: False
______________________
id: 52 reward: 0.0 service_time: 1544 s_time: 0 penalty: 0 agent_num: 40 done: False
______________________
id: 51 reward: 0.0024916943521594683 service_time: 2092 s_time: -6 penalty: 0 agent_num: 43 done: False
______________________
id: 55 reward: -0.0173992673992674 service_time: 2450 s_time: 38 penalty: 0 agent_num: 39 done: False
______________________
id: 40 reward: -0.024825783972125436 service_time: 2332 s_time: 57 penalty: 0 agent_num: 41 done: False
______________________
id: 54 reward: 0.01847290640394089 service_time: 2774 s_time: -30 penalty: 0 agent_num: 29 done: False
______________________
id: 50 reward: -0.03474903474903475 service_time: 2789 s_time: 72 penalty: 0 agent_num: 37 done: False
______________________
id: 42 reward: 0.0010504201680672268 service_time: 1944 s_time: -2 penalty: 0 agent_num: 34 done: False
______________________
id: 53 reward: -0.040584415584415584 service_time: 2553 s_time: 75 penalty: 0 agent_num: 33 done: False
______________________
id: 41 reward: -0.01746894409937888 service_time: 2341 s_time: 45 penalty: 0 agent_num: 46 done: False
______________________
Step:  2368
Pretraining Loss:  tensor(0.2628, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.15 service_time: 1337 s_time: 84 penalty: 0 agent_num: 10 done: False
______________________
id: 46 reward: -0.16785714285714284 service_time: 1494 s_time: 94 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: 0.0 service_time: 1268 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: -0.01711309523809524 service_time: 1340 s_time: 23 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: -0.011224489795918367 service_time: 1672 s_time: 22 penalty: 0 agent_num: 35 done: False
______________________
id: 42 reward: -0.025210084033613446 service_time: 1992 s_time: 48 penalty: 0 agent_num: 34 done: False
______________________
id: 51 reward: -0.02367109634551495 service_time: 2149 s_time: 57 penalty: 0 agent_num: 43 done: False
______________________
id: 52 reward: -0.010267857142857143 service_time: 1567 s_time: 23 penalty: 0 agent_num: 40 done: False
______________________
id: 55 reward: -0.004120879120879121 service_time: 2459 s_time: 9 penalty: 0 agent_num: 39 done: False
______________________
id: 48 reward: -0.010382059800664452 service_time: 2107 s_time: 25 penalty: 0 agent_num: 43 done: False
______________________
id: 47 reward: -0.012548262548262547 service_time: 2410 s_time: 26 penalty: 0 agent_num: 37 done: False
______________________
id: 40 reward: -0.009146341463414634 service_time: 2353 s_time: 21 penalty: 0 agent_num: 41 done: False
______________________
id: 41 reward: 0.0 service_time: 2341 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 54 reward: 0.0 service_time: 2774 s_time: 0 penalty: 0 agent_num: 29 done: False
______________________
id: 53 reward: 0.026515151515151516 service_time: 2504 s_time: -49 penalty: 0 agent_num: 33 done: False
______________________
id: 50 reward: 0.005791505791505791 service_time: 2777 s_time: -12 penalty: 0 agent_num: 37 done: False
______________________
Step:  2384
Pretraining Loss:  tensor(0.2458, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.0017857142857142857 service_time: 1336 s_time: -1 penalty: 0 agent_num: 10 done: False
______________________
id: 46 reward: 0.14464285714285716 service_time: 1413 s_time: -81 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: -0.12012987012987013 service_time: 1342 s_time: 74 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: 0.0 service_time: 1340 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 48 reward: 0.0008305647840531562 service_time: 2105 s_time: -2 penalty: 0 agent_num: 43 done: False
______________________
id: 55 reward: 0.003663003663003663 service_time: 2451 s_time: -8 penalty: 0 agent_num: 39 done: False
______________________
id: 51 reward: 0.0 service_time: 2149 s_time: 0 penalty: 0 agent_num: 43 done: False
______________________
id: 40 reward: -0.01524390243902439 service_time: 2388 s_time: 35 penalty: 0 agent_num: 41 done: False
______________________
id: 42 reward: -0.01838235294117647 service_time: 2027 s_time: 35 penalty: 0 agent_num: 34 done: False
______________________
id: 47 reward: -0.009652509652509652 service_time: 2430 s_time: 20 penalty: 0 agent_num: 37 done: False
______________________
id: 45 reward: -0.02959183673469388 service_time: 1730 s_time: 58 penalty: 0 agent_num: 35 done: False
______________________
id: 52 reward: -0.0004464285714285714 service_time: 1568 s_time: 1 penalty: 0 agent_num: 40 done: False
______________________
id: 50 reward: -0.010135135135135136 service_time: 2798 s_time: 21 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: -0.03896103896103896 service_time: 2576 s_time: 72 penalty: 0 agent_num: 33 done: False
______________________
id: 41 reward: -0.021350931677018632 service_time: 2396 s_time: 55 penalty: 0 agent_num: 46 done: False
______________________
id: 54 reward: -0.06958128078817734 service_time: 2887 s_time: 113 penalty: 0 agent_num: 29 done: False
______________________
Step:  2400
Pretraining Loss:  tensor(0.2359, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.05 service_time: 1308 s_time: -28 penalty: 0 agent_num: 10 done: False
______________________
id: 46 reward: 0.0 service_time: 1413 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: 0.0 service_time: 1342 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: -0.013392857142857142 service_time: 1358 s_time: 18 penalty: 0 agent_num: 24 done: False
______________________
id: 42 reward: -0.018907563025210083 service_time: 2063 s_time: 36 penalty: 0 agent_num: 34 done: False
______________________
id: 45 reward: 0.0 service_time: 1730 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 51 reward: -0.022425249169435217 service_time: 2203 s_time: 54 penalty: 0 agent_num: 43 done: False
______________________
id: 55 reward: -0.004578754578754579 service_time: 2461 s_time: 10 penalty: 0 agent_num: 39 done: False
______________________
id: 48 reward: -0.012458471760797342 service_time: 2135 s_time: 30 penalty: 0 agent_num: 43 done: False
______________________
id: 50 reward: -0.014961389961389961 service_time: 2829 s_time: 31 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: 0.013528138528138528 service_time: 2551 s_time: -25 penalty: 0 agent_num: 33 done: False
______________________
id: 40 reward: -0.012630662020905924 service_time: 2417 s_time: 29 penalty: 0 agent_num: 41 done: False
______________________
id: 47 reward: -0.013513513513513514 service_time: 2458 s_time: 28 penalty: 0 agent_num: 37 done: False
______________________
id: 41 reward: 0.0015527950310559005 service_time: 2392 s_time: -4 penalty: 0 agent_num: 46 done: False
______________________
id: 54 reward: -0.03263546798029557 service_time: 2940 s_time: 53 penalty: 0 agent_num: 29 done: False
______________________
id: 52 reward: -0.008928571428571428 service_time: 1588 s_time: 20 penalty: 0 agent_num: 40 done: False
______________________
Step:  2416
Pretraining Loss:  tensor(0.2387, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: 0.0 service_time: 1308 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: -0.03896103896103896 service_time: 1366 s_time: 24 penalty: 0 agent_num: 11 done: False
______________________
id: 46 reward: 0.0 service_time: 1413 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 44 reward: -0.03050595238095238 service_time: 1399 s_time: 41 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: -0.012755102040816327 service_time: 1755 s_time: 25 penalty: 0 agent_num: 35 done: False
______________________
id: 55 reward: 0.0018315018315018315 service_time: 2457 s_time: -4 penalty: 0 agent_num: 39 done: False
______________________
id: 48 reward: -0.020348837209302327 service_time: 2184 s_time: 49 penalty: 0 agent_num: 43 done: False
______________________
id: 52 reward: -0.010714285714285714 service_time: 1612 s_time: 24 penalty: 0 agent_num: 40 done: False
______________________
id: 54 reward: 0.008004926108374385 service_time: 2927 s_time: -13 penalty: 0 agent_num: 29 done: False
______________________
id: 51 reward: 0.0 service_time: 2203 s_time: 0 penalty: 0 agent_num: 43 done: False
______________________
id: 50 reward: -0.019787644787644786 service_time: 2870 s_time: 41 penalty: 0 agent_num: 37 done: False
______________________
id: 47 reward: -0.0009652509652509653 service_time: 2460 s_time: 2 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: -0.056818181818181816 service_time: 2656 s_time: 105 penalty: 0 agent_num: 33 done: False
______________________
id: 40 reward: -0.011759581881533102 service_time: 2444 s_time: 27 penalty: 0 agent_num: 41 done: False
______________________
id: 42 reward: -0.019432773109243698 service_time: 2100 s_time: 37 penalty: 0 agent_num: 34 done: False
______________________
id: 41 reward: -0.006211180124223602 service_time: 2408 s_time: 16 penalty: 0 agent_num: 46 done: False
______________________
Step:  2432
Pretraining Loss:  tensor(0.2491, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.0035714285714285713 service_time: 1310 s_time: 2 penalty: 0 agent_num: 10 done: False
______________________
id: 46 reward: -0.02857142857142857 service_time: 1429 s_time: 16 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: 0.003246753246753247 service_time: 1364 s_time: -2 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: 0.0 service_time: 1399 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: 0.0005102040816326531 service_time: 1754 s_time: -1 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: 0.0 service_time: 2927 s_time: 0 penalty: 0 agent_num: 29 done: False
______________________
id: 42 reward: -0.017857142857142856 service_time: 2134 s_time: 34 penalty: 0 agent_num: 34 done: False
______________________
id: 47 reward: 0.0 service_time: 2460 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 51 reward: -0.022425249169435217 service_time: 2257 s_time: 54 penalty: 0 agent_num: 43 done: False
______________________
id: 48 reward: 0.0 service_time: 2184 s_time: 0 penalty: 0 agent_num: 43 done: False
______________________
id: 50 reward: -0.016409266409266408 service_time: 2904 s_time: 34 penalty: 0 agent_num: 37 done: False
______________________
id: 40 reward: 0.0013066202090592336 service_time: 2441 s_time: -3 penalty: 0 agent_num: 41 done: False
______________________
id: 52 reward: -0.008035714285714285 service_time: 1630 s_time: 18 penalty: 0 agent_num: 40 done: False
______________________
id: 53 reward: -0.027056277056277056 service_time: 2706 s_time: 50 penalty: 0 agent_num: 33 done: False
______________________
id: 41 reward: -0.018633540372670808 service_time: 2456 s_time: 48 penalty: 0 agent_num: 46 done: False
______________________
id: 55 reward: 20.000915750915752 service_time: 2455 s_time: -2 penalty: 0 agent_num: 39 done: True
______________________
Step:  2448
Pretraining Loss:  tensor(0.3063, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.05714285714285714 service_time: 1342 s_time: 32 penalty: 0 agent_num: 10 done: False
______________________
id: 46 reward: 0.0017857142857142857 service_time: 1428 s_time: -1 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: -0.12175324675324675 service_time: 1439 s_time: 75 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: -0.023065476190476192 service_time: 1430 s_time: 31 penalty: 0 agent_num: 24 done: False
______________________
id: 55 reward: -0.006211180124223602 service_time: 16 s_time: 16 penalty: 0 agent_num: 46 done: False
______________________
id: 45 reward: -0.0005102040816326531 service_time: 1755 s_time: 1 penalty: 0 agent_num: 35 done: False
______________________
id: 47 reward: -0.03185328185328185 service_time: 2526 s_time: 66 penalty: 0 agent_num: 37 done: False
______________________
id: 48 reward: -0.022840531561461794 service_time: 2239 s_time: 55 penalty: 0 agent_num: 43 done: False
______________________
id: 40 reward: -0.01524390243902439 service_time: 2476 s_time: 35 penalty: 0 agent_num: 41 done: False
______________________
id: 50 reward: -0.0033783783783783786 service_time: 2911 s_time: 7 penalty: 0 agent_num: 37 done: False
______________________
id: 42 reward: -0.017857142857142856 service_time: 2168 s_time: 34 penalty: 0 agent_num: 34 done: False
______________________
id: 53 reward: 0.005411255411255411 service_time: 2696 s_time: -10 penalty: 0 agent_num: 33 done: False
______________________
id: 51 reward: -0.014534883720930232 service_time: 2292 s_time: 35 penalty: 0 agent_num: 43 done: False
______________________
id: 41 reward: 0.0 service_time: 2456 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 52 reward: -0.015178571428571428 service_time: 1664 s_time: 34 penalty: 0 agent_num: 40 done: False
______________________
id: 54 reward: 20.00615763546798 service_time: 2917 s_time: -10 penalty: 0 agent_num: 29 done: True
______________________
Step:  2464
Pretraining Loss:  tensor(0.2066, device='cuda:0', grad_fn=<MeanBackward0>)
id: 46 reward: -0.17857142857142858 service_time: 1528 s_time: 100 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: 0.0 service_time: 1439 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: -0.15535714285714286 service_time: 1429 s_time: 87 penalty: 0 agent_num: 10 done: False
______________________
id: 54 reward: -0.007722007722007722 service_time: 16 s_time: 16 penalty: 0 agent_num: 37 done: False
______________________
id: 44 reward: 0.002232142857142857 service_time: 1427 s_time: -3 penalty: 0 agent_num: 24 done: False
______________________
id: 55 reward: -0.005822981366459627 service_time: 31 s_time: 15 penalty: 0 agent_num: 46 done: False
______________________
id: 45 reward: -0.00816326530612245 service_time: 1771 s_time: 16 penalty: 0 agent_num: 35 done: False
______________________
id: 47 reward: 0.0 service_time: 2526 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 51 reward: -0.010382059800664452 service_time: 2317 s_time: 25 penalty: 0 agent_num: 43 done: False
______________________
id: 52 reward: -0.004910714285714286 service_time: 1675 s_time: 11 penalty: 0 agent_num: 40 done: False
______________________
id: 50 reward: -0.0009652509652509653 service_time: 2913 s_time: 2 penalty: 0 agent_num: 37 done: False
______________________
id: 42 reward: -0.018907563025210083 service_time: 2204 s_time: 36 penalty: 0 agent_num: 34 done: False
______________________
id: 48 reward: 0.0 service_time: 2239 s_time: 0 penalty: 0 agent_num: 43 done: False
______________________
id: 53 reward: 0.004329004329004329 service_time: 2688 s_time: -8 penalty: 0 agent_num: 33 done: False
______________________
id: 40 reward: -0.009146341463414634 service_time: 2497 s_time: 21 penalty: 0 agent_num: 41 done: False
______________________
id: 41 reward: -0.008928571428571428 service_time: 2479 s_time: 23 penalty: 0 agent_num: 46 done: False
______________________
Step:  2480
Pretraining Loss:  tensor(0.1725, device='cuda:0', grad_fn=<MeanBackward0>)
id: 46 reward: -0.08214285714285714 service_time: 1574 s_time: 46 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: -0.04707792207792208 service_time: 1468 s_time: 29 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: 0.15714285714285714 service_time: 1341 s_time: -88 penalty: 0 agent_num: 10 done: False
______________________
id: 54 reward: -0.013030888030888031 service_time: 43 s_time: 27 penalty: 0 agent_num: 37 done: False
______________________
id: 44 reward: -0.009672619047619048 service_time: 1440 s_time: 13 penalty: 0 agent_num: 24 done: False
______________________
id: 55 reward: -0.007375776397515528 service_time: 50 s_time: 19 penalty: 0 agent_num: 46 done: False
______________________
id: 45 reward: 0.0005102040816326531 service_time: 1770 s_time: -1 penalty: 0 agent_num: 35 done: False
______________________
id: 47 reward: -0.019305019305019305 service_time: 2566 s_time: 40 penalty: 0 agent_num: 37 done: False
______________________
id: 48 reward: -0.004568106312292359 service_time: 2250 s_time: 11 penalty: 0 agent_num: 43 done: False
______________________
id: 42 reward: -0.013130252100840336 service_time: 2229 s_time: 25 penalty: 0 agent_num: 34 done: False
______________________
id: 51 reward: -0.014119601328903655 service_time: 2351 s_time: 34 penalty: 0 agent_num: 43 done: False
______________________
id: 52 reward: -0.013839285714285714 service_time: 1706 s_time: 31 penalty: 0 agent_num: 40 done: False
______________________
id: 40 reward: -0.011759581881533102 service_time: 2524 s_time: 27 penalty: 0 agent_num: 41 done: False
______________________
id: 53 reward: -0.032467532467532464 service_time: 2748 s_time: 60 penalty: 0 agent_num: 33 done: False
______________________
id: 50 reward: -0.012548262548262547 service_time: 2939 s_time: 26 penalty: 0 agent_num: 37 done: False
______________________
id: 41 reward: -0.006211180124223602 service_time: 2495 s_time: 16 penalty: 0 agent_num: 46 done: False
______________________
Step:  2496
Pretraining Loss:  tensor(0.1673, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.0375 service_time: 1362 s_time: 21 penalty: 0 agent_num: 10 done: False
______________________
id: 46 reward: -0.0875 service_time: 1623 s_time: 49 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: -0.06493506493506493 service_time: 1508 s_time: 40 penalty: 0 agent_num: 11 done: False
______________________
id: 54 reward: 0.0 service_time: 43 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 44 reward: -0.013392857142857142 service_time: 1458 s_time: 18 penalty: 0 agent_num: 24 done: False
______________________
id: 55 reward: -0.013975155279503106 service_time: 86 s_time: 36 penalty: 0 agent_num: 46 done: False
______________________
id: 45 reward: -0.01479591836734694 service_time: 1799 s_time: 29 penalty: 0 agent_num: 35 done: False
______________________
id: 53 reward: -0.01461038961038961 service_time: 2775 s_time: 27 penalty: 0 agent_num: 33 done: False
______________________
id: 47 reward: 0.0 service_time: 2566 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 51 reward: -0.009136212624584718 service_time: 2373 s_time: 22 penalty: 0 agent_num: 43 done: False
______________________
id: 50 reward: -0.004343629343629344 service_time: 2948 s_time: 9 penalty: 0 agent_num: 37 done: False
______________________
id: 52 reward: 0.0 service_time: 1706 s_time: 0 penalty: 0 agent_num: 40 done: False
______________________
id: 42 reward: -0.013130252100840336 service_time: 2254 s_time: 25 penalty: 0 agent_num: 34 done: False
______________________
id: 40 reward: -0.017857142857142856 service_time: 2565 s_time: 41 penalty: 0 agent_num: 41 done: False
______________________
id: 41 reward: -0.009316770186335404 service_time: 2519 s_time: 24 penalty: 0 agent_num: 46 done: False
______________________
id: 48 reward: 19.99543189368771 service_time: 2261 s_time: 11 penalty: 0 agent_num: 43 done: True
______________________
Step:  2512
Pretraining Loss:  tensor(0.1786, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.23392857142857143 service_time: 1493 s_time: 131 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: 0.008116883116883116 service_time: 1503 s_time: -5 penalty: 0 agent_num: 11 done: False
______________________
id: 46 reward: -0.1982142857142857 service_time: 1734 s_time: 111 penalty: 0 agent_num: 10 done: False
______________________
id: 54 reward: -0.021235521235521235 service_time: 87 s_time: 44 penalty: 0 agent_num: 37 done: False
______________________
id: 45 reward: -0.013265306122448979 service_time: 1825 s_time: 26 penalty: 0 agent_num: 35 done: False
______________________
id: 44 reward: -0.03869047619047619 service_time: 1510 s_time: 52 penalty: 0 agent_num: 24 done: False
______________________
id: 55 reward: 0.0007763975155279503 service_time: 84 s_time: -2 penalty: 0 agent_num: 46 done: False
______________________
id: 42 reward: 0.0010504201680672268 service_time: 2252 s_time: -2 penalty: 0 agent_num: 34 done: False
______________________
id: 51 reward: 0.0008305647840531562 service_time: 2371 s_time: -2 penalty: 0 agent_num: 43 done: False
______________________
id: 52 reward: 0.0 service_time: 1706 s_time: 0 penalty: 0 agent_num: 40 done: False
______________________
id: 53 reward: -0.01893939393939394 service_time: 2810 s_time: 35 penalty: 0 agent_num: 33 done: False
______________________
id: 50 reward: 0.005308880308880309 service_time: 2937 s_time: -11 penalty: 0 agent_num: 37 done: False
______________________
id: 41 reward: 0.0007763975155279503 service_time: 2517 s_time: -2 penalty: 0 agent_num: 46 done: False
______________________
id: 47 reward: 0.0 service_time: 2566 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 48 reward: -0.01746894409937888 service_time: 45 s_time: 45 penalty: 0 agent_num: 46 done: False
______________________
id: 40 reward: 0.0 service_time: 2565 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
Step:  2528
Pretraining Loss:  tensor(0.1573, device='cuda:0', grad_fn=<MeanBackward0>)
id: 46 reward: -0.15357142857142858 service_time: 1820 s_time: 86 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: 0.0 service_time: 1503 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: 0.0 service_time: 1493 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 55 reward: -0.024456521739130436 service_time: 147 s_time: 63 penalty: 0 agent_num: 46 done: False
______________________
id: 45 reward: -0.009183673469387756 service_time: 1843 s_time: 18 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: -0.016891891891891893 service_time: 122 s_time: 35 penalty: 0 agent_num: 37 done: False
______________________
id: 47 reward: 0.0 service_time: 2566 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 50 reward: 0.0 service_time: 2937 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: -0.015692640692640692 service_time: 2839 s_time: 29 penalty: 0 agent_num: 33 done: False
______________________
id: 44 reward: -0.028273809523809524 service_time: 1548 s_time: 38 penalty: 0 agent_num: 24 done: False
______________________
id: 51 reward: -0.0070598006644518275 service_time: 2388 s_time: 17 penalty: 0 agent_num: 43 done: False
______________________
id: 52 reward: -0.011160714285714286 service_time: 1731 s_time: 25 penalty: 0 agent_num: 40 done: False
______________________
id: 40 reward: -0.023083623693379792 service_time: 2618 s_time: 53 penalty: 0 agent_num: 41 done: False
______________________
id: 42 reward: -0.032563025210084036 service_time: 2314 s_time: 62 penalty: 0 agent_num: 34 done: False
______________________
id: 41 reward: 0.0 service_time: 2517 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 48 reward: 0.0 service_time: 45 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
Step:  2544
Pretraining Loss:  tensor(0.1562, device='cuda:0', grad_fn=<MeanBackward0>)
id: 46 reward: -0.08928571428571429 service_time: 1870 s_time: 50 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: -0.11201298701298701 service_time: 1572 s_time: 69 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: 0.0 service_time: 1493 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 54 reward: -0.013513513513513514 service_time: 150 s_time: 28 penalty: 0 agent_num: 37 done: False
______________________
id: 55 reward: -0.009316770186335404 service_time: 171 s_time: 24 penalty: 0 agent_num: 46 done: False
______________________
id: 45 reward: 0.0 service_time: 1843 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 53 reward: 0.0005411255411255411 service_time: 2838 s_time: -1 penalty: 0 agent_num: 33 done: False
______________________
id: 47 reward: 0.0 service_time: 2566 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 42 reward: -0.006827731092436975 service_time: 2327 s_time: 13 penalty: 0 agent_num: 34 done: False
______________________
id: 50 reward: 0.0 service_time: 2937 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 52 reward: 0.0 service_time: 1731 s_time: 0 penalty: 0 agent_num: 40 done: False
______________________
id: 44 reward: -0.022321428571428572 service_time: 1578 s_time: 30 penalty: 0 agent_num: 24 done: False
______________________
id: 48 reward: -0.01048136645962733 service_time: 72 s_time: 27 penalty: 0 agent_num: 46 done: False
______________________
id: 41 reward: 0.0 service_time: 2517 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 51 reward: -0.024501661129568107 service_time: 2447 s_time: 59 penalty: 0 agent_num: 43 done: False
______________________
id: 40 reward: 0.0008710801393728223 service_time: 2616 s_time: -2 penalty: 0 agent_num: 41 done: False
______________________
Step:  2560
Pretraining Loss:  tensor(0.1616, device='cuda:0', grad_fn=<MeanBackward0>)
id: 43 reward: 0.0 service_time: 1572 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 46 reward: -0.19285714285714287 service_time: 1978 s_time: 108 penalty: 0 agent_num: 10 done: False
______________________
id: 49 reward: 0.0 service_time: 1493 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 54 reward: -0.012065637065637066 service_time: 175 s_time: 25 penalty: 0 agent_num: 37 done: False
______________________
id: 45 reward: -0.007142857142857143 service_time: 1857 s_time: 14 penalty: 0 agent_num: 35 done: False
______________________
id: 47 reward: 0.0028957528957528956 service_time: 2560 s_time: -6 penalty: 0 agent_num: 37 done: False
______________________
id: 48 reward: -0.01281055900621118 service_time: 105 s_time: 33 penalty: 0 agent_num: 46 done: False
______________________
id: 50 reward: 0.0 service_time: 2937 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 42 reward: -0.022584033613445378 service_time: 2370 s_time: 43 penalty: 0 agent_num: 34 done: False
______________________
id: 53 reward: -0.017857142857142856 service_time: 2871 s_time: 33 penalty: 0 agent_num: 33 done: False
______________________
id: 52 reward: -0.010267857142857143 service_time: 1754 s_time: 23 penalty: 0 agent_num: 40 done: False
______________________
id: 55 reward: -0.01358695652173913 service_time: 206 s_time: 35 penalty: 0 agent_num: 46 done: False
______________________
id: 40 reward: 0.0 service_time: 2616 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 44 reward: -0.011160714285714286 service_time: 1593 s_time: 15 penalty: 0 agent_num: 24 done: False
______________________
id: 51 reward: -0.010382059800664452 service_time: 2472 s_time: 25 penalty: 0 agent_num: 43 done: False
______________________
id: 41 reward: 20.002717391304348 service_time: 2510 s_time: -7 penalty: 0 agent_num: 46 done: True
______________________
Step:  2576
Pretraining Loss:  tensor(0.1657, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.021103896103896104 service_time: 13 s_time: 13 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: -0.08214285714285714 service_time: 1539 s_time: 46 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: 0.0 service_time: 1572 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 46 reward: -0.22142857142857142 service_time: 2102 s_time: 124 penalty: 0 agent_num: 10 done: False
______________________
id: 54 reward: -0.016891891891891893 service_time: 210 s_time: 35 penalty: 0 agent_num: 37 done: False
______________________
id: 45 reward: -0.0005102040816326531 service_time: 1858 s_time: 1 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.01048136645962733 service_time: 132 s_time: 27 penalty: 0 agent_num: 46 done: False
______________________
id: 50 reward: 0.002413127413127413 service_time: 2932 s_time: -5 penalty: 0 agent_num: 37 done: False
______________________
id: 42 reward: -0.011554621848739496 service_time: 2392 s_time: 22 penalty: 0 agent_num: 34 done: False
______________________
id: 55 reward: -0.006987577639751553 service_time: 224 s_time: 18 penalty: 0 agent_num: 46 done: False
______________________
id: 51 reward: 0.0 service_time: 2472 s_time: 0 penalty: 0 agent_num: 43 done: False
______________________
id: 52 reward: -0.005357142857142857 service_time: 1766 s_time: 12 penalty: 0 agent_num: 40 done: False
______________________
id: 53 reward: -0.03463203463203463 service_time: 2935 s_time: 64 penalty: 0 agent_num: 33 done: False
______________________
id: 44 reward: 0.0 service_time: 1593 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 40 reward: 0.0 service_time: 2616 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 47 reward: 20.001447876447877 service_time: 2557 s_time: -3 penalty: 0 agent_num: 37 done: True
______________________
Step:  2592
Pretraining Loss:  tensor(0.1890, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.022727272727272728 service_time: 27 s_time: 14 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: -0.008035714285714285 service_time: 9 s_time: 9 penalty: 0 agent_num: 20 done: False
______________________
id: 49 reward: -0.12142857142857143 service_time: 1607 s_time: 68 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: 0.0 service_time: 1572 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 46 reward: -0.21607142857142858 service_time: 2223 s_time: 121 penalty: 0 agent_num: 10 done: False
______________________
id: 45 reward: -0.015816326530612244 service_time: 1889 s_time: 31 penalty: 0 agent_num: 35 done: False
______________________
id: 50 reward: 0.0 service_time: 2932 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 42 reward: 0.0 service_time: 2392 s_time: 0 penalty: 0 agent_num: 34 done: False
______________________
id: 54 reward: -0.013996138996138996 service_time: 239 s_time: 29 penalty: 0 agent_num: 37 done: False
______________________
id: 48 reward: -0.014751552795031056 service_time: 170 s_time: 38 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: 0.0 service_time: 2935 s_time: 0 penalty: 0 agent_num: 33 done: False
______________________
id: 55 reward: -0.009316770186335404 service_time: 248 s_time: 24 penalty: 0 agent_num: 46 done: False
______________________
id: 44 reward: 0.0 service_time: 1593 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 51 reward: 0.0 service_time: 2472 s_time: 0 penalty: 0 agent_num: 43 done: False
______________________
id: 52 reward: -0.006696428571428571 service_time: 1781 s_time: 15 penalty: 0 agent_num: 40 done: False
______________________
id: 40 reward: 20.003048780487806 service_time: 2609 s_time: -7 penalty: 0 agent_num: 41 done: True
______________________
Step:  2608
Pretraining Loss:  tensor(0.1723, device='cuda:0', grad_fn=<MeanBackward0>)
id: 47 reward: -0.027678571428571427 service_time: 40 s_time: 31 penalty: 0 agent_num: 20 done: False
______________________
id: 41 reward: -0.04220779220779221 service_time: 53 s_time: 26 penalty: 0 agent_num: 11 done: False
______________________
id: 43 reward: -0.01461038961038961 service_time: 1581 s_time: 9 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: -0.17857142857142858 service_time: 1707 s_time: 100 penalty: 0 agent_num: 10 done: False
______________________
id: 46 reward: -0.16785714285714284 service_time: 2317 s_time: 94 penalty: 0 agent_num: 10 done: False
______________________
id: 40 reward: -0.012244897959183673 service_time: 24 s_time: 24 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: 0.0 service_time: 239 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 45 reward: -0.0163265306122449 service_time: 1921 s_time: 32 penalty: 0 agent_num: 35 done: False
______________________
id: 51 reward: 0.0008305647840531562 service_time: 2470 s_time: -2 penalty: 0 agent_num: 43 done: False
______________________
id: 42 reward: -0.014180672268907563 service_time: 2419 s_time: 27 penalty: 0 agent_num: 34 done: False
______________________
id: 55 reward: -0.01591614906832298 service_time: 289 s_time: 41 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: -0.0005411255411255411 service_time: 2936 s_time: 1 penalty: 0 agent_num: 33 done: False
______________________
id: 44 reward: -0.03571428571428571 service_time: 1641 s_time: 48 penalty: 0 agent_num: 24 done: False
______________________
id: 48 reward: 0.0 service_time: 170 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 52 reward: -0.022321428571428572 service_time: 1831 s_time: 50 penalty: 0 agent_num: 40 done: False
______________________
id: 50 reward: 20.0 service_time: 2932 s_time: 0 penalty: 0 agent_num: 37 done: True
______________________
Step:  2624
Pretraining Loss:  tensor(0.1734, device='cuda:0', grad_fn=<MeanBackward0>)
id: 47 reward: 0.0 service_time: 40 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 50 reward: -0.012987012987012988 service_time: 16 s_time: 16 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: -0.10892857142857143 service_time: 1768 s_time: 61 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: -0.05357142857142857 service_time: 86 s_time: 33 penalty: 0 agent_num: 11 done: False
______________________
id: 43 reward: -0.1525974025974026 service_time: 1675 s_time: 94 penalty: 0 agent_num: 11 done: False
______________________
id: 46 reward: -0.10357142857142858 service_time: 2375 s_time: 58 penalty: 0 agent_num: 10 done: False
______________________
id: 45 reward: 0.0 service_time: 1921 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 40 reward: -0.02193877551020408 service_time: 67 s_time: 43 penalty: 0 agent_num: 35 done: False
______________________
id: 53 reward: 0.0005411255411255411 service_time: 2935 s_time: -1 penalty: 0 agent_num: 33 done: False
______________________
id: 54 reward: -0.024613899613899613 service_time: 290 s_time: 51 penalty: 0 agent_num: 37 done: False
______________________
id: 42 reward: -0.01365546218487395 service_time: 2445 s_time: 26 penalty: 0 agent_num: 34 done: False
______________________
id: 55 reward: -0.01281055900621118 service_time: 322 s_time: 33 penalty: 0 agent_num: 46 done: False
______________________
id: 52 reward: 0.0 service_time: 1831 s_time: 0 penalty: 0 agent_num: 40 done: False
______________________
id: 48 reward: -0.026785714285714284 service_time: 239 s_time: 69 penalty: 0 agent_num: 46 done: False
______________________
id: 44 reward: -0.012648809523809524 service_time: 1658 s_time: 17 penalty: 0 agent_num: 24 done: False
______________________
id: 51 reward: 20.00249169435216 service_time: 2464 s_time: -6 penalty: 0 agent_num: 43 done: True
______________________
Step:  2640
Pretraining Loss:  tensor(0.1653, device='cuda:0', grad_fn=<MeanBackward0>)
id: 50 reward: -0.005681818181818182 service_time: 23 s_time: 7 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: -0.0125 service_time: 54 s_time: 14 penalty: 0 agent_num: 20 done: False
______________________
id: 51 reward: -0.013975155279503106 service_time: 18 s_time: 18 penalty: 0 agent_num: 23 done: False
______________________
id: 49 reward: -0.0625 service_time: 1803 s_time: 35 penalty: 0 agent_num: 10 done: False
______________________
id: 46 reward: -0.2125 service_time: 2494 s_time: 119 penalty: 0 agent_num: 10 done: False
______________________
id: 40 reward: 0.0 service_time: 67 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 43 reward: -0.09415584415584416 service_time: 1733 s_time: 58 penalty: 0 agent_num: 11 done: False
______________________
id: 41 reward: -0.0633116883116883 service_time: 125 s_time: 39 penalty: 0 agent_num: 11 done: False
______________________
id: 54 reward: -0.014961389961389961 service_time: 321 s_time: 31 penalty: 0 agent_num: 37 done: False
______________________
id: 45 reward: 0.0 service_time: 1921 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 44 reward: 0.000744047619047619 service_time: 1657 s_time: -1 penalty: 0 agent_num: 24 done: False
______________________
id: 55 reward: 0.0 service_time: 322 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 42 reward: -0.01995798319327731 service_time: 2483 s_time: 38 penalty: 0 agent_num: 34 done: False
______________________
id: 48 reward: -0.010869565217391304 service_time: 267 s_time: 28 penalty: 0 agent_num: 46 done: False
______________________
id: 52 reward: -0.014732142857142857 service_time: 1864 s_time: 33 penalty: 0 agent_num: 40 done: False
______________________
id: 53 reward: 20.001082251082252 service_time: 2933 s_time: -2 penalty: 0 agent_num: 33 done: True
______________________
Step:  2656
Pretraining Loss:  tensor(0.1890, device='cuda:0', grad_fn=<MeanBackward0>)
id: 50 reward: -0.011363636363636364 service_time: 37 s_time: 14 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: -0.018633540372670808 service_time: 42 s_time: 24 penalty: 0 agent_num: 23 done: False
______________________
id: 47 reward: -0.020535714285714286 service_time: 77 s_time: 23 penalty: 0 agent_num: 20 done: False
______________________
id: 43 reward: -0.08116883116883117 service_time: 1783 s_time: 50 penalty: 0 agent_num: 11 done: False
______________________
id: 46 reward: -0.3821428571428571 service_time: 2708 s_time: 214 penalty: 0 agent_num: 10 done: False
______________________
id: 49 reward: -0.09285714285714286 service_time: 1855 s_time: 52 penalty: 0 agent_num: 10 done: False
______________________
id: 53 reward: -0.017421602787456445 service_time: 40 s_time: 40 penalty: 0 agent_num: 41 done: False
______________________
id: 41 reward: -0.03896103896103896 service_time: 149 s_time: 24 penalty: 0 agent_num: 11 done: False
______________________
id: 40 reward: -0.025510204081632654 service_time: 117 s_time: 50 penalty: 0 agent_num: 35 done: False
______________________
id: 55 reward: -0.007375776397515528 service_time: 341 s_time: 19 penalty: 0 agent_num: 46 done: False
______________________
id: 48 reward: -0.011645962732919254 service_time: 297 s_time: 30 penalty: 0 agent_num: 46 done: False
______________________
id: 42 reward: 0.0 service_time: 2483 s_time: 0 penalty: 0 agent_num: 34 done: False
______________________
id: 52 reward: 0.0 service_time: 1864 s_time: 0 penalty: 0 agent_num: 40 done: False
______________________
id: 45 reward: 0.0 service_time: 1921 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: -0.006274131274131274 service_time: 334 s_time: 13 penalty: 0 agent_num: 37 done: False
______________________
id: 44 reward: -0.012648809523809524 service_time: 1674 s_time: 17 penalty: 0 agent_num: 24 done: False
______________________
Step:  2672
Pretraining Loss:  tensor(0.1632, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.012987012987012988 service_time: 157 s_time: 8 penalty: 0 agent_num: 11 done: False
______________________
id: 46 reward: -0.20535714285714285 service_time: 2823 s_time: 115 penalty: 0 agent_num: 10 done: False
______________________
id: 47 reward: -0.04107142857142857 service_time: 123 s_time: 46 penalty: 0 agent_num: 20 done: False
______________________
id: 50 reward: 0.0 service_time: 37 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: -0.11071428571428571 service_time: 1917 s_time: 62 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: -0.05844155844155844 service_time: 1819 s_time: 36 penalty: 0 agent_num: 11 done: False
______________________
id: 51 reward: -0.011645962732919254 service_time: 57 s_time: 15 penalty: 0 agent_num: 23 done: False
______________________
id: 45 reward: -0.00816326530612245 service_time: 1937 s_time: 16 penalty: 0 agent_num: 35 done: False
______________________
id: 44 reward: -0.00818452380952381 service_time: 1685 s_time: 11 penalty: 0 agent_num: 24 done: False
______________________
id: 53 reward: -0.013066202090592335 service_time: 70 s_time: 30 penalty: 0 agent_num: 41 done: False
______________________
id: 54 reward: -0.00916988416988417 service_time: 353 s_time: 19 penalty: 0 agent_num: 37 done: False
______________________
id: 55 reward: -0.010869565217391304 service_time: 369 s_time: 28 penalty: 0 agent_num: 46 done: False
______________________
id: 42 reward: 0.0 service_time: 2483 s_time: 0 penalty: 0 agent_num: 34 done: False
______________________
id: 48 reward: -0.007375776397515528 service_time: 316 s_time: 19 penalty: 0 agent_num: 46 done: False
______________________
id: 40 reward: -0.014285714285714285 service_time: 145 s_time: 28 penalty: 0 agent_num: 35 done: False
______________________
id: 52 reward: 0.0 service_time: 1864 s_time: 0 penalty: 0 agent_num: 40 done: False
______________________
Step:  2688
Pretraining Loss:  tensor(0.1695, device='cuda:0', grad_fn=<MeanBackward0>)
id: 50 reward: -0.0349025974025974 service_time: 80 s_time: 43 penalty: 0 agent_num: 22 done: False
______________________
id: 41 reward: -0.048701298701298704 service_time: 187 s_time: 30 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: 0.0 service_time: 123 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 43 reward: -0.125 service_time: 1896 s_time: 77 penalty: 0 agent_num: 11 done: False
______________________
id: 46 reward: -0.3625 service_time: 3026 s_time: 203 penalty: 0 agent_num: 10 done: False
______________________
id: 49 reward: -0.13214285714285715 service_time: 1991 s_time: 74 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: -0.02251552795031056 service_time: 86 s_time: 29 penalty: 0 agent_num: 23 done: False
______________________
id: 53 reward: -0.010017421602787456 service_time: 93 s_time: 23 penalty: 0 agent_num: 41 done: False
______________________
id: 40 reward: -0.00816326530612245 service_time: 161 s_time: 16 penalty: 0 agent_num: 35 done: False
______________________
id: 45 reward: 0.0 service_time: 1937 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 55 reward: -0.005046583850931677 service_time: 382 s_time: 13 penalty: 0 agent_num: 46 done: False
______________________
id: 42 reward: 0.0 service_time: 2483 s_time: 0 penalty: 0 agent_num: 34 done: False
______________________
id: 54 reward: -0.016891891891891893 service_time: 388 s_time: 35 penalty: 0 agent_num: 37 done: False
______________________
id: 48 reward: -0.010093167701863354 service_time: 342 s_time: 26 penalty: 0 agent_num: 46 done: False
______________________
id: 44 reward: -0.018601190476190476 service_time: 1710 s_time: 25 penalty: 0 agent_num: 24 done: False
______________________
id: 52 reward: 0.0 service_time: 1864 s_time: 0 penalty: 0 agent_num: 40 done: False
______________________
Step:  2704
Pretraining Loss:  tensor(0.1773, device='cuda:0', grad_fn=<MeanBackward0>)
id: 46 reward: -0.14464285714285716 service_time: 3107 s_time: 81 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: 0.0 service_time: 86 s_time: 0 penalty: 0 agent_num: 23 done: False
______________________
id: 49 reward: -0.16607142857142856 service_time: 2084 s_time: 93 penalty: 0 agent_num: 10 done: False
______________________
id: 47 reward: -0.02142857142857143 service_time: 147 s_time: 24 penalty: 0 agent_num: 20 done: False
______________________
id: 50 reward: -0.024350649350649352 service_time: 110 s_time: 30 penalty: 0 agent_num: 22 done: False
______________________
id: 41 reward: -0.08441558441558442 service_time: 239 s_time: 52 penalty: 0 agent_num: 11 done: False
______________________
id: 43 reward: -0.29707792207792205 service_time: 2079 s_time: 183 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: -0.018601190476190476 service_time: 1735 s_time: 25 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: -0.01683673469387755 service_time: 1970 s_time: 33 penalty: 0 agent_num: 35 done: False
______________________
id: 40 reward: -0.009693877551020408 service_time: 180 s_time: 19 penalty: 0 agent_num: 35 done: False
______________________
id: 55 reward: -0.007763975155279503 service_time: 402 s_time: 20 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: -0.003484320557491289 service_time: 101 s_time: 8 penalty: 0 agent_num: 41 done: False
______________________
id: 42 reward: 0.0 service_time: 2483 s_time: 0 penalty: 0 agent_num: 34 done: False
______________________
id: 54 reward: -0.005308880308880309 service_time: 399 s_time: 11 penalty: 0 agent_num: 37 done: False
______________________
id: 48 reward: -0.006211180124223602 service_time: 358 s_time: 16 penalty: 0 agent_num: 46 done: False
______________________
id: 52 reward: -0.010714285714285714 service_time: 1888 s_time: 24 penalty: 0 agent_num: 40 done: False
______________________
Step:  2720
Pretraining Loss:  tensor(0.1958, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.011363636363636364 service_time: 246 s_time: 7 penalty: 0 agent_num: 11 done: False
______________________
id: 46 reward: -0.1875 service_time: 3212 s_time: 105 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: -0.04114906832298137 service_time: 139 s_time: 53 penalty: 0 agent_num: 23 done: False
______________________
id: 43 reward: -0.23214285714285715 service_time: 2222 s_time: 143 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: -0.020535714285714286 service_time: 170 s_time: 23 penalty: 0 agent_num: 20 done: False
______________________
id: 50 reward: -0.02922077922077922 service_time: 146 s_time: 36 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: -0.08928571428571429 service_time: 2134 s_time: 50 penalty: 0 agent_num: 10 done: False
______________________
id: 40 reward: -0.01173469387755102 service_time: 203 s_time: 23 penalty: 0 agent_num: 35 done: False
______________________
id: 53 reward: 0.0 service_time: 101 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 45 reward: -0.013775510204081633 service_time: 1997 s_time: 27 penalty: 0 agent_num: 35 done: False
______________________
id: 42 reward: 0.0 service_time: 2483 s_time: 0 penalty: 0 agent_num: 34 done: False
______________________
id: 54 reward: -0.005308880308880309 service_time: 410 s_time: 11 penalty: 0 agent_num: 37 done: False
______________________
id: 55 reward: -0.006211180124223602 service_time: 418 s_time: 16 penalty: 0 agent_num: 46 done: False
______________________
id: 48 reward: -0.010093167701863354 service_time: 384 s_time: 26 penalty: 0 agent_num: 46 done: False
______________________
id: 44 reward: -0.015625 service_time: 1756 s_time: 21 penalty: 0 agent_num: 24 done: False
______________________
id: 52 reward: -0.016517857142857143 service_time: 1925 s_time: 37 penalty: 0 agent_num: 40 done: False
______________________
Step:  2736
Pretraining Loss:  tensor(0.2084, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.06655844155844155 service_time: 287 s_time: 41 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: -0.013392857142857142 service_time: 185 s_time: 15 penalty: 0 agent_num: 20 done: False
______________________
id: 46 reward: -0.3410714285714286 service_time: 3403 s_time: 191 penalty: 0 agent_num: 10 done: False
______________________
id: 49 reward: -0.15357142857142858 service_time: 2220 s_time: 86 penalty: 0 agent_num: 10 done: False
______________________
id: 50 reward: -0.024350649350649352 service_time: 176 s_time: 30 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: -0.03493788819875776 service_time: 184 s_time: 45 penalty: 0 agent_num: 23 done: False
______________________
id: 43 reward: -0.14285714285714285 service_time: 2310 s_time: 88 penalty: 0 agent_num: 11 done: False
______________________
id: 40 reward: -0.006122448979591836 service_time: 215 s_time: 12 penalty: 0 agent_num: 35 done: False
______________________
id: 45 reward: 0.0 service_time: 1997 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 44 reward: 0.0 service_time: 1756 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 54 reward: -0.002413127413127413 service_time: 415 s_time: 5 penalty: 0 agent_num: 37 done: False
______________________
id: 55 reward: -0.010093167701863354 service_time: 444 s_time: 26 penalty: 0 agent_num: 46 done: False
______________________
id: 52 reward: -0.0035714285714285713 service_time: 1933 s_time: 8 penalty: 0 agent_num: 40 done: False
______________________
id: 48 reward: -0.01125776397515528 service_time: 413 s_time: 29 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: -0.013501742160278746 service_time: 132 s_time: 31 penalty: 0 agent_num: 41 done: False
______________________
id: 42 reward: 20.001050420168067 service_time: 2481 s_time: -2 penalty: 0 agent_num: 34 done: True
______________________
Step:  2752
Pretraining Loss:  tensor(0.2065, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: 0.021103896103896104 service_time: 274 s_time: -13 penalty: 0 agent_num: 11 done: False
______________________
id: 46 reward: -0.3142857142857143 service_time: 3579 s_time: 176 penalty: 0 agent_num: 10 done: False
______________________
id: 42 reward: -0.021825396825396824 service_time: 33 s_time: 33 penalty: 0 agent_num: 27 done: False
______________________
id: 43 reward: -0.14772727272727273 service_time: 2401 s_time: 91 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: -0.11785714285714285 service_time: 2286 s_time: 66 penalty: 0 agent_num: 10 done: False
______________________
id: 50 reward: -0.01948051948051948 service_time: 200 s_time: 24 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: 0.0 service_time: 185 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 53 reward: -0.004790940766550522 service_time: 143 s_time: 11 penalty: 0 agent_num: 41 done: False
______________________
id: 51 reward: -0.020186335403726708 service_time: 210 s_time: 26 penalty: 0 agent_num: 23 done: False
______________________
id: 45 reward: 0.0 service_time: 1997 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 40 reward: -0.0163265306122449 service_time: 247 s_time: 32 penalty: 0 agent_num: 35 done: False
______________________
id: 55 reward: -0.004270186335403727 service_time: 455 s_time: 11 penalty: 0 agent_num: 46 done: False
______________________
id: 48 reward: 0.0 service_time: 413 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 54 reward: -0.028474903474903474 service_time: 474 s_time: 59 penalty: 0 agent_num: 37 done: False
______________________
id: 44 reward: -0.009672619047619048 service_time: 1769 s_time: 13 penalty: 0 agent_num: 24 done: False
______________________
id: 52 reward: -0.0035714285714285713 service_time: 1941 s_time: 8 penalty: 0 agent_num: 40 done: False
______________________
Step:  2768
Pretraining Loss:  tensor(0.2080, device='cuda:0', grad_fn=<MeanBackward0>)
id: 43 reward: -0.15097402597402598 service_time: 2494 s_time: 93 penalty: 0 agent_num: 11 done: False
______________________
id: 41 reward: 0.011363636363636364 service_time: 267 s_time: -7 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: -0.2767857142857143 service_time: 2441 s_time: 155 penalty: 0 agent_num: 10 done: False
______________________
id: 50 reward: -0.020292207792207792 service_time: 225 s_time: 25 penalty: 0 agent_num: 22 done: False
______________________
id: 46 reward: -0.4142857142857143 service_time: 3811 s_time: 232 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: -0.006987577639751553 service_time: 219 s_time: 9 penalty: 0 agent_num: 23 done: False
______________________
id: 42 reward: 0.0 service_time: 33 s_time: 0 penalty: 0 agent_num: 27 done: False
______________________
id: 47 reward: -0.0026785714285714286 service_time: 188 s_time: 3 penalty: 0 agent_num: 20 done: False
______________________
id: 44 reward: -0.012648809523809524 service_time: 1786 s_time: 17 penalty: 0 agent_num: 24 done: False
______________________
id: 54 reward: 0.00048262548262548264 service_time: 473 s_time: -1 penalty: 0 agent_num: 37 done: False
______________________
id: 45 reward: -0.01683673469387755 service_time: 2030 s_time: 33 penalty: 0 agent_num: 35 done: False
______________________
id: 40 reward: -0.001530612244897959 service_time: 250 s_time: 3 penalty: 0 agent_num: 35 done: False
______________________
id: 55 reward: -0.006987577639751553 service_time: 473 s_time: 18 penalty: 0 agent_num: 46 done: False
______________________
id: 48 reward: -0.01358695652173913 service_time: 448 s_time: 35 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: -0.0078397212543554 service_time: 161 s_time: 18 penalty: 0 agent_num: 41 done: False
______________________
id: 52 reward: -0.011607142857142858 service_time: 1967 s_time: 26 penalty: 0 agent_num: 40 done: False
______________________
Step:  2784
Pretraining Loss:  tensor(0.2232, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.012987012987012988 service_time: 275 s_time: 8 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: -0.44107142857142856 service_time: 2688 s_time: 247 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: -0.10876623376623376 service_time: 2561 s_time: 67 penalty: 0 agent_num: 11 done: False
______________________
id: 50 reward: 0.0 service_time: 225 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 46 reward: -0.3125 service_time: 3986 s_time: 175 penalty: 0 agent_num: 10 done: False
______________________
id: 42 reward: -0.028439153439153438 service_time: 76 s_time: 43 penalty: 0 agent_num: 27 done: False
______________________
id: 51 reward: -0.017857142857142856 service_time: 242 s_time: 23 penalty: 0 agent_num: 23 done: False
______________________
id: 53 reward: -0.009146341463414634 service_time: 182 s_time: 21 penalty: 0 agent_num: 41 done: False
______________________
id: 47 reward: -0.01607142857142857 service_time: 206 s_time: 18 penalty: 0 agent_num: 20 done: False
______________________
id: 45 reward: -0.012244897959183673 service_time: 2054 s_time: 24 penalty: 0 agent_num: 35 done: False
______________________
id: 44 reward: 0.0 service_time: 1786 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 54 reward: -0.017374517374517374 service_time: 509 s_time: 36 penalty: 0 agent_num: 37 done: False
______________________
id: 55 reward: -0.009704968944099378 service_time: 498 s_time: 25 penalty: 0 agent_num: 46 done: False
______________________
id: 48 reward: -0.01436335403726708 service_time: 485 s_time: 37 penalty: 0 agent_num: 46 done: False
______________________
id: 40 reward: -0.03571428571428571 service_time: 320 s_time: 70 penalty: 0 agent_num: 35 done: False
______________________
id: 52 reward: -0.015625 service_time: 2002 s_time: 35 penalty: 0 agent_num: 40 done: False
______________________
Step:  2800
Pretraining Loss:  tensor(0.2122, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: 0.0 service_time: 275 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 46 reward: -0.21964285714285714 service_time: 4109 s_time: 123 penalty: 0 agent_num: 10 done: False
______________________
id: 47 reward: -0.01875 service_time: 227 s_time: 21 penalty: 0 agent_num: 20 done: False
______________________
id: 49 reward: -0.26071428571428573 service_time: 2834 s_time: 146 penalty: 0 agent_num: 10 done: False
______________________
id: 50 reward: -0.045454545454545456 service_time: 281 s_time: 56 penalty: 0 agent_num: 22 done: False
______________________
id: 43 reward: -0.3587662337662338 service_time: 2782 s_time: 221 penalty: 0 agent_num: 11 done: False
______________________
id: 42 reward: -0.01917989417989418 service_time: 105 s_time: 29 penalty: 0 agent_num: 27 done: False
______________________
id: 51 reward: -0.016304347826086956 service_time: 263 s_time: 21 penalty: 0 agent_num: 23 done: False
______________________
id: 44 reward: -0.014136904761904762 service_time: 1805 s_time: 19 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: -0.017346938775510204 service_time: 2088 s_time: 34 penalty: 0 agent_num: 35 done: False
______________________
id: 55 reward: 0.0 service_time: 498 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 40 reward: -0.02193877551020408 service_time: 363 s_time: 43 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: -0.005791505791505791 service_time: 521 s_time: 12 penalty: 0 agent_num: 37 done: False
______________________
id: 48 reward: -0.01203416149068323 service_time: 516 s_time: 31 penalty: 0 agent_num: 46 done: False
______________________
id: 52 reward: 0.0 service_time: 2002 s_time: 0 penalty: 0 agent_num: 40 done: False
______________________
id: 53 reward: -0.012630662020905924 service_time: 211 s_time: 29 penalty: 0 agent_num: 41 done: False
______________________
Step:  2816
Pretraining Loss:  tensor(0.2165, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.0762987012987013 service_time: 322 s_time: 47 penalty: 0 agent_num: 11 done: False
______________________
id: 43 reward: -0.18181818181818182 service_time: 2894 s_time: 112 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: -0.15535714285714286 service_time: 2921 s_time: 87 penalty: 0 agent_num: 10 done: False
______________________
id: 46 reward: -0.17142857142857143 service_time: 4205 s_time: 96 penalty: 0 agent_num: 10 done: False
______________________
id: 47 reward: 0.0 service_time: 227 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 42 reward: -0.015873015873015872 service_time: 129 s_time: 24 penalty: 0 agent_num: 27 done: False
______________________
id: 50 reward: 0.0 service_time: 281 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: -0.019409937888198756 service_time: 288 s_time: 25 penalty: 0 agent_num: 23 done: False
______________________
id: 44 reward: 0.0 service_time: 1805 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 54 reward: -0.01833976833976834 service_time: 559 s_time: 38 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: -0.004790940766550522 service_time: 222 s_time: 11 penalty: 0 agent_num: 41 done: False
______________________
id: 55 reward: -0.006211180124223602 service_time: 514 s_time: 16 penalty: 0 agent_num: 46 done: False
______________________
id: 40 reward: 0.0 service_time: 363 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 45 reward: -0.013265306122448979 service_time: 2114 s_time: 26 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.007763975155279503 service_time: 536 s_time: 20 penalty: 0 agent_num: 46 done: False
______________________
id: 52 reward: -0.004910714285714286 service_time: 2013 s_time: 11 penalty: 0 agent_num: 40 done: False
______________________
Step:  2832
Pretraining Loss:  tensor(0.2098, device='cuda:0', grad_fn=<MeanBackward0>)
id: 46 reward: -0.2732142857142857 service_time: 4358 s_time: 153 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: -0.3555194805194805 service_time: 3113 s_time: 219 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: -0.14821428571428572 service_time: 3004 s_time: 83 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: -0.008540372670807454 service_time: 299 s_time: 11 penalty: 0 agent_num: 23 done: False
______________________
id: 47 reward: -0.026785714285714284 service_time: 257 s_time: 30 penalty: 0 agent_num: 20 done: False
______________________
id: 41 reward: -0.05194805194805195 service_time: 354 s_time: 32 penalty: 0 agent_num: 11 done: False
______________________
id: 42 reward: -0.026455026455026454 service_time: 169 s_time: 40 penalty: 0 agent_num: 27 done: False
______________________
id: 50 reward: -0.03896103896103896 service_time: 329 s_time: 48 penalty: 0 agent_num: 22 done: False
______________________
id: 44 reward: -0.036458333333333336 service_time: 1854 s_time: 49 penalty: 0 agent_num: 24 done: False
______________________
id: 53 reward: -0.009146341463414634 service_time: 243 s_time: 21 penalty: 0 agent_num: 41 done: False
______________________
id: 40 reward: -0.007142857142857143 service_time: 377 s_time: 14 penalty: 0 agent_num: 35 done: False
______________________
id: 45 reward: -0.009183673469387756 service_time: 2132 s_time: 18 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.01281055900621118 service_time: 569 s_time: 33 penalty: 0 agent_num: 46 done: False
______________________
id: 54 reward: 0.0 service_time: 559 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 55 reward: -0.02406832298136646 service_time: 576 s_time: 62 penalty: 0 agent_num: 46 done: False
______________________
id: 52 reward: -0.007589285714285714 service_time: 2030 s_time: 17 penalty: 0 agent_num: 40 done: False
______________________
Step:  2848
Pretraining Loss:  tensor(0.2568, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: 0.04383116883116883 service_time: 327 s_time: -27 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: -0.28035714285714286 service_time: 3161 s_time: 157 penalty: 0 agent_num: 10 done: False
______________________
id: 47 reward: -0.024107142857142858 service_time: 284 s_time: 27 penalty: 0 agent_num: 20 done: False
______________________
id: 46 reward: -0.3142857142857143 service_time: 4534 s_time: 176 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: -0.34415584415584416 service_time: 3325 s_time: 212 penalty: 0 agent_num: 11 done: False
______________________
id: 51 reward: 0.0 service_time: 299 s_time: 0 penalty: 0 agent_num: 23 done: False
______________________
id: 50 reward: -0.07711038961038962 service_time: 424 s_time: 95 penalty: 0 agent_num: 22 done: False
______________________
id: 42 reward: -0.03439153439153439 service_time: 221 s_time: 52 penalty: 0 agent_num: 27 done: False
______________________
id: 44 reward: -0.008928571428571428 service_time: 1866 s_time: 12 penalty: 0 agent_num: 24 done: False
______________________
id: 53 reward: 0.0 service_time: 243 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 54 reward: -0.025096525096525095 service_time: 611 s_time: 52 penalty: 0 agent_num: 37 done: False
______________________
id: 40 reward: -0.025510204081632654 service_time: 427 s_time: 50 penalty: 0 agent_num: 35 done: False
______________________
id: 45 reward: -0.0163265306122449 service_time: 2164 s_time: 32 penalty: 0 agent_num: 35 done: False
______________________
id: 55 reward: 0.0 service_time: 576 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 48 reward: 0.0 service_time: 569 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 52 reward: 0.0 service_time: 2030 s_time: 0 penalty: 0 agent_num: 40 done: False
______________________
Step:  2864
Pretraining Loss:  tensor(0.2593, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: 0.011363636363636364 service_time: 320 s_time: -7 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: -0.1767857142857143 service_time: 3260 s_time: 99 penalty: 0 agent_num: 10 done: False
______________________
id: 46 reward: -0.29642857142857143 service_time: 4700 s_time: 166 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: -0.12987012987012986 service_time: 3405 s_time: 80 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: 0.0 service_time: 284 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 42 reward: -0.015873015873015872 service_time: 245 s_time: 24 penalty: 0 agent_num: 27 done: False
______________________
id: 50 reward: -0.008928571428571428 service_time: 435 s_time: 11 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: -0.07142857142857142 service_time: 391 s_time: 92 penalty: 0 agent_num: 23 done: False
______________________
id: 40 reward: -0.01479591836734694 service_time: 456 s_time: 29 penalty: 0 agent_num: 35 done: False
______________________
id: 44 reward: -0.018601190476190476 service_time: 1891 s_time: 25 penalty: 0 agent_num: 24 done: False
______________________
id: 53 reward: -0.013937282229965157 service_time: 275 s_time: 32 penalty: 0 agent_num: 41 done: False
______________________
id: 55 reward: -0.010093167701863354 service_time: 602 s_time: 26 penalty: 0 agent_num: 46 done: False
______________________
id: 54 reward: -0.005791505791505791 service_time: 623 s_time: 12 penalty: 0 agent_num: 37 done: False
______________________
id: 45 reward: 0.0 service_time: 2164 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.022903726708074536 service_time: 628 s_time: 59 penalty: 0 agent_num: 46 done: False
______________________
id: 52 reward: -0.007142857142857143 service_time: 2046 s_time: 16 penalty: 0 agent_num: 40 done: False
______________________
Step:  2880
Pretraining Loss:  tensor(0.2958, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: 0.0 service_time: 320 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 43 reward: -0.2077922077922078 service_time: 3533 s_time: 128 penalty: 0 agent_num: 11 done: False
______________________
id: 46 reward: -0.2375 service_time: 4833 s_time: 133 penalty: 0 agent_num: 10 done: False
______________________
id: 47 reward: -0.01607142857142857 service_time: 302 s_time: 18 penalty: 0 agent_num: 20 done: False
______________________
id: 49 reward: -0.1625 service_time: 3351 s_time: 91 penalty: 0 agent_num: 10 done: False
______________________
id: 45 reward: -0.008673469387755102 service_time: 2181 s_time: 17 penalty: 0 agent_num: 35 done: False
______________________
id: 44 reward: -0.028273809523809524 service_time: 1929 s_time: 38 penalty: 0 agent_num: 24 done: False
______________________
id: 53 reward: 0.0 service_time: 275 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 50 reward: -0.02353896103896104 service_time: 464 s_time: 29 penalty: 0 agent_num: 22 done: False
______________________
id: 40 reward: -0.04030612244897959 service_time: 535 s_time: 79 penalty: 0 agent_num: 35 done: False
______________________
id: 55 reward: 0.0 service_time: 602 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 51 reward: -0.02872670807453416 service_time: 428 s_time: 37 penalty: 0 agent_num: 23 done: False
______________________
id: 54 reward: -0.012548262548262547 service_time: 649 s_time: 26 penalty: 0 agent_num: 37 done: False
______________________
id: 42 reward: -0.01984126984126984 service_time: 275 s_time: 30 penalty: 0 agent_num: 27 done: False
______________________
id: 48 reward: 0.0 service_time: 628 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 52 reward: 0.0 service_time: 2046 s_time: 0 penalty: 0 agent_num: 40 done: False
______________________
Step:  2896
Pretraining Loss:  tensor(0.2568, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.017857142857142856 service_time: 331 s_time: 11 penalty: 0 agent_num: 11 done: False
______________________
id: 46 reward: -0.9267857142857143 service_time: 5352 s_time: 519 penalty: 0 agent_num: 10 done: False
______________________
id: 49 reward: -0.32142857142857145 service_time: 3531 s_time: 180 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: -0.25811688311688313 service_time: 3692 s_time: 159 penalty: 0 agent_num: 11 done: False
______________________
id: 42 reward: -0.007936507936507936 service_time: 287 s_time: 12 penalty: 0 agent_num: 27 done: False
______________________
id: 47 reward: 0.0 service_time: 302 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 50 reward: -0.01461038961038961 service_time: 482 s_time: 18 penalty: 0 agent_num: 22 done: False
______________________
id: 44 reward: 0.002232142857142857 service_time: 1926 s_time: -3 penalty: 0 agent_num: 24 done: False
______________________
id: 53 reward: -0.009146341463414634 service_time: 296 s_time: 21 penalty: 0 agent_num: 41 done: False
______________________
id: 40 reward: 0.011224489795918367 service_time: 513 s_time: -22 penalty: 0 agent_num: 35 done: False
______________________
id: 51 reward: -0.034161490683229816 service_time: 472 s_time: 44 penalty: 0 agent_num: 23 done: False
______________________
id: 45 reward: -0.0163265306122449 service_time: 2213 s_time: 32 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.01203416149068323 service_time: 659 s_time: 31 penalty: 0 agent_num: 46 done: False
______________________
id: 54 reward: 0.0 service_time: 649 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 52 reward: 0.0 service_time: 2046 s_time: 0 penalty: 0 agent_num: 40 done: False
______________________
id: 55 reward: -0.021739130434782608 service_time: 658 s_time: 56 penalty: 0 agent_num: 46 done: False
______________________
Step:  2912
Pretraining Loss:  tensor(0.2745, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: 0.003246753246753247 service_time: 329 s_time: -2 penalty: 0 agent_num: 11 done: False
______________________
id: 43 reward: -0.3587662337662338 service_time: 3913 s_time: 221 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: -0.23214285714285715 service_time: 3661 s_time: 130 penalty: 0 agent_num: 10 done: False
______________________
id: 46 reward: -0.2732142857142857 service_time: 5505 s_time: 153 penalty: 0 agent_num: 10 done: False
______________________
id: 47 reward: -0.025 service_time: 330 s_time: 28 penalty: 0 agent_num: 20 done: False
______________________
id: 44 reward: -0.029017857142857144 service_time: 1965 s_time: 39 penalty: 0 agent_num: 24 done: False
______________________
id: 40 reward: -0.012755102040816327 service_time: 538 s_time: 25 penalty: 0 agent_num: 35 done: False
______________________
id: 51 reward: 0.0015527950310559005 service_time: 470 s_time: -2 penalty: 0 agent_num: 23 done: False
______________________
id: 45 reward: 0.0 service_time: 2213 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 42 reward: 0.0 service_time: 287 s_time: 0 penalty: 0 agent_num: 27 done: False
______________________
id: 48 reward: -0.01591614906832298 service_time: 700 s_time: 41 penalty: 0 agent_num: 46 done: False
______________________
id: 50 reward: -0.012987012987012988 service_time: 498 s_time: 16 penalty: 0 agent_num: 22 done: False
______________________
id: 54 reward: -0.02557915057915058 service_time: 702 s_time: 53 penalty: 0 agent_num: 37 done: False
______________________
id: 52 reward: -0.004910714285714286 service_time: 2057 s_time: 11 penalty: 0 agent_num: 40 done: False
______________________
id: 53 reward: -0.04965156794425087 service_time: 410 s_time: 114 penalty: 0 agent_num: 41 done: False
______________________
id: 55 reward: -0.012422360248447204 service_time: 690 s_time: 32 penalty: 0 agent_num: 46 done: False
______________________
Step:  2928
Pretraining Loss:  tensor(0.2618, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: 0.0 service_time: 329 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: -0.29642857142857143 service_time: 3827 s_time: 166 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: -0.14772727272727273 service_time: 4004 s_time: 91 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: 0.0 service_time: 330 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 46 reward: -0.2571428571428571 service_time: 5649 s_time: 144 penalty: 0 agent_num: 10 done: False
______________________
id: 42 reward: -0.027116402116402115 service_time: 328 s_time: 41 penalty: 0 agent_num: 27 done: False
______________________
id: 50 reward: -0.033279220779220776 service_time: 539 s_time: 41 penalty: 0 agent_num: 22 done: False
______________________
id: 44 reward: 0.0 service_time: 1965 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 40 reward: -0.007142857142857143 service_time: 552 s_time: 14 penalty: 0 agent_num: 35 done: False
______________________
id: 51 reward: 0.015527950310559006 service_time: 450 s_time: -20 penalty: 0 agent_num: 23 done: False
______________________
id: 54 reward: 0.0 service_time: 702 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 48 reward: 0.0 service_time: 700 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 45 reward: -0.01479591836734694 service_time: 2242 s_time: 29 penalty: 0 agent_num: 35 done: False
______________________
id: 55 reward: -0.01203416149068323 service_time: 721 s_time: 31 penalty: 0 agent_num: 46 done: False
______________________
id: 52 reward: 0.0017857142857142857 service_time: 2053 s_time: -4 penalty: 0 agent_num: 40 done: False
______________________
id: 53 reward: 0.010017421602787456 service_time: 387 s_time: -23 penalty: 0 agent_num: 41 done: False
______________________
Step:  2944
Pretraining Loss:  tensor(0.2373, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: 0.0 service_time: 329 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 46 reward: -0.3625 service_time: 5852 s_time: 203 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: -0.30357142857142855 service_time: 4191 s_time: 187 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: 0.0 service_time: 330 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 51 reward: -0.008540372670807454 service_time: 461 s_time: 11 penalty: 0 agent_num: 23 done: False
______________________
id: 49 reward: -0.24642857142857144 service_time: 3965 s_time: 138 penalty: 0 agent_num: 10 done: False
______________________
id: 44 reward: -0.009672619047619048 service_time: 1978 s_time: 13 penalty: 0 agent_num: 24 done: False
______________________
id: 40 reward: -0.013265306122448979 service_time: 578 s_time: 26 penalty: 0 agent_num: 35 done: False
______________________
id: 42 reward: -0.01917989417989418 service_time: 357 s_time: 29 penalty: 0 agent_num: 27 done: False
______________________
id: 45 reward: -0.004081632653061225 service_time: 2250 s_time: 8 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.021350931677018632 service_time: 755 s_time: 55 penalty: 0 agent_num: 46 done: False
______________________
id: 55 reward: -0.007375776397515528 service_time: 740 s_time: 19 penalty: 0 agent_num: 46 done: False
______________________
id: 54 reward: -0.036196911196911194 service_time: 777 s_time: 75 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: -0.014372822299651568 service_time: 420 s_time: 33 penalty: 0 agent_num: 41 done: False
______________________
id: 50 reward: -0.016233766233766232 service_time: 559 s_time: 20 penalty: 0 agent_num: 22 done: False
______________________
id: 52 reward: -0.014732142857142857 service_time: 2086 s_time: 33 penalty: 0 agent_num: 40 done: False
______________________
Step:  2960
Pretraining Loss:  tensor(0.2677, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: 0.0 service_time: 329 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 43 reward: -0.21266233766233766 service_time: 4322 s_time: 131 penalty: 0 agent_num: 11 done: False
______________________
id: 46 reward: -0.2892857142857143 service_time: 6014 s_time: 162 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: -0.049689440993788817 service_time: 525 s_time: 64 penalty: 0 agent_num: 23 done: False
______________________
id: 47 reward: -0.007142857142857143 service_time: 338 s_time: 8 penalty: 0 agent_num: 20 done: False
______________________
id: 42 reward: -0.015873015873015872 service_time: 381 s_time: 24 penalty: 0 agent_num: 27 done: False
______________________
id: 44 reward: -0.025297619047619048 service_time: 2012 s_time: 34 penalty: 0 agent_num: 24 done: False
______________________
id: 49 reward: -0.2642857142857143 service_time: 4113 s_time: 148 penalty: 0 agent_num: 10 done: False
______________________
id: 53 reward: -0.004355400696864111 service_time: 430 s_time: 10 penalty: 0 agent_num: 41 done: False
______________________
id: 45 reward: -0.009183673469387756 service_time: 2268 s_time: 18 penalty: 0 agent_num: 35 done: False
______________________
id: 55 reward: 0.0 service_time: 740 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 48 reward: -0.011645962732919254 service_time: 785 s_time: 30 penalty: 0 agent_num: 46 done: False
______________________
id: 40 reward: -0.02142857142857143 service_time: 620 s_time: 42 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: -0.0028957528957528956 service_time: 783 s_time: 6 penalty: 0 agent_num: 37 done: False
______________________
id: 50 reward: -0.010551948051948052 service_time: 572 s_time: 13 penalty: 0 agent_num: 22 done: False
______________________
id: 52 reward: -0.010267857142857143 service_time: 2109 s_time: 23 penalty: 0 agent_num: 40 done: False
______________________
Step:  2976
Pretraining Loss:  tensor(0.2619, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: 0.030844155844155844 service_time: 310 s_time: -19 penalty: 0 agent_num: 11 done: False
______________________
id: 46 reward: -0.33035714285714285 service_time: 6199 s_time: 185 penalty: 0 agent_num: 10 done: False
______________________
id: 49 reward: -0.26964285714285713 service_time: 4264 s_time: 151 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: -0.2532467532467532 service_time: 4478 s_time: 156 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: 0.0 service_time: 2012 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 47 reward: -0.016964285714285713 service_time: 357 s_time: 19 penalty: 0 agent_num: 20 done: False
______________________
id: 51 reward: -0.029503105590062112 service_time: 563 s_time: 38 penalty: 0 agent_num: 23 done: False
______________________
id: 45 reward: -0.012244897959183673 service_time: 2292 s_time: 24 penalty: 0 agent_num: 35 done: False
______________________
id: 50 reward: -0.025162337662337664 service_time: 603 s_time: 31 penalty: 0 agent_num: 22 done: False
______________________
id: 40 reward: -0.014285714285714285 service_time: 648 s_time: 28 penalty: 0 agent_num: 35 done: False
______________________
id: 53 reward: -0.008275261324041812 service_time: 449 s_time: 19 penalty: 0 agent_num: 41 done: False
______________________
id: 42 reward: -0.03306878306878307 service_time: 431 s_time: 50 penalty: 0 agent_num: 27 done: False
______________________
id: 55 reward: -0.01281055900621118 service_time: 773 s_time: 33 penalty: 0 agent_num: 46 done: False
______________________
id: 52 reward: 0.0 service_time: 2109 s_time: 0 penalty: 0 agent_num: 40 done: False
______________________
id: 48 reward: -0.008928571428571428 service_time: 808 s_time: 23 penalty: 0 agent_num: 46 done: False
______________________
id: 54 reward: -0.016891891891891893 service_time: 818 s_time: 35 penalty: 0 agent_num: 37 done: False
______________________
Step:  2992
Pretraining Loss:  tensor(0.3609, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.045454545454545456 service_time: 338 s_time: 28 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: -0.3107142857142857 service_time: 4438 s_time: 174 penalty: 0 agent_num: 10 done: False
______________________
id: 46 reward: -0.3375 service_time: 6388 s_time: 189 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: -0.7012987012987013 service_time: 4910 s_time: 432 penalty: 0 agent_num: 11 done: False
______________________
id: 51 reward: -0.012422360248447204 service_time: 579 s_time: 16 penalty: 0 agent_num: 23 done: False
______________________
id: 47 reward: -0.02857142857142857 service_time: 389 s_time: 32 penalty: 0 agent_num: 20 done: False
______________________
id: 44 reward: -0.020089285714285716 service_time: 2039 s_time: 27 penalty: 0 agent_num: 24 done: False
______________________
id: 53 reward: -0.013937282229965157 service_time: 481 s_time: 32 penalty: 0 agent_num: 41 done: False
______________________
id: 48 reward: -0.007763975155279503 service_time: 828 s_time: 20 penalty: 0 agent_num: 46 done: False
______________________
id: 45 reward: 0.0 service_time: 2292 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 55 reward: -0.006987577639751553 service_time: 791 s_time: 18 penalty: 0 agent_num: 46 done: False
______________________
id: 54 reward: -0.011583011583011582 service_time: 842 s_time: 24 penalty: 0 agent_num: 37 done: False
______________________
id: 40 reward: -0.01683673469387755 service_time: 681 s_time: 33 penalty: 0 agent_num: 35 done: False
______________________
id: 50 reward: 0.0 service_time: 603 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 52 reward: -0.0125 service_time: 2137 s_time: 28 penalty: 0 agent_num: 40 done: False
______________________
id: 42 reward: -0.0205026455026455 service_time: 462 s_time: 31 penalty: 0 agent_num: 27 done: False
______________________
Step:  3008
Pretraining Loss:  tensor(0.2860, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.05357142857142857 service_time: 371 s_time: 33 penalty: 0 agent_num: 11 done: False
______________________
id: 43 reward: -0.18668831168831168 service_time: 5025 s_time: 115 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: -0.22678571428571428 service_time: 4565 s_time: 127 penalty: 0 agent_num: 10 done: False
______________________
id: 47 reward: 0.0008928571428571428 service_time: 388 s_time: -1 penalty: 0 agent_num: 20 done: False
______________________
id: 51 reward: -0.024844720496894408 service_time: 611 s_time: 32 penalty: 0 agent_num: 23 done: False
______________________
id: 46 reward: -0.29642857142857143 service_time: 6554 s_time: 166 penalty: 0 agent_num: 10 done: False
______________________
id: 44 reward: 0.0 service_time: 2039 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: -0.01173469387755102 service_time: 2315 s_time: 23 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: -0.010617760617760617 service_time: 864 s_time: 22 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: -0.012630662020905924 service_time: 510 s_time: 29 penalty: 0 agent_num: 41 done: False
______________________
id: 40 reward: -0.012755102040816327 service_time: 706 s_time: 25 penalty: 0 agent_num: 35 done: False
______________________
id: 55 reward: -0.008152173913043478 service_time: 812 s_time: 21 penalty: 0 agent_num: 46 done: False
______________________
id: 52 reward: 0.0 service_time: 2137 s_time: 0 penalty: 0 agent_num: 40 done: False
______________________
id: 42 reward: -0.02976190476190476 service_time: 507 s_time: 45 penalty: 0 agent_num: 27 done: False
______________________
id: 50 reward: -0.07467532467532467 service_time: 695 s_time: 92 penalty: 0 agent_num: 22 done: False
______________________
id: 48 reward: -0.017080745341614908 service_time: 872 s_time: 44 penalty: 0 agent_num: 46 done: False
______________________
Step:  3024
Pretraining Loss:  tensor(0.3399, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: 0.0 service_time: 371 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 43 reward: -0.5422077922077922 service_time: 5359 s_time: 334 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: -0.0125 service_time: 402 s_time: 14 penalty: 0 agent_num: 20 done: False
______________________
id: 49 reward: -0.2767857142857143 service_time: 4720 s_time: 155 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: -0.02717391304347826 service_time: 646 s_time: 35 penalty: 0 agent_num: 23 done: False
______________________
id: 46 reward: -0.30357142857142855 service_time: 6724 s_time: 170 penalty: 0 agent_num: 10 done: False
______________________
id: 44 reward: -0.006696428571428571 service_time: 2048 s_time: 9 penalty: 0 agent_num: 24 done: False
______________________
id: 45 reward: 0.0 service_time: 2315 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 40 reward: -0.01479591836734694 service_time: 735 s_time: 29 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: 0.0009652509652509653 service_time: 862 s_time: -2 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: -0.008710801393728223 service_time: 530 s_time: 20 penalty: 0 agent_num: 41 done: False
______________________
id: 55 reward: -0.010093167701863354 service_time: 838 s_time: 26 penalty: 0 agent_num: 46 done: False
______________________
id: 50 reward: -0.025974025974025976 service_time: 727 s_time: 32 penalty: 0 agent_num: 22 done: False
______________________
id: 48 reward: 0.0011645962732919255 service_time: 869 s_time: -3 penalty: 0 agent_num: 46 done: False
______________________
id: 52 reward: -0.008928571428571428 service_time: 2157 s_time: 20 penalty: 0 agent_num: 40 done: False
______________________
id: 42 reward: -0.008597883597883597 service_time: 520 s_time: 13 penalty: 0 agent_num: 27 done: False
______________________
Step:  3040
Pretraining Loss:  tensor(0.2998, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.30714285714285716 service_time: 4892 s_time: 172 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: -0.05844155844155844 service_time: 407 s_time: 36 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: -0.0125 service_time: 416 s_time: 14 penalty: 0 agent_num: 20 done: False
______________________
id: 51 reward: -0.02251552795031056 service_time: 675 s_time: 29 penalty: 0 agent_num: 23 done: False
______________________
id: 46 reward: -0.38392857142857145 service_time: 6939 s_time: 215 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: -0.5081168831168831 service_time: 5672 s_time: 313 penalty: 0 agent_num: 11 done: False
______________________
id: 40 reward: -0.011224489795918367 service_time: 757 s_time: 22 penalty: 0 agent_num: 35 done: False
______________________
id: 44 reward: 0.0 service_time: 2048 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 54 reward: -0.023166023166023165 service_time: 910 s_time: 48 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: 0.0 service_time: 530 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 45 reward: -0.011224489795918367 service_time: 2337 s_time: 22 penalty: 0 agent_num: 35 done: False
______________________
id: 55 reward: -0.011645962732919254 service_time: 868 s_time: 30 penalty: 0 agent_num: 46 done: False
______________________
id: 52 reward: -0.003125 service_time: 2164 s_time: 7 penalty: 0 agent_num: 40 done: False
______________________
id: 50 reward: -0.017857142857142856 service_time: 749 s_time: 22 penalty: 0 agent_num: 22 done: False
______________________
id: 48 reward: -0.01746894409937888 service_time: 914 s_time: 45 penalty: 0 agent_num: 46 done: False
______________________
id: 42 reward: -0.03042328042328042 service_time: 566 s_time: 46 penalty: 0 agent_num: 27 done: False
______________________
Step:  3056
Pretraining Loss:  tensor(0.3037, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: 0.0 service_time: 407 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: 0.0 service_time: 416 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 49 reward: -0.5696428571428571 service_time: 5211 s_time: 319 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: -0.3344155844155844 service_time: 5878 s_time: 206 penalty: 0 agent_num: 11 done: False
______________________
id: 46 reward: -0.4089285714285714 service_time: 7168 s_time: 229 penalty: 0 agent_num: 10 done: False
______________________
id: 44 reward: 0.0 service_time: 2048 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 40 reward: -0.015306122448979591 service_time: 787 s_time: 30 penalty: 0 agent_num: 35 done: False
______________________
id: 45 reward: -0.011224489795918367 service_time: 2359 s_time: 22 penalty: 0 agent_num: 35 done: False
______________________
id: 53 reward: -0.01088850174216028 service_time: 555 s_time: 25 penalty: 0 agent_num: 41 done: False
______________________
id: 54 reward: -0.017374517374517374 service_time: 946 s_time: 36 penalty: 0 agent_num: 37 done: False
______________________
id: 51 reward: -0.026397515527950312 service_time: 709 s_time: 34 penalty: 0 agent_num: 23 done: False
______________________
id: 55 reward: -0.005434782608695652 service_time: 882 s_time: 14 penalty: 0 agent_num: 46 done: False
______________________
id: 48 reward: 0.0007763975155279503 service_time: 912 s_time: -2 penalty: 0 agent_num: 46 done: False
______________________
id: 52 reward: -0.011607142857142858 service_time: 2190 s_time: 26 penalty: 0 agent_num: 40 done: False
______________________
id: 50 reward: -0.007305194805194805 service_time: 758 s_time: 9 penalty: 0 agent_num: 22 done: False
______________________
id: 42 reward: -0.021164021164021163 service_time: 598 s_time: 32 penalty: 0 agent_num: 27 done: False
______________________
Step:  3072
Pretraining Loss:  tensor(0.3735, device='cuda:0', grad_fn=<MeanBackward0>)
id: 43 reward: -0.6444805194805194 service_time: 6275 s_time: 397 penalty: 0 agent_num: 11 done: False
______________________
id: 41 reward: 0.0 service_time: 407 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: 0.0 service_time: 416 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 49 reward: -0.38571428571428573 service_time: 5427 s_time: 216 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: -0.03183229813664596 service_time: 750 s_time: 41 penalty: 0 agent_num: 23 done: False
______________________
id: 46 reward: -0.37142857142857144 service_time: 7376 s_time: 208 penalty: 0 agent_num: 10 done: False
______________________
id: 40 reward: 0.0 service_time: 787 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 45 reward: 0.0 service_time: 2359 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 55 reward: -0.007375776397515528 service_time: 901 s_time: 19 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: -0.016114982578397212 service_time: 592 s_time: 37 penalty: 0 agent_num: 41 done: False
______________________
id: 50 reward: -0.01461038961038961 service_time: 776 s_time: 18 penalty: 0 agent_num: 22 done: False
______________________
id: 44 reward: -0.03422619047619048 service_time: 2094 s_time: 46 penalty: 0 agent_num: 24 done: False
______________________
id: 54 reward: 0.00048262548262548264 service_time: 945 s_time: -1 penalty: 0 agent_num: 37 done: False
______________________
id: 52 reward: 0.0 service_time: 2190 s_time: 0 penalty: 0 agent_num: 40 done: False
______________________
id: 48 reward: -0.009316770186335404 service_time: 936 s_time: 24 penalty: 0 agent_num: 46 done: False
______________________
id: 42 reward: -0.011904761904761904 service_time: 616 s_time: 18 penalty: 0 agent_num: 27 done: False
______________________
Step:  3088
Pretraining Loss:  tensor(0.3544, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: 0.0 service_time: 407 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: -0.6625 service_time: 5798 s_time: 371 penalty: 0 agent_num: 10 done: False
______________________
id: 47 reward: -0.016964285714285713 service_time: 435 s_time: 19 penalty: 0 agent_num: 20 done: False
______________________
id: 46 reward: -0.49642857142857144 service_time: 7654 s_time: 278 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: -0.2905844155844156 service_time: 6454 s_time: 179 penalty: 0 agent_num: 11 done: False
______________________
id: 40 reward: -0.0336734693877551 service_time: 853 s_time: 66 penalty: 0 agent_num: 35 done: False
______________________
id: 44 reward: -0.014136904761904762 service_time: 2113 s_time: 19 penalty: 0 agent_num: 24 done: False
______________________
id: 51 reward: -0.03881987577639751 service_time: 800 s_time: 50 penalty: 0 agent_num: 23 done: False
______________________
id: 54 reward: -0.01833976833976834 service_time: 983 s_time: 38 penalty: 0 agent_num: 37 done: False
______________________
id: 48 reward: -0.005822981366459627 service_time: 951 s_time: 15 penalty: 0 agent_num: 46 done: False
______________________
id: 45 reward: -0.018877551020408164 service_time: 2396 s_time: 37 penalty: 0 agent_num: 35 done: False
______________________
id: 55 reward: -0.008152173913043478 service_time: 922 s_time: 21 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: -0.014808362369337979 service_time: 626 s_time: 34 penalty: 0 agent_num: 41 done: False
______________________
id: 50 reward: 0.0 service_time: 776 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 52 reward: 0.0 service_time: 2190 s_time: 0 penalty: 0 agent_num: 40 done: False
______________________
id: 42 reward: -0.011904761904761904 service_time: 634 s_time: 18 penalty: 0 agent_num: 27 done: False
______________________
Step:  3104
Pretraining Loss:  tensor(0.3266, device='cuda:0', grad_fn=<MeanBackward0>)
id: 49 reward: -0.3339285714285714 service_time: 5985 s_time: 187 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: 0.0 service_time: 407 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: 0.0 service_time: 435 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 46 reward: -0.4392857142857143 service_time: 7900 s_time: 246 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: -0.6948051948051948 service_time: 6882 s_time: 428 penalty: 0 agent_num: 11 done: False
______________________
id: 45 reward: -0.001530612244897959 service_time: 2399 s_time: 3 penalty: 0 agent_num: 35 done: False
______________________
id: 40 reward: -0.014285714285714285 service_time: 881 s_time: 28 penalty: 0 agent_num: 35 done: False
______________________
id: 50 reward: 0.028409090909090908 service_time: 741 s_time: -35 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: -0.03571428571428571 service_time: 846 s_time: 46 penalty: 0 agent_num: 23 done: False
______________________
id: 54 reward: -0.020752895752895753 service_time: 1026 s_time: 43 penalty: 0 agent_num: 37 done: False
______________________
id: 55 reward: -0.009316770186335404 service_time: 946 s_time: 24 penalty: 0 agent_num: 46 done: False
______________________
id: 44 reward: 0.0 service_time: 2113 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 53 reward: -0.014808362369337979 service_time: 660 s_time: 34 penalty: 0 agent_num: 41 done: False
______________________
id: 42 reward: 0.004629629629629629 service_time: 627 s_time: -7 penalty: 0 agent_num: 27 done: False
______________________
id: 48 reward: -0.020186335403726708 service_time: 1003 s_time: 52 penalty: 0 agent_num: 46 done: False
______________________
id: 52 reward: -0.00625 service_time: 2204 s_time: 14 penalty: 0 agent_num: 40 done: False
______________________
Step:  3120
Pretraining Loss:  tensor(0.3348, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: 0.0 service_time: 407 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: 0.0 service_time: 435 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 49 reward: -0.4125 service_time: 6216 s_time: 231 penalty: 0 agent_num: 10 done: False
______________________
id: 43 reward: -0.237012987012987 service_time: 7028 s_time: 146 penalty: 0 agent_num: 11 done: False
______________________
id: 40 reward: 0.0010204081632653062 service_time: 879 s_time: -2 penalty: 0 agent_num: 35 done: False
______________________
id: 51 reward: 0.02562111801242236 service_time: 813 s_time: -33 penalty: 0 agent_num: 23 done: False
______________________
id: 45 reward: -0.01683673469387755 service_time: 2432 s_time: 33 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: 0.0011645962732919255 service_time: 1000 s_time: -3 penalty: 0 agent_num: 46 done: False
______________________
id: 46 reward: 0.0 service_time: 7900 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 54 reward: -0.013996138996138996 service_time: 1055 s_time: 29 penalty: 0 agent_num: 37 done: False
______________________
id: 55 reward: -0.006987577639751553 service_time: 964 s_time: 18 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: 0.0 service_time: 660 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 50 reward: 0.0016233766233766235 service_time: 739 s_time: -2 penalty: 0 agent_num: 22 done: False
______________________
id: 44 reward: -0.01636904761904762 service_time: 2135 s_time: 22 penalty: 0 agent_num: 24 done: False
______________________
id: 52 reward: -0.005803571428571429 service_time: 2217 s_time: 13 penalty: 0 agent_num: 40 done: False
______________________
id: 42 reward: -0.046957671957671955 service_time: 698 s_time: 71 penalty: 0 agent_num: 27 done: False
______________________
Step:  3136
Pretraining Loss:  tensor(0.4729, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.04383116883116883 service_time: 434 s_time: 27 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: -0.4089285714285714 service_time: 6445 s_time: 229 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: -0.030279503105590064 service_time: 852 s_time: 39 penalty: 0 agent_num: 23 done: False
______________________
id: 45 reward: 0.0010204081632653062 service_time: 2430 s_time: -2 penalty: 0 agent_num: 35 done: False
______________________
id: 50 reward: -0.017045454545454544 service_time: 760 s_time: 21 penalty: 0 agent_num: 22 done: False
______________________
id: 44 reward: 0.0 service_time: 2135 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 54 reward: -0.009652509652509652 service_time: 1075 s_time: 20 penalty: 0 agent_num: 37 done: False
______________________
id: 47 reward: -0.03660714285714286 service_time: 476 s_time: 41 penalty: 0 agent_num: 20 done: False
______________________
id: 40 reward: -0.034183673469387756 service_time: 946 s_time: 67 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.01281055900621118 service_time: 1033 s_time: 33 penalty: 0 agent_num: 46 done: False
______________________
id: 46 reward: 20.001785714285713 service_time: 7899 s_time: -1 penalty: 0 agent_num: 10 done: True
______________________
id: 55 reward: 0.0 service_time: 964 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: -0.028310104529616725 service_time: 725 s_time: 65 penalty: 0 agent_num: 41 done: False
______________________
id: 52 reward: -0.012053571428571429 service_time: 2244 s_time: 27 penalty: 0 agent_num: 40 done: False
______________________
id: 43 reward: 19.636363636363637 service_time: 7252 s_time: 224 penalty: 0 agent_num: 11 done: True
______________________
id: 42 reward: -0.018518518518518517 service_time: 726 s_time: 28 penalty: 0 agent_num: 27 done: False
______________________
Step:  3152
Pretraining Loss:  tensor(0.7155, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.06168831168831169 service_time: 472 s_time: 38 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: -0.04017857142857143 service_time: 521 s_time: 45 penalty: 0 agent_num: 20 done: False
______________________
id: 49 reward: -0.29642857142857143 service_time: 6611 s_time: 166 penalty: 0 agent_num: 10 done: False
______________________
id: 50 reward: 0.008928571428571428 service_time: 749 s_time: -11 penalty: 0 agent_num: 22 done: False
______________________
id: 46 reward: -0.005398671096345515 service_time: 13 s_time: 13 penalty: 0 agent_num: 43 done: False
______________________
id: 54 reward: -0.006756756756756757 service_time: 1089 s_time: 14 penalty: 0 agent_num: 37 done: False
______________________
id: 40 reward: -0.015816326530612244 service_time: 977 s_time: 31 penalty: 0 agent_num: 35 done: False
______________________
id: 45 reward: -0.001530612244897959 service_time: 2433 s_time: 3 penalty: 0 agent_num: 35 done: False
______________________
id: 43 reward: -0.009453781512605041 service_time: 18 s_time: 18 penalty: 0 agent_num: 34 done: False
______________________
id: 55 reward: -0.004658385093167702 service_time: 976 s_time: 12 penalty: 0 agent_num: 46 done: False
______________________
id: 51 reward: -0.031055900621118012 service_time: 892 s_time: 40 penalty: 0 agent_num: 23 done: False
______________________
id: 44 reward: -0.014136904761904762 service_time: 2154 s_time: 19 penalty: 0 agent_num: 24 done: False
______________________
id: 52 reward: 0.0 service_time: 2244 s_time: 0 penalty: 0 agent_num: 40 done: False
______________________
id: 48 reward: -0.01048136645962733 service_time: 1060 s_time: 27 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: -0.01088850174216028 service_time: 750 s_time: 25 penalty: 0 agent_num: 41 done: False
______________________
id: 42 reward: 0.003968253968253968 service_time: 720 s_time: -6 penalty: 0 agent_num: 27 done: False
______________________
Step:  3168
Pretraining Loss:  tensor(0.2566, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.04707792207792208 service_time: 501 s_time: 29 penalty: 0 agent_num: 11 done: False
______________________
id: 43 reward: -0.01523109243697479 service_time: 47 s_time: 29 penalty: 0 agent_num: 34 done: False
______________________
id: 46 reward: -0.012458471760797342 service_time: 43 s_time: 30 penalty: 0 agent_num: 43 done: False
______________________
id: 47 reward: -0.015178571428571428 service_time: 538 s_time: 17 penalty: 0 agent_num: 20 done: False
______________________
id: 44 reward: 0.0 service_time: 2154 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 49 reward: -0.7535714285714286 service_time: 7033 s_time: 422 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: -0.06521739130434782 service_time: 976 s_time: 84 penalty: 0 agent_num: 23 done: False
______________________
id: 55 reward: -0.010093167701863354 service_time: 1002 s_time: 26 penalty: 0 agent_num: 46 done: False
______________________
id: 54 reward: 0.0009652509652509653 service_time: 1087 s_time: -2 penalty: 0 agent_num: 37 done: False
______________________
id: 40 reward: -0.008673469387755102 service_time: 994 s_time: 17 penalty: 0 agent_num: 35 done: False
______________________
id: 50 reward: -0.05438311688311688 service_time: 816 s_time: 67 penalty: 0 agent_num: 22 done: False
______________________
id: 48 reward: -0.005822981366459627 service_time: 1075 s_time: 15 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: -0.002613240418118467 service_time: 756 s_time: 6 penalty: 0 agent_num: 41 done: False
______________________
id: 52 reward: -0.015625 service_time: 2279 s_time: 35 penalty: 0 agent_num: 40 done: False
______________________
id: 42 reward: -0.018518518518518517 service_time: 748 s_time: 28 penalty: 0 agent_num: 27 done: False
______________________
id: 45 reward: 20.00357142857143 service_time: 2426 s_time: -7 penalty: 0 agent_num: 35 done: True
______________________
------------------------------------
| time/                 |          |
|    fps                | 7        |
|    iterations         | 200      |
|    time_elapsed       | 405      |
|    total_timesteps    | 3200     |
| train/                |          |
|    entropy_loss       | 0.000888 |
|    explained_variance | -28.9    |
|    learning_rate      | 1e-05    |
|    n_updates          | 199      |
|    policy_loss        | 0.257    |
|    value_loss         | 0.638    |
------------------------------------
Step:  3184
Pretraining Loss:  tensor(0.2473, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: -0.02142857142857143 service_time: 12 s_time: 12 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: -0.040584415584415584 service_time: 526 s_time: 25 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: 0.0 service_time: 538 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 43 reward: -0.0063025210084033615 service_time: 59 s_time: 12 penalty: 0 agent_num: 34 done: False
______________________
id: 50 reward: -0.06574675324675325 service_time: 897 s_time: 81 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: -0.3875 service_time: 7250 s_time: 217 penalty: 0 agent_num: 10 done: False
______________________
id: 46 reward: -0.007890365448504983 service_time: 62 s_time: 19 penalty: 0 agent_num: 43 done: False
______________________
id: 54 reward: -0.018822393822393823 service_time: 1126 s_time: 39 penalty: 0 agent_num: 37 done: False
______________________
id: 40 reward: -0.015306122448979591 service_time: 1024 s_time: 30 penalty: 0 agent_num: 35 done: False
______________________
id: 55 reward: 0.0 service_time: 1002 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 44 reward: -0.005208333333333333 service_time: 2161 s_time: 7 penalty: 0 agent_num: 24 done: False
______________________
id: 48 reward: -0.01125776397515528 service_time: 1104 s_time: 29 penalty: 0 agent_num: 46 done: False
______________________
id: 52 reward: 0.0 service_time: 2279 s_time: 0 penalty: 0 agent_num: 40 done: False
______________________
id: 53 reward: -0.017857142857142856 service_time: 797 s_time: 41 penalty: 0 agent_num: 41 done: False
______________________
id: 51 reward: -0.024844720496894408 service_time: 1008 s_time: 32 penalty: 0 agent_num: 23 done: False
______________________
id: 42 reward: -0.026455026455026454 service_time: 788 s_time: 40 penalty: 0 agent_num: 27 done: False
______________________
Step:  3200
Pretraining Loss:  tensor(0.3648, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: 0.0 service_time: 12 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: 0.0 service_time: 526 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: -0.4732142857142857 service_time: 7515 s_time: 265 penalty: 0 agent_num: 10 done: False
______________________
id: 47 reward: -0.0008928571428571428 service_time: 539 s_time: 1 penalty: 0 agent_num: 20 done: False
______________________
id: 50 reward: 0.016233766233766232 service_time: 877 s_time: -20 penalty: 0 agent_num: 22 done: False
______________________
id: 43 reward: -0.003676470588235294 service_time: 66 s_time: 7 penalty: 0 agent_num: 34 done: False
______________________
id: 46 reward: -0.007890365448504983 service_time: 81 s_time: 19 penalty: 0 agent_num: 43 done: False
______________________
id: 51 reward: 0.008540372670807454 service_time: 997 s_time: -11 penalty: 0 agent_num: 23 done: False
______________________
id: 44 reward: -0.02976190476190476 service_time: 2201 s_time: 40 penalty: 0 agent_num: 24 done: False
______________________
id: 54 reward: -0.015926640926640926 service_time: 1159 s_time: 33 penalty: 0 agent_num: 37 done: False
______________________
id: 55 reward: -0.01591614906832298 service_time: 1043 s_time: 41 penalty: 0 agent_num: 46 done: False
______________________
id: 40 reward: 0.0005102040816326531 service_time: 1023 s_time: -1 penalty: 0 agent_num: 35 done: False
______________________
id: 52 reward: -0.005357142857142857 service_time: 2291 s_time: 12 penalty: 0 agent_num: 40 done: False
______________________
id: 48 reward: -0.005046583850931677 service_time: 1117 s_time: 13 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: -0.016114982578397212 service_time: 834 s_time: 37 penalty: 0 agent_num: 41 done: False
______________________
id: 42 reward: -0.02513227513227513 service_time: 826 s_time: 38 penalty: 0 agent_num: 27 done: False
______________________
Step:  3216
Pretraining Loss:  tensor(0.3705, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: -0.04285714285714286 service_time: 36 s_time: 24 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: 0.0 service_time: 526 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 50 reward: -0.12012987012987013 service_time: 1025 s_time: 148 penalty: 0 agent_num: 22 done: False
______________________
id: 43 reward: -0.014180672268907563 service_time: 93 s_time: 27 penalty: 0 agent_num: 34 done: False
______________________
id: 46 reward: -0.003737541528239203 service_time: 90 s_time: 9 penalty: 0 agent_num: 43 done: False
______________________
id: 49 reward: -0.42142857142857143 service_time: 7751 s_time: 236 penalty: 0 agent_num: 10 done: False
______________________
id: 54 reward: -0.012548262548262547 service_time: 1185 s_time: 26 penalty: 0 agent_num: 37 done: False
______________________
id: 47 reward: -0.03660714285714286 service_time: 580 s_time: 41 penalty: 0 agent_num: 20 done: False
______________________
id: 55 reward: -0.009704968944099378 service_time: 1068 s_time: 25 penalty: 0 agent_num: 46 done: False
______________________
id: 51 reward: 0.008540372670807454 service_time: 986 s_time: -11 penalty: 0 agent_num: 23 done: False
______________________
id: 44 reward: 0.0 service_time: 2201 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 48 reward: -0.01746894409937888 service_time: 1162 s_time: 45 penalty: 0 agent_num: 46 done: False
______________________
id: 40 reward: -0.02193877551020408 service_time: 1066 s_time: 43 penalty: 0 agent_num: 35 done: False
______________________
id: 52 reward: 0.0 service_time: 2291 s_time: 0 penalty: 0 agent_num: 40 done: False
______________________
id: 42 reward: -0.021825396825396824 service_time: 859 s_time: 33 penalty: 0 agent_num: 27 done: False
______________________
id: 53 reward: -0.008710801393728223 service_time: 854 s_time: 20 penalty: 0 agent_num: 41 done: False
______________________
Step:  3232
Pretraining Loss:  tensor(0.3266, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: 0.0 service_time: 36 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: -0.09902597402597403 service_time: 587 s_time: 61 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: -0.44107142857142856 service_time: 7998 s_time: 247 penalty: 0 agent_num: 10 done: False
______________________
id: 47 reward: -0.02857142857142857 service_time: 612 s_time: 32 penalty: 0 agent_num: 20 done: False
______________________
id: 46 reward: -0.014119601328903655 service_time: 124 s_time: 34 penalty: 0 agent_num: 43 done: False
______________________
id: 43 reward: -0.006827731092436975 service_time: 106 s_time: 13 penalty: 0 agent_num: 34 done: False
______________________
id: 51 reward: 0.0 service_time: 986 s_time: 0 penalty: 0 agent_num: 23 done: False
______________________
id: 44 reward: -0.020833333333333332 service_time: 2229 s_time: 28 penalty: 0 agent_num: 24 done: False
______________________
id: 54 reward: -0.010135135135135136 service_time: 1206 s_time: 21 penalty: 0 agent_num: 37 done: False
______________________
id: 55 reward: 0.0 service_time: 1068 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 40 reward: -0.030612244897959183 service_time: 1126 s_time: 60 penalty: 0 agent_num: 35 done: False
______________________
id: 53 reward: -0.002613240418118467 service_time: 860 s_time: 6 penalty: 0 agent_num: 41 done: False
______________________
id: 48 reward: 0.0 service_time: 1162 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 42 reward: -0.007275132275132275 service_time: 870 s_time: 11 penalty: 0 agent_num: 27 done: False
______________________
id: 50 reward: -0.010551948051948052 service_time: 1038 s_time: 13 penalty: 0 agent_num: 22 done: False
______________________
id: 52 reward: -0.016517857142857143 service_time: 2328 s_time: 37 penalty: 0 agent_num: 40 done: False
______________________
Step:  3248
Pretraining Loss:  tensor(0.3314, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: -0.06607142857142857 service_time: 73 s_time: 37 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: -0.06493506493506493 service_time: 627 s_time: 40 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: -0.023214285714285715 service_time: 638 s_time: 26 penalty: 0 agent_num: 20 done: False
______________________
id: 43 reward: -0.019432773109243698 service_time: 143 s_time: 37 penalty: 0 agent_num: 34 done: False
______________________
id: 51 reward: 0.011645962732919254 service_time: 971 s_time: -15 penalty: 0 agent_num: 23 done: False
______________________
id: 49 reward: 0.0 service_time: 7998 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 46 reward: -0.004152823920265781 service_time: 134 s_time: 10 penalty: 0 agent_num: 43 done: False
______________________
id: 55 reward: -0.013198757763975156 service_time: 1102 s_time: 34 penalty: 0 agent_num: 46 done: False
______________________
id: 44 reward: -0.020089285714285716 service_time: 2256 s_time: 27 penalty: 0 agent_num: 24 done: False
______________________
id: 50 reward: 0.0016233766233766235 service_time: 1036 s_time: -2 penalty: 0 agent_num: 22 done: False
______________________
id: 48 reward: -0.014751552795031056 service_time: 1200 s_time: 38 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: -0.013501742160278746 service_time: 891 s_time: 31 penalty: 0 agent_num: 41 done: False
______________________
id: 40 reward: -0.003061224489795918 service_time: 1132 s_time: 6 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: -0.01447876447876448 service_time: 1236 s_time: 30 penalty: 0 agent_num: 37 done: False
______________________
id: 52 reward: -0.011160714285714286 service_time: 2353 s_time: 25 penalty: 0 agent_num: 40 done: False
______________________
id: 42 reward: 0.003968253968253968 service_time: 864 s_time: -6 penalty: 0 agent_num: 27 done: False
______________________
Step:  3264
Pretraining Loss:  tensor(0.3391, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: -0.05 service_time: 101 s_time: 28 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: -0.045454545454545456 service_time: 655 s_time: 28 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: 0.0 service_time: 638 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 43 reward: 0.0 service_time: 143 s_time: 0 penalty: 0 agent_num: 34 done: False
______________________
id: 51 reward: -0.062111801242236024 service_time: 1051 s_time: 80 penalty: 0 agent_num: 23 done: False
______________________
id: 46 reward: 0.0 service_time: 134 s_time: 0 penalty: 0 agent_num: 43 done: False
______________________
id: 50 reward: 0.026785714285714284 service_time: 1003 s_time: -33 penalty: 0 agent_num: 22 done: False
______________________
id: 44 reward: 0.0 service_time: 2256 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 49 reward: 0.014285714285714285 service_time: 7990 s_time: -8 penalty: 0 agent_num: 10 done: False
______________________
id: 54 reward: -0.017857142857142856 service_time: 1273 s_time: 37 penalty: 0 agent_num: 37 done: False
______________________
id: 55 reward: -0.009704968944099378 service_time: 1127 s_time: 25 penalty: 0 agent_num: 46 done: False
______________________
id: 40 reward: -0.01479591836734694 service_time: 1161 s_time: 29 penalty: 0 agent_num: 35 done: False
______________________
id: 52 reward: 0.0 service_time: 2353 s_time: 0 penalty: 0 agent_num: 40 done: False
______________________
id: 53 reward: -0.010452961672473868 service_time: 915 s_time: 24 penalty: 0 agent_num: 41 done: False
______________________
id: 48 reward: -0.01203416149068323 service_time: 1231 s_time: 31 penalty: 0 agent_num: 46 done: False
______________________
id: 42 reward: -0.03306878306878307 service_time: 914 s_time: 50 penalty: 0 agent_num: 27 done: False
______________________
Step:  3280
Pretraining Loss:  tensor(0.3438, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: -0.04642857142857143 service_time: 127 s_time: 26 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: 0.022727272727272728 service_time: 641 s_time: -14 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: -0.014285714285714285 service_time: 654 s_time: 16 penalty: 0 agent_num: 20 done: False
______________________
id: 43 reward: -0.029936974789915968 service_time: 200 s_time: 57 penalty: 0 agent_num: 34 done: False
______________________
id: 46 reward: -0.02159468438538206 service_time: 186 s_time: 52 penalty: 0 agent_num: 43 done: False
______________________
id: 50 reward: -0.03977272727272727 service_time: 1052 s_time: 49 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: 0.006211180124223602 service_time: 1043 s_time: -8 penalty: 0 agent_num: 23 done: False
______________________
id: 44 reward: -0.009672619047619048 service_time: 2269 s_time: 13 penalty: 0 agent_num: 24 done: False
______________________
id: 54 reward: 0.0 service_time: 1273 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 55 reward: -0.004658385093167702 service_time: 1139 s_time: 12 penalty: 0 agent_num: 46 done: False
______________________
id: 40 reward: -0.01020408163265306 service_time: 1181 s_time: 20 penalty: 0 agent_num: 35 done: False
______________________
id: 53 reward: -0.016986062717770034 service_time: 954 s_time: 39 penalty: 0 agent_num: 41 done: False
______________________
id: 48 reward: -0.009316770186335404 service_time: 1255 s_time: 24 penalty: 0 agent_num: 46 done: False
______________________
id: 49 reward: 20.0 service_time: 7990 s_time: 0 penalty: 0 agent_num: 10 done: True
______________________
id: 42 reward: 0.005952380952380952 service_time: 905 s_time: -9 penalty: 0 agent_num: 27 done: False
______________________
id: 52 reward: -0.013839285714285714 service_time: 2384 s_time: 31 penalty: 0 agent_num: 40 done: False
______________________
Step:  3296
Pretraining Loss:  tensor(0.3959, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: 0.0 service_time: 641 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 45 reward: -0.08214285714285714 service_time: 173 s_time: 46 penalty: 0 agent_num: 10 done: False
______________________
id: 49 reward: -0.02857142857142857 service_time: 32 s_time: 32 penalty: 0 agent_num: 20 done: False
______________________
id: 47 reward: -0.014285714285714285 service_time: 670 s_time: 16 penalty: 0 agent_num: 20 done: False
______________________
id: 51 reward: -0.04192546583850932 service_time: 1097 s_time: 54 penalty: 0 agent_num: 23 done: False
______________________
id: 50 reward: 0.022727272727272728 service_time: 1024 s_time: -28 penalty: 0 agent_num: 22 done: False
______________________
id: 46 reward: -0.011627906976744186 service_time: 214 s_time: 28 penalty: 0 agent_num: 43 done: False
______________________
id: 44 reward: -0.03273809523809524 service_time: 2313 s_time: 44 penalty: 0 agent_num: 24 done: False
______________________
id: 54 reward: -0.027992277992277992 service_time: 1331 s_time: 58 penalty: 0 agent_num: 37 done: False
______________________
id: 43 reward: -0.023109243697478993 service_time: 244 s_time: 44 penalty: 0 agent_num: 34 done: False
______________________
id: 40 reward: -0.022448979591836733 service_time: 1225 s_time: 44 penalty: 0 agent_num: 35 done: False
______________________
id: 55 reward: 0.0 service_time: 1139 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 42 reward: -0.023148148148148147 service_time: 940 s_time: 35 penalty: 0 agent_num: 27 done: False
______________________
id: 53 reward: -0.006968641114982578 service_time: 970 s_time: 16 penalty: 0 agent_num: 41 done: False
______________________
id: 48 reward: -0.01203416149068323 service_time: 1286 s_time: 31 penalty: 0 agent_num: 46 done: False
______________________
id: 52 reward: -0.010267857142857143 service_time: 2407 s_time: 23 penalty: 0 agent_num: 40 done: False
______________________
Step:  3312
Pretraining Loss:  tensor(0.3176, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: -0.08571428571428572 service_time: 221 s_time: 48 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: 0.0 service_time: 641 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: 0.0 service_time: 670 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 49 reward: -0.01875 service_time: 53 s_time: 21 penalty: 0 agent_num: 20 done: False
______________________
id: 50 reward: -0.0633116883116883 service_time: 1102 s_time: 78 penalty: 0 agent_num: 22 done: False
______________________
id: 46 reward: 0.0 service_time: 214 s_time: 0 penalty: 0 agent_num: 43 done: False
______________________
id: 51 reward: -0.02872670807453416 service_time: 1134 s_time: 37 penalty: 0 agent_num: 23 done: False
______________________
id: 54 reward: -0.02027027027027027 service_time: 1373 s_time: 42 penalty: 0 agent_num: 37 done: False
______________________
id: 40 reward: -0.0066326530612244895 service_time: 1238 s_time: 13 penalty: 0 agent_num: 35 done: False
______________________
id: 55 reward: -0.021350931677018632 service_time: 1194 s_time: 55 penalty: 0 agent_num: 46 done: False
______________________
id: 48 reward: 0.0 service_time: 1286 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 43 reward: 0.0010504201680672268 service_time: 242 s_time: -2 penalty: 0 agent_num: 34 done: False
______________________
id: 53 reward: -0.006968641114982578 service_time: 986 s_time: 16 penalty: 0 agent_num: 41 done: False
______________________
id: 44 reward: 0.005208333333333333 service_time: 2306 s_time: -7 penalty: 0 agent_num: 24 done: False
______________________
id: 52 reward: -0.002232142857142857 service_time: 2412 s_time: 5 penalty: 0 agent_num: 40 done: False
______________________
id: 42 reward: -0.022486772486772486 service_time: 974 s_time: 34 penalty: 0 agent_num: 27 done: False
______________________
Step:  3328
Pretraining Loss:  tensor(0.3366, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: 0.0 service_time: 641 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: -0.025892857142857145 service_time: 82 s_time: 29 penalty: 0 agent_num: 20 done: False
______________________
id: 45 reward: -0.09107142857142857 service_time: 272 s_time: 51 penalty: 0 agent_num: 10 done: False
______________________
id: 47 reward: -0.007142857142857143 service_time: 678 s_time: 8 penalty: 0 agent_num: 20 done: False
______________________
id: 50 reward: 0.026785714285714284 service_time: 1069 s_time: -33 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: -0.018633540372670808 service_time: 1158 s_time: 24 penalty: 0 agent_num: 23 done: False
______________________
id: 40 reward: -0.01989795918367347 service_time: 1277 s_time: 39 penalty: 0 agent_num: 35 done: False
______________________
id: 46 reward: -0.02823920265780731 service_time: 282 s_time: 68 penalty: 0 agent_num: 43 done: False
______________________
id: 43 reward: -0.022584033613445378 service_time: 285 s_time: 43 penalty: 0 agent_num: 34 done: False
______________________
id: 55 reward: -0.005434782608695652 service_time: 1208 s_time: 14 penalty: 0 agent_num: 46 done: False
______________________
id: 42 reward: -0.012566137566137565 service_time: 993 s_time: 19 penalty: 0 agent_num: 27 done: False
______________________
id: 44 reward: -0.028273809523809524 service_time: 2344 s_time: 38 penalty: 0 agent_num: 24 done: False
______________________
id: 54 reward: -0.015444015444015444 service_time: 1405 s_time: 32 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: -0.0156794425087108 service_time: 1022 s_time: 36 penalty: 0 agent_num: 41 done: False
______________________
id: 52 reward: -0.016517857142857143 service_time: 2449 s_time: 37 penalty: 0 agent_num: 40 done: False
______________________
id: 48 reward: -0.02562111801242236 service_time: 1352 s_time: 66 penalty: 0 agent_num: 46 done: False
______________________
Step:  3344
Pretraining Loss:  tensor(0.3024, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: 0.019642857142857142 service_time: 261 s_time: -11 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: 0.0 service_time: 641 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: -0.022321428571428572 service_time: 703 s_time: 25 penalty: 0 agent_num: 20 done: False
______________________
id: 50 reward: 0.005681818181818182 service_time: 1062 s_time: -7 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: -0.019642857142857142 service_time: 104 s_time: 22 penalty: 0 agent_num: 20 done: False
______________________
id: 46 reward: -0.005398671096345515 service_time: 295 s_time: 13 penalty: 0 agent_num: 43 done: False
______________________
id: 54 reward: -0.008204633204633204 service_time: 1422 s_time: 17 penalty: 0 agent_num: 37 done: False
______________________
id: 51 reward: 0.005434782608695652 service_time: 1151 s_time: -7 penalty: 0 agent_num: 23 done: False
______________________
id: 42 reward: -0.01917989417989418 service_time: 1022 s_time: 29 penalty: 0 agent_num: 27 done: False
______________________
id: 40 reward: -0.010714285714285714 service_time: 1298 s_time: 21 penalty: 0 agent_num: 35 done: False
______________________
id: 43 reward: -0.01207983193277311 service_time: 308 s_time: 23 penalty: 0 agent_num: 34 done: False
______________________
id: 48 reward: -0.010869565217391304 service_time: 1380 s_time: 28 penalty: 0 agent_num: 46 done: False
______________________
id: 55 reward: 0.0 service_time: 1208 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: 0.0 service_time: 1022 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 44 reward: -0.028273809523809524 service_time: 2382 s_time: 38 penalty: 0 agent_num: 24 done: False
______________________
id: 52 reward: 19.990178571428572 service_time: 2471 s_time: 22 penalty: 0 agent_num: 40 done: True
______________________
Step:  3360
Pretraining Loss:  tensor(0.3043, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: 0.0 service_time: 641 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 45 reward: -0.008928571428571428 service_time: 266 s_time: 5 penalty: 0 agent_num: 10 done: False
______________________
id: 52 reward: -0.00974025974025974 service_time: 12 s_time: 12 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: -0.020535714285714286 service_time: 127 s_time: 23 penalty: 0 agent_num: 20 done: False
______________________
id: 47 reward: 0.0 service_time: 703 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 50 reward: 0.0 service_time: 1062 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: -0.029503105590062112 service_time: 1189 s_time: 38 penalty: 0 agent_num: 23 done: False
______________________
id: 40 reward: -0.010714285714285714 service_time: 1319 s_time: 21 penalty: 0 agent_num: 35 done: False
______________________
id: 46 reward: -0.011212624584717609 service_time: 322 s_time: 27 penalty: 0 agent_num: 43 done: False
______________________
id: 54 reward: 0.0009652509652509653 service_time: 1420 s_time: -2 penalty: 0 agent_num: 37 done: False
______________________
id: 43 reward: -0.012605042016806723 service_time: 332 s_time: 24 penalty: 0 agent_num: 34 done: False
______________________
id: 44 reward: 0.0 service_time: 2382 s_time: 0 penalty: 0 agent_num: 24 done: False
______________________
id: 42 reward: -0.027116402116402115 service_time: 1063 s_time: 41 penalty: 0 agent_num: 27 done: False
______________________
id: 55 reward: -0.009704968944099378 service_time: 1233 s_time: 25 penalty: 0 agent_num: 46 done: False
______________________
id: 48 reward: -0.008152173913043478 service_time: 1401 s_time: 21 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: -0.02221254355400697 service_time: 1073 s_time: 51 penalty: 0 agent_num: 41 done: False
______________________
Step:  3376
Pretraining Loss:  tensor(0.3378, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.0633116883116883 service_time: 680 s_time: 39 penalty: 0 agent_num: 11 done: False
______________________
id: 52 reward: -0.015422077922077922 service_time: 31 s_time: 19 penalty: 0 agent_num: 22 done: False
______________________
id: 45 reward: -0.055357142857142855 service_time: 297 s_time: 31 penalty: 0 agent_num: 10 done: False
______________________
id: 50 reward: 0.01461038961038961 service_time: 1044 s_time: -18 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: -0.024107142857142858 service_time: 154 s_time: 27 penalty: 0 agent_num: 20 done: False
______________________
id: 47 reward: 0.0 service_time: 703 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 42 reward: -0.003968253968253968 service_time: 1069 s_time: 6 penalty: 0 agent_num: 27 done: False
______________________
id: 46 reward: -0.009551495016611296 service_time: 345 s_time: 23 penalty: 0 agent_num: 43 done: False
______________________
id: 51 reward: 0.0 service_time: 1189 s_time: 0 penalty: 0 agent_num: 23 done: False
______________________
id: 40 reward: -0.012755102040816327 service_time: 1344 s_time: 25 penalty: 0 agent_num: 35 done: False
______________________
id: 55 reward: -0.018245341614906832 service_time: 1280 s_time: 47 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: -0.013501742160278746 service_time: 1104 s_time: 31 penalty: 0 agent_num: 41 done: False
______________________
id: 43 reward: -0.023634453781512604 service_time: 377 s_time: 45 penalty: 0 agent_num: 34 done: False
______________________
id: 54 reward: -0.02557915057915058 service_time: 1473 s_time: 53 penalty: 0 agent_num: 37 done: False
______________________
id: 44 reward: -0.041666666666666664 service_time: 2438 s_time: 56 penalty: 0 agent_num: 24 done: False
______________________
id: 48 reward: -0.013198757763975156 service_time: 1435 s_time: 34 penalty: 0 agent_num: 46 done: False
______________________
Step:  3392
Pretraining Loss:  tensor(0.3197, device='cuda:0', grad_fn=<MeanBackward0>)
id: 52 reward: -0.028409090909090908 service_time: 66 s_time: 35 penalty: 0 agent_num: 22 done: False
______________________
id: 41 reward: -0.037337662337662336 service_time: 703 s_time: 23 penalty: 0 agent_num: 11 done: False
______________________
id: 45 reward: 0.044642857142857144 service_time: 272 s_time: -25 penalty: 0 agent_num: 10 done: False
______________________
id: 49 reward: -0.024107142857142858 service_time: 181 s_time: 27 penalty: 0 agent_num: 20 done: False
______________________
id: 47 reward: -0.04017857142857143 service_time: 748 s_time: 45 penalty: 0 agent_num: 20 done: False
______________________
id: 50 reward: 0.0 service_time: 1044 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: 0.0 service_time: 1189 s_time: 0 penalty: 0 agent_num: 23 done: False
______________________
id: 40 reward: -0.012244897959183673 service_time: 1368 s_time: 24 penalty: 0 agent_num: 35 done: False
______________________
id: 42 reward: -0.01917989417989418 service_time: 1098 s_time: 29 penalty: 0 agent_num: 27 done: False
______________________
id: 43 reward: -0.012605042016806723 service_time: 401 s_time: 24 penalty: 0 agent_num: 34 done: False
______________________
id: 46 reward: 0.0 service_time: 345 s_time: 0 penalty: 0 agent_num: 43 done: False
______________________
id: 54 reward: 0.0014478764478764478 service_time: 1470 s_time: -3 penalty: 0 agent_num: 37 done: False
______________________
id: 55 reward: -0.01125776397515528 service_time: 1309 s_time: 29 penalty: 0 agent_num: 46 done: False
______________________
id: 44 reward: -0.01711309523809524 service_time: 2461 s_time: 23 penalty: 0 agent_num: 24 done: False
______________________
id: 53 reward: -0.008275261324041812 service_time: 1123 s_time: 19 penalty: 0 agent_num: 41 done: False
______________________
id: 48 reward: 0.0 service_time: 1435 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
Step:  3408
Pretraining Loss:  tensor(0.3102, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.06818181818181818 service_time: 745 s_time: 42 penalty: 0 agent_num: 11 done: False
______________________
id: 52 reward: -0.03571428571428571 service_time: 110 s_time: 44 penalty: 0 agent_num: 22 done: False
______________________
id: 45 reward: 0.0 service_time: 272 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 47 reward: 0.0 service_time: 748 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 50 reward: -0.024350649350649352 service_time: 1074 s_time: 30 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: -0.01607142857142857 service_time: 199 s_time: 18 penalty: 0 agent_num: 20 done: False
______________________
id: 46 reward: -0.016611295681063124 service_time: 385 s_time: 40 penalty: 0 agent_num: 43 done: False
______________________
id: 54 reward: -0.02895752895752896 service_time: 1530 s_time: 60 penalty: 0 agent_num: 37 done: False
______________________
id: 55 reward: -0.006987577639751553 service_time: 1327 s_time: 18 penalty: 0 agent_num: 46 done: False
______________________
id: 42 reward: 0.0013227513227513227 service_time: 1096 s_time: -2 penalty: 0 agent_num: 27 done: False
______________________
id: 51 reward: -0.04736024844720497 service_time: 1250 s_time: 61 penalty: 0 agent_num: 23 done: False
______________________
id: 43 reward: -0.013130252100840336 service_time: 426 s_time: 25 penalty: 0 agent_num: 34 done: False
______________________
id: 40 reward: -0.020918367346938777 service_time: 1409 s_time: 41 penalty: 0 agent_num: 35 done: False
______________________
id: 53 reward: -0.0039198606271777 service_time: 1132 s_time: 9 penalty: 0 agent_num: 41 done: False
______________________
id: 48 reward: -0.026785714285714284 service_time: 1504 s_time: 69 penalty: 0 agent_num: 46 done: False
______________________
id: 44 reward: -0.004464285714285714 service_time: 2467 s_time: 6 penalty: 0 agent_num: 24 done: False
______________________
Step:  3424
Pretraining Loss:  tensor(0.3109, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: 0.04107142857142857 service_time: 249 s_time: -23 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: -0.06818181818181818 service_time: 787 s_time: 42 penalty: 0 agent_num: 11 done: False
______________________
id: 52 reward: -0.024350649350649352 service_time: 140 s_time: 30 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: -0.011607142857142858 service_time: 212 s_time: 13 penalty: 0 agent_num: 20 done: False
______________________
id: 47 reward: 0.0 service_time: 748 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 51 reward: 0.030279503105590064 service_time: 1211 s_time: -39 penalty: 0 agent_num: 23 done: False
______________________
id: 40 reward: -0.019387755102040816 service_time: 1447 s_time: 38 penalty: 0 agent_num: 35 done: False
______________________
id: 46 reward: -0.0049833887043189366 service_time: 397 s_time: 12 penalty: 0 agent_num: 43 done: False
______________________
id: 55 reward: 0.0 service_time: 1327 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 54 reward: -0.0033783783783783786 service_time: 1537 s_time: 7 penalty: 0 agent_num: 37 done: False
______________________
id: 43 reward: -0.0005252100840336134 service_time: 427 s_time: 1 penalty: 0 agent_num: 34 done: False
______________________
id: 42 reward: 0.003968253968253968 service_time: 1090 s_time: -6 penalty: 0 agent_num: 27 done: False
______________________
id: 50 reward: -0.033279220779220776 service_time: 1115 s_time: 41 penalty: 0 agent_num: 22 done: False
______________________
id: 53 reward: -0.01132404181184669 service_time: 1158 s_time: 26 penalty: 0 agent_num: 41 done: False
______________________
id: 48 reward: -0.010869565217391304 service_time: 1532 s_time: 28 penalty: 0 agent_num: 46 done: False
______________________
id: 44 reward: 20.006696428571427 service_time: 2458 s_time: -9 penalty: 0 agent_num: 24 done: True
______________________
Step:  3440
Pretraining Loss:  tensor(0.3086, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: -0.044642857142857144 service_time: 274 s_time: 25 penalty: 0 agent_num: 10 done: False
______________________
id: 47 reward: -0.023214285714285715 service_time: 774 s_time: 26 penalty: 0 agent_num: 20 done: False
______________________
id: 41 reward: 0.0 service_time: 787 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 44 reward: -0.009615384615384616 service_time: 21 s_time: 21 penalty: 0 agent_num: 39 done: False
______________________
id: 52 reward: 0.0 service_time: 140 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: 0.010093167701863354 service_time: 1198 s_time: -13 penalty: 0 agent_num: 23 done: False
______________________
id: 49 reward: -0.033035714285714286 service_time: 249 s_time: 37 penalty: 0 agent_num: 20 done: False
______________________
id: 42 reward: -0.017857142857142856 service_time: 1117 s_time: 27 penalty: 0 agent_num: 27 done: False
______________________
id: 50 reward: 0.0 service_time: 1115 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 46 reward: -0.011627906976744186 service_time: 425 s_time: 28 penalty: 0 agent_num: 43 done: False
______________________
id: 54 reward: -0.004343629343629344 service_time: 1546 s_time: 9 penalty: 0 agent_num: 37 done: False
______________________
id: 55 reward: -0.01746894409937888 service_time: 1372 s_time: 45 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: 0.0 service_time: 1158 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 43 reward: -0.01838235294117647 service_time: 462 s_time: 35 penalty: 0 agent_num: 34 done: False
______________________
id: 40 reward: -0.015816326530612244 service_time: 1478 s_time: 31 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.01125776397515528 service_time: 1561 s_time: 29 penalty: 0 agent_num: 46 done: False
______________________
Step:  3456
Pretraining Loss:  tensor(0.2331, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: -0.04285714285714286 service_time: 298 s_time: 24 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: 0.0 service_time: 787 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: -0.027678571428571427 service_time: 280 s_time: 31 penalty: 0 agent_num: 20 done: False
______________________
id: 47 reward: 0.0 service_time: 774 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 44 reward: -0.01282051282051282 service_time: 49 s_time: 28 penalty: 0 agent_num: 39 done: False
______________________
id: 52 reward: -0.025974025974025976 service_time: 172 s_time: 32 penalty: 0 agent_num: 22 done: False
______________________
id: 42 reward: 0.009259259259259259 service_time: 1103 s_time: -14 penalty: 0 agent_num: 27 done: False
______________________
id: 51 reward: -0.036490683229813664 service_time: 1245 s_time: 47 penalty: 0 agent_num: 23 done: False
______________________
id: 40 reward: 0.0 service_time: 1478 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 46 reward: -0.00872093023255814 service_time: 446 s_time: 21 penalty: 0 agent_num: 43 done: False
______________________
id: 54 reward: 0.0 service_time: 1546 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 50 reward: 0.0 service_time: 1115 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 43 reward: -0.01207983193277311 service_time: 485 s_time: 23 penalty: 0 agent_num: 34 done: False
______________________
id: 55 reward: 0.0 service_time: 1372 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: -0.02569686411149826 service_time: 1217 s_time: 59 penalty: 0 agent_num: 41 done: False
______________________
id: 48 reward: -0.012422360248447204 service_time: 1593 s_time: 32 penalty: 0 agent_num: 46 done: False
______________________
Step:  3472
Pretraining Loss:  tensor(0.2357, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: 0.0 service_time: 298 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: 0.05032467532467533 service_time: 756 s_time: -31 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: 0.0 service_time: 774 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 52 reward: -0.030032467532467532 service_time: 209 s_time: 37 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: -0.02142857142857143 service_time: 304 s_time: 24 penalty: 0 agent_num: 20 done: False
______________________
id: 44 reward: -0.01510989010989011 service_time: 82 s_time: 33 penalty: 0 agent_num: 39 done: False
______________________
id: 51 reward: 0.0 service_time: 1245 s_time: 0 penalty: 0 agent_num: 23 done: False
______________________
id: 42 reward: -0.005291005291005291 service_time: 1111 s_time: 8 penalty: 0 agent_num: 27 done: False
______________________
id: 50 reward: -0.022727272727272728 service_time: 1143 s_time: 28 penalty: 0 agent_num: 22 done: False
______________________
id: 46 reward: -0.0070598006644518275 service_time: 463 s_time: 17 penalty: 0 agent_num: 43 done: False
______________________
id: 43 reward: -0.019432773109243698 service_time: 522 s_time: 37 penalty: 0 agent_num: 34 done: False
______________________
id: 53 reward: -0.00043554006968641115 service_time: 1218 s_time: 1 penalty: 0 agent_num: 41 done: False
______________________
id: 55 reward: -0.013975155279503106 service_time: 1408 s_time: 36 penalty: 0 agent_num: 46 done: False
______________________
id: 54 reward: -0.030405405405405407 service_time: 1609 s_time: 63 penalty: 0 agent_num: 37 done: False
______________________
id: 40 reward: -0.011224489795918367 service_time: 1500 s_time: 22 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.009316770186335404 service_time: 1617 s_time: 24 penalty: 0 agent_num: 46 done: False
______________________
Step:  3488
Pretraining Loss:  tensor(0.2516, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: 0.0 service_time: 298 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: -0.09415584415584416 service_time: 814 s_time: 58 penalty: 0 agent_num: 11 done: False
______________________
id: 51 reward: 0.011645962732919254 service_time: 1230 s_time: -15 penalty: 0 agent_num: 23 done: False
______________________
id: 49 reward: -0.03571428571428571 service_time: 344 s_time: 40 penalty: 0 agent_num: 20 done: False
______________________
id: 52 reward: 0.0 service_time: 209 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: -0.025 service_time: 802 s_time: 28 penalty: 0 agent_num: 20 done: False
______________________
id: 42 reward: -0.027777777777777776 service_time: 1153 s_time: 42 penalty: 0 agent_num: 27 done: False
______________________
id: 44 reward: 0.0 service_time: 82 s_time: 0 penalty: 0 agent_num: 39 done: False
______________________
id: 46 reward: -0.0070598006644518275 service_time: 480 s_time: 17 penalty: 0 agent_num: 43 done: False
______________________
id: 50 reward: -0.04626623376623377 service_time: 1200 s_time: 57 penalty: 0 agent_num: 22 done: False
______________________
id: 40 reward: -0.015306122448979591 service_time: 1530 s_time: 30 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: -0.01833976833976834 service_time: 1647 s_time: 38 penalty: 0 agent_num: 37 done: False
______________________
id: 55 reward: -0.013198757763975156 service_time: 1442 s_time: 34 penalty: 0 agent_num: 46 done: False
______________________
id: 43 reward: -0.026785714285714284 service_time: 573 s_time: 51 penalty: 0 agent_num: 34 done: False
______________________
id: 48 reward: -0.005434782608695652 service_time: 1631 s_time: 14 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: -0.016114982578397212 service_time: 1255 s_time: 37 penalty: 0 agent_num: 41 done: False
______________________
Step:  3504
Pretraining Loss:  tensor(0.2402, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: -0.04107142857142857 service_time: 321 s_time: 23 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: -0.006493506493506494 service_time: 818 s_time: 4 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: -0.020535714285714286 service_time: 825 s_time: 23 penalty: 0 agent_num: 20 done: False
______________________
id: 52 reward: -0.03977272727272727 service_time: 258 s_time: 49 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: 0.0 service_time: 1230 s_time: 0 penalty: 0 agent_num: 23 done: False
______________________
id: 49 reward: -0.033035714285714286 service_time: 381 s_time: 37 penalty: 0 agent_num: 20 done: False
______________________
id: 42 reward: -0.042328042328042326 service_time: 1217 s_time: 64 penalty: 0 agent_num: 27 done: False
______________________
id: 50 reward: 0.0 service_time: 1200 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 44 reward: -0.011446886446886446 service_time: 107 s_time: 25 penalty: 0 agent_num: 39 done: False
______________________
id: 46 reward: -0.01287375415282392 service_time: 511 s_time: 31 penalty: 0 agent_num: 43 done: False
______________________
id: 55 reward: -0.008152173913043478 service_time: 1463 s_time: 21 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: -0.008710801393728223 service_time: 1275 s_time: 20 penalty: 0 agent_num: 41 done: False
______________________
id: 43 reward: -0.01838235294117647 service_time: 608 s_time: 35 penalty: 0 agent_num: 34 done: False
______________________
id: 40 reward: -0.02857142857142857 service_time: 1586 s_time: 56 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: -0.012548262548262547 service_time: 1673 s_time: 26 penalty: 0 agent_num: 37 done: False
______________________
id: 48 reward: 0.00038819875776397513 service_time: 1630 s_time: -1 penalty: 0 agent_num: 46 done: False
______________________
Step:  3520
Pretraining Loss:  tensor(0.2663, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: 0.0035714285714285713 service_time: 319 s_time: -2 penalty: 0 agent_num: 10 done: False
______________________
id: 47 reward: -0.02142857142857143 service_time: 849 s_time: 24 penalty: 0 agent_num: 20 done: False
______________________
id: 41 reward: 0.0 service_time: 818 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 51 reward: 0.005434782608695652 service_time: 1223 s_time: -7 penalty: 0 agent_num: 23 done: False
______________________
id: 44 reward: -0.017857142857142856 service_time: 146 s_time: 39 penalty: 0 agent_num: 39 done: False
______________________
id: 49 reward: -0.024107142857142858 service_time: 408 s_time: 27 penalty: 0 agent_num: 20 done: False
______________________
id: 50 reward: -0.06412337662337662 service_time: 1279 s_time: 79 penalty: 0 agent_num: 22 done: False
______________________
id: 52 reward: -0.016233766233766232 service_time: 278 s_time: 20 penalty: 0 agent_num: 22 done: False
______________________
id: 46 reward: 0.0004152823920265781 service_time: 510 s_time: -1 penalty: 0 agent_num: 43 done: False
______________________
id: 40 reward: -0.0020408163265306124 service_time: 1590 s_time: 4 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: -0.00723938223938224 service_time: 1688 s_time: 15 penalty: 0 agent_num: 37 done: False
______________________
id: 55 reward: 0.0 service_time: 1463 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 48 reward: -0.019021739130434784 service_time: 1679 s_time: 49 penalty: 0 agent_num: 46 done: False
______________________
id: 43 reward: -0.008928571428571428 service_time: 625 s_time: 17 penalty: 0 agent_num: 34 done: False
______________________
id: 53 reward: 0.00043554006968641115 service_time: 1274 s_time: -1 penalty: 0 agent_num: 41 done: False
______________________
id: 42 reward: -0.05423280423280423 service_time: 1299 s_time: 82 penalty: 0 agent_num: 27 done: False
______________________
Step:  3536
Pretraining Loss:  tensor(0.2735, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: 0.0 service_time: 319 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: -0.03896103896103896 service_time: 842 s_time: 24 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: -0.029464285714285714 service_time: 882 s_time: 33 penalty: 0 agent_num: 20 done: False
______________________
id: 51 reward: 0.0015527950310559005 service_time: 1221 s_time: -2 penalty: 0 agent_num: 23 done: False
______________________
id: 52 reward: -0.025974025974025976 service_time: 310 s_time: 32 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: -0.027678571428571427 service_time: 439 s_time: 31 penalty: 0 agent_num: 20 done: False
______________________
id: 46 reward: -0.009136212624584718 service_time: 532 s_time: 22 penalty: 0 agent_num: 43 done: False
______________________
id: 44 reward: -0.006868131868131868 service_time: 161 s_time: 15 penalty: 0 agent_num: 39 done: False
______________________
id: 42 reward: -0.05092592592592592 service_time: 1376 s_time: 77 penalty: 0 agent_num: 27 done: False
______________________
id: 40 reward: -0.017346938775510204 service_time: 1624 s_time: 34 penalty: 0 agent_num: 35 done: False
______________________
id: 55 reward: -0.009704968944099378 service_time: 1488 s_time: 25 penalty: 0 agent_num: 46 done: False
______________________
id: 43 reward: -0.020483193277310924 service_time: 664 s_time: 39 penalty: 0 agent_num: 34 done: False
______________________
id: 53 reward: -0.02264808362369338 service_time: 1326 s_time: 52 penalty: 0 agent_num: 41 done: False
______________________
id: 54 reward: -0.019305019305019305 service_time: 1728 s_time: 40 penalty: 0 agent_num: 37 done: False
______________________
id: 50 reward: -0.05844155844155844 service_time: 1351 s_time: 72 penalty: 0 agent_num: 22 done: False
______________________
id: 48 reward: -0.021350931677018632 service_time: 1734 s_time: 55 penalty: 0 agent_num: 46 done: False
______________________
Step:  3552
Pretraining Loss:  tensor(0.2810, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: 0.02857142857142857 service_time: 303 s_time: -16 penalty: 0 agent_num: 10 done: False
______________________
id: 52 reward: -0.002435064935064935 service_time: 313 s_time: 3 penalty: 0 agent_num: 22 done: False
______________________
id: 41 reward: -0.04220779220779221 service_time: 868 s_time: 26 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: -0.02857142857142857 service_time: 471 s_time: 32 penalty: 0 agent_num: 20 done: False
______________________
id: 51 reward: -0.02096273291925466 service_time: 1248 s_time: 27 penalty: 0 agent_num: 23 done: False
______________________
id: 47 reward: -0.02857142857142857 service_time: 914 s_time: 32 penalty: 0 agent_num: 20 done: False
______________________
id: 44 reward: -0.011904761904761904 service_time: 187 s_time: 26 penalty: 0 agent_num: 39 done: False
______________________
id: 46 reward: -0.012043189368770765 service_time: 561 s_time: 29 penalty: 0 agent_num: 43 done: False
______________________
id: 40 reward: 0.0 service_time: 1624 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 50 reward: -0.012987012987012988 service_time: 1367 s_time: 16 penalty: 0 agent_num: 22 done: False
______________________
id: 54 reward: 0.00048262548262548264 service_time: 1727 s_time: -1 penalty: 0 agent_num: 37 done: False
______________________
id: 43 reward: 0.0 service_time: 664 s_time: 0 penalty: 0 agent_num: 34 done: False
______________________
id: 55 reward: -0.021350931677018632 service_time: 1543 s_time: 55 penalty: 0 agent_num: 46 done: False
______________________
id: 48 reward: -0.013975155279503106 service_time: 1770 s_time: 36 penalty: 0 agent_num: 46 done: False
______________________
id: 42 reward: -0.01521164021164021 service_time: 1399 s_time: 23 penalty: 0 agent_num: 27 done: False
______________________
id: 53 reward: -0.017857142857142856 service_time: 1367 s_time: 41 penalty: 0 agent_num: 41 done: False
______________________
Step:  3568
Pretraining Loss:  tensor(0.2878, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: 0.0 service_time: 303 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: 0.0 service_time: 868 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: -0.025892857142857145 service_time: 500 s_time: 29 penalty: 0 agent_num: 20 done: False
______________________
id: 51 reward: 0.0015527950310559005 service_time: 1246 s_time: -2 penalty: 0 agent_num: 23 done: False
______________________
id: 47 reward: 0.0 service_time: 914 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 52 reward: -0.024350649350649352 service_time: 343 s_time: 30 penalty: 0 agent_num: 22 done: False
______________________
id: 44 reward: -0.013278388278388278 service_time: 216 s_time: 29 penalty: 0 agent_num: 39 done: False
______________________
id: 46 reward: -0.011212624584717609 service_time: 588 s_time: 27 penalty: 0 agent_num: 43 done: False
______________________
id: 50 reward: -0.07873376623376624 service_time: 1464 s_time: 97 penalty: 0 agent_num: 22 done: False
______________________
id: 42 reward: 0.009259259259259259 service_time: 1385 s_time: -14 penalty: 0 agent_num: 27 done: False
______________________
id: 43 reward: -0.01838235294117647 service_time: 699 s_time: 35 penalty: 0 agent_num: 34 done: False
______________________
id: 40 reward: -0.008673469387755102 service_time: 1641 s_time: 17 penalty: 0 agent_num: 35 done: False
______________________
id: 55 reward: -0.006599378881987578 service_time: 1560 s_time: 17 penalty: 0 agent_num: 46 done: False
______________________
id: 54 reward: -0.013996138996138996 service_time: 1756 s_time: 29 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: -0.007404181184668989 service_time: 1384 s_time: 17 penalty: 0 agent_num: 41 done: False
______________________
id: 48 reward: -0.009704968944099378 service_time: 1795 s_time: 25 penalty: 0 agent_num: 46 done: False
______________________
Step:  3584
Pretraining Loss:  tensor(0.3100, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: 0.0 service_time: 303 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 51 reward: -0.037267080745341616 service_time: 1294 s_time: 48 penalty: 0 agent_num: 23 done: False
______________________
id: 47 reward: -0.027678571428571427 service_time: 945 s_time: 31 penalty: 0 agent_num: 20 done: False
______________________
id: 41 reward: 0.0 service_time: 868 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: -0.022321428571428572 service_time: 525 s_time: 25 penalty: 0 agent_num: 20 done: False
______________________
id: 52 reward: -0.020292207792207792 service_time: 368 s_time: 25 penalty: 0 agent_num: 22 done: False
______________________
id: 44 reward: -0.011904761904761904 service_time: 242 s_time: 26 penalty: 0 agent_num: 39 done: False
______________________
id: 42 reward: -0.004629629629629629 service_time: 1392 s_time: 7 penalty: 0 agent_num: 27 done: False
______________________
id: 46 reward: -0.013289036544850499 service_time: 620 s_time: 32 penalty: 0 agent_num: 43 done: False
______________________
id: 54 reward: -0.01447876447876448 service_time: 1786 s_time: 30 penalty: 0 agent_num: 37 done: False
______________________
id: 50 reward: -0.013798701298701298 service_time: 1481 s_time: 17 penalty: 0 agent_num: 22 done: False
______________________
id: 43 reward: -0.022584033613445378 service_time: 742 s_time: 43 penalty: 0 agent_num: 34 done: False
______________________
id: 48 reward: 0.00038819875776397513 service_time: 1794 s_time: -1 penalty: 0 agent_num: 46 done: False
______________________
id: 55 reward: -0.00038819875776397513 service_time: 1561 s_time: 1 penalty: 0 agent_num: 46 done: False
______________________
id: 40 reward: -0.052551020408163264 service_time: 1744 s_time: 103 penalty: 0 agent_num: 35 done: False
______________________
id: 53 reward: -0.016986062717770034 service_time: 1423 s_time: 39 penalty: 0 agent_num: 41 done: False
______________________
Step:  3600
Pretraining Loss:  tensor(0.3466, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: 0.0 service_time: 303 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 52 reward: -0.008116883116883116 service_time: 378 s_time: 10 penalty: 0 agent_num: 22 done: False
______________________
id: 41 reward: 0.0 service_time: 868 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: -0.02857142857142857 service_time: 557 s_time: 32 penalty: 0 agent_num: 20 done: False
______________________
id: 47 reward: 0.0 service_time: 945 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 50 reward: -0.1112012987012987 service_time: 1618 s_time: 137 penalty: 0 agent_num: 22 done: False
______________________
id: 44 reward: -0.016025641025641024 service_time: 277 s_time: 35 penalty: 0 agent_num: 39 done: False
______________________
id: 51 reward: -0.015527950310559006 service_time: 1314 s_time: 20 penalty: 0 agent_num: 23 done: False
______________________
id: 46 reward: -0.004152823920265781 service_time: 630 s_time: 10 penalty: 0 agent_num: 43 done: False
______________________
id: 42 reward: 0.011904761904761904 service_time: 1374 s_time: -18 penalty: 0 agent_num: 27 done: False
______________________
id: 54 reward: 0.0009652509652509653 service_time: 1784 s_time: -2 penalty: 0 agent_num: 37 done: False
______________________
id: 40 reward: -0.0163265306122449 service_time: 1776 s_time: 32 penalty: 0 agent_num: 35 done: False
______________________
id: 55 reward: -0.025232919254658384 service_time: 1626 s_time: 65 penalty: 0 agent_num: 46 done: False
______________________
id: 43 reward: -0.022584033613445378 service_time: 785 s_time: 43 penalty: 0 agent_num: 34 done: False
______________________
id: 48 reward: -0.016692546583850932 service_time: 1837 s_time: 43 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: 0.004790940766550522 service_time: 1412 s_time: -11 penalty: 0 agent_num: 41 done: False
______________________
Step:  3616
Pretraining Loss:  tensor(0.3560, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: 0.0 service_time: 303 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: -0.09090909090909091 service_time: 924 s_time: 56 penalty: 0 agent_num: 11 done: False
______________________
id: 52 reward: 0.0 service_time: 378 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: 0.0 service_time: 557 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 50 reward: -0.007305194805194805 service_time: 1627 s_time: 9 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: -0.059006211180124224 service_time: 1390 s_time: 76 penalty: 0 agent_num: 23 done: False
______________________
id: 44 reward: -0.013736263736263736 service_time: 307 s_time: 30 penalty: 0 agent_num: 39 done: False
______________________
id: 46 reward: -0.007475083056478406 service_time: 648 s_time: 18 penalty: 0 agent_num: 43 done: False
______________________
id: 47 reward: -0.008035714285714285 service_time: 954 s_time: 9 penalty: 0 agent_num: 20 done: False
______________________
id: 54 reward: -0.008687258687258687 service_time: 1802 s_time: 18 penalty: 0 agent_num: 37 done: False
______________________
id: 55 reward: 0.0 service_time: 1626 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 42 reward: -0.05886243386243386 service_time: 1463 s_time: 89 penalty: 0 agent_num: 27 done: False
______________________
id: 43 reward: -0.020483193277310924 service_time: 824 s_time: 39 penalty: 0 agent_num: 34 done: False
______________________
id: 53 reward: -0.010017421602787456 service_time: 1435 s_time: 23 penalty: 0 agent_num: 41 done: False
______________________
id: 48 reward: -0.017080745341614908 service_time: 1881 s_time: 44 penalty: 0 agent_num: 46 done: False
______________________
id: 40 reward: -0.01479591836734694 service_time: 1805 s_time: 29 penalty: 0 agent_num: 35 done: False
______________________
Step:  3632
Pretraining Loss:  tensor(0.4068, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: 0.0 service_time: 303 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: 0.0 service_time: 924 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 52 reward: -0.017045454545454544 service_time: 399 s_time: 21 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: -0.0375 service_time: 996 s_time: 42 penalty: 0 agent_num: 20 done: False
______________________
id: 50 reward: -0.013798701298701298 service_time: 1644 s_time: 17 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: -0.023214285714285715 service_time: 583 s_time: 26 penalty: 0 agent_num: 20 done: False
______________________
id: 44 reward: -0.010531135531135532 service_time: 330 s_time: 23 penalty: 0 agent_num: 39 done: False
______________________
id: 51 reward: -0.026397515527950312 service_time: 1424 s_time: 34 penalty: 0 agent_num: 23 done: False
______________________
id: 46 reward: -0.009551495016611296 service_time: 671 s_time: 23 penalty: 0 agent_num: 43 done: False
______________________
id: 40 reward: -0.004591836734693878 service_time: 1814 s_time: 9 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: -0.022683397683397683 service_time: 1849 s_time: 47 penalty: 0 agent_num: 37 done: False
______________________
id: 55 reward: -0.01436335403726708 service_time: 1663 s_time: 37 penalty: 0 agent_num: 46 done: False
______________________
id: 42 reward: -0.051587301587301584 service_time: 1541 s_time: 78 penalty: 0 agent_num: 27 done: False
______________________
id: 53 reward: -0.01132404181184669 service_time: 1461 s_time: 26 penalty: 0 agent_num: 41 done: False
______________________
id: 48 reward: -0.002329192546583851 service_time: 1887 s_time: 6 penalty: 0 agent_num: 46 done: False
______________________
id: 43 reward: -0.02100840336134454 service_time: 864 s_time: 40 penalty: 0 agent_num: 34 done: False
______________________
Step:  3648
Pretraining Loss:  tensor(0.4001, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: -0.04107142857142857 service_time: 326 s_time: 23 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: -0.03409090909090909 service_time: 945 s_time: 21 penalty: 0 agent_num: 11 done: False
______________________
id: 52 reward: -0.026785714285714284 service_time: 432 s_time: 33 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: -0.002329192546583851 service_time: 1427 s_time: 3 penalty: 0 agent_num: 23 done: False
______________________
id: 49 reward: -0.025892857142857145 service_time: 612 s_time: 29 penalty: 0 agent_num: 20 done: False
______________________
id: 50 reward: 0.021915584415584416 service_time: 1617 s_time: -27 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: 0.0 service_time: 996 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 44 reward: -0.00641025641025641 service_time: 344 s_time: 14 penalty: 0 agent_num: 39 done: False
______________________
id: 46 reward: -0.008305647840531562 service_time: 691 s_time: 20 penalty: 0 agent_num: 43 done: False
______________________
id: 54 reward: 0.0 service_time: 1849 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: -0.006097560975609756 service_time: 1475 s_time: 14 penalty: 0 agent_num: 41 done: False
______________________
id: 42 reward: -0.016534391534391533 service_time: 1566 s_time: 25 penalty: 0 agent_num: 27 done: False
______________________
id: 55 reward: -0.009704968944099378 service_time: 1688 s_time: 25 penalty: 0 agent_num: 46 done: False
______________________
id: 40 reward: -0.008673469387755102 service_time: 1831 s_time: 17 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.01203416149068323 service_time: 1918 s_time: 31 penalty: 0 agent_num: 46 done: False
______________________
id: 43 reward: 0.004201680672268907 service_time: 856 s_time: -8 penalty: 0 agent_num: 34 done: False
______________________
Step:  3664
Pretraining Loss:  tensor(0.3941, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: 0.0 service_time: 326 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: 0.011363636363636364 service_time: 938 s_time: -7 penalty: 0 agent_num: 11 done: False
______________________
id: 52 reward: -0.048701298701298704 service_time: 492 s_time: 60 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: -0.01607142857142857 service_time: 1014 s_time: 18 penalty: 0 agent_num: 20 done: False
______________________
id: 50 reward: -0.030032467532467532 service_time: 1654 s_time: 37 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: 0.0 service_time: 612 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 44 reward: -0.003663003663003663 service_time: 352 s_time: 8 penalty: 0 agent_num: 39 done: False
______________________
id: 54 reward: -0.027992277992277992 service_time: 1907 s_time: 58 penalty: 0 agent_num: 37 done: False
______________________
id: 46 reward: -0.009136212624584718 service_time: 713 s_time: 22 penalty: 0 agent_num: 43 done: False
______________________
id: 51 reward: -0.014751552795031056 service_time: 1446 s_time: 19 penalty: 0 agent_num: 23 done: False
______________________
id: 55 reward: 0.0 service_time: 1688 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 42 reward: -0.011243386243386243 service_time: 1583 s_time: 17 penalty: 0 agent_num: 27 done: False
______________________
id: 53 reward: -0.02003484320557491 service_time: 1521 s_time: 46 penalty: 0 agent_num: 41 done: False
______________________
id: 43 reward: -0.02153361344537815 service_time: 897 s_time: 41 penalty: 0 agent_num: 34 done: False
______________________
id: 48 reward: 0.0 service_time: 1918 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 40 reward: -0.008673469387755102 service_time: 1848 s_time: 17 penalty: 0 agent_num: 35 done: False
______________________
Step:  3680
Pretraining Loss:  tensor(0.3653, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: 0.0 service_time: 326 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: 0.0 service_time: 938 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 52 reward: -0.021103896103896104 service_time: 518 s_time: 26 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: -0.023214285714285715 service_time: 1040 s_time: 26 penalty: 0 agent_num: 20 done: False
______________________
id: 51 reward: -0.046583850931677016 service_time: 1506 s_time: 60 penalty: 0 agent_num: 23 done: False
______________________
id: 49 reward: 0.0 service_time: 612 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 50 reward: -0.007305194805194805 service_time: 1663 s_time: 9 penalty: 0 agent_num: 22 done: False
______________________
id: 44 reward: -0.010073260073260074 service_time: 374 s_time: 22 penalty: 0 agent_num: 39 done: False
______________________
id: 46 reward: -0.01287375415282392 service_time: 744 s_time: 31 penalty: 0 agent_num: 43 done: False
______________________
id: 55 reward: -0.007763975155279503 service_time: 1708 s_time: 20 penalty: 0 agent_num: 46 done: False
______________________
id: 54 reward: 0.002413127413127413 service_time: 1902 s_time: -5 penalty: 0 agent_num: 37 done: False
______________________
id: 42 reward: -0.01521164021164021 service_time: 1606 s_time: 23 penalty: 0 agent_num: 27 done: False
______________________
id: 48 reward: -0.013198757763975156 service_time: 1952 s_time: 34 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: 0.0 service_time: 1521 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 40 reward: -0.014285714285714285 service_time: 1876 s_time: 28 penalty: 0 agent_num: 35 done: False
______________________
id: 43 reward: -0.009453781512605041 service_time: 915 s_time: 18 penalty: 0 agent_num: 34 done: False
______________________
Step:  3696
Pretraining Loss:  tensor(0.3721, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: -0.04642857142857143 service_time: 352 s_time: 26 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: -0.06168831168831169 service_time: 976 s_time: 38 penalty: 0 agent_num: 11 done: False
______________________
id: 52 reward: 0.0 service_time: 518 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: -0.06339285714285714 service_time: 683 s_time: 71 penalty: 0 agent_num: 20 done: False
______________________
id: 47 reward: 0.0 service_time: 1040 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 50 reward: -0.0016233766233766235 service_time: 1665 s_time: 2 penalty: 0 agent_num: 22 done: False
______________________
id: 44 reward: -0.013736263736263736 service_time: 404 s_time: 30 penalty: 0 agent_num: 39 done: False
______________________
id: 54 reward: -0.00916988416988417 service_time: 1921 s_time: 19 penalty: 0 agent_num: 37 done: False
______________________
id: 46 reward: 0.0 service_time: 744 s_time: 0 penalty: 0 agent_num: 43 done: False
______________________
id: 51 reward: -0.05745341614906832 service_time: 1580 s_time: 74 penalty: 0 agent_num: 23 done: False
______________________
id: 53 reward: -0.01916376306620209 service_time: 1565 s_time: 44 penalty: 0 agent_num: 41 done: False
______________________
id: 55 reward: -0.01746894409937888 service_time: 1753 s_time: 45 penalty: 0 agent_num: 46 done: False
______________________
id: 40 reward: -0.012755102040816327 service_time: 1901 s_time: 25 penalty: 0 agent_num: 35 done: False
______________________
id: 42 reward: -0.018518518518518517 service_time: 1634 s_time: 28 penalty: 0 agent_num: 27 done: False
______________________
id: 48 reward: -0.01125776397515528 service_time: 1981 s_time: 29 penalty: 0 agent_num: 46 done: False
______________________
id: 43 reward: -0.032563025210084036 service_time: 977 s_time: 62 penalty: 0 agent_num: 34 done: False
______________________
Step:  3712
Pretraining Loss:  tensor(0.3733, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: -0.055357142857142855 service_time: 383 s_time: 31 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: 0.0016233766233766235 service_time: 975 s_time: -1 penalty: 0 agent_num: 11 done: False
______________________
id: 52 reward: -0.024350649350649352 service_time: 548 s_time: 30 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: -0.02857142857142857 service_time: 1072 s_time: 32 penalty: 0 agent_num: 20 done: False
______________________
id: 49 reward: 0.030357142857142857 service_time: 649 s_time: -34 penalty: 0 agent_num: 20 done: False
______________________
id: 50 reward: 0.0016233766233766235 service_time: 1663 s_time: -2 penalty: 0 agent_num: 22 done: False
______________________
id: 42 reward: -0.016534391534391533 service_time: 1659 s_time: 25 penalty: 0 agent_num: 27 done: False
______________________
id: 46 reward: -0.024916943521594685 service_time: 804 s_time: 60 penalty: 0 agent_num: 43 done: False
______________________
id: 44 reward: -0.013278388278388278 service_time: 433 s_time: 29 penalty: 0 agent_num: 39 done: False
______________________
id: 55 reward: -0.005822981366459627 service_time: 1768 s_time: 15 penalty: 0 agent_num: 46 done: False
______________________
id: 51 reward: -0.06754658385093168 service_time: 1667 s_time: 87 penalty: 0 agent_num: 23 done: False
______________________
id: 48 reward: -0.0011645962732919255 service_time: 1984 s_time: 3 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: 0.0 service_time: 1565 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 54 reward: -0.037644787644787646 service_time: 1999 s_time: 78 penalty: 0 agent_num: 37 done: False
______________________
id: 40 reward: 0.0020408163265306124 service_time: 1897 s_time: -4 penalty: 0 agent_num: 35 done: False
______________________
id: 43 reward: -0.01365546218487395 service_time: 1003 s_time: 26 penalty: 0 agent_num: 34 done: False
______________________
Step:  3728
Pretraining Loss:  tensor(0.3670, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: 0.010714285714285714 service_time: 377 s_time: -6 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: 0.0 service_time: 975 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: -0.03571428571428571 service_time: 689 s_time: 40 penalty: 0 agent_num: 20 done: False
______________________
id: 52 reward: -0.037337662337662336 service_time: 594 s_time: 46 penalty: 0 agent_num: 22 done: False
______________________
id: 50 reward: -0.025974025974025976 service_time: 1695 s_time: 32 penalty: 0 agent_num: 22 done: False
______________________
id: 44 reward: 0.0 service_time: 433 s_time: 0 penalty: 0 agent_num: 39 done: False
______________________
id: 47 reward: 0.0 service_time: 1072 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 46 reward: -0.009966777408637873 service_time: 828 s_time: 24 penalty: 0 agent_num: 43 done: False
______________________
id: 53 reward: -0.013501742160278746 service_time: 1596 s_time: 31 penalty: 0 agent_num: 41 done: False
______________________
id: 51 reward: 0.011645962732919254 service_time: 1652 s_time: -15 penalty: 0 agent_num: 23 done: False
______________________
id: 55 reward: -0.004270186335403727 service_time: 1779 s_time: 11 penalty: 0 agent_num: 46 done: False
______________________
id: 54 reward: -0.011583011583011582 service_time: 2023 s_time: 24 penalty: 0 agent_num: 37 done: False
______________________
id: 40 reward: -0.02295918367346939 service_time: 1942 s_time: 45 penalty: 0 agent_num: 35 done: False
______________________
id: 42 reward: -0.0205026455026455 service_time: 1690 s_time: 31 penalty: 0 agent_num: 27 done: False
______________________
id: 48 reward: -0.004270186335403727 service_time: 1995 s_time: 11 penalty: 0 agent_num: 46 done: False
______________________
id: 43 reward: -0.028361344537815126 service_time: 1057 s_time: 54 penalty: 0 agent_num: 34 done: False
______________________
Step:  3744
Pretraining Loss:  tensor(0.3896, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: 0.0 service_time: 377 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: -0.06655844155844155 service_time: 1016 s_time: 41 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: 0.016964285714285713 service_time: 670 s_time: -19 penalty: 0 agent_num: 20 done: False
______________________
id: 52 reward: -0.01948051948051948 service_time: 618 s_time: 24 penalty: 0 agent_num: 22 done: False
______________________
id: 50 reward: -0.02353896103896104 service_time: 1724 s_time: 29 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: -0.04017857142857143 service_time: 1117 s_time: 45 penalty: 0 agent_num: 20 done: False
______________________
id: 44 reward: -0.027930402930402932 service_time: 494 s_time: 61 penalty: 0 agent_num: 39 done: False
______________________
id: 51 reward: -0.07298136645962733 service_time: 1746 s_time: 94 penalty: 0 agent_num: 23 done: False
______________________
id: 42 reward: -0.0013227513227513227 service_time: 1692 s_time: 2 penalty: 0 agent_num: 27 done: False
______________________
id: 55 reward: -0.01048136645962733 service_time: 1806 s_time: 27 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: -0.003484320557491289 service_time: 1604 s_time: 8 penalty: 0 agent_num: 41 done: False
______________________
id: 40 reward: -0.006122448979591836 service_time: 1954 s_time: 12 penalty: 0 agent_num: 35 done: False
______________________
id: 46 reward: -0.0170265780730897 service_time: 869 s_time: 41 penalty: 0 agent_num: 43 done: False
______________________
id: 54 reward: -0.013513513513513514 service_time: 2051 s_time: 28 penalty: 0 agent_num: 37 done: False
______________________
id: 48 reward: -0.025232919254658384 service_time: 2060 s_time: 65 penalty: 0 agent_num: 46 done: False
______________________
id: 43 reward: -0.014705882352941176 service_time: 1085 s_time: 28 penalty: 0 agent_num: 34 done: False
______________________
Step:  3760
Pretraining Loss:  tensor(0.3716, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: -0.06428571428571428 service_time: 413 s_time: 36 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: 0.0 service_time: 1016 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: 0.008035714285714285 service_time: 1108 s_time: -9 penalty: 0 agent_num: 20 done: False
______________________
id: 50 reward: -0.0625 service_time: 1801 s_time: 77 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: 0.0 service_time: 670 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 52 reward: 0.0 service_time: 618 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 44 reward: -0.009615384615384616 service_time: 515 s_time: 21 penalty: 0 agent_num: 39 done: False
______________________
id: 53 reward: -0.016550522648083623 service_time: 1642 s_time: 38 penalty: 0 agent_num: 41 done: False
______________________
id: 40 reward: -0.008673469387755102 service_time: 1971 s_time: 17 penalty: 0 agent_num: 35 done: False
______________________
id: 51 reward: 0.0007763975155279503 service_time: 1745 s_time: -1 penalty: 0 agent_num: 23 done: False
______________________
id: 42 reward: -0.04497354497354497 service_time: 1760 s_time: 68 penalty: 0 agent_num: 27 done: False
______________________
id: 55 reward: -0.0015527950310559005 service_time: 1810 s_time: 4 penalty: 0 agent_num: 46 done: False
______________________
id: 54 reward: -0.011583011583011582 service_time: 2075 s_time: 24 penalty: 0 agent_num: 37 done: False
______________________
id: 46 reward: -0.011627906976744186 service_time: 897 s_time: 28 penalty: 0 agent_num: 43 done: False
______________________
id: 48 reward: -0.007763975155279503 service_time: 2080 s_time: 20 penalty: 0 agent_num: 46 done: False
______________________
id: 43 reward: -0.0063025210084033615 service_time: 1097 s_time: 12 penalty: 0 agent_num: 34 done: False
______________________
Step:  3776
Pretraining Loss:  tensor(0.3814, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: 0.0 service_time: 413 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: 0.0 service_time: 1016 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 50 reward: 0.002435064935064935 service_time: 1798 s_time: -3 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: 0.010714285714285714 service_time: 658 s_time: -12 penalty: 0 agent_num: 20 done: False
______________________
id: 52 reward: -0.048701298701298704 service_time: 678 s_time: 60 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: -0.020535714285714286 service_time: 1131 s_time: 23 penalty: 0 agent_num: 20 done: False
______________________
id: 44 reward: -0.013736263736263736 service_time: 545 s_time: 30 penalty: 0 agent_num: 39 done: False
______________________
id: 55 reward: -0.01203416149068323 service_time: 1841 s_time: 31 penalty: 0 agent_num: 46 done: False
______________________
id: 42 reward: -0.009259259259259259 service_time: 1774 s_time: 14 penalty: 0 agent_num: 27 done: False
______________________
id: 51 reward: 0.011645962732919254 service_time: 1730 s_time: -15 penalty: 0 agent_num: 23 done: False
______________________
id: 54 reward: -0.015444015444015444 service_time: 2107 s_time: 32 penalty: 0 agent_num: 37 done: False
______________________
id: 48 reward: -0.007763975155279503 service_time: 2100 s_time: 20 penalty: 0 agent_num: 46 done: False
______________________
id: 40 reward: 0.0 service_time: 1971 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 53 reward: -0.009146341463414634 service_time: 1663 s_time: 21 penalty: 0 agent_num: 41 done: False
______________________
id: 46 reward: -0.014119601328903655 service_time: 931 s_time: 34 penalty: 0 agent_num: 43 done: False
______________________
id: 43 reward: -0.01838235294117647 service_time: 1132 s_time: 35 penalty: 0 agent_num: 34 done: False
______________________
Step:  3792
Pretraining Loss:  tensor(0.3619, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: -0.09285714285714286 service_time: 465 s_time: 52 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: 0.0 service_time: 1016 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 52 reward: -0.011363636363636364 service_time: 692 s_time: 14 penalty: 0 agent_num: 22 done: False
______________________
id: 50 reward: 0.0 service_time: 1798 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: 0.0 service_time: 1131 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 49 reward: -0.022321428571428572 service_time: 683 s_time: 25 penalty: 0 agent_num: 20 done: False
______________________
id: 44 reward: -0.014652014652014652 service_time: 577 s_time: 32 penalty: 0 agent_num: 39 done: False
______________________
id: 46 reward: -0.005398671096345515 service_time: 944 s_time: 13 penalty: 0 agent_num: 43 done: False
______________________
id: 51 reward: 0.013198757763975156 service_time: 1713 s_time: -17 penalty: 0 agent_num: 23 done: False
______________________
id: 40 reward: -0.022448979591836733 service_time: 2015 s_time: 44 penalty: 0 agent_num: 35 done: False
______________________
id: 53 reward: -0.012195121951219513 service_time: 1691 s_time: 28 penalty: 0 agent_num: 41 done: False
______________________
id: 55 reward: -0.010093167701863354 service_time: 1867 s_time: 26 penalty: 0 agent_num: 46 done: False
______________________
id: 42 reward: 0.0006613756613756613 service_time: 1773 s_time: -1 penalty: 0 agent_num: 27 done: False
______________________
id: 54 reward: 0.0009652509652509653 service_time: 2105 s_time: -2 penalty: 0 agent_num: 37 done: False
______________________
id: 48 reward: -0.0038819875776397515 service_time: 2110 s_time: 10 penalty: 0 agent_num: 46 done: False
______________________
id: 43 reward: -0.01838235294117647 service_time: 1167 s_time: 35 penalty: 0 agent_num: 34 done: False
______________________
Step:  3808
Pretraining Loss:  tensor(0.3862, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: 0.005357142857142857 service_time: 462 s_time: -3 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: -0.10714285714285714 service_time: 1082 s_time: 66 penalty: 0 agent_num: 11 done: False
______________________
id: 50 reward: -0.02922077922077922 service_time: 1834 s_time: 36 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: -0.04196428571428571 service_time: 730 s_time: 47 penalty: 0 agent_num: 20 done: False
______________________
id: 52 reward: 0.0 service_time: 692 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: -0.04107142857142857 service_time: 1177 s_time: 46 penalty: 0 agent_num: 20 done: False
______________________
id: 44 reward: -0.016483516483516484 service_time: 613 s_time: 36 penalty: 0 agent_num: 39 done: False
______________________
id: 42 reward: -0.04365079365079365 service_time: 1839 s_time: 66 penalty: 0 agent_num: 27 done: False
______________________
id: 55 reward: 0.0 service_time: 1867 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 46 reward: -0.015780730897009966 service_time: 982 s_time: 38 penalty: 0 agent_num: 43 done: False
______________________
id: 51 reward: -0.03571428571428571 service_time: 1759 s_time: 46 penalty: 0 agent_num: 23 done: False
______________________
id: 53 reward: 0.0 service_time: 1691 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 40 reward: -0.027040816326530614 service_time: 2068 s_time: 53 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: 0.0 service_time: 2110 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 54 reward: -0.024613899613899613 service_time: 2156 s_time: 51 penalty: 0 agent_num: 37 done: False
______________________
id: 43 reward: -0.013130252100840336 service_time: 1192 s_time: 25 penalty: 0 agent_num: 34 done: False
______________________
Step:  3824
Pretraining Loss:  tensor(0.3797, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: 0.0125 service_time: 455 s_time: -7 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: -0.021103896103896104 service_time: 1095 s_time: 13 penalty: 0 agent_num: 11 done: False
______________________
id: 50 reward: -0.03571428571428571 service_time: 1878 s_time: 44 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: -0.02142857142857143 service_time: 754 s_time: 24 penalty: 0 agent_num: 20 done: False
______________________
id: 52 reward: -0.049512987012987016 service_time: 753 s_time: 61 penalty: 0 agent_num: 22 done: False
______________________
id: 42 reward: 0.005291005291005291 service_time: 1831 s_time: -8 penalty: 0 agent_num: 27 done: False
______________________
id: 44 reward: -0.007783882783882784 service_time: 630 s_time: 17 penalty: 0 agent_num: 39 done: False
______________________
id: 46 reward: -0.00872093023255814 service_time: 1003 s_time: 21 penalty: 0 agent_num: 43 done: False
______________________
id: 51 reward: -0.08462732919254658 service_time: 1868 s_time: 109 penalty: 0 agent_num: 23 done: False
______________________
id: 47 reward: 0.008928571428571428 service_time: 1167 s_time: -10 penalty: 0 agent_num: 20 done: False
______________________
id: 55 reward: -0.01358695652173913 service_time: 1902 s_time: 35 penalty: 0 agent_num: 46 done: False
______________________
id: 54 reward: -0.021235521235521235 service_time: 2200 s_time: 44 penalty: 0 agent_num: 37 done: False
______________________
id: 40 reward: -0.006122448979591836 service_time: 2080 s_time: 12 penalty: 0 agent_num: 35 done: False
______________________
id: 43 reward: -0.014705882352941176 service_time: 1220 s_time: 28 penalty: 0 agent_num: 34 done: False
______________________
id: 53 reward: -0.018728222996515678 service_time: 1734 s_time: 43 penalty: 0 agent_num: 41 done: False
______________________
id: 48 reward: -0.013975155279503106 service_time: 2146 s_time: 36 penalty: 0 agent_num: 46 done: False
______________________
Step:  3840
Pretraining Loss:  tensor(0.3643, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: -0.10714285714285714 service_time: 515 s_time: 60 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: -0.03571428571428571 service_time: 1117 s_time: 22 penalty: 0 agent_num: 11 done: False
______________________
id: 50 reward: 0.0 service_time: 1878 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 52 reward: 0.025162337662337664 service_time: 722 s_time: -31 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: 0.0 service_time: 754 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 47 reward: -0.022321428571428572 service_time: 1192 s_time: 25 penalty: 0 agent_num: 20 done: False
______________________
id: 42 reward: -0.04298941798941799 service_time: 1896 s_time: 65 penalty: 0 agent_num: 27 done: False
______________________
id: 44 reward: -0.005952380952380952 service_time: 643 s_time: 13 penalty: 0 agent_num: 39 done: False
______________________
id: 55 reward: -0.0038819875776397515 service_time: 1912 s_time: 10 penalty: 0 agent_num: 46 done: False
______________________
id: 40 reward: -0.01173469387755102 service_time: 2103 s_time: 23 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: 0.0 service_time: 2200 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 48 reward: -0.006987577639751553 service_time: 2164 s_time: 18 penalty: 0 agent_num: 46 done: False
______________________
id: 51 reward: -0.019409937888198756 service_time: 1893 s_time: 25 penalty: 0 agent_num: 23 done: False
______________________
id: 43 reward: -0.013130252100840336 service_time: 1245 s_time: 25 penalty: 0 agent_num: 34 done: False
______________________
id: 46 reward: -0.013704318936877076 service_time: 1036 s_time: 33 penalty: 0 agent_num: 43 done: False
______________________
id: 53 reward: -0.008710801393728223 service_time: 1754 s_time: 20 penalty: 0 agent_num: 41 done: False
______________________
Step:  3856
Pretraining Loss:  tensor(0.3762, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: -0.1875 service_time: 620 s_time: 105 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: -0.1185064935064935 service_time: 1190 s_time: 73 penalty: 0 agent_num: 11 done: False
______________________
id: 50 reward: 0.0 service_time: 1878 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: 0.0017857142857142857 service_time: 1190 s_time: -2 penalty: 0 agent_num: 20 done: False
______________________
id: 49 reward: -0.030357142857142857 service_time: 788 s_time: 34 penalty: 0 agent_num: 20 done: False
______________________
id: 44 reward: -0.00641025641025641 service_time: 657 s_time: 14 penalty: 0 agent_num: 39 done: False
______________________
id: 42 reward: 0.0 service_time: 1896 s_time: 0 penalty: 0 agent_num: 27 done: False
______________________
id: 51 reward: -0.016304347826086956 service_time: 1914 s_time: 21 penalty: 0 agent_num: 23 done: False
______________________
id: 54 reward: -0.017857142857142856 service_time: 2237 s_time: 37 penalty: 0 agent_num: 37 done: False
______________________
id: 40 reward: -0.013265306122448979 service_time: 2129 s_time: 26 penalty: 0 agent_num: 35 done: False
______________________
id: 55 reward: 0.0007763975155279503 service_time: 1910 s_time: -2 penalty: 0 agent_num: 46 done: False
______________________
id: 52 reward: -0.04626623376623377 service_time: 779 s_time: 57 penalty: 0 agent_num: 22 done: False
______________________
id: 46 reward: -0.009551495016611296 service_time: 1059 s_time: 23 penalty: 0 agent_num: 43 done: False
______________________
id: 43 reward: -0.017331932773109245 service_time: 1278 s_time: 33 penalty: 0 agent_num: 34 done: False
______________________
id: 53 reward: -0.01524390243902439 service_time: 1789 s_time: 35 penalty: 0 agent_num: 41 done: False
______________________
id: 48 reward: -0.0011645962732919255 service_time: 2167 s_time: 3 penalty: 0 agent_num: 46 done: False
______________________
Step:  3872
Pretraining Loss:  tensor(0.3954, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: 0.0 service_time: 620 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: 0.0 service_time: 1190 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: 0.0 service_time: 788 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 47 reward: 0.0 service_time: 1190 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 52 reward: -0.021915584415584416 service_time: 806 s_time: 27 penalty: 0 agent_num: 22 done: False
______________________
id: 50 reward: 0.0 service_time: 1878 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 44 reward: -0.020146520146520148 service_time: 701 s_time: 44 penalty: 0 agent_num: 39 done: False
______________________
id: 55 reward: -0.02096273291925466 service_time: 1964 s_time: 54 penalty: 0 agent_num: 46 done: False
______________________
id: 40 reward: -0.012755102040816327 service_time: 2154 s_time: 25 penalty: 0 agent_num: 35 done: False
______________________
id: 42 reward: -0.041666666666666664 service_time: 1959 s_time: 63 penalty: 0 agent_num: 27 done: False
______________________
id: 54 reward: -0.015444015444015444 service_time: 2269 s_time: 32 penalty: 0 agent_num: 37 done: False
______________________
id: 51 reward: 0.002329192546583851 service_time: 1911 s_time: -3 penalty: 0 agent_num: 23 done: False
______________________
id: 43 reward: -0.016281512605042018 service_time: 1309 s_time: 31 penalty: 0 agent_num: 34 done: False
______________________
id: 46 reward: -0.009136212624584718 service_time: 1081 s_time: 22 penalty: 0 agent_num: 43 done: False
______________________
id: 48 reward: -0.02251552795031056 service_time: 2225 s_time: 58 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: 0.0008710801393728223 service_time: 1787 s_time: -2 penalty: 0 agent_num: 41 done: False
______________________
Step:  3888
Pretraining Loss:  tensor(0.4039, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: 0.0 service_time: 620 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: -0.17857142857142858 service_time: 1300 s_time: 110 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: -0.019642857142857142 service_time: 1212 s_time: 22 penalty: 0 agent_num: 20 done: False
______________________
id: 50 reward: -0.05438311688311688 service_time: 1945 s_time: 67 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: 0.0 service_time: 788 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 44 reward: 0.0 service_time: 701 s_time: 0 penalty: 0 agent_num: 39 done: False
______________________
id: 51 reward: 0.0 service_time: 1911 s_time: 0 penalty: 0 agent_num: 23 done: False
______________________
id: 42 reward: -0.056216931216931214 service_time: 2044 s_time: 85 penalty: 0 agent_num: 27 done: False
______________________
id: 40 reward: -0.01683673469387755 service_time: 2187 s_time: 33 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: -0.009652509652509652 service_time: 2289 s_time: 20 penalty: 0 agent_num: 37 done: False
______________________
id: 52 reward: 0.021103896103896104 service_time: 780 s_time: -26 penalty: 0 agent_num: 22 done: False
______________________
id: 55 reward: -0.010869565217391304 service_time: 1992 s_time: 28 penalty: 0 agent_num: 46 done: False
______________________
id: 43 reward: -0.02468487394957983 service_time: 1356 s_time: 47 penalty: 0 agent_num: 34 done: False
______________________
id: 53 reward: -0.02700348432055749 service_time: 1849 s_time: 62 penalty: 0 agent_num: 41 done: False
______________________
id: 46 reward: -0.012043189368770765 service_time: 1110 s_time: 29 penalty: 0 agent_num: 43 done: False
______________________
id: 48 reward: -0.017857142857142856 service_time: 2271 s_time: 46 penalty: 0 agent_num: 46 done: False
______________________
Step:  3904
Pretraining Loss:  tensor(0.3533, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: 0.05194805194805195 service_time: 1268 s_time: -32 penalty: 0 agent_num: 11 done: False
______________________
id: 45 reward: 0.0 service_time: 620 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 47 reward: 0.0 service_time: 1212 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 52 reward: -0.028409090909090908 service_time: 815 s_time: 35 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: 0.0 service_time: 788 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 50 reward: -0.01461038961038961 service_time: 1963 s_time: 18 penalty: 0 agent_num: 22 done: False
______________________
id: 44 reward: -0.016483516483516484 service_time: 737 s_time: 36 penalty: 0 agent_num: 39 done: False
______________________
id: 51 reward: -0.07298136645962733 service_time: 2005 s_time: 94 penalty: 0 agent_num: 23 done: False
______________________
id: 42 reward: -0.01984126984126984 service_time: 2074 s_time: 30 penalty: 0 agent_num: 27 done: False
______________________
id: 54 reward: -0.016891891891891893 service_time: 2324 s_time: 35 penalty: 0 agent_num: 37 done: False
______________________
id: 48 reward: -0.005822981366459627 service_time: 2286 s_time: 15 penalty: 0 agent_num: 46 done: False
______________________
id: 46 reward: -0.009966777408637873 service_time: 1134 s_time: 24 penalty: 0 agent_num: 43 done: False
______________________
id: 55 reward: -0.017857142857142856 service_time: 2038 s_time: 46 penalty: 0 agent_num: 46 done: False
______________________
id: 40 reward: -0.025 service_time: 2236 s_time: 49 penalty: 0 agent_num: 35 done: False
______________________
id: 53 reward: 0.0008710801393728223 service_time: 1847 s_time: -2 penalty: 0 agent_num: 41 done: False
______________________
id: 43 reward: -0.025735294117647058 service_time: 1405 s_time: 49 penalty: 0 agent_num: 34 done: False
______________________
Step:  3920
Pretraining Loss:  tensor(0.3439, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: 0.0 service_time: 620 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: 0.0 service_time: 1268 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: 0.0 service_time: 788 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 47 reward: -0.013392857142857142 service_time: 1227 s_time: 15 penalty: 0 agent_num: 20 done: False
______________________
id: 50 reward: -0.020292207792207792 service_time: 1988 s_time: 25 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: -0.010093167701863354 service_time: 2018 s_time: 13 penalty: 0 agent_num: 23 done: False
______________________
id: 52 reward: 0.011363636363636364 service_time: 801 s_time: -14 penalty: 0 agent_num: 22 done: False
______________________
id: 42 reward: -0.022486772486772486 service_time: 2108 s_time: 34 penalty: 0 agent_num: 27 done: False
______________________
id: 54 reward: -0.012548262548262547 service_time: 2350 s_time: 26 penalty: 0 agent_num: 37 done: False
______________________
id: 46 reward: -0.008305647840531562 service_time: 1154 s_time: 20 penalty: 0 agent_num: 43 done: False
______________________
id: 44 reward: -0.031135531135531136 service_time: 805 s_time: 68 penalty: 0 agent_num: 39 done: False
______________________
id: 55 reward: 0.0007763975155279503 service_time: 2036 s_time: -2 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: -0.03092334494773519 service_time: 1918 s_time: 71 penalty: 0 agent_num: 41 done: False
______________________
id: 48 reward: 0.002717391304347826 service_time: 2279 s_time: -7 penalty: 0 agent_num: 46 done: False
______________________
id: 40 reward: -0.018877551020408164 service_time: 2273 s_time: 37 penalty: 0 agent_num: 35 done: False
______________________
id: 43 reward: -0.01995798319327731 service_time: 1443 s_time: 38 penalty: 0 agent_num: 34 done: False
______________________
Step:  3936
Pretraining Loss:  tensor(0.3475, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: -0.0375 service_time: 641 s_time: 21 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: -0.04383116883116883 service_time: 1295 s_time: 27 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: 0.0017857142857142857 service_time: 786 s_time: -2 penalty: 0 agent_num: 20 done: False
______________________
id: 52 reward: -0.032467532467532464 service_time: 841 s_time: 40 penalty: 0 agent_num: 22 done: False
______________________
id: 50 reward: 0.015422077922077922 service_time: 1969 s_time: -19 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: 0.0 service_time: 1227 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 51 reward: -0.020186335403726708 service_time: 2044 s_time: 26 penalty: 0 agent_num: 23 done: False
______________________
id: 54 reward: 0.0 service_time: 2350 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 42 reward: -0.03306878306878307 service_time: 2158 s_time: 50 penalty: 0 agent_num: 27 done: False
______________________
id: 44 reward: -0.004578754578754579 service_time: 815 s_time: 10 penalty: 0 agent_num: 39 done: False
______________________
id: 48 reward: -0.02251552795031056 service_time: 2337 s_time: 58 penalty: 0 agent_num: 46 done: False
______________________
id: 46 reward: 0.0008305647840531562 service_time: 1152 s_time: -2 penalty: 0 agent_num: 43 done: False
______________________
id: 55 reward: -0.015139751552795032 service_time: 2075 s_time: 39 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: 0.003048780487804878 service_time: 1911 s_time: -7 penalty: 0 agent_num: 41 done: False
______________________
id: 40 reward: -0.018367346938775512 service_time: 2309 s_time: 36 penalty: 0 agent_num: 35 done: False
______________________
id: 43 reward: -0.015756302521008403 service_time: 1473 s_time: 30 penalty: 0 agent_num: 34 done: False
______________________
Step:  3952
Pretraining Loss:  tensor(0.3876, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: 0.0 service_time: 641 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: 0.0 service_time: 1295 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: -0.01607142857142857 service_time: 1245 s_time: 18 penalty: 0 agent_num: 20 done: False
______________________
id: 52 reward: -0.041396103896103896 service_time: 892 s_time: 51 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: -0.015178571428571428 service_time: 803 s_time: 17 penalty: 0 agent_num: 20 done: False
______________________
id: 51 reward: -0.05357142857142857 service_time: 2113 s_time: 69 penalty: 0 agent_num: 23 done: False
______________________
id: 50 reward: -0.02922077922077922 service_time: 2005 s_time: 36 penalty: 0 agent_num: 22 done: False
______________________
id: 42 reward: 0.001984126984126984 service_time: 2155 s_time: -3 penalty: 0 agent_num: 27 done: False
______________________
id: 55 reward: -0.01203416149068323 service_time: 2106 s_time: 31 penalty: 0 agent_num: 46 done: False
______________________
id: 54 reward: -0.02895752895752896 service_time: 2410 s_time: 60 penalty: 0 agent_num: 37 done: False
______________________
id: 40 reward: 0.003061224489795918 service_time: 2303 s_time: -6 penalty: 0 agent_num: 35 done: False
______________________
id: 44 reward: -0.014652014652014652 service_time: 847 s_time: 32 penalty: 0 agent_num: 39 done: False
______________________
id: 46 reward: -0.016196013289036543 service_time: 1191 s_time: 39 penalty: 0 agent_num: 43 done: False
______________________
id: 48 reward: -0.008152173913043478 service_time: 2358 s_time: 21 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: -0.027874564459930314 service_time: 1975 s_time: 64 penalty: 0 agent_num: 41 done: False
______________________
id: 43 reward: -0.026785714285714284 service_time: 1524 s_time: 51 penalty: 0 agent_num: 34 done: False
______________________
Step:  3968
Pretraining Loss:  tensor(0.3607, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: 0.0 service_time: 641 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: -0.027597402597402596 service_time: 1312 s_time: 17 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: 0.0 service_time: 803 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 52 reward: -0.00974025974025974 service_time: 904 s_time: 12 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: -0.020186335403726708 service_time: 2139 s_time: 26 penalty: 0 agent_num: 23 done: False
______________________
id: 50 reward: -0.06168831168831169 service_time: 2081 s_time: 76 penalty: 0 agent_num: 22 done: False
______________________
id: 44 reward: -0.005036630036630037 service_time: 858 s_time: 11 penalty: 0 agent_num: 39 done: False
______________________
id: 47 reward: -0.010714285714285714 service_time: 1257 s_time: 12 penalty: 0 agent_num: 20 done: False
______________________
id: 46 reward: -0.012043189368770765 service_time: 1220 s_time: 29 penalty: 0 agent_num: 43 done: False
______________________
id: 42 reward: 0.026455026455026454 service_time: 2115 s_time: -40 penalty: 0 agent_num: 27 done: False
______________________
id: 48 reward: 0.0 service_time: 2358 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 55 reward: -0.01358695652173913 service_time: 2141 s_time: 35 penalty: 0 agent_num: 46 done: False
______________________
id: 54 reward: 0.0 service_time: 2410 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: -0.016114982578397212 service_time: 2012 s_time: 37 penalty: 0 agent_num: 41 done: False
______________________
id: 40 reward: -0.03214285714285714 service_time: 2366 s_time: 63 penalty: 0 agent_num: 35 done: False
______________________
id: 43 reward: -0.014180672268907563 service_time: 1551 s_time: 27 penalty: 0 agent_num: 34 done: False
______________________
Step:  3984
Pretraining Loss:  tensor(0.3913, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: 0.0 service_time: 641 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: 0.1038961038961039 service_time: 1248 s_time: -64 penalty: 0 agent_num: 11 done: False
______________________
id: 52 reward: -0.026785714285714284 service_time: 937 s_time: 33 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: -0.03660714285714286 service_time: 844 s_time: 41 penalty: 0 agent_num: 20 done: False
______________________
id: 47 reward: -0.05267857142857143 service_time: 1316 s_time: 59 penalty: 0 agent_num: 20 done: False
______________________
id: 42 reward: 0.0 service_time: 2115 s_time: 0 penalty: 0 agent_num: 27 done: False
______________________
id: 51 reward: -0.02562111801242236 service_time: 2172 s_time: 33 penalty: 0 agent_num: 23 done: False
______________________
id: 50 reward: 0.03165584415584415 service_time: 2042 s_time: -39 penalty: 0 agent_num: 22 done: False
______________________
id: 46 reward: 0.0 service_time: 1220 s_time: 0 penalty: 0 agent_num: 43 done: False
______________________
id: 44 reward: -0.01098901098901099 service_time: 882 s_time: 24 penalty: 0 agent_num: 39 done: False
______________________
id: 40 reward: 0.001530612244897959 service_time: 2363 s_time: -3 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: -0.03426640926640927 service_time: 2481 s_time: 71 penalty: 0 agent_num: 37 done: False
______________________
id: 55 reward: -0.009704968944099378 service_time: 2166 s_time: 25 penalty: 0 agent_num: 46 done: False
______________________
id: 48 reward: -0.022127329192546584 service_time: 2415 s_time: 57 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: 0.0 service_time: 2012 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 43 reward: -0.015756302521008403 service_time: 1581 s_time: 30 penalty: 0 agent_num: 34 done: False
______________________
Step:  4000
Pretraining Loss:  tensor(0.4274, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: 0.0 service_time: 641 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: 0.0 service_time: 1248 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: -0.05803571428571429 service_time: 909 s_time: 65 penalty: 0 agent_num: 20 done: False
______________________
id: 52 reward: 0.010551948051948052 service_time: 924 s_time: -13 penalty: 0 agent_num: 22 done: False
______________________
id: 50 reward: -0.052759740259740256 service_time: 2107 s_time: 65 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: 0.0 service_time: 1316 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 51 reward: 0.0 service_time: 2172 s_time: 0 penalty: 0 agent_num: 23 done: False
______________________
id: 44 reward: 0.0 service_time: 882 s_time: 0 penalty: 0 agent_num: 39 done: False
______________________
id: 46 reward: -0.023255813953488372 service_time: 1276 s_time: 56 penalty: 0 agent_num: 43 done: False
______________________
id: 55 reward: -0.0034937888198757765 service_time: 2175 s_time: 9 penalty: 0 agent_num: 46 done: False
______________________
id: 42 reward: -0.02447089947089947 service_time: 2152 s_time: 37 penalty: 0 agent_num: 27 done: False
______________________
id: 48 reward: -0.005046583850931677 service_time: 2428 s_time: 13 penalty: 0 agent_num: 46 done: False
______________________
id: 40 reward: -0.0326530612244898 service_time: 2427 s_time: 64 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: 0.0009652509652509653 service_time: 2479 s_time: -2 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: -0.009146341463414634 service_time: 2033 s_time: 21 penalty: 0 agent_num: 41 done: False
______________________
id: 43 reward: -0.009978991596638655 service_time: 1600 s_time: 19 penalty: 0 agent_num: 34 done: False
______________________
Step:  4016
Pretraining Loss:  tensor(0.4074, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: 0.0 service_time: 641 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: 0.0 service_time: 1248 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 52 reward: 0.006493506493506494 service_time: 916 s_time: -8 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: -0.11517857142857142 service_time: 1038 s_time: 129 penalty: 0 agent_num: 20 done: False
______________________
id: 47 reward: 0.0 service_time: 1316 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 51 reward: 0.0 service_time: 2172 s_time: 0 penalty: 0 agent_num: 23 done: False
______________________
id: 42 reward: 0.0 service_time: 2152 s_time: 0 penalty: 0 agent_num: 27 done: False
______________________
id: 50 reward: 0.021103896103896104 service_time: 2081 s_time: -26 penalty: 0 agent_num: 22 done: False
______________________
id: 44 reward: -0.011904761904761904 service_time: 908 s_time: 26 penalty: 0 agent_num: 39 done: False
______________________
id: 55 reward: -0.007375776397515528 service_time: 2194 s_time: 19 penalty: 0 agent_num: 46 done: False
______________________
id: 46 reward: -0.006229235880398671 service_time: 1291 s_time: 15 penalty: 0 agent_num: 43 done: False
______________________
id: 48 reward: -0.01203416149068323 service_time: 2459 s_time: 31 penalty: 0 agent_num: 46 done: False
______________________
id: 40 reward: -0.007142857142857143 service_time: 2441 s_time: 14 penalty: 0 agent_num: 35 done: False
______________________
id: 53 reward: 0.0 service_time: 2033 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 54 reward: -0.033301158301158304 service_time: 2548 s_time: 69 penalty: 0 agent_num: 37 done: False
______________________
id: 43 reward: -0.023109243697478993 service_time: 1644 s_time: 44 penalty: 0 agent_num: 34 done: False
______________________
Step:  4032
Pretraining Loss:  tensor(0.3995, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: 0.0 service_time: 641 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: 0.025974025974025976 service_time: 1232 s_time: -16 penalty: 0 agent_num: 11 done: False
______________________
id: 52 reward: -0.022727272727272728 service_time: 944 s_time: 28 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: 0.0 service_time: 1316 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 49 reward: -0.09107142857142857 service_time: 1140 s_time: 102 penalty: 0 agent_num: 20 done: False
______________________
id: 51 reward: -0.016304347826086956 service_time: 2193 s_time: 21 penalty: 0 agent_num: 23 done: False
______________________
id: 44 reward: -0.012362637362637362 service_time: 935 s_time: 27 penalty: 0 agent_num: 39 done: False
______________________
id: 42 reward: -0.003968253968253968 service_time: 2158 s_time: 6 penalty: 0 agent_num: 27 done: False
______________________
id: 40 reward: -0.005612244897959183 service_time: 2452 s_time: 11 penalty: 0 agent_num: 35 done: False
______________________
id: 46 reward: -0.009551495016611296 service_time: 1314 s_time: 23 penalty: 0 agent_num: 43 done: False
______________________
id: 50 reward: -0.011363636363636364 service_time: 2095 s_time: 14 penalty: 0 agent_num: 22 done: False
______________________
id: 55 reward: -0.01048136645962733 service_time: 2221 s_time: 27 penalty: 0 agent_num: 46 done: False
______________________
id: 48 reward: -0.01125776397515528 service_time: 2488 s_time: 29 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: -0.023083623693379792 service_time: 2086 s_time: 53 penalty: 0 agent_num: 41 done: False
______________________
id: 54 reward: -0.015444015444015444 service_time: 2580 s_time: 32 penalty: 0 agent_num: 37 done: False
______________________
id: 43 reward: -0.01050420168067227 service_time: 1664 s_time: 20 penalty: 0 agent_num: 34 done: False
______________________
Step:  4048
Pretraining Loss:  tensor(0.3855, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: -0.033928571428571426 service_time: 660 s_time: 19 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: -0.060064935064935064 service_time: 1269 s_time: 37 penalty: 0 agent_num: 11 done: False
______________________
id: 50 reward: -0.07224025974025974 service_time: 2184 s_time: 89 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: -0.004464285714285714 service_time: 1321 s_time: 5 penalty: 0 agent_num: 20 done: False
______________________
id: 52 reward: -0.08279220779220779 service_time: 1046 s_time: 102 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: -0.03571428571428571 service_time: 2239 s_time: 46 penalty: 0 agent_num: 23 done: False
______________________
id: 42 reward: -0.04497354497354497 service_time: 2226 s_time: 68 penalty: 0 agent_num: 27 done: False
______________________
id: 49 reward: 0.0035714285714285713 service_time: 1136 s_time: -4 penalty: 0 agent_num: 20 done: False
______________________
id: 40 reward: -0.022448979591836733 service_time: 2496 s_time: 44 penalty: 0 agent_num: 35 done: False
______________________
id: 46 reward: -0.006644518272425249 service_time: 1330 s_time: 16 penalty: 0 agent_num: 43 done: False
______________________
id: 55 reward: -0.01281055900621118 service_time: 2254 s_time: 33 penalty: 0 agent_num: 46 done: False
______________________
id: 44 reward: -0.0260989010989011 service_time: 992 s_time: 57 penalty: 0 agent_num: 39 done: False
______________________
id: 48 reward: -0.010869565217391304 service_time: 2516 s_time: 28 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: -0.006533101045296167 service_time: 2101 s_time: 15 penalty: 0 agent_num: 41 done: False
______________________
id: 43 reward: 0.017857142857142856 service_time: 1630 s_time: -34 penalty: 0 agent_num: 34 done: False
______________________
id: 54 reward: -0.010617760617760617 service_time: 2602 s_time: 22 penalty: 0 agent_num: 37 done: False
______________________
Step:  4064
Pretraining Loss:  tensor(0.3481, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: -0.07857142857142857 service_time: 704 s_time: 44 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: -0.032467532467532464 service_time: 1289 s_time: 20 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: 0.0 service_time: 1321 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 50 reward: 0.016233766233766232 service_time: 2164 s_time: -20 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: 0.017080745341614908 service_time: 2217 s_time: -22 penalty: 0 agent_num: 23 done: False
______________________
id: 52 reward: -0.0689935064935065 service_time: 1131 s_time: 85 penalty: 0 agent_num: 22 done: False
______________________
id: 44 reward: -0.004120879120879121 service_time: 1001 s_time: 9 penalty: 0 agent_num: 39 done: False
______________________
id: 40 reward: -0.015816326530612244 service_time: 2527 s_time: 31 penalty: 0 agent_num: 35 done: False
______________________
id: 55 reward: -0.01281055900621118 service_time: 2287 s_time: 33 penalty: 0 agent_num: 46 done: False
______________________
id: 46 reward: -0.006229235880398671 service_time: 1345 s_time: 15 penalty: 0 agent_num: 43 done: False
______________________
id: 49 reward: -0.027678571428571427 service_time: 1167 s_time: 31 penalty: 0 agent_num: 20 done: False
______________________
id: 42 reward: 0.005291005291005291 service_time: 2218 s_time: -8 penalty: 0 agent_num: 27 done: False
______________________
id: 48 reward: 0.0 service_time: 2516 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: -0.021341463414634148 service_time: 2150 s_time: 49 penalty: 0 agent_num: 41 done: False
______________________
id: 43 reward: -0.013130252100840336 service_time: 1655 s_time: 25 penalty: 0 agent_num: 34 done: False
______________________
id: 54 reward: -0.007722007722007722 service_time: 2618 s_time: 16 penalty: 0 agent_num: 37 done: False
______________________
Step:  4080
Pretraining Loss:  tensor(0.3220, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.02922077922077922 service_time: 1307 s_time: 18 penalty: 0 agent_num: 11 done: False
______________________
id: 45 reward: -0.05892857142857143 service_time: 737 s_time: 33 penalty: 0 agent_num: 10 done: False
______________________
id: 47 reward: 0.0 service_time: 1321 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 50 reward: -0.030032467532467532 service_time: 2201 s_time: 37 penalty: 0 agent_num: 22 done: False
______________________
id: 52 reward: 0.021915584415584416 service_time: 1104 s_time: -27 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: 0.0 service_time: 2217 s_time: 0 penalty: 0 agent_num: 23 done: False
______________________
id: 42 reward: -0.0013227513227513227 service_time: 2220 s_time: 2 penalty: 0 agent_num: 27 done: False
______________________
id: 49 reward: -0.05357142857142857 service_time: 1227 s_time: 60 penalty: 0 agent_num: 20 done: False
______________________
id: 44 reward: 0.0 service_time: 1001 s_time: 0 penalty: 0 agent_num: 39 done: False
______________________
id: 48 reward: -0.02251552795031056 service_time: 2574 s_time: 58 penalty: 0 agent_num: 46 done: False
______________________
id: 46 reward: -0.009966777408637873 service_time: 1369 s_time: 24 penalty: 0 agent_num: 43 done: False
______________________
id: 40 reward: -0.008673469387755102 service_time: 2544 s_time: 17 penalty: 0 agent_num: 35 done: False
______________________
id: 53 reward: 0.00043554006968641115 service_time: 2149 s_time: -1 penalty: 0 agent_num: 41 done: False
______________________
id: 55 reward: 0.003105590062111801 service_time: 2279 s_time: -8 penalty: 0 agent_num: 46 done: False
______________________
id: 54 reward: -0.008204633204633204 service_time: 2635 s_time: 17 penalty: 0 agent_num: 37 done: False
______________________
id: 43 reward: -0.018907563025210083 service_time: 1691 s_time: 36 penalty: 0 agent_num: 34 done: False
______________________
Step:  4096
Pretraining Loss:  tensor(0.3041, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: 0.0 service_time: 1307 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 45 reward: 0.0 service_time: 737 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 52 reward: -0.003246753246753247 service_time: 1108 s_time: 4 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: 0.0 service_time: 1321 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 50 reward: 0.0016233766233766235 service_time: 2199 s_time: -2 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: -0.05357142857142857 service_time: 2286 s_time: 69 penalty: 0 agent_num: 23 done: False
______________________
id: 44 reward: -0.011446886446886446 service_time: 1026 s_time: 25 penalty: 0 agent_num: 39 done: False
______________________
id: 49 reward: -0.04375 service_time: 1276 s_time: 49 penalty: 0 agent_num: 20 done: False
______________________
id: 42 reward: -0.01521164021164021 service_time: 2243 s_time: 23 penalty: 0 agent_num: 27 done: False
______________________
id: 55 reward: -0.005434782608695652 service_time: 2293 s_time: 14 penalty: 0 agent_num: 46 done: False
______________________
id: 46 reward: 0.0016611295681063123 service_time: 1365 s_time: -4 penalty: 0 agent_num: 43 done: False
______________________
id: 40 reward: -0.00816326530612245 service_time: 2560 s_time: 16 penalty: 0 agent_num: 35 done: False
______________________
id: 53 reward: -0.02177700348432056 service_time: 2199 s_time: 50 penalty: 0 agent_num: 41 done: False
______________________
id: 48 reward: -0.007375776397515528 service_time: 2593 s_time: 19 penalty: 0 agent_num: 46 done: False
______________________
id: 43 reward: -0.008928571428571428 service_time: 1708 s_time: 17 penalty: 0 agent_num: 34 done: False
______________________
id: 54 reward: -0.022683397683397683 service_time: 2682 s_time: 47 penalty: 0 agent_num: 37 done: False
______________________
Step:  4112
Pretraining Loss:  tensor(0.3275, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.03896103896103896 service_time: 1331 s_time: 24 penalty: 0 agent_num: 11 done: False
______________________
id: 45 reward: 0.0 service_time: 737 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 50 reward: -0.06493506493506493 service_time: 2279 s_time: 80 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: -0.020535714285714286 service_time: 1299 s_time: 23 penalty: 0 agent_num: 20 done: False
______________________
id: 51 reward: -0.030279503105590064 service_time: 2325 s_time: 39 penalty: 0 agent_num: 23 done: False
______________________
id: 47 reward: -0.03214285714285714 service_time: 1357 s_time: 36 penalty: 0 agent_num: 20 done: False
______________________
id: 42 reward: -0.028439153439153438 service_time: 2286 s_time: 43 penalty: 0 agent_num: 27 done: False
______________________
id: 52 reward: -0.00974025974025974 service_time: 1120 s_time: 12 penalty: 0 agent_num: 22 done: False
______________________
id: 44 reward: -0.014652014652014652 service_time: 1058 s_time: 32 penalty: 0 agent_num: 39 done: False
______________________
id: 40 reward: 0.0005102040816326531 service_time: 2559 s_time: -1 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: 0.00048262548262548264 service_time: 2681 s_time: -1 penalty: 0 agent_num: 37 done: False
______________________
id: 48 reward: -0.010093167701863354 service_time: 2619 s_time: 26 penalty: 0 agent_num: 46 done: False
______________________
id: 46 reward: -0.017857142857142856 service_time: 1408 s_time: 43 penalty: 0 agent_num: 43 done: False
______________________
id: 55 reward: -0.017857142857142856 service_time: 2339 s_time: 46 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: -0.013937282229965157 service_time: 2231 s_time: 32 penalty: 0 agent_num: 41 done: False
______________________
id: 43 reward: 0.0063025210084033615 service_time: 1696 s_time: -12 penalty: 0 agent_num: 34 done: False
______________________
Step:  4128
Pretraining Loss:  tensor(0.3305, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.1314935064935065 service_time: 1412 s_time: 81 penalty: 0 agent_num: 11 done: False
______________________
id: 45 reward: -0.039285714285714285 service_time: 759 s_time: 22 penalty: 0 agent_num: 10 done: False
______________________
id: 52 reward: -0.03571428571428571 service_time: 1164 s_time: 44 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: -0.017857142857142856 service_time: 1319 s_time: 20 penalty: 0 agent_num: 20 done: False
______________________
id: 51 reward: -0.07065217391304347 service_time: 2416 s_time: 91 penalty: 0 agent_num: 23 done: False
______________________
id: 50 reward: -0.044642857142857144 service_time: 2334 s_time: 55 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: -0.014285714285714285 service_time: 1373 s_time: 16 penalty: 0 agent_num: 20 done: False
______________________
id: 44 reward: -0.014194139194139194 service_time: 1089 s_time: 31 penalty: 0 agent_num: 39 done: False
______________________
id: 55 reward: 0.0 service_time: 2339 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 40 reward: -0.0336734693877551 service_time: 2625 s_time: 66 penalty: 0 agent_num: 35 done: False
______________________
id: 53 reward: -0.013501742160278746 service_time: 2262 s_time: 31 penalty: 0 agent_num: 41 done: False
______________________
id: 46 reward: -0.007890365448504983 service_time: 1427 s_time: 19 penalty: 0 agent_num: 43 done: False
______________________
id: 42 reward: -0.01521164021164021 service_time: 2309 s_time: 23 penalty: 0 agent_num: 27 done: False
______________________
id: 43 reward: -0.013130252100840336 service_time: 1721 s_time: 25 penalty: 0 agent_num: 34 done: False
______________________
id: 54 reward: -0.008204633204633204 service_time: 2698 s_time: 17 penalty: 0 agent_num: 37 done: False
______________________
id: 48 reward: -0.017857142857142856 service_time: 2665 s_time: 46 penalty: 0 agent_num: 46 done: False
______________________
Step:  4144
Pretraining Loss:  tensor(0.3155, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.0762987012987013 service_time: 1459 s_time: 47 penalty: 0 agent_num: 11 done: False
______________________
id: 45 reward: 0.0 service_time: 759 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 52 reward: 0.03814935064935065 service_time: 1117 s_time: -47 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: -0.10403726708074534 service_time: 2550 s_time: 134 penalty: 0 agent_num: 23 done: False
______________________
id: 49 reward: 0.039285714285714285 service_time: 1275 s_time: -44 penalty: 0 agent_num: 20 done: False
______________________
id: 50 reward: 0.0 service_time: 2334 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 44 reward: -0.01282051282051282 service_time: 1117 s_time: 28 penalty: 0 agent_num: 39 done: False
______________________
id: 54 reward: -0.010135135135135136 service_time: 2719 s_time: 21 penalty: 0 agent_num: 37 done: False
______________________
id: 40 reward: -0.020918367346938777 service_time: 2666 s_time: 41 penalty: 0 agent_num: 35 done: False
______________________
id: 43 reward: -0.01207983193277311 service_time: 1744 s_time: 23 penalty: 0 agent_num: 34 done: False
______________________
id: 47 reward: -0.011607142857142858 service_time: 1386 s_time: 13 penalty: 0 agent_num: 20 done: False
______________________
id: 48 reward: -0.01125776397515528 service_time: 2694 s_time: 29 penalty: 0 agent_num: 46 done: False
______________________
id: 42 reward: -0.04298941798941799 service_time: 2374 s_time: 65 penalty: 0 agent_num: 27 done: False
______________________
id: 53 reward: -0.006533101045296167 service_time: 2277 s_time: 15 penalty: 0 agent_num: 41 done: False
______________________
id: 55 reward: -0.023680124223602484 service_time: 2400 s_time: 61 penalty: 0 agent_num: 46 done: False
______________________
id: 46 reward: -0.02117940199335548 service_time: 1478 s_time: 51 penalty: 0 agent_num: 43 done: False
______________________
Step:  4160
Pretraining Loss:  tensor(0.3343, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: 0.012987012987012988 service_time: 1451 s_time: -8 penalty: 0 agent_num: 11 done: False
______________________
id: 45 reward: -0.0625 service_time: 794 s_time: 35 penalty: 0 agent_num: 10 done: False
______________________
id: 49 reward: -0.06339285714285714 service_time: 1346 s_time: 71 penalty: 0 agent_num: 20 done: False
______________________
id: 52 reward: -0.03896103896103896 service_time: 1165 s_time: 48 penalty: 0 agent_num: 22 done: False
______________________
id: 50 reward: 0.0 service_time: 2334 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 44 reward: -0.010531135531135532 service_time: 1140 s_time: 23 penalty: 0 agent_num: 39 done: False
______________________
id: 51 reward: 0.05201863354037267 service_time: 2483 s_time: -67 penalty: 0 agent_num: 23 done: False
______________________
id: 47 reward: -0.023214285714285715 service_time: 1412 s_time: 26 penalty: 0 agent_num: 20 done: False
______________________
id: 53 reward: -0.020905923344947737 service_time: 2325 s_time: 48 penalty: 0 agent_num: 41 done: False
______________________
id: 40 reward: -0.015816326530612244 service_time: 2697 s_time: 31 penalty: 0 agent_num: 35 done: False
______________________
id: 43 reward: -0.020483193277310924 service_time: 1783 s_time: 39 penalty: 0 agent_num: 34 done: False
______________________
id: 55 reward: -0.010093167701863354 service_time: 2426 s_time: 26 penalty: 0 agent_num: 46 done: False
______________________
id: 46 reward: -0.007890365448504983 service_time: 1497 s_time: 19 penalty: 0 agent_num: 43 done: False
______________________
id: 48 reward: -0.013198757763975156 service_time: 2728 s_time: 34 penalty: 0 agent_num: 46 done: False
______________________
id: 42 reward: -0.041005291005291 service_time: 2436 s_time: 62 penalty: 0 agent_num: 27 done: False
______________________
id: 54 reward: -0.00723938223938224 service_time: 2734 s_time: 15 penalty: 0 agent_num: 37 done: False
______________________
Step:  4176
Pretraining Loss:  tensor(0.3367, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: 0.0 service_time: 794 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: -0.05194805194805195 service_time: 1483 s_time: 32 penalty: 0 agent_num: 11 done: False
______________________
id: 50 reward: 0.0 service_time: 2334 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 52 reward: -0.0633116883116883 service_time: 1243 s_time: 78 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: 0.008540372670807454 service_time: 2472 s_time: -11 penalty: 0 agent_num: 23 done: False
______________________
id: 49 reward: 0.020535714285714286 service_time: 1323 s_time: -23 penalty: 0 agent_num: 20 done: False
______________________
id: 54 reward: 0.0014478764478764478 service_time: 2731 s_time: -3 penalty: 0 agent_num: 37 done: False
______________________
id: 43 reward: -0.0010504201680672268 service_time: 1785 s_time: 2 penalty: 0 agent_num: 34 done: False
______________________
id: 44 reward: -0.0086996336996337 service_time: 1159 s_time: 19 penalty: 0 agent_num: 39 done: False
______________________
id: 47 reward: -0.015178571428571428 service_time: 1429 s_time: 17 penalty: 0 agent_num: 20 done: False
______________________
id: 40 reward: -0.013265306122448979 service_time: 2723 s_time: 26 penalty: 0 agent_num: 35 done: False
______________________
id: 42 reward: 0.02513227513227513 service_time: 2398 s_time: -38 penalty: 0 agent_num: 27 done: False
______________________
id: 55 reward: 0.00038819875776397513 service_time: 2425 s_time: -1 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: -0.017857142857142856 service_time: 2366 s_time: 41 penalty: 0 agent_num: 41 done: False
______________________
id: 46 reward: -0.0070598006644518275 service_time: 1514 s_time: 17 penalty: 0 agent_num: 43 done: False
______________________
id: 48 reward: -0.012422360248447204 service_time: 2760 s_time: 32 penalty: 0 agent_num: 46 done: False
______________________
Step:  4192
Pretraining Loss:  tensor(0.3556, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: 0.0 service_time: 794 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: -0.06655844155844155 service_time: 1524 s_time: 41 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: -0.04285714285714286 service_time: 1371 s_time: 48 penalty: 0 agent_num: 20 done: False
______________________
id: 47 reward: -0.023214285714285715 service_time: 1455 s_time: 26 penalty: 0 agent_num: 20 done: False
______________________
id: 52 reward: 0.011363636363636364 service_time: 1229 s_time: -14 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: -0.07142857142857142 service_time: 2564 s_time: 92 penalty: 0 agent_num: 23 done: False
______________________
id: 44 reward: -0.019688644688644688 service_time: 1202 s_time: 43 penalty: 0 agent_num: 39 done: False
______________________
id: 42 reward: 0.006613756613756613 service_time: 2388 s_time: -10 penalty: 0 agent_num: 27 done: False
______________________
id: 50 reward: -0.1534090909090909 service_time: 2523 s_time: 189 penalty: 0 agent_num: 22 done: False
______________________
id: 55 reward: -0.02562111801242236 service_time: 2491 s_time: 66 penalty: 0 agent_num: 46 done: False
______________________
id: 40 reward: -0.012755102040816327 service_time: 2748 s_time: 25 penalty: 0 agent_num: 35 done: False
______________________
id: 43 reward: -0.03571428571428571 service_time: 1853 s_time: 68 penalty: 0 agent_num: 34 done: False
______________________
id: 54 reward: -0.03426640926640927 service_time: 2802 s_time: 71 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: -0.009581881533101045 service_time: 2388 s_time: 22 penalty: 0 agent_num: 41 done: False
______________________
id: 48 reward: -0.008928571428571428 service_time: 2783 s_time: 23 penalty: 0 agent_num: 46 done: False
______________________
id: 46 reward: -0.02117940199335548 service_time: 1565 s_time: 51 penalty: 0 agent_num: 43 done: False
______________________
Step:  4208
Pretraining Loss:  tensor(0.3764, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: -0.19464285714285715 service_time: 903 s_time: 109 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: -0.1314935064935065 service_time: 1605 s_time: 81 penalty: 0 agent_num: 11 done: False
______________________
id: 52 reward: 0.0 service_time: 1229 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: 0.013975155279503106 service_time: 2546 s_time: -18 penalty: 0 agent_num: 23 done: False
______________________
id: 50 reward: 0.05762987012987013 service_time: 2452 s_time: -71 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: -0.016964285714285713 service_time: 1474 s_time: 19 penalty: 0 agent_num: 20 done: False
______________________
id: 49 reward: -0.020535714285714286 service_time: 1394 s_time: 23 penalty: 0 agent_num: 20 done: False
______________________
id: 42 reward: -0.001984126984126984 service_time: 2391 s_time: 3 penalty: 0 agent_num: 27 done: False
______________________
id: 40 reward: -0.026020408163265306 service_time: 2799 s_time: 51 penalty: 0 agent_num: 35 done: False
______________________
id: 44 reward: -0.011904761904761904 service_time: 1228 s_time: 26 penalty: 0 agent_num: 39 done: False
______________________
id: 43 reward: -0.01207983193277311 service_time: 1876 s_time: 23 penalty: 0 agent_num: 34 done: False
______________________
id: 54 reward: -0.011583011583011582 service_time: 2826 s_time: 24 penalty: 0 agent_num: 37 done: False
______________________
id: 55 reward: 0.0 service_time: 2491 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: -0.006533101045296167 service_time: 2403 s_time: 15 penalty: 0 agent_num: 41 done: False
______________________
id: 48 reward: -0.011645962732919254 service_time: 2813 s_time: 30 penalty: 0 agent_num: 46 done: False
______________________
id: 46 reward: -0.010382059800664452 service_time: 1590 s_time: 25 penalty: 0 agent_num: 43 done: False
______________________
Step:  4224
Pretraining Loss:  tensor(0.3914, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: -0.08392857142857142 service_time: 950 s_time: 47 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: 0.04220779220779221 service_time: 1579 s_time: -26 penalty: 0 agent_num: 11 done: False
______________________
id: 52 reward: -0.013798701298701298 service_time: 1246 s_time: 17 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: -0.026785714285714284 service_time: 1504 s_time: 30 penalty: 0 agent_num: 20 done: False
______________________
id: 49 reward: -0.04375 service_time: 1443 s_time: 49 penalty: 0 agent_num: 20 done: False
______________________
id: 51 reward: -0.04813664596273292 service_time: 2608 s_time: 62 penalty: 0 agent_num: 23 done: False
______________________
id: 50 reward: 0.021103896103896104 service_time: 2426 s_time: -26 penalty: 0 agent_num: 22 done: False
______________________
id: 44 reward: 0.0 service_time: 1228 s_time: 0 penalty: 0 agent_num: 39 done: False
______________________
id: 40 reward: 0.0 service_time: 2799 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 42 reward: -0.027116402116402115 service_time: 2432 s_time: 41 penalty: 0 agent_num: 27 done: False
______________________
id: 53 reward: -0.004355400696864111 service_time: 2413 s_time: 10 penalty: 0 agent_num: 41 done: False
______________________
id: 43 reward: -0.015756302521008403 service_time: 1906 s_time: 30 penalty: 0 agent_num: 34 done: False
______________________
id: 54 reward: -0.016409266409266408 service_time: 2860 s_time: 34 penalty: 0 agent_num: 37 done: False
______________________
id: 55 reward: -0.01281055900621118 service_time: 2524 s_time: 33 penalty: 0 agent_num: 46 done: False
______________________
id: 48 reward: -0.008152173913043478 service_time: 2834 s_time: 21 penalty: 0 agent_num: 46 done: False
______________________
id: 46 reward: -0.009966777408637873 service_time: 1614 s_time: 24 penalty: 0 agent_num: 43 done: False
______________________
Step:  4240
Pretraining Loss:  tensor(0.3678, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: 0.0 service_time: 950 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: -0.048701298701298704 service_time: 1609 s_time: 30 penalty: 0 agent_num: 11 done: False
______________________
id: 52 reward: 0.0016233766233766235 service_time: 1244 s_time: -2 penalty: 0 agent_num: 22 done: False
______________________
id: 50 reward: -0.037337662337662336 service_time: 2472 s_time: 46 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: 0.0 service_time: 1504 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 49 reward: 0.039285714285714285 service_time: 1399 s_time: -44 penalty: 0 agent_num: 20 done: False
______________________
id: 51 reward: -0.1063664596273292 service_time: 2745 s_time: 137 penalty: 0 agent_num: 23 done: False
______________________
id: 44 reward: -0.027930402930402932 service_time: 1289 s_time: 61 penalty: 0 agent_num: 39 done: False
______________________
id: 54 reward: 0.0 service_time: 2860 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 55 reward: -0.006211180124223602 service_time: 2540 s_time: 16 penalty: 0 agent_num: 46 done: False
______________________
id: 40 reward: -0.007142857142857143 service_time: 2813 s_time: 14 penalty: 0 agent_num: 35 done: False
______________________
id: 43 reward: 0.0005252100840336134 service_time: 1905 s_time: -1 penalty: 0 agent_num: 34 done: False
______________________
id: 53 reward: -0.01916376306620209 service_time: 2457 s_time: 44 penalty: 0 agent_num: 41 done: False
______________________
id: 42 reward: -0.056216931216931214 service_time: 2517 s_time: 85 penalty: 0 agent_num: 27 done: False
______________________
id: 46 reward: -0.010382059800664452 service_time: 1639 s_time: 25 penalty: 0 agent_num: 43 done: False
______________________
id: 48 reward: -0.013198757763975156 service_time: 2868 s_time: 34 penalty: 0 agent_num: 46 done: False
______________________
Step:  4256
Pretraining Loss:  tensor(0.3751, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.09415584415584416 service_time: 1667 s_time: 58 penalty: 0 agent_num: 11 done: False
______________________
id: 45 reward: -0.008928571428571428 service_time: 955 s_time: 5 penalty: 0 agent_num: 10 done: False
______________________
id: 47 reward: 0.0 service_time: 1504 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 50 reward: 0.0 service_time: 2472 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 52 reward: -0.03409090909090909 service_time: 1286 s_time: 42 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: -0.024844720496894408 service_time: 2777 s_time: 32 penalty: 0 agent_num: 23 done: False
______________________
id: 40 reward: -0.0413265306122449 service_time: 2894 s_time: 81 penalty: 0 agent_num: 35 done: False
______________________
id: 44 reward: 0.0009157509157509158 service_time: 1287 s_time: -2 penalty: 0 agent_num: 39 done: False
______________________
id: 43 reward: -0.02153361344537815 service_time: 1946 s_time: 41 penalty: 0 agent_num: 34 done: False
______________________
id: 49 reward: 0.0 service_time: 1399 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 54 reward: -0.015926640926640926 service_time: 2893 s_time: 33 penalty: 0 agent_num: 37 done: False
______________________
id: 55 reward: -0.008928571428571428 service_time: 2563 s_time: 23 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: -0.004355400696864111 service_time: 2467 s_time: 10 penalty: 0 agent_num: 41 done: False
______________________
id: 42 reward: -0.06084656084656084 service_time: 2609 s_time: 92 penalty: 0 agent_num: 27 done: False
______________________
id: 48 reward: -0.008152173913043478 service_time: 2889 s_time: 21 penalty: 0 agent_num: 46 done: False
______________________
id: 46 reward: -0.010382059800664452 service_time: 1664 s_time: 25 penalty: 0 agent_num: 43 done: False
______________________
Step:  4272
Pretraining Loss:  tensor(0.3721, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: 0.0035714285714285713 service_time: 953 s_time: -2 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: 0.0 service_time: 1667 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: -0.016964285714285713 service_time: 1523 s_time: 19 penalty: 0 agent_num: 20 done: False
______________________
id: 49 reward: 0.0 service_time: 1399 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 50 reward: -0.015422077922077922 service_time: 2491 s_time: 19 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: 0.03493788819875776 service_time: 2732 s_time: -45 penalty: 0 agent_num: 23 done: False
______________________
id: 52 reward: -0.040584415584415584 service_time: 1336 s_time: 50 penalty: 0 agent_num: 22 done: False
______________________
id: 54 reward: 0.0014478764478764478 service_time: 2890 s_time: -3 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: 0.002613240418118467 service_time: 2461 s_time: -6 penalty: 0 agent_num: 41 done: False
______________________
id: 43 reward: -0.02100840336134454 service_time: 1986 s_time: 40 penalty: 0 agent_num: 34 done: False
______________________
id: 55 reward: 0.0 service_time: 2563 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 44 reward: -0.033424908424908424 service_time: 1360 s_time: 73 penalty: 0 agent_num: 39 done: False
______________________
id: 40 reward: -0.004081632653061225 service_time: 2902 s_time: 8 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.01591614906832298 service_time: 2930 s_time: 41 penalty: 0 agent_num: 46 done: False
______________________
id: 46 reward: 0.0033222591362126247 service_time: 1656 s_time: -8 penalty: 0 agent_num: 43 done: False
______________________
id: 42 reward: -0.12764550264550265 service_time: 2802 s_time: 193 penalty: 0 agent_num: 27 done: False
______________________
Step:  4288
Pretraining Loss:  tensor(0.3621, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: 0.0 service_time: 953 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: 0.0 service_time: 1667 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: 0.0 service_time: 1523 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 50 reward: -0.022727272727272728 service_time: 2519 s_time: 28 penalty: 0 agent_num: 22 done: False
______________________
id: 52 reward: -0.024350649350649352 service_time: 1366 s_time: 30 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: -0.020186335403726708 service_time: 2758 s_time: 26 penalty: 0 agent_num: 23 done: False
______________________
id: 49 reward: -0.025892857142857145 service_time: 1428 s_time: 29 penalty: 0 agent_num: 20 done: False
______________________
id: 40 reward: -0.01989795918367347 service_time: 2941 s_time: 39 penalty: 0 agent_num: 35 done: False
______________________
id: 46 reward: -0.006229235880398671 service_time: 1671 s_time: 15 penalty: 0 agent_num: 43 done: False
______________________
id: 43 reward: 0.0 service_time: 1986 s_time: 0 penalty: 0 agent_num: 34 done: False
______________________
id: 55 reward: -0.03183229813664596 service_time: 2645 s_time: 82 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: -0.024390243902439025 service_time: 2517 s_time: 56 penalty: 0 agent_num: 41 done: False
______________________
id: 48 reward: -0.0019409937888198758 service_time: 2935 s_time: 5 penalty: 0 agent_num: 46 done: False
______________________
id: 44 reward: 0.0013736263736263737 service_time: 1357 s_time: -3 penalty: 0 agent_num: 39 done: False
______________________
id: 54 reward: -0.032818532818532815 service_time: 2958 s_time: 68 penalty: 0 agent_num: 37 done: False
______________________
id: 42 reward: -0.05291005291005291 service_time: 2882 s_time: 80 penalty: 0 agent_num: 27 done: False
______________________
Step:  4304
Pretraining Loss:  tensor(0.3508, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: -0.0875 service_time: 1002 s_time: 49 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: -0.03571428571428571 service_time: 1689 s_time: 22 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: -0.04642857142857143 service_time: 1480 s_time: 52 penalty: 0 agent_num: 20 done: False
______________________
id: 50 reward: 0.0 service_time: 2519 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: -0.024107142857142858 service_time: 1550 s_time: 27 penalty: 0 agent_num: 20 done: False
______________________
id: 52 reward: 0.028409090909090908 service_time: 1331 s_time: -35 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: -0.03493788819875776 service_time: 2803 s_time: 45 penalty: 0 agent_num: 23 done: False
______________________
id: 54 reward: -0.020752895752895753 service_time: 3001 s_time: 43 penalty: 0 agent_num: 37 done: False
______________________
id: 43 reward: -0.022058823529411766 service_time: 2028 s_time: 42 penalty: 0 agent_num: 34 done: False
______________________
id: 55 reward: -0.008928571428571428 service_time: 2668 s_time: 23 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: -0.018728222996515678 service_time: 2560 s_time: 43 penalty: 0 agent_num: 41 done: False
______________________
id: 44 reward: -0.024725274725274724 service_time: 1411 s_time: 54 penalty: 0 agent_num: 39 done: False
______________________
id: 46 reward: -0.014950166112956811 service_time: 1707 s_time: 36 penalty: 0 agent_num: 43 done: False
______________________
id: 48 reward: 0.0011645962732919255 service_time: 2932 s_time: -3 penalty: 0 agent_num: 46 done: False
______________________
id: 40 reward: -0.012244897959183673 service_time: 2965 s_time: 24 penalty: 0 agent_num: 35 done: False
______________________
id: 42 reward: -0.03968253968253968 service_time: 2942 s_time: 60 penalty: 0 agent_num: 27 done: False
______________________
Step:  4320
Pretraining Loss:  tensor(0.3412, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: 0.0 service_time: 1002 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: -0.12987012987012986 service_time: 1769 s_time: 80 penalty: 0 agent_num: 11 done: False
______________________
id: 52 reward: -0.022727272727272728 service_time: 1359 s_time: 28 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: 0.0 service_time: 1550 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 50 reward: 0.0 service_time: 2519 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: -0.029464285714285714 service_time: 1513 s_time: 33 penalty: 0 agent_num: 20 done: False
______________________
id: 51 reward: 0.002329192546583851 service_time: 2800 s_time: -3 penalty: 0 agent_num: 23 done: False
______________________
id: 43 reward: -0.01050420168067227 service_time: 2048 s_time: 20 penalty: 0 agent_num: 34 done: False
______________________
id: 40 reward: -0.011224489795918367 service_time: 2987 s_time: 22 penalty: 0 agent_num: 35 done: False
______________________
id: 46 reward: -0.010382059800664452 service_time: 1732 s_time: 25 penalty: 0 agent_num: 43 done: False
______________________
id: 55 reward: -0.006987577639751553 service_time: 2686 s_time: 18 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: -0.017421602787456445 service_time: 2600 s_time: 40 penalty: 0 agent_num: 41 done: False
______________________
id: 48 reward: -0.01436335403726708 service_time: 2969 s_time: 37 penalty: 0 agent_num: 46 done: False
______________________
id: 54 reward: -0.013513513513513514 service_time: 3029 s_time: 28 penalty: 0 agent_num: 37 done: False
______________________
id: 44 reward: -0.007326007326007326 service_time: 1427 s_time: 16 penalty: 0 agent_num: 39 done: False
______________________
id: 42 reward: 0.032407407407407406 service_time: 2893 s_time: -49 penalty: 0 agent_num: 27 done: False
______________________
Step:  4336
Pretraining Loss:  tensor(0.3427, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: 0.0 service_time: 1769 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 45 reward: 0.0 service_time: 1002 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 52 reward: -0.05519480519480519 service_time: 1427 s_time: 68 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: -0.00625 service_time: 1557 s_time: 7 penalty: 0 agent_num: 20 done: False
______________________
id: 50 reward: 0.0 service_time: 2519 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: -0.025892857142857145 service_time: 1542 s_time: 29 penalty: 0 agent_num: 20 done: False
______________________
id: 51 reward: 0.016304347826086956 service_time: 2779 s_time: -21 penalty: 0 agent_num: 23 done: False
______________________
id: 43 reward: -0.003676470588235294 service_time: 2055 s_time: 7 penalty: 0 agent_num: 34 done: False
______________________
id: 54 reward: -0.009652509652509652 service_time: 3049 s_time: 20 penalty: 0 agent_num: 37 done: False
______________________
id: 46 reward: -0.008305647840531562 service_time: 1752 s_time: 20 penalty: 0 agent_num: 43 done: False
______________________
id: 40 reward: -0.01173469387755102 service_time: 3010 s_time: 23 penalty: 0 agent_num: 35 done: False
______________________
id: 53 reward: -0.012195121951219513 service_time: 2628 s_time: 28 penalty: 0 agent_num: 41 done: False
______________________
id: 44 reward: -0.011446886446886446 service_time: 1452 s_time: 25 penalty: 0 agent_num: 39 done: False
______________________
id: 48 reward: -0.01281055900621118 service_time: 3002 s_time: 33 penalty: 0 agent_num: 46 done: False
______________________
id: 55 reward: -0.01591614906832298 service_time: 2727 s_time: 41 penalty: 0 agent_num: 46 done: False
______________________
id: 42 reward: -0.06018518518518518 service_time: 2984 s_time: 91 penalty: 0 agent_num: 27 done: False
______________________
Step:  4352
Pretraining Loss:  tensor(0.3081, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: -0.06964285714285715 service_time: 1041 s_time: 39 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: 0.0 service_time: 1769 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 47 reward: 0.0008928571428571428 service_time: 1556 s_time: -1 penalty: 0 agent_num: 20 done: False
______________________
id: 52 reward: -0.025162337662337664 service_time: 1458 s_time: 31 penalty: 0 agent_num: 22 done: False
______________________
id: 50 reward: -0.06412337662337662 service_time: 2598 s_time: 79 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: 0.0 service_time: 1542 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 51 reward: -0.040372670807453416 service_time: 2831 s_time: 52 penalty: 0 agent_num: 23 done: False
______________________
id: 43 reward: 0.0 service_time: 2055 s_time: 0 penalty: 0 agent_num: 34 done: False
______________________
id: 44 reward: -0.019688644688644688 service_time: 1495 s_time: 43 penalty: 0 agent_num: 39 done: False
______________________
id: 40 reward: -0.007653061224489796 service_time: 3025 s_time: 15 penalty: 0 agent_num: 35 done: False
______________________
id: 55 reward: -0.007763975155279503 service_time: 2747 s_time: 20 penalty: 0 agent_num: 46 done: False
______________________
id: 48 reward: -0.002717391304347826 service_time: 3009 s_time: 7 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: -0.006097560975609756 service_time: 2642 s_time: 14 penalty: 0 agent_num: 41 done: False
______________________
id: 46 reward: -0.014950166112956811 service_time: 1788 s_time: 36 penalty: 0 agent_num: 43 done: False
______________________
id: 54 reward: 0.0 service_time: 3049 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 42 reward: -0.009259259259259259 service_time: 2998 s_time: 14 penalty: 0 agent_num: 27 done: False
______________________
Step:  4368
Pretraining Loss:  tensor(0.3410, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: -0.18506493506493507 service_time: 1883 s_time: 114 penalty: 0 agent_num: 11 done: False
______________________
id: 45 reward: -0.12321428571428572 service_time: 1110 s_time: 69 penalty: 0 agent_num: 10 done: False
______________________
id: 50 reward: 0.0008116883116883117 service_time: 2597 s_time: -1 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: -0.06160714285714286 service_time: 1611 s_time: 69 penalty: 0 agent_num: 20 done: False
______________________
id: 47 reward: -0.04196428571428571 service_time: 1603 s_time: 47 penalty: 0 agent_num: 20 done: False
______________________
id: 52 reward: -0.1444805194805195 service_time: 1636 s_time: 178 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: -0.027950310559006212 service_time: 2867 s_time: 36 penalty: 0 agent_num: 23 done: False
______________________
id: 43 reward: -0.03623949579831933 service_time: 2124 s_time: 69 penalty: 0 agent_num: 34 done: False
______________________
id: 46 reward: -0.011212624584717609 service_time: 1815 s_time: 27 penalty: 0 agent_num: 43 done: False
______________________
id: 54 reward: -0.020752895752895753 service_time: 3092 s_time: 43 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: -0.007404181184668989 service_time: 2659 s_time: 17 penalty: 0 agent_num: 41 done: False
______________________
id: 44 reward: -0.01510989010989011 service_time: 1528 s_time: 33 penalty: 0 agent_num: 39 done: False
______________________
id: 40 reward: -0.018367346938775512 service_time: 3061 s_time: 36 penalty: 0 agent_num: 35 done: False
______________________
id: 55 reward: 0.0 service_time: 2747 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 48 reward: -0.002717391304347826 service_time: 3016 s_time: 7 penalty: 0 agent_num: 46 done: False
______________________
id: 42 reward: 0.052248677248677246 service_time: 2919 s_time: -79 penalty: 0 agent_num: 27 done: False
______________________
Step:  4384
Pretraining Loss:  tensor(0.3342, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: 0.09253246753246754 service_time: 1826 s_time: -57 penalty: 0 agent_num: 11 done: False
______________________
id: 45 reward: 0.0 service_time: 1110 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 50 reward: -0.11931818181818182 service_time: 2744 s_time: 147 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: 0.011607142857142858 service_time: 1598 s_time: -13 penalty: 0 agent_num: 20 done: False
______________________
id: 47 reward: 0.0 service_time: 1603 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 51 reward: -0.023291925465838508 service_time: 2897 s_time: 30 penalty: 0 agent_num: 23 done: False
______________________
id: 43 reward: -0.01523109243697479 service_time: 2153 s_time: 29 penalty: 0 agent_num: 34 done: False
______________________
id: 52 reward: 0.00487012987012987 service_time: 1630 s_time: -6 penalty: 0 agent_num: 22 done: False
______________________
id: 53 reward: -0.024390243902439025 service_time: 2715 s_time: 56 penalty: 0 agent_num: 41 done: False
______________________
id: 44 reward: 0.0009157509157509158 service_time: 1526 s_time: -2 penalty: 0 agent_num: 39 done: False
______________________
id: 55 reward: -0.01358695652173913 service_time: 2782 s_time: 35 penalty: 0 agent_num: 46 done: False
______________________
id: 42 reward: 0.0006613756613756613 service_time: 2918 s_time: -1 penalty: 0 agent_num: 27 done: False
______________________
id: 46 reward: -0.01287375415282392 service_time: 1846 s_time: 31 penalty: 0 agent_num: 43 done: False
______________________
id: 48 reward: -0.008152173913043478 service_time: 3037 s_time: 21 penalty: 0 agent_num: 46 done: False
______________________
id: 40 reward: -0.008673469387755102 service_time: 3078 s_time: 17 penalty: 0 agent_num: 35 done: False
______________________
id: 54 reward: -0.019787644787644786 service_time: 3133 s_time: 41 penalty: 0 agent_num: 37 done: False
______________________
Step:  4400
Pretraining Loss:  tensor(0.3420, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: 0.0 service_time: 1826 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 45 reward: -0.04107142857142857 service_time: 1133 s_time: 23 penalty: 0 agent_num: 10 done: False
______________________
id: 49 reward: -0.033035714285714286 service_time: 1635 s_time: 37 penalty: 0 agent_num: 20 done: False
______________________
id: 50 reward: -0.027597402597402596 service_time: 2778 s_time: 34 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: 0.0 service_time: 1603 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 51 reward: 0.023291925465838508 service_time: 2867 s_time: -30 penalty: 0 agent_num: 23 done: False
______________________
id: 52 reward: -0.060876623376623376 service_time: 1705 s_time: 75 penalty: 0 agent_num: 22 done: False
______________________
id: 43 reward: -0.005777310924369748 service_time: 2164 s_time: 11 penalty: 0 agent_num: 34 done: False
______________________
id: 46 reward: 0.0029069767441860465 service_time: 1839 s_time: -7 penalty: 0 agent_num: 43 done: False
______________________
id: 42 reward: 0.0496031746031746 service_time: 2843 s_time: -75 penalty: 0 agent_num: 27 done: False
______________________
id: 44 reward: -0.0018315018315018315 service_time: 1530 s_time: 4 penalty: 0 agent_num: 39 done: False
______________________
id: 40 reward: 0.0020408163265306124 service_time: 3074 s_time: -4 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.014751552795031056 service_time: 3075 s_time: 38 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: 0.0039198606271777 service_time: 2706 s_time: -9 penalty: 0 agent_num: 41 done: False
______________________
id: 55 reward: -0.008928571428571428 service_time: 2805 s_time: 23 penalty: 0 agent_num: 46 done: False
______________________
id: 54 reward: -0.0222007722007722 service_time: 3179 s_time: 46 penalty: 0 agent_num: 37 done: False
______________________
Step:  4416
Pretraining Loss:  tensor(0.3230, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: 0.0 service_time: 1133 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: 0.008116883116883116 service_time: 1821 s_time: -5 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: 0.0 service_time: 1635 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 47 reward: -0.03214285714285714 service_time: 1639 s_time: 36 penalty: 0 agent_num: 20 done: False
______________________
id: 50 reward: 0.0016233766233766235 service_time: 2776 s_time: -2 penalty: 0 agent_num: 22 done: False
______________________
id: 42 reward: -0.023148148148148147 service_time: 2878 s_time: 35 penalty: 0 agent_num: 27 done: False
______________________
id: 43 reward: -0.02415966386554622 service_time: 2210 s_time: 46 penalty: 0 agent_num: 34 done: False
______________________
id: 52 reward: -0.010551948051948052 service_time: 1718 s_time: 13 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: -0.04425465838509317 service_time: 2924 s_time: 57 penalty: 0 agent_num: 23 done: False
______________________
id: 44 reward: 0.0 service_time: 1530 s_time: 0 penalty: 0 agent_num: 39 done: False
______________________
id: 53 reward: -0.01524390243902439 service_time: 2741 s_time: 35 penalty: 0 agent_num: 41 done: False
______________________
id: 40 reward: -0.022448979591836733 service_time: 3118 s_time: 44 penalty: 0 agent_num: 35 done: False
______________________
id: 55 reward: 0.0 service_time: 2805 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 46 reward: -0.03239202657807309 service_time: 1917 s_time: 78 penalty: 0 agent_num: 43 done: False
______________________
id: 54 reward: -0.02027027027027027 service_time: 3221 s_time: 42 penalty: 0 agent_num: 37 done: False
______________________
id: 48 reward: -0.009316770186335404 service_time: 3099 s_time: 24 penalty: 0 agent_num: 46 done: False
______________________
Step:  4432
Pretraining Loss:  tensor(0.3498, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: 0.0 service_time: 1821 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 45 reward: -0.044642857142857144 service_time: 1158 s_time: 25 penalty: 0 agent_num: 10 done: False
______________________
id: 49 reward: 0.0 service_time: 1635 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 51 reward: 0.0 service_time: 2924 s_time: 0 penalty: 0 agent_num: 23 done: False
______________________
id: 47 reward: -0.01607142857142857 service_time: 1657 s_time: 18 penalty: 0 agent_num: 20 done: False
______________________
id: 50 reward: -0.07061688311688312 service_time: 2863 s_time: 87 penalty: 0 agent_num: 22 done: False
______________________
id: 52 reward: -0.018668831168831168 service_time: 1741 s_time: 23 penalty: 0 agent_num: 22 done: False
______________________
id: 46 reward: 0.0004152823920265781 service_time: 1916 s_time: -1 penalty: 0 agent_num: 43 done: False
______________________
id: 53 reward: 0.0008710801393728223 service_time: 2739 s_time: -2 penalty: 0 agent_num: 41 done: False
______________________
id: 42 reward: -0.021825396825396824 service_time: 2911 s_time: 33 penalty: 0 agent_num: 27 done: False
______________________
id: 44 reward: -0.035256410256410256 service_time: 1607 s_time: 77 penalty: 0 agent_num: 39 done: False
______________________
id: 43 reward: -0.02415966386554622 service_time: 2256 s_time: 46 penalty: 0 agent_num: 34 done: False
______________________
id: 55 reward: -0.009316770186335404 service_time: 2829 s_time: 24 penalty: 0 agent_num: 46 done: False
______________________
id: 54 reward: 0.002413127413127413 service_time: 3216 s_time: -5 penalty: 0 agent_num: 37 done: False
______________________
id: 48 reward: 0.0 service_time: 3099 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 40 reward: -0.023979591836734693 service_time: 3165 s_time: 47 penalty: 0 agent_num: 35 done: False
______________________
Step:  4448
Pretraining Loss:  tensor(0.3162, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: 0.048214285714285716 service_time: 1131 s_time: -27 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: -0.037337662337662336 service_time: 1844 s_time: 23 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: 0.0008928571428571428 service_time: 1634 s_time: -1 penalty: 0 agent_num: 20 done: False
______________________
id: 50 reward: 0.003246753246753247 service_time: 2859 s_time: -4 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: -0.026785714285714284 service_time: 1687 s_time: 30 penalty: 0 agent_num: 20 done: False
______________________
id: 51 reward: -0.08074534161490683 service_time: 3028 s_time: 104 penalty: 0 agent_num: 23 done: False
______________________
id: 43 reward: 0.0010504201680672268 service_time: 2254 s_time: -2 penalty: 0 agent_num: 34 done: False
______________________
id: 52 reward: 0.006493506493506494 service_time: 1733 s_time: -8 penalty: 0 agent_num: 22 done: False
______________________
id: 53 reward: -0.014372822299651568 service_time: 2772 s_time: 33 penalty: 0 agent_num: 41 done: False
______________________
id: 42 reward: 0.02447089947089947 service_time: 2874 s_time: -37 penalty: 0 agent_num: 27 done: False
______________________
id: 55 reward: -0.017080745341614908 service_time: 2873 s_time: 44 penalty: 0 agent_num: 46 done: False
______________________
id: 40 reward: -0.012244897959183673 service_time: 3189 s_time: 24 penalty: 0 agent_num: 35 done: False
______________________
id: 46 reward: -0.0303156146179402 service_time: 1989 s_time: 73 penalty: 0 agent_num: 43 done: False
______________________
id: 54 reward: -0.04005791505791506 service_time: 3299 s_time: 83 penalty: 0 agent_num: 37 done: False
______________________
id: 44 reward: -0.0173992673992674 service_time: 1645 s_time: 38 penalty: 0 agent_num: 39 done: False
______________________
id: 48 reward: -0.022127329192546584 service_time: 3156 s_time: 57 penalty: 0 agent_num: 46 done: False
______________________
Step:  4464
Pretraining Loss:  tensor(0.3172, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: -0.08392857142857142 service_time: 1178 s_time: 47 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: -0.21915584415584416 service_time: 1979 s_time: 135 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: -0.05714285714285714 service_time: 1698 s_time: 64 penalty: 0 agent_num: 20 done: False
______________________
id: 50 reward: 0.008928571428571428 service_time: 2848 s_time: -11 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: 0.0 service_time: 1687 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 44 reward: 0.005952380952380952 service_time: 1632 s_time: -13 penalty: 0 agent_num: 39 done: False
______________________
id: 42 reward: 0.001984126984126984 service_time: 2871 s_time: -3 penalty: 0 agent_num: 27 done: False
______________________
id: 52 reward: 0.002435064935064935 service_time: 1730 s_time: -3 penalty: 0 agent_num: 22 done: False
______________________
id: 53 reward: 0.0 service_time: 2772 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 43 reward: -0.029411764705882353 service_time: 2310 s_time: 56 penalty: 0 agent_num: 34 done: False
______________________
id: 51 reward: -0.03183229813664596 service_time: 3069 s_time: 41 penalty: 0 agent_num: 23 done: False
______________________
id: 46 reward: -0.020764119601328904 service_time: 2039 s_time: 50 penalty: 0 agent_num: 43 done: False
______________________
id: 40 reward: -0.018877551020408164 service_time: 3226 s_time: 37 penalty: 0 agent_num: 35 done: False
______________________
id: 55 reward: -0.01591614906832298 service_time: 2914 s_time: 41 penalty: 0 agent_num: 46 done: False
______________________
id: 54 reward: -0.012065637065637066 service_time: 3324 s_time: 25 penalty: 0 agent_num: 37 done: False
______________________
id: 48 reward: -0.011645962732919254 service_time: 3186 s_time: 30 penalty: 0 agent_num: 46 done: False
______________________
Step:  4480
Pretraining Loss:  tensor(0.3329, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: 0.0 service_time: 1178 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: 0.0 service_time: 1979 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: 0.0017857142857142857 service_time: 1696 s_time: -2 penalty: 0 agent_num: 20 done: False
______________________
id: 51 reward: -0.021739130434782608 service_time: 3097 s_time: 28 penalty: 0 agent_num: 23 done: False
______________________
id: 47 reward: -0.008035714285714285 service_time: 1696 s_time: 9 penalty: 0 agent_num: 20 done: False
______________________
id: 50 reward: -0.024350649350649352 service_time: 2878 s_time: 30 penalty: 0 agent_num: 22 done: False
______________________
id: 44 reward: -0.01282051282051282 service_time: 1660 s_time: 28 penalty: 0 agent_num: 39 done: False
______________________
id: 52 reward: 0.030032467532467532 service_time: 1693 s_time: -37 penalty: 0 agent_num: 22 done: False
______________________
id: 42 reward: -0.016534391534391533 service_time: 2896 s_time: 25 penalty: 0 agent_num: 27 done: False
______________________
id: 53 reward: -0.014372822299651568 service_time: 2805 s_time: 33 penalty: 0 agent_num: 41 done: False
______________________
id: 43 reward: -0.015756302521008403 service_time: 2340 s_time: 30 penalty: 0 agent_num: 34 done: False
______________________
id: 54 reward: 0.0014478764478764478 service_time: 3321 s_time: -3 penalty: 0 agent_num: 37 done: False
______________________
id: 46 reward: -0.00872093023255814 service_time: 2060 s_time: 21 penalty: 0 agent_num: 43 done: False
______________________
id: 40 reward: -0.011224489795918367 service_time: 3248 s_time: 22 penalty: 0 agent_num: 35 done: False
______________________
id: 55 reward: 0.0 service_time: 2914 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 48 reward: -0.005046583850931677 service_time: 3199 s_time: 13 penalty: 0 agent_num: 46 done: False
______________________
Step:  4496
Pretraining Loss:  tensor(0.3508, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: -0.05892857142857143 service_time: 1211 s_time: 33 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: 0.0 service_time: 1979 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: -0.10446428571428572 service_time: 1813 s_time: 117 penalty: 0 agent_num: 20 done: False
______________________
id: 47 reward: -0.04107142857142857 service_time: 1742 s_time: 46 penalty: 0 agent_num: 20 done: False
______________________
id: 50 reward: 0.0016233766233766235 service_time: 2876 s_time: -2 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: -0.010869565217391304 service_time: 3111 s_time: 14 penalty: 0 agent_num: 23 done: False
______________________
id: 52 reward: 0.017857142857142856 service_time: 1671 s_time: -22 penalty: 0 agent_num: 22 done: False
______________________
id: 44 reward: -0.011904761904761904 service_time: 1686 s_time: 26 penalty: 0 agent_num: 39 done: False
______________________
id: 42 reward: -0.06481481481481481 service_time: 2994 s_time: 98 penalty: 0 agent_num: 27 done: False
______________________
id: 43 reward: -0.018907563025210083 service_time: 2376 s_time: 36 penalty: 0 agent_num: 34 done: False
______________________
id: 40 reward: -0.01173469387755102 service_time: 3271 s_time: 23 penalty: 0 agent_num: 35 done: False
______________________
id: 53 reward: -0.0195993031358885 service_time: 2850 s_time: 45 penalty: 0 agent_num: 41 done: False
______________________
id: 48 reward: -0.010093167701863354 service_time: 3225 s_time: 26 penalty: 0 agent_num: 46 done: False
______________________
id: 46 reward: -0.010382059800664452 service_time: 2085 s_time: 25 penalty: 0 agent_num: 43 done: False
______________________
id: 54 reward: -0.016891891891891893 service_time: 3356 s_time: 35 penalty: 0 agent_num: 37 done: False
______________________
id: 55 reward: -0.034161490683229816 service_time: 3002 s_time: 88 penalty: 0 agent_num: 46 done: False
______________________
Step:  4512
Pretraining Loss:  tensor(0.3929, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: 0.0 service_time: 1211 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: -0.07142857142857142 service_time: 2023 s_time: 44 penalty: 0 agent_num: 11 done: False
______________________
id: 50 reward: -0.05844155844155844 service_time: 2948 s_time: 72 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: 0.0 service_time: 1742 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 49 reward: 0.0026785714285714286 service_time: 1810 s_time: -3 penalty: 0 agent_num: 20 done: False
______________________
id: 51 reward: -0.05201863354037267 service_time: 3178 s_time: 67 penalty: 0 agent_num: 23 done: False
______________________
id: 42 reward: 0.007936507936507936 service_time: 2982 s_time: -12 penalty: 0 agent_num: 27 done: False
______________________
id: 43 reward: -0.013130252100840336 service_time: 2401 s_time: 25 penalty: 0 agent_num: 34 done: False
______________________
id: 44 reward: -0.006868131868131868 service_time: 1701 s_time: 15 penalty: 0 agent_num: 39 done: False
______________________
id: 52 reward: 0.003246753246753247 service_time: 1667 s_time: -4 penalty: 0 agent_num: 22 done: False
______________________
id: 53 reward: -0.009146341463414634 service_time: 2871 s_time: 21 penalty: 0 agent_num: 41 done: False
______________________
id: 40 reward: -0.0035714285714285713 service_time: 3278 s_time: 7 penalty: 0 agent_num: 35 done: False
______________________
id: 46 reward: 0.0 service_time: 2085 s_time: 0 penalty: 0 agent_num: 43 done: False
______________________
id: 48 reward: -0.008152173913043478 service_time: 3246 s_time: 21 penalty: 0 agent_num: 46 done: False
______________________
id: 54 reward: -0.0019305019305019305 service_time: 3360 s_time: 4 penalty: 0 agent_num: 37 done: False
______________________
id: 55 reward: 0.0 service_time: 3002 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
Step:  4528
Pretraining Loss:  tensor(0.3910, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: 0.0 service_time: 1211 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: 0.0 service_time: 2023 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: 0.0 service_time: 1810 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 50 reward: 0.00487012987012987 service_time: 2942 s_time: -6 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: 0.0017857142857142857 service_time: 1740 s_time: -2 penalty: 0 agent_num: 20 done: False
______________________
id: 52 reward: -0.025974025974025976 service_time: 1699 s_time: 32 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: 0.002329192546583851 service_time: 3175 s_time: -3 penalty: 0 agent_num: 23 done: False
______________________
id: 42 reward: 0.0 service_time: 2982 s_time: 0 penalty: 0 agent_num: 27 done: False
______________________
id: 44 reward: -0.011446886446886446 service_time: 1726 s_time: 25 penalty: 0 agent_num: 39 done: False
______________________
id: 43 reward: -0.014180672268907563 service_time: 2428 s_time: 27 penalty: 0 agent_num: 34 done: False
______________________
id: 54 reward: -0.010617760617760617 service_time: 3382 s_time: 22 penalty: 0 agent_num: 37 done: False
______________________
id: 40 reward: -0.020918367346938777 service_time: 3319 s_time: 41 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.01125776397515528 service_time: 3275 s_time: 29 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: -0.017857142857142856 service_time: 2912 s_time: 41 penalty: 0 agent_num: 41 done: False
______________________
id: 46 reward: -0.023255813953488372 service_time: 2141 s_time: 56 penalty: 0 agent_num: 43 done: False
______________________
id: 55 reward: -0.021739130434782608 service_time: 3058 s_time: 56 penalty: 0 agent_num: 46 done: False
______________________
Step:  4544
Pretraining Loss:  tensor(0.4005, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: -0.20535714285714285 service_time: 1326 s_time: 115 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: 0.0 service_time: 2023 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 51 reward: 0.008540372670807454 service_time: 3164 s_time: -11 penalty: 0 agent_num: 23 done: False
______________________
id: 49 reward: -0.04285714285714286 service_time: 1858 s_time: 48 penalty: 0 agent_num: 20 done: False
______________________
id: 47 reward: -0.014285714285714285 service_time: 1756 s_time: 16 penalty: 0 agent_num: 20 done: False
______________________
id: 50 reward: -0.030032467532467532 service_time: 2979 s_time: 37 penalty: 0 agent_num: 22 done: False
______________________
id: 43 reward: -0.016281512605042018 service_time: 2459 s_time: 31 penalty: 0 agent_num: 34 done: False
______________________
id: 44 reward: -0.021062271062271064 service_time: 1772 s_time: 46 penalty: 0 agent_num: 39 done: False
______________________
id: 52 reward: -0.03165584415584415 service_time: 1738 s_time: 39 penalty: 0 agent_num: 22 done: False
______________________
id: 42 reward: -0.03306878306878307 service_time: 3032 s_time: 50 penalty: 0 agent_num: 27 done: False
______________________
id: 53 reward: -0.004355400696864111 service_time: 2922 s_time: 10 penalty: 0 agent_num: 41 done: False
______________________
id: 40 reward: -0.01479591836734694 service_time: 3348 s_time: 29 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: -0.007375776397515528 service_time: 3294 s_time: 19 penalty: 0 agent_num: 46 done: False
______________________
id: 54 reward: -0.037644787644787646 service_time: 3460 s_time: 78 penalty: 0 agent_num: 37 done: False
______________________
id: 46 reward: -0.011212624584717609 service_time: 2168 s_time: 27 penalty: 0 agent_num: 43 done: False
______________________
id: 55 reward: -0.010093167701863354 service_time: 3084 s_time: 26 penalty: 0 agent_num: 46 done: False
______________________
Step:  4560
Pretraining Loss:  tensor(0.3594, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: 0.08035714285714286 service_time: 1281 s_time: -45 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: 0.0 service_time: 2023 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 52 reward: -0.040584415584415584 service_time: 1788 s_time: 50 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: -0.03482142857142857 service_time: 1795 s_time: 39 penalty: 0 agent_num: 20 done: False
______________________
id: 51 reward: -0.04580745341614907 service_time: 3223 s_time: 59 penalty: 0 agent_num: 23 done: False
______________________
id: 50 reward: -0.017045454545454544 service_time: 3000 s_time: 21 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: 0.00625 service_time: 1851 s_time: -7 penalty: 0 agent_num: 20 done: False
______________________
id: 43 reward: -0.011029411764705883 service_time: 2480 s_time: 21 penalty: 0 agent_num: 34 done: False
______________________
id: 42 reward: -0.0205026455026455 service_time: 3063 s_time: 31 penalty: 0 agent_num: 27 done: False
______________________
id: 40 reward: -0.013775510204081633 service_time: 3375 s_time: 27 penalty: 0 agent_num: 35 done: False
______________________
id: 53 reward: 0.0 service_time: 2922 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 54 reward: -0.017374517374517374 service_time: 3496 s_time: 36 penalty: 0 agent_num: 37 done: False
______________________
id: 44 reward: 0.0086996336996337 service_time: 1753 s_time: -19 penalty: 0 agent_num: 39 done: False
______________________
id: 46 reward: -0.007890365448504983 service_time: 2187 s_time: 19 penalty: 0 agent_num: 43 done: False
______________________
id: 48 reward: -0.010869565217391304 service_time: 3322 s_time: 28 penalty: 0 agent_num: 46 done: False
______________________
id: 55 reward: 0.0007763975155279503 service_time: 3082 s_time: -2 penalty: 0 agent_num: 46 done: False
______________________
Step:  4576
Pretraining Loss:  tensor(0.3278, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: 0.0 service_time: 1281 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: 0.0 service_time: 2023 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 51 reward: 0.0015527950310559005 service_time: 3221 s_time: -2 penalty: 0 agent_num: 23 done: False
______________________
id: 50 reward: -0.017045454545454544 service_time: 3021 s_time: 21 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: -0.017857142857142856 service_time: 1815 s_time: 20 penalty: 0 agent_num: 20 done: False
______________________
id: 49 reward: -0.015178571428571428 service_time: 1868 s_time: 17 penalty: 0 agent_num: 20 done: False
______________________
id: 44 reward: -0.014194139194139194 service_time: 1784 s_time: 31 penalty: 0 agent_num: 39 done: False
______________________
id: 42 reward: -0.03306878306878307 service_time: 3113 s_time: 50 penalty: 0 agent_num: 27 done: False
______________________
id: 43 reward: -0.013130252100840336 service_time: 2505 s_time: 25 penalty: 0 agent_num: 34 done: False
______________________
id: 54 reward: 0.002413127413127413 service_time: 3491 s_time: -5 penalty: 0 agent_num: 37 done: False
______________________
id: 52 reward: 0.00487012987012987 service_time: 1782 s_time: -6 penalty: 0 agent_num: 22 done: False
______________________
id: 48 reward: -0.011645962732919254 service_time: 3352 s_time: 30 penalty: 0 agent_num: 46 done: False
______________________
id: 46 reward: -0.005813953488372093 service_time: 2201 s_time: 14 penalty: 0 agent_num: 43 done: False
______________________
id: 53 reward: -0.012630662020905924 service_time: 2951 s_time: 29 penalty: 0 agent_num: 41 done: False
______________________
id: 40 reward: 0.0005102040816326531 service_time: 3374 s_time: -1 penalty: 0 agent_num: 35 done: False
______________________
id: 55 reward: -0.02562111801242236 service_time: 3148 s_time: 66 penalty: 0 agent_num: 46 done: False
______________________
Step:  4592
Pretraining Loss:  tensor(0.3018, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: 0.0 service_time: 1281 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: -0.1038961038961039 service_time: 2087 s_time: 64 penalty: 0 agent_num: 11 done: False
______________________
id: 51 reward: -0.036490683229813664 service_time: 3268 s_time: 47 penalty: 0 agent_num: 23 done: False
______________________
id: 47 reward: 0.0 service_time: 1815 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 50 reward: -0.0633116883116883 service_time: 3099 s_time: 78 penalty: 0 agent_num: 22 done: False
______________________
id: 42 reward: -0.046957671957671955 service_time: 3184 s_time: 71 penalty: 0 agent_num: 27 done: False
______________________
id: 52 reward: -0.07142857142857142 service_time: 1870 s_time: 88 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: -0.10535714285714286 service_time: 1986 s_time: 118 penalty: 0 agent_num: 20 done: False
______________________
id: 43 reward: -0.0005252100840336134 service_time: 2506 s_time: 1 penalty: 0 agent_num: 34 done: False
______________________
id: 40 reward: -0.02040816326530612 service_time: 3414 s_time: 40 penalty: 0 agent_num: 35 done: False
______________________
id: 44 reward: -0.007326007326007326 service_time: 1800 s_time: 16 penalty: 0 agent_num: 39 done: False
______________________
id: 54 reward: -0.03957528957528957 service_time: 3573 s_time: 82 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: -0.006097560975609756 service_time: 2965 s_time: 14 penalty: 0 agent_num: 41 done: False
______________________
id: 48 reward: -0.011645962732919254 service_time: 3382 s_time: 30 penalty: 0 agent_num: 46 done: False
______________________
id: 46 reward: 0.0 service_time: 2201 s_time: 0 penalty: 0 agent_num: 43 done: False
______________________
id: 55 reward: -0.014751552795031056 service_time: 3186 s_time: 38 penalty: 0 agent_num: 46 done: False
______________________
Step:  4608
Pretraining Loss:  tensor(0.3224, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: 0.0 service_time: 1281 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: -0.08766233766233766 service_time: 2141 s_time: 54 penalty: 0 agent_num: 11 done: False
______________________
id: 51 reward: -0.014751552795031056 service_time: 3287 s_time: 19 penalty: 0 agent_num: 23 done: False
______________________
id: 50 reward: 0.0016233766233766235 service_time: 3097 s_time: -2 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: -0.05178571428571429 service_time: 1873 s_time: 58 penalty: 0 agent_num: 20 done: False
______________________
id: 49 reward: 0.07321428571428572 service_time: 1904 s_time: -82 penalty: 0 agent_num: 20 done: False
______________________
id: 44 reward: -0.009157509157509158 service_time: 1820 s_time: 20 penalty: 0 agent_num: 39 done: False
______________________
id: 52 reward: -0.030032467532467532 service_time: 1907 s_time: 37 penalty: 0 agent_num: 22 done: False
______________________
id: 43 reward: -0.031512605042016806 service_time: 2566 s_time: 60 penalty: 0 agent_num: 34 done: False
______________________
id: 42 reward: -0.047619047619047616 service_time: 3256 s_time: 72 penalty: 0 agent_num: 27 done: False
______________________
id: 40 reward: -0.013265306122448979 service_time: 3440 s_time: 26 penalty: 0 agent_num: 35 done: False
______________________
id: 53 reward: 0.0 service_time: 2965 s_time: 0 penalty: 0 agent_num: 41 done: False
______________________
id: 48 reward: -0.01125776397515528 service_time: 3411 s_time: 29 penalty: 0 agent_num: 46 done: False
______________________
id: 54 reward: -0.008204633204633204 service_time: 3590 s_time: 17 penalty: 0 agent_num: 37 done: False
______________________
id: 55 reward: -0.006211180124223602 service_time: 3202 s_time: 16 penalty: 0 agent_num: 46 done: False
______________________
id: 46 reward: -0.007475083056478406 service_time: 2219 s_time: 18 penalty: 0 agent_num: 43 done: False
______________________
Step:  4624
Pretraining Loss:  tensor(0.3312, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: -0.13392857142857142 service_time: 1356 s_time: 75 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: 0.0 service_time: 2141 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: 0.0125 service_time: 1890 s_time: -14 penalty: 0 agent_num: 20 done: False
______________________
id: 50 reward: -0.02922077922077922 service_time: 3133 s_time: 36 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: -0.0015527950310559005 service_time: 3289 s_time: 2 penalty: 0 agent_num: 23 done: False
______________________
id: 47 reward: -0.0008928571428571428 service_time: 1874 s_time: 1 penalty: 0 agent_num: 20 done: False
______________________
id: 52 reward: -0.07142857142857142 service_time: 1995 s_time: 88 penalty: 0 agent_num: 22 done: False
______________________
id: 42 reward: 0.005291005291005291 service_time: 3248 s_time: -8 penalty: 0 agent_num: 27 done: False
______________________
id: 44 reward: -0.008241758241758242 service_time: 1838 s_time: 18 penalty: 0 agent_num: 39 done: False
______________________
id: 43 reward: -0.01838235294117647 service_time: 2601 s_time: 35 penalty: 0 agent_num: 34 done: False
______________________
id: 40 reward: -0.015816326530612244 service_time: 3471 s_time: 31 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: 0.0 service_time: 3411 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 54 reward: -0.006756756756756757 service_time: 3604 s_time: 14 penalty: 0 agent_num: 37 done: False
______________________
id: 53 reward: -0.028745644599303136 service_time: 3031 s_time: 66 penalty: 0 agent_num: 41 done: False
______________________
id: 55 reward: 0.0 service_time: 3202 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 46 reward: -0.013704318936877076 service_time: 2252 s_time: 33 penalty: 0 agent_num: 43 done: False
______________________
Step:  4640
Pretraining Loss:  tensor(0.3304, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: -0.05178571428571429 service_time: 1385 s_time: 29 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: -0.027597402597402596 service_time: 2158 s_time: 17 penalty: 0 agent_num: 11 done: False
______________________
id: 51 reward: 0.0 service_time: 3289 s_time: 0 penalty: 0 agent_num: 23 done: False
______________________
id: 52 reward: -0.05357142857142857 service_time: 2061 s_time: 66 penalty: 0 agent_num: 22 done: False
______________________
id: 49 reward: -0.06696428571428571 service_time: 1965 s_time: 75 penalty: 0 agent_num: 20 done: False
______________________
id: 47 reward: 0.0008928571428571428 service_time: 1873 s_time: -1 penalty: 0 agent_num: 20 done: False
______________________
id: 50 reward: -0.10064935064935066 service_time: 3257 s_time: 124 penalty: 0 agent_num: 22 done: False
______________________
id: 40 reward: -0.00816326530612245 service_time: 3487 s_time: 16 penalty: 0 agent_num: 35 done: False
______________________
id: 42 reward: -0.022486772486772486 service_time: 3282 s_time: 34 penalty: 0 agent_num: 27 done: False
______________________
id: 44 reward: 0.0022893772893772895 service_time: 1833 s_time: -5 penalty: 0 agent_num: 39 done: False
______________________
id: 43 reward: -0.01365546218487395 service_time: 2627 s_time: 26 penalty: 0 agent_num: 34 done: False
______________________
id: 48 reward: -0.017080745341614908 service_time: 3455 s_time: 44 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: -0.008275261324041812 service_time: 3050 s_time: 19 penalty: 0 agent_num: 41 done: False
______________________
id: 54 reward: -0.006274131274131274 service_time: 3617 s_time: 13 penalty: 0 agent_num: 37 done: False
______________________
id: 55 reward: -0.013975155279503106 service_time: 3238 s_time: 36 penalty: 0 agent_num: 46 done: False
______________________
id: 46 reward: -0.01951827242524917 service_time: 2299 s_time: 47 penalty: 0 agent_num: 43 done: False
______________________
Step:  4656
Pretraining Loss:  tensor(0.3268, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: 0.0 service_time: 1385 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: 0.0 service_time: 2158 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: 0.02142857142857143 service_time: 1941 s_time: -24 penalty: 0 agent_num: 20 done: False
______________________
id: 51 reward: 0.0 service_time: 3289 s_time: 0 penalty: 0 agent_num: 23 done: False
______________________
id: 47 reward: -0.019642857142857142 service_time: 1895 s_time: 22 penalty: 0 agent_num: 20 done: False
______________________
id: 50 reward: -0.07305194805194805 service_time: 3347 s_time: 90 penalty: 0 agent_num: 22 done: False
______________________
id: 42 reward: -0.016534391534391533 service_time: 3307 s_time: 25 penalty: 0 agent_num: 27 done: False
______________________
id: 52 reward: 0.0 service_time: 2061 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 44 reward: -0.019230769230769232 service_time: 1875 s_time: 42 penalty: 0 agent_num: 39 done: False
______________________
id: 40 reward: -0.0035714285714285713 service_time: 3494 s_time: 7 penalty: 0 agent_num: 35 done: False
______________________
id: 48 reward: 0.0 service_time: 3455 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 43 reward: -0.01365546218487395 service_time: 2653 s_time: 26 penalty: 0 agent_num: 34 done: False
______________________
id: 54 reward: -0.019787644787644786 service_time: 3658 s_time: 41 penalty: 0 agent_num: 37 done: False
______________________
id: 55 reward: -0.013198757763975156 service_time: 3272 s_time: 34 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: -0.010452961672473868 service_time: 3074 s_time: 24 penalty: 0 agent_num: 41 done: False
______________________
id: 46 reward: -0.02159468438538206 service_time: 2351 s_time: 52 penalty: 0 agent_num: 43 done: False
______________________
Step:  4672
Pretraining Loss:  tensor(0.3129, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: -0.1125 service_time: 1448 s_time: 63 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: 0.0 service_time: 2158 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: 0.0 service_time: 1941 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 51 reward: -0.010869565217391304 service_time: 3303 s_time: 14 penalty: 0 agent_num: 23 done: False
______________________
id: 52 reward: -0.05519480519480519 service_time: 2129 s_time: 68 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: -0.020535714285714286 service_time: 1918 s_time: 23 penalty: 0 agent_num: 20 done: False
______________________
id: 50 reward: -0.007305194805194805 service_time: 3356 s_time: 9 penalty: 0 agent_num: 22 done: False
______________________
id: 42 reward: 0.0 service_time: 3307 s_time: 0 penalty: 0 agent_num: 27 done: False
______________________
id: 40 reward: -0.01989795918367347 service_time: 3533 s_time: 39 penalty: 0 agent_num: 35 done: False
______________________
id: 44 reward: -0.024725274725274724 service_time: 1929 s_time: 54 penalty: 0 agent_num: 39 done: False
______________________
id: 43 reward: 0.0031512605042016808 service_time: 2647 s_time: -6 penalty: 0 agent_num: 34 done: False
______________________
id: 48 reward: -0.016692546583850932 service_time: 3498 s_time: 43 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: -0.01088850174216028 service_time: 3099 s_time: 25 penalty: 0 agent_num: 41 done: False
______________________
id: 54 reward: -0.013513513513513514 service_time: 3686 s_time: 28 penalty: 0 agent_num: 37 done: False
______________________
id: 55 reward: -0.01746894409937888 service_time: 3317 s_time: 45 penalty: 0 agent_num: 46 done: False
______________________
id: 46 reward: -0.015780730897009966 service_time: 2389 s_time: 38 penalty: 0 agent_num: 43 done: False
______________________
Step:  4688
Pretraining Loss:  tensor(0.3200, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: 0.0 service_time: 1448 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: -0.16233766233766234 service_time: 2258 s_time: 100 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: 0.0 service_time: 1941 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 50 reward: -0.027597402597402596 service_time: 3390 s_time: 34 penalty: 0 agent_num: 22 done: False
______________________
id: 52 reward: 0.0016233766233766235 service_time: 2127 s_time: -2 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: -0.052795031055900624 service_time: 3371 s_time: 68 penalty: 0 agent_num: 23 done: False
______________________
id: 42 reward: -0.03835978835978836 service_time: 3365 s_time: 58 penalty: 0 agent_num: 27 done: False
______________________
id: 44 reward: -0.004578754578754579 service_time: 1939 s_time: 10 penalty: 0 agent_num: 39 done: False
______________________
id: 47 reward: -0.020535714285714286 service_time: 1941 s_time: 23 penalty: 0 agent_num: 20 done: False
______________________
id: 43 reward: -0.026785714285714284 service_time: 2698 s_time: 51 penalty: 0 agent_num: 34 done: False
______________________
id: 40 reward: -0.01683673469387755 service_time: 3566 s_time: 33 penalty: 0 agent_num: 35 done: False
______________________
id: 55 reward: 0.002329192546583851 service_time: 3311 s_time: -6 penalty: 0 agent_num: 46 done: False
______________________
id: 48 reward: -0.014751552795031056 service_time: 3536 s_time: 38 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: -0.008710801393728223 service_time: 3119 s_time: 20 penalty: 0 agent_num: 41 done: False
______________________
id: 54 reward: -0.026061776061776062 service_time: 3740 s_time: 54 penalty: 0 agent_num: 37 done: False
______________________
id: 46 reward: -0.01287375415282392 service_time: 2420 s_time: 31 penalty: 0 agent_num: 43 done: False
______________________
Step:  4704
Pretraining Loss:  tensor(0.3292, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: -0.04642857142857143 service_time: 1474 s_time: 26 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: 0.0 service_time: 2258 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: -0.014285714285714285 service_time: 1957 s_time: 16 penalty: 0 agent_num: 20 done: False
______________________
id: 51 reward: 0.0 service_time: 3371 s_time: 0 penalty: 0 agent_num: 23 done: False
______________________
id: 50 reward: 0.06655844155844155 service_time: 3308 s_time: -82 penalty: 0 agent_num: 22 done: False
______________________
id: 52 reward: 0.0 service_time: 2127 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: -0.02142857142857143 service_time: 1965 s_time: 24 penalty: 0 agent_num: 20 done: False
______________________
id: 42 reward: 0.01455026455026455 service_time: 3343 s_time: -22 penalty: 0 agent_num: 27 done: False
______________________
id: 44 reward: -0.012362637362637362 service_time: 1966 s_time: 27 penalty: 0 agent_num: 39 done: False
______________________
id: 40 reward: -0.004081632653061225 service_time: 3574 s_time: 8 penalty: 0 agent_num: 35 done: False
______________________
id: 43 reward: -0.0015756302521008404 service_time: 2701 s_time: 3 penalty: 0 agent_num: 34 done: False
______________________
id: 48 reward: -0.009316770186335404 service_time: 3560 s_time: 24 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: -0.006968641114982578 service_time: 3135 s_time: 16 penalty: 0 agent_num: 41 done: False
______________________
id: 55 reward: -0.020574534161490684 service_time: 3364 s_time: 53 penalty: 0 agent_num: 46 done: False
______________________
id: 54 reward: -0.00916988416988417 service_time: 3759 s_time: 19 penalty: 0 agent_num: 37 done: False
______________________
id: 46 reward: 0.0 service_time: 2420 s_time: 0 penalty: 0 agent_num: 43 done: False
______________________
Step:  4720
Pretraining Loss:  tensor(0.3097, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: -0.03571428571428571 service_time: 1494 s_time: 20 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: 0.0 service_time: 2258 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: -0.09464285714285714 service_time: 2063 s_time: 106 penalty: 0 agent_num: 20 done: False
______________________
id: 50 reward: 0.02353896103896104 service_time: 3279 s_time: -29 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: 0.0 service_time: 3371 s_time: 0 penalty: 0 agent_num: 23 done: False
______________________
id: 52 reward: 0.028409090909090908 service_time: 2092 s_time: -35 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: 0.0 service_time: 1965 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 42 reward: 0.0 service_time: 3343 s_time: 0 penalty: 0 agent_num: 27 done: False
______________________
id: 44 reward: -0.008241758241758242 service_time: 1984 s_time: 18 penalty: 0 agent_num: 39 done: False
______________________
id: 40 reward: -0.007653061224489796 service_time: 3589 s_time: 15 penalty: 0 agent_num: 35 done: False
______________________
id: 53 reward: -0.016114982578397212 service_time: 3172 s_time: 37 penalty: 0 agent_num: 41 done: False
______________________
id: 55 reward: -0.01203416149068323 service_time: 3395 s_time: 31 penalty: 0 agent_num: 46 done: False
______________________
id: 43 reward: -0.03571428571428571 service_time: 2769 s_time: 68 penalty: 0 agent_num: 34 done: False
______________________
id: 48 reward: -0.007375776397515528 service_time: 3579 s_time: 19 penalty: 0 agent_num: 46 done: False
______________________
id: 54 reward: 0.0 service_time: 3759 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 46 reward: -0.01079734219269103 service_time: 2446 s_time: 26 penalty: 0 agent_num: 43 done: False
______________________
Step:  4736
Pretraining Loss:  tensor(0.2929, device='cuda:0', grad_fn=<MeanBackward0>)
id: 41 reward: 0.0 service_time: 2258 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 45 reward: -0.04642857142857143 service_time: 1520 s_time: 26 penalty: 0 agent_num: 10 done: False
______________________
id: 49 reward: 0.027678571428571427 service_time: 2032 s_time: -31 penalty: 0 agent_num: 20 done: False
______________________
id: 50 reward: 0.024350649350649352 service_time: 3249 s_time: -30 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: -0.0007763975155279503 service_time: 3372 s_time: 1 penalty: 0 agent_num: 23 done: False
______________________
id: 52 reward: -0.03165584415584415 service_time: 2131 s_time: 39 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: 0.0 service_time: 1965 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 42 reward: 0.0 service_time: 3343 s_time: 0 penalty: 0 agent_num: 27 done: False
______________________
id: 40 reward: -0.008673469387755102 service_time: 3606 s_time: 17 penalty: 0 agent_num: 35 done: False
______________________
id: 44 reward: -0.014194139194139194 service_time: 2015 s_time: 31 penalty: 0 agent_num: 39 done: False
______________________
id: 43 reward: -0.009453781512605041 service_time: 2787 s_time: 18 penalty: 0 agent_num: 34 done: False
______________________
id: 48 reward: -0.007375776397515528 service_time: 3598 s_time: 19 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: -0.02003484320557491 service_time: 3218 s_time: 46 penalty: 0 agent_num: 41 done: False
______________________
id: 55 reward: -0.008928571428571428 service_time: 3418 s_time: 23 penalty: 0 agent_num: 46 done: False
______________________
id: 54 reward: -0.032818532818532815 service_time: 3827 s_time: 68 penalty: 0 agent_num: 37 done: False
______________________
id: 46 reward: -0.02616279069767442 service_time: 2509 s_time: 63 penalty: 0 agent_num: 43 done: False
______________________
Step:  4752
Pretraining Loss:  tensor(0.3226, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: 0.0017857142857142857 service_time: 1519 s_time: -1 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: 0.0 service_time: 2258 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: -0.019642857142857142 service_time: 2054 s_time: 22 penalty: 0 agent_num: 20 done: False
______________________
id: 51 reward: -0.07919254658385093 service_time: 3474 s_time: 102 penalty: 0 agent_num: 23 done: False
______________________
id: 50 reward: -0.049512987012987016 service_time: 3310 s_time: 61 penalty: 0 agent_num: 22 done: False
______________________
id: 52 reward: 0.00487012987012987 service_time: 2125 s_time: -6 penalty: 0 agent_num: 22 done: False
______________________
id: 42 reward: 0.0 service_time: 3343 s_time: 0 penalty: 0 agent_num: 27 done: False
______________________
id: 47 reward: -0.04107142857142857 service_time: 2011 s_time: 46 penalty: 0 agent_num: 20 done: False
______________________
id: 44 reward: -0.005494505494505495 service_time: 2027 s_time: 12 penalty: 0 agent_num: 39 done: False
______________________
id: 43 reward: -0.014705882352941176 service_time: 2815 s_time: 28 penalty: 0 agent_num: 34 done: False
______________________
id: 40 reward: -0.012755102040816327 service_time: 3631 s_time: 25 penalty: 0 agent_num: 35 done: False
______________________
id: 55 reward: -0.008152173913043478 service_time: 3439 s_time: 21 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: -0.011759581881533102 service_time: 3245 s_time: 27 penalty: 0 agent_num: 41 done: False
______________________
id: 48 reward: -0.008152173913043478 service_time: 3619 s_time: 21 penalty: 0 agent_num: 46 done: False
______________________
id: 54 reward: -0.010617760617760617 service_time: 3849 s_time: 22 penalty: 0 agent_num: 37 done: False
______________________
id: 46 reward: -0.014119601328903655 service_time: 2543 s_time: 34 penalty: 0 agent_num: 43 done: False
______________________
Step:  4768
Pretraining Loss:  tensor(0.3467, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: 0.0 service_time: 1519 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: -0.08928571428571429 service_time: 2313 s_time: 55 penalty: 0 agent_num: 11 done: False
______________________
id: 50 reward: 0.01948051948051948 service_time: 3286 s_time: -24 penalty: 0 agent_num: 22 done: False
______________________
id: 51 reward: 0.06288819875776397 service_time: 3393 s_time: -81 penalty: 0 agent_num: 23 done: False
______________________
id: 49 reward: 0.014285714285714285 service_time: 2038 s_time: -16 penalty: 0 agent_num: 20 done: False
______________________
id: 52 reward: -0.01948051948051948 service_time: 2149 s_time: 24 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: 0.0 service_time: 2011 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 42 reward: 0.011243386243386243 service_time: 3326 s_time: -17 penalty: 0 agent_num: 27 done: False
______________________
id: 40 reward: 0.0 service_time: 3631 s_time: 0 penalty: 0 agent_num: 35 done: False
______________________
id: 44 reward: 0.0 service_time: 2027 s_time: 0 penalty: 0 agent_num: 39 done: False
______________________
id: 48 reward: 0.0 service_time: 3619 s_time: 0 penalty: 0 agent_num: 46 done: False
______________________
id: 53 reward: -0.014372822299651568 service_time: 3278 s_time: 33 penalty: 0 agent_num: 41 done: False
______________________
id: 43 reward: -0.025210084033613446 service_time: 2863 s_time: 48 penalty: 0 agent_num: 34 done: False
______________________
id: 55 reward: -0.006987577639751553 service_time: 3457 s_time: 18 penalty: 0 agent_num: 46 done: False
______________________
id: 54 reward: -0.012065637065637066 service_time: 3874 s_time: 25 penalty: 0 agent_num: 37 done: False
______________________
id: 46 reward: -0.007890365448504983 service_time: 2562 s_time: 19 penalty: 0 agent_num: 43 done: False
______________________
------------------------------------
| time/                 |          |
|    fps                | 8        |
|    iterations         | 300      |
|    time_elapsed       | 538      |
|    total_timesteps    | 4800     |
| train/                |          |
|    entropy_loss       | 0.00111  |
|    explained_variance | -175     |
|    learning_rate      | 1e-05    |
|    n_updates          | 299      |
|    policy_loss        | 0.347    |
|    value_loss         | 0.324    |
------------------------------------
Step:  4784
Pretraining Loss:  tensor(0.3390, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: -0.04285714285714286 service_time: 1543 s_time: 24 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: -0.030844155844155844 service_time: 2332 s_time: 19 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: -0.03482142857142857 service_time: 2077 s_time: 39 penalty: 0 agent_num: 20 done: False
______________________
id: 51 reward: -0.04114906832298137 service_time: 3446 s_time: 53 penalty: 0 agent_num: 23 done: False
______________________
id: 50 reward: 0.010551948051948052 service_time: 3273 s_time: -13 penalty: 0 agent_num: 22 done: False
______________________
id: 52 reward: 0.0 service_time: 2149 s_time: 0 penalty: 0 agent_num: 22 done: False
______________________
id: 42 reward: -0.017195767195767195 service_time: 3352 s_time: 26 penalty: 0 agent_num: 27 done: False
______________________
id: 47 reward: 0.0 service_time: 2011 s_time: 0 penalty: 0 agent_num: 20 done: False
______________________
id: 40 reward: -0.011224489795918367 service_time: 3653 s_time: 22 penalty: 0 agent_num: 35 done: False
______________________
id: 44 reward: -0.015567765567765568 service_time: 2061 s_time: 34 penalty: 0 agent_num: 39 done: False
______________________
id: 55 reward: -0.0034937888198757765 service_time: 3466 s_time: 9 penalty: 0 agent_num: 46 done: False
______________________
id: 43 reward: -0.0021008403361344537 service_time: 2867 s_time: 4 penalty: 0 agent_num: 34 done: False
______________________
id: 53 reward: 0.0008710801393728223 service_time: 3276 s_time: -2 penalty: 0 agent_num: 41 done: False
______________________
id: 46 reward: 0.0 service_time: 2562 s_time: 0 penalty: 0 agent_num: 43 done: False
______________________
id: 54 reward: -0.015926640926640926 service_time: 3907 s_time: 33 penalty: 0 agent_num: 37 done: False
______________________
id: 48 reward: -0.019798136645962732 service_time: 3670 s_time: 51 penalty: 0 agent_num: 46 done: False
______________________
Step:  4800
Pretraining Loss:  tensor(0.3472, device='cuda:0', grad_fn=<MeanBackward0>)
id: 45 reward: 0.0 service_time: 1543 s_time: 0 penalty: 0 agent_num: 10 done: False
______________________
id: 41 reward: 0.0 service_time: 2332 s_time: 0 penalty: 0 agent_num: 11 done: False
______________________
id: 49 reward: -0.05178571428571429 service_time: 2135 s_time: 58 penalty: 0 agent_num: 20 done: False
______________________
id: 51 reward: -0.1545031055900621 service_time: 3645 s_time: 199 penalty: 0 agent_num: 23 done: False
______________________
id: 50 reward: -0.032467532467532464 service_time: 3313 s_time: 40 penalty: 0 agent_num: 22 done: False
______________________
id: 47 reward: -0.026785714285714284 service_time: 2041 s_time: 30 penalty: 0 agent_num: 20 done: False
______________________
id: 52 reward: 0.00487012987012987 service_time: 2143 s_time: -6 penalty: 0 agent_num: 22 done: False
______________________
id: 42 reward: -0.09060846560846561 service_time: 3489 s_time: 137 penalty: 0 agent_num: 27 done: False
______________________
id: 40 reward: -0.02142857142857143 service_time: 3695 s_time: 42 penalty: 0 agent_num: 35 done: False
______________________
id: 44 reward: -0.03021978021978022 service_time: 2127 s_time: 66 penalty: 0 agent_num: 39 done: False
______________________
id: 53 reward: -0.016986062717770034 service_time: 3315 s_time: 39 penalty: 0 agent_num: 41 done: False
______________________
id: 55 reward: -0.006987577639751553 service_time: 3484 s_time: 18 penalty: 0 agent_num: 46 done: False
______________________
id: 43 reward: -0.011554621848739496 service_time: 2889 s_time: 22 penalty: 0 agent_num: 34 done: False
______________________
id: 48 reward: -0.023291925465838508 service_time: 3730 s_time: 60 penalty: 0 agent_num: 46 done: False
______________________
id: 54 reward: 0.0 service_time: 3907 s_time: 0 penalty: 0 agent_num: 37 done: False
______________________
id: 46 reward: -0.01951827242524917 service_time: 2609 s_time: 47 penalty: 0 agent_num: 43 done: False
______________________
Step:  4816
Pretraining Loss:  tensor(0.3451, device='cuda:0', grad_fn=<MeanBackward0>)
